Metadata-Version: 2.1
Name: baserun
Version: 0.5.0
Summary: Tools for testing, debugging, and evaluating LLM features.
Author-email: Adam Ginzberg <adam@baserun.ai>
License: MIT License
        
        Copyright (c) 2023 Mochi Labs, Inc.
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
Project-URL: Homepage, https://baserun.ai
Project-URL: Repository, https://github.com/baserun-ai/baserun-py
Requires-Python: >=3.7.1
Description-Content-Type: text/markdown
License-File: LICENSE

# Baserun

**[Baserun](https://baserun.ai)** is the collaborative workspace for AI teams. Our mission is to simplify the testing, debugging, and evaluation of LLM features to help you get your app production-ready.

## Quick Start

Install `baserun`

```bash
pip install baserun
```

Get your API key from the [Baserun dashboard](https://baserun.ai/settings) and set it as an environment variable:

```bash
export BASERUN_API_KEY="your_api_key_here"
```

Use our pytest plugin and start immediately logging to Baserun. By default all OpenAI completion and chat requests will be logged to Baserun. Logs are aggregated by test.

```python
# test_module.py

import openai

def test_paris_trip():
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        temperature=0.7,
        messages=[
            {
                "role": "user",
                "content": "What are three activities to do in Paris?"
            }
        ],
    )
    
    assert "Eiffel Tower" in response['choices'][0]['message']['content']
```

To run the test and log to baserun:

```bash
pytest --baserun test_module.py
...
========================Baserun========================
Test results available at: https://baserun.ai/runs/<id>
=======================================================
```

## Custom logs

### log
Logs a custom message to Baserun. If Baserun is not initialized, this function will have no effect.

#### Parameters
* message (str): The custom log message to be recorded.
* payload (Union[str, Dict]): The log's additional data, which can be either a string or a dictionary.

```python
import baserun

def test_custom_log():
    ...
    baserun.log("CustomEvent", payload={"key": "value"})
```

## Production monitoring with baserun.trace

### trace
Aggregates a trace of all logs generated by a function call to Baserun. By default all OpenAI completion and chat requests will be logged as part of the trace. If Baserun is not initialized, baserun.trace will have no effect.

#### Parameters
* function (Callable): The function to be traced.
* metadata (Optional[Dict]): Additional metadata to record alongside the traced logs.

### Initialization
Add your BASERUN_API_KEY as an environment variable and then initialize Baserun at the entry point of your application.

```python
import baserun

if env == 'production':
    baserun.init()
```

Then either decorate the function that you would like to trace:

```python
import baserun

@baserun.trace
def get_response():
    ...
```

or wrap the function and optionally pass any additional metadata:
```python
import baserun

def get_response(message):
    ...

traced_get_response = baserun.trace(get_response, {"userId": 123})
traced_get_response(message)
```
