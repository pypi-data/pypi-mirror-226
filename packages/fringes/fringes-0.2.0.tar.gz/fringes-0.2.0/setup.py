# -*- coding: utf-8 -*-
from setuptools import setup

packages = \
['fringes']

package_data = \
{'': ['*']}

install_requires = \
['asdf>=2.14.3,<3.0.0',
 'numba>=0.57.1,<0.58.0',
 'numpy>=1.23.5,<2.0.0',
 'opencv-contrib-python>=4.7.0,<5.0.0',
 'pyyaml>=6.0,<7.0',
 'scikit-image>=0.21.0,<0.22.0',
 'scipy>=1.10.0,<2.0.0',
 'si-prefix>=1.2.2,<2.0.0',
 'sympy>=1.11.1,<2.0.0',
 'toml>=0.10.2,<0.11.0']

setup_kwargs = {
    'name': 'fringes',
    'version': '0.2.0',
    'description': 'Phase shifting algorithms for encoding and decoding sinusoidal fringe patterns.',
    'long_description': '# Fringes\n![PyPI](https://img.shields.io/pypi/v/fringes)\n![GitHub top language](https://img.shields.io/github/languages/top/comimag/fringes)\n![Read the Docs](https://img.shields.io/readthedocs/fringes)\n[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n![PyPI - License](https://img.shields.io/pypi/l/fringes)\n![PyPI - Downloads](https://img.shields.io/pypi/dm/fringes)\n\n<!---\n![GitHub](https://img.shields.io/github/license/comimag/fringes)\n--->\n\nEasy to use tool for generating and analyzing fringe patterns with phase shifting algorithms.\n\n<!---\nAuthor: Christian Kludt\n\n<img src="docs/readme/shift.gif" width="256"/>\n\n## Description\nThis package provides the handy `Fringes` class which handles all the required parameters\nfor configuring fringe pattern sequences\nand provides methods for fringe analysis.\n--->\n\n![Coding Scheme](https://raw.githubusercontent.com/comimag/fringes/develop/docs/readme/coding-scheme.gif)\\\nFigure 1: Phase Shift Coding Scheme.\n\n<!---\nlink to  paper, please cite\n--->\n\n<!---\n### Features\n\n- Generalized Temporal Phase Unwrappting (GTPU)\n- Noise model and Uncertainty Propagation\n- Optimal Coding Strategy\n- Deinterlacing\n- Multiplexing\n- Filtering Phase Maps\n- Remapping\n\n### Background\nMany applications, such as fringe projection [[1]](#1) or fringe reflection (deflectometry) [[2]](#2),\nrequire the ability to encode positional data.\nTo do this, sinusoidal fringe patterns are used to encode the position on the screen (in pixel coordinates)\nat which the camera pixels were looking at during acquisition.\n\n![Coding Scheme](docs/readme/coding-scheme.gif?raw=True)\\\nFigure 1: Phase Shifting Coding Scheme.\n\n- #### Encoding\n  - #### Spatial Modulation\n    <code>I = A + B cos(2&pi;v<sub>i</sub>x - &straightphi;<sub>i</sub>)</code>\n  \n    The x- resp. y-coordinate `ξ` of the screen\n    is normalized into the range `X = [0, 1)` by dividing through the pattern length `L`\n    and used to modulate the radiance in a sinusoidal fringe pattern `I`\n    with offset `A`, amplitude `B` and spatial frequency `v`.\n    An additional phase offset <code>&straightphi;<sub>i</sub></code> may be set,\n    e.g. to let the fringe patterns start with a gray value of zero.\n    There can be `K` sets, with `K` being the number of fringe patterns\n    with different spatial frequency <code>v<sub>i</sub></code>, <code>i &isin; {&Nopf;<sub>0</sub> | i < K}</code>.\n\n  - #### Temporal Modulation\n    <code>I = A + B cos(2&pi;v<sub>i</sub>x - 2&pi;f<sub>i</sub>t - &straightphi;<sub>i</sub>)</code>\n    \n    The patterns are then shifted <code>N<sub>i</sub></code> times\n    with an equidistant phase shift of <code>2&pi;f<sub>i</sub>/N<sub>i</sub></code>.\n    This is equal to sampling over <code>f<sub>i</sub></code> periods\n    with <code>N<sub>i</code> sample points\n    at time steps <code>t = n / N<sub>i</sub></code>, <code>n &isin; {&Nopf;<sub>0</sub> | n < N<sub>i</sub>}</code>.\n\n- #### Decoding\n  - #### Temporal Demodulation\n    <code>&straightphi;<sub>i</sub> &equiv; &phi;<sub>i</sub> mod 2&pi;</code>\\\n    <code>&xi; &equiv; &lambda;<sub>i</sub>&straightphi;<sub>i</sub>/(2&pi;) mod &lambda;<sub>i</sub></code>\\\n    From these shifts, the phase maps <code>&straightphi;<sub>i</sub></code> are determined [[3]](#3).\n    Due to the trigonometric functions used,\n    the global phase <code>&phi;<sub>i</sub> = 2&pi;v<sub>i</sub>x - &straightphi;<sub>0</sub></code>\n    is wrapped into the interval <code>[0, 2 &pi;]</code> with <code>v<sub>i</sub></code> periods.\n    - #### Spatial Demodulation (Phase Unwrapping)\n      To obtain the encoded coordinate <code>&xi;</code>, three tasks must be executed:\n      1. Undo the spatial modulation\n         by finding the correct period order number\n         <code>k<sub>i</sub> &isin; {&Nopf;<sub>0</sub> | k<sub>i</sub> < &lceil;v<sub>i</sub>&rceil;}</code> for each set `i`.\n         The global phase is then estimated to be <code>&phi;<sub>i</sub> = k<sub>i</sub> 2&pi; + &straightphi;<sub>i</sub></code>\\.\n      2. Recover the common independent variables, i.e. the coordinates <code>&xi;<sub>i</sub></code>,\n         by linearly rescaling the global phase map: \n         <code>&xi;<sub>i</sub> = L&phi;<sub>i</sub> / 2&pi;</code>,\n         with `L` being the pattern length (in pixel).\n      3. Fuse the K coordinate maps by weighted averaging:\n         <code>&xi; = &sum;<sub>i</sub>&xi;<sub>i</sub>w<sub>i</sub> / &sum;<sub>i</sub>w<sub>i</sub></code>.\n         To obtain an optimal estimate, use inverse variance weighting,\n        i.e. use the inverse variances of the coordinate maps as the weights for averaging:\n         <code>w<sub>i</sub> = 1 / &sigma;<sub>&straightphi;,i</sub><sup>2</sup></code>,\n         with <code>&sigma;<sub>&straightphi;,i</sub> &prop; B<sub>i</sub> / v<sub>i</sub> / &radic;N<sub>i</sub></code>\n         [[4]](#4).\n      \n      This constitutes the registration, which is a mapping in the same pixel grid as the camera sensor\n      and contains the information where each camera pixel, i.e. each camera sightray, was looking at\n      during the fringe pattern acquisition.\n      Note that in contrast to binary coding schemes, e.g. Gray code,\n      the coordinate is obtained with sub-pixel precision.\n      \n      - #### No Unwrapping\n        If only one set `K = 1` with spatial frequency <code>v &le; 1</code> is used,\n        no unwrapping is required because one period covers the complete coding range.\n        In this case, only the scaling part has to be executed.\n\n      - #### Temporal Phase Unwrapping (TPU)\n        If multiple sets with different spatial frequencies <code>v<sub>i</sub></code> are used\n        and the unambiguous measurement range is larger than the coding range, i.e. <code>UMR &ge; L</code>,\n        the ambiguity of the phase map is resolved by\n        generalized multi-frequency temporal phase unwrapping (GTPU).\n      \n      - #### Spatial Phase Unwrapping (SPU)\n        However, if only one set with `v > 1` is used, or multiple sets but  `UMR < L`,\n        the ambiguous phase <code>&straightphi;</code> is unwrapped\n        analyzing the neighbouring phase values [[5]](#5), [[6]](#6).\n        This only yields a relative phase map, therefore absolute positions are unknown.\n      \n      - #### Fourier-transform method (FTM)\n        In some cases, the phase signal introduced by the object\'s distortion of the fringe pattern\n        can be extracted with a purely spatial analysis by virtue of the Fourier-transform method [[7]](#7), [[8]](#8):\n        The recorded phase consists of a carrier with the spatial frequency `v\'` and the signal\n        (please note that `v\'` denotes the spatial frequency in the recorded (camera) frame,\n        therefore `v` and `v\'` are related by the imaging of the optical system but not identical):\n        <code>&phi; = &phi;<sub>c</sub> + &phi;<sub>s</sub> = 2&pi;v\'x + &straightphi;<sub>0</sub> + &phi;<sub>s</sub></code>.\n        If the offset `A`, the amplitude `B` anf the signal phase <code>&phi;<sub>s</sub></code> vary slowly\n        compared with the variation introduced by the spatial-carrier frequency `v\'`,\n        i.e. the surface is rather smooth and has no sharp edges, and the spatial carrier frequency `v\'` is high enough,\n        i.e. `v >> 1`, their spetra can be separated and therefore filtered in the frequency space.\n        For this purpose, the recorded fringe pattern is Fourier transformed\n        by the use of the two-dimensional fast-Fourier-transform (2DFFT) algorithm - hence the name - \n        and processed in its spatial frequency domain.\n        Here, the Fourier spectra are separated by the carrier frequency `v\'`, cf. Figure 3.\n        We filter out the background variation `A`,\n        select either of the two spectra on the carrier,\n        and translate it by `v\'` on the frequency axis toward the origin.\n        Again using the 2DFFT algorithm, we compute the inverse Fourier-transform.\n        Now we have the signal phase <code>&phi;<sub>s</sub></code> in the imaginary part\n        completely separated from the unwanted amplitude variation `B` in the real part.\n        Subsequently, a spatial phase-unwrapping algorithm may be deployed to remove any remaining phase jumps.\n        This phase unwrapping method is not critical\n        if the signal-to-noise ratio is higher than 10\n        and the gradients of the signal phase <code>&phi;<sub>s</sub></code> are less than <code>&pi;</code> per pixel.\n        Again, this only yields a relative phase map, therefore absolute positions are unknown.\n        \n        <img src="docs/readme/FTM.png" width="320"/>\\\n        Figure 3: From [[7]](#7). In this image, the spatial frequency is denotes as f. (A) Separated Fourier spectra;\n        (B) single spectrum selected and translated to the origin. \n--->\n\n<!---\nIn an alternative formulation, the absolute quantities offset `A` and amplitude `B`\nare replaced by the maximal possible gray value `Imax`\nand the relative quantities exposure (relative average intensity) `β` and visibilty (relative fringe contrast) `V`\n[[9]](#9):\n\n```\nI = A + B * cos(Φ) = Imax * β * (1 + V * cos(Φ))\n```\n\nThe two parameters `β` and `V` describe the phase shifting signal `I`\nindependently of the value range of the light source or camera.\nBoth lie within the interval `[0, 1]` with the additional condition <code>β &le; 1 / (1 + V)</code>;\nelse, the radiance of the light source would be higher than the maximal possible value `Imax`.\nTherefore, the valid values are limited for <code>β &ge; 0.5 </code>.\nThe optimal fringe contrast is achieved for `β = 0.5` and `V = 1`. \n\n<img src="docs/readme/codomain.png" width="480"/>\\\nFigure 2: Fringe pattern as a function of `β` and `V`.\n\nThe advantage of this representation is the normalization of the descriptive parameters `β` and `V`\nand thereby the separation of additive and multiplicative influences.\n\nThe exposure `β` is affected by additional, constant light (not modulating the signal):\n- the maximum brightness of the light source,\n- the exposure time and the aperture setting of the camera,\n- the absorption of optical elements (e.g. filters).\n\nThe visibility `V` of the fringes is influenced by:\n- the maximum contrast of the light source,\n- the modulation transfer function of the optical elements (e.g. the scattering characteristics of the test object),\n- the depth of field and defocus,\n- the resolution of the camera\n(the camera pixel size projected onto the light source acts as a low pass filter, reducing the modulation of the signal).\n--->\n\n<!---\n## Contents\n- [Installation](#installation)\n- [Usage](#usage)\n- [Graphical User Interface](#graphical-user-interface)\n- [Optimal Coding Strategy](#optimal-coding-strategy)\n- [Troubleshooting](#troubleshooting)\n- [License](#license)\n- [Project Status](#project-status)\n- [References](#references)\n--->\n\n## Installation\nYou can install `fringes` directly from [PyPi](https://pypi.org/) via `pip`:\n\n```\npip install fringes\n```\n\n## Usage\nYou instantiate, parameterize and deploy the `Fringes` class:\n\n```python\nimport fringes as frng  # import module\n\nf = frng.Fringes()      # instantiate class\n\nf.glossary              # get glossary\nf.X = 1920              # set width of the fringe patterns\nf.Y = 1080              # set height of the fringe patterns\nf.K = 2                 # set number of sets\nf.N = 4                 # set number of shifts\nf.v = [9, 10]           # set spatial frequencies\nf.T                     # get number of frames\n                            \nI = f.encode()          # encode fringe patterns\nA, B, x = f.decode(I)   # decode fringe patterns\n```\n\n<!---\nf.logger.setLevel("DEBUG")  # set logging level\nYou can change the [logging level](https://docs.python.org/3/library/logging.html#levels) of a `Fringes` instance.\nFor example, changing it to `\'DEBUG\'` gives you verbose feedback on which parameters are changed\nand how long functions take to execute.\n\nAll parameters are accesible by the respective attributes of the `Fringes` instance\n(a glossary of them is obtained by the class attribute `glossary`).\n--->\n\nAll parameters are accesible by the respective attributes of the `Fringes` instance\n(a glossary of them is obtained by the attribute `glossary`).\nThey are implemented as class properties (managed attributes).\nNote that some attributes have subdependencies, hence dependent attributes might change as well.\nCircular dependencies are resolved automatically.\n\n<!---\nThey are implemented as class properties (managed attributes), which are parsed when setting,\nso usually several input types are accepted\n(e.g. `bool`, `int`, `float` for scalars\nand additionally `list`, `tuple`, `ndarray` for arrays).\nNote that some attributes have subdependencies (cf. Figure 3) , hence dependent attributes might change as well.\nCircular dependencies are resolved automatically.\n--->\n\nFor generating the fringe pattern sequence `I`, use the method `encode()`.\\\nIt returns a [NumPy array](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html) \nin videoshape (frames `T`, width `X`, height `Y`, color channels `C`).\n\nFor analyzing (recorded) fringe patterns, use the method `decode()`.\\\nIt returns the Numpy arrays brightness `A`, modulation `B` and coordinate `x`.\n\n<!---\nFor analyzing (recorded) fringe patterns, use the method `decode()`.\nIt will return a [namedtuple](https://docs.python.org/3/library/collections.html#collections.namedtuple), \ncontaining the Numpy arrays brightness `A`, modulation `B` and the coordinates `ξ`,\nall in videoshape.\n\n<img src="docs/readme/interdependencies.svg" width="720"/>\\\nFigure 3: Parameters and their Interdependencies.\n\nEach set (cf. frames in middle column in Figure 1)\nconsists of the following attributes (cf. black box in Figure 3):\n- `N`: number of shifts\n- `l`: wavelength [px]\n- `v`: spatial frequency, i.e. number of periods (per screen length `L`)\n- `f`: temporal frequency, i.e. number of periods to shift over\n\nEach is an array with shape (number of directions `D`, number of sets `K`).\\\nFor example, if <code>N.shape &equiv; (2, 3)</code>, it means that we encode `D = 2` directions with `K = 3` sets each.\n\nChanging `D` or `K` directly, changes the shape of all set attributes.\\\nWhen setting a set attribute with a new shape (`D\'`, `K\'`),\n`D` and `K` are updated as well as the shape of the other set attributes.\\\nIf a set attribute is 1D, then it is stacked to match the number of directions `D`.\\\nIf a set attribute is 0D i.e. a scalar, then all values are simply replaced by the new one.\n\n`l` and `v` are related by `l = L / v`.\nWhen `L` changes, `v` is kept constant and only `l` is changed.\n--->\n\n## Graphical User Interface\nDo you need a GUI? `Fringes` has a sister project that is called `Fringes-GUI`: https://pypi.org/project/fringes-gui/\n\n<!---\n## __Quality Metrics__\n`UMR` denotes the unambiguous measurement range.\nThe coding is only unique within the interval `[0, UMR)`; after that it repeats itself.\nThe `UMR` is derived from `l` and `v`:\n- If <code>l &isin; &Nopf;</code>, <code>UMR = lcm(l<sub>i</sub>)</code> with `lcm` being the least common multiple.\n- Else, if <code>v &isin; &Nopf;</code>,\n  <code>UMR = `L`/ gcd(v<sub>i</sub>)</code> with `gcd` being the greatest common divisor.\n- Else, if <code>l &and; v &isin; &#8474;</code>, `lcm` resp. `gcd` are extended to rational numbers.\n- Else, if <code>l &and; v &isin; &#8477; \\ &#8474;</code>, `l` and `v` are approximated by rational numbers\n  with a fixed length of decimal digits.\n\n`eta` denotes the coding efficiency `L / UMR`. It makes no sense to choose `UMR` much larger than `L`,\nbecause then a significant part of the coding range is not used.\n\n`u` denotes the minimum possible uncertainty of the measurement in pixels.\nIt is based on the phase noise model from [[4]](#4)\nand propagated through the unwrapping process and the phase fusion.\nIt is influenced by the fringe attributes\n- `M`: number of averaged intensity samples,\n- `N`: number of phase shifts,\n- `l`: wavelengths of the fringes,\n- `B`: measured amplitude\n\nand the measurement hardware-specific noise sources [[10]](#10), [[11]](#11)\n- `quant`: quantization noise of the light source or camera,\n- `dark`: dark noise of the used camera,\n- `shot`: photon noise of light itself,\n- `gain`: system gain of the used camera.\n\n`DR = UMR / u` is the dynamic range of the phase shift coding\nand is a measure of how many points can be distinguished within the unambiguous measurement range `[0, UMR)`.\nIt remains constant if `L` and hence `l` are scaled (the scaling factor cancels out).\n\n`SNR = L / u` is the signal-to-noise ratio of the phase shift coding\nand is a masure of how many points can be distinguished within the screen length `[0, L)`.\nAgain, it remains constant if `L` and hence `l` are scaled (the scaling factor cancels out).\n\n## __Optimal Coding Strategy__\nAs makes sense intuitively, more sets `K` as well as more shifts `N` per set reduce the uncertainty `u` after decoding.\nA minimum of 3 shifts is needed to solve for the 3 unknowns brightness `A`, modulation `B` and coordinate `ξ`.\nAny additional 2 shifts compensate for one harmonic of the recorded fringe pattern.\nTherefore, higher accuracy can be achieved using more shifts `N`, but the time required to capture them \nsets a practical upper limit to the feasible number of shifts.\n\nGenerally, shorter wavelengths `l` (or equivalently more periods `v`) reduce the uncertainty `u`,\nbut the resolution of the camera and the display must resolve the fringe pattern spatially.\nHence, the used hardware imposes a lower bound for the wavelength (or upper bound for the number of periods).\n   \nAlso, small wavelengths might result in a smaller unambiguous measurement range `UMR`.\nIf two or more sets `K` are used and their wavelengths `l` resp. number of periods `v` are relative primes,\nthe unambiguous measurement range can be increased many times.\nAs a consequence, one can use much smaller wavelenghts `l` (larger number of periods `v`).\n\nHowever, it must be assured that the unambiguous measurment range is always equal or larger than both,\nthe width `X` and the height `Y`.\nElse, [temporal phase unwrapping](#temporal-phase-unwrapping--tpu-) would yield wrong results and thus instead\n[spatial phase unwrapping](#spatial-phase-unwrapping--spu-) is used.\nBe aware that in the latter case only a relative phase map is obtained,\nwhich lacks the information of where exactly the camera pixels were imaged to during acquisition.\n\nTo simplify finding and setting the optimal parameters, one can choose from the followng options:\n- `v` can be set to `\'optimal\'`.\n  This automatically determines the optimal integer set of `v`,\n  based on the maximal resolvable spatial frequency `vmax`.\\\n- Equivalently, `l` can also be set to `\'optimal\'`.\n  This will automatically determine the optimal integer set of `l`,\n  based on the minimal resolvable wavelength `lmin = L / vmax`.\n- `T` can be set directly, based on the desired acquisition time.\n  The optimal `K`, `N` and  - if necessary - the multiplexing methods will be determined automatically.\n- Instead of the options above, one can simply use the function `optimize()`\n  to automatically set the optimal `v`, `l`, `T` and multiplexing methods.\n\nHowever, those methods only perform optimally\nif the recorded modulation `B` is known (or can be estimated) for each certain spatial frequencies `v`.\n1. Option A: Measure the **modulation transfer function (MTF)** at a given number of sample points:\n   1. Set `K` to the required number of sample ponts (usually 10 is a good value).\n   2. Set `v` to `\'exponential\'`.\n      This will create spatial frequencies `v` spaced evenly on a log scale (a geometric progression),\n      starting from `0` up to `vmax`.\n   3. Encode, acquire and decode the fringe pattern sequence.\n   4. Mask the values of `B` with nan where the camera wasn\'t looking at the screen.\n   5. Call `Bv(B)` with the estimated modulation from the measurement as the argument.\n   6. Finlly, to get the modulation `B` at certain spatial frequencies `v`, simply call `MTF(v)`. \n      This method interpolates the modulation from the measurements `Bv` at the points `v`.\n2. Option B: Estimate the **magnification** and the **Point Spread Function (PSF)** of the imaging system:\n   1. Set the attributes `magnification` and `PSF` of the `Fringes` instance.\n      `PSF` is given as the standard deviation of the Point Spread Function.\n   2. Finlly, to get the modulation `B` at certain spatial frequencies `v`, simply call `MTF(v)`. \n      This method computes the modulation from the specified attributes `magnifiction` and `PSF` directly.\n--->\n\n## Troubleshooting\n<!---\n- __`poetry install` does not work__  \n  First, ensure that poetry is installed correctly as descibed on the [Poetry Website](https://python-poetry.org/docs/).\\\n  Secondly, ensure the correct python version is installed on your system, as specified in the file `pyproject.toml`!\\\n  Thirdly, this can be caused by a proxy which `pip` does not handle correctly.\n  Manually setting the proxy in the Windows settings or even adding a system variable \n  `https_proxy = http://YOUR_PROXY:PORT` can resolve this.\n--->\n\n- __Decoding takes a long time__  \n  This is most likely due to the just-in-time compiler [Numba](https://numba.pydata.org/), \n  which is used for this computationally expensive functions:\n  During the first execution, an initial compilation is executed. \n  This can take several tens of seconds up to single digit minutes, depending on your CPU.\n  However, for any subsequent execution, the compiled code is cached and the code of the function runs much faster, \n  approaching the speeds of code written in C.\n\n<!---\n- __My decoded coordinates show lots of noise__\n  - Make sure the exposure of your camera is adjusted so that the fringe patterns show up with maximum contrast.\n    Try to avoid under- and overexposure during acquisition.\n  - Try using more, sets `K` and/or shifts `N`.\n  - Adjust the used wavelengths `l` resp. number of periods `v` to ensure the unamboguous measurement range\n    is larger than the pattern length, i.e. <code>UMR &ge; L</code>.\n  - If the decoded modulation is much lower than the decoded brightness,\n    try to use larger wavelengths `l` resp. smaller number of periods `v`.\\\n    If the decoded modulation remains low even with very large wavelengths (less than five periods per screen length),\n    and you are conducting a deflectometric mesurement, the surface under test is probably too rough.\n    Since deflectometry is for specular and glossy surfaces only, it isn\'t suited for scattering ones.\n    You should consider a different measurement technique, e.g. fringe projection.\n\n- __My decoded coordinates show systematic offsets__\n  - First, ensure that the correct frames were captured while acquiring the fringe pattern sequence.\n    If the timings are not set correctly, the sequence may be a frame off.\n  - Secondly, this might occur if either the camera or the display used have a gamma value very different from 1.\n    - Typically, screens have a gamma value of 2.2; therefore compensate by setting the inverse value\n      <code>gamma<sup>-1</sup> = 1 / 2.2 &approx; 0.45</code> to the `gamma` attribute of the `Fringes` instance.\\\n      Alternatively, change the gamma value of the light source or camera directly.\n    - You can use the static method `gamma_auto_correct` to\n      automatically estimate and apply the gamma correction factor to linearize the display/camera response curve.\n    - You might also use more shifts `N` to compensate for the dominant harmonics of the gamma-nonlinearities.\n--->\n\n## License\nCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License\n\n## Project Status\nThis package is under active development, so features and functionally will be added in the future.\nFeature requests are warmly welcomed!\n\n## References\n<a id="1">[1]</a>\n[Burke et al.,\n“Reverse engineering by fringe projection,”\nInterferometry XI: Applications,\n2002.](https://doi.org/10.1117/12.473547)\n\n<a id="2">[2]</a>\n[Burke et al.,\n"Deflectometry for specular surfaces: an overview",\nAdvanced Optical Technologies,\n2023.](https://doi.org/10.3389/aot.2023.1237687)\n\n<a id="3">[3]</a>\n[Burke,\n"Phase Decoding and Reconstruction",\nOptical Methods for Solid Mechanics: A Full-Field Approach,\n2012.](https://www.wiley.com/en-us/Optical+Methods+for+Solid+Mechanics%3A+A+Full+Field+Approach-p-9783527411115)\n\n<a id="4">[4]</a>\n[Surrel,\n"Additive noise effect in digital phase detection",\nApplied Optics,\n1997.](https://doi.org/10.1364/AO.36.000271)\n\n<a id="5">[5]</a>\n[Herráez et al.,\n"Fast two-dimensional phase-unwrapping algorithm based on sorting by reliability following a noncontinuous path",\nApplied Optics,\n2002.](https://doi.org/10.1364/AO.41.007437)\n\n<a id="6">[6]</a>\n[Lei et al.,\n"A novel algorithm based on histogram processing of reliability for two-dimensional phase unwrapping",\nOptik - International Journal for Light and Electron Optics,\n2015.](https://doi.org/10.1016/j.ijleo.2015.04.070)\n\n<a id="7">[7]</a>\n[Takeda et al.,\n"Fourier-transform method of fringe-pattern analysis for computer-based topography and interferometry",\nJournal of the Optical Society of America,\n1982.](https://doi.org/10.1364/JOSA.72.000156)\n\n<a id="8">[8]</a>\n[Massig and Heppner,\n"Fringe-pattern analysis with high accuracy by use of the Fourier-transform method: theory and experimental tests",\nApplied Optocs,\n2001.](https://doi.org/10.1364/AO.40.002081)\n\n<a id="9">[9]</a>\n[Fischer et al.,\n"Vorhersage des Phasenrauschens in optischen Messsystemen mit strukturierter Beleuchtung",\nTechnisches Messen,\n2012.](https://doi.org/10.1524/teme.2012.0256)\n\n<a id="10">[10]</a>\n[EMVA,\n"Standard for Characterization of Image Sensors and Cameras Release 4.0 Linear",\nEuropean Machine Vision Association,\n2021.](https://www.emva.org/standards-technology/emva-1288/emva-standard-1288-downloads-2/)\n\n<a id="11">[11]</a>\n[Bothe,\n"Grundlegende Untersuchungen zur Formerfassung mit einem neuartigen Prinzip der Streifenprojektion und Realisierung in einer kompakten 3D-Kamera",\nDissertation,\nISBN 978-3-933762-24-5,\nBIAS Bremen,\n2008.](https://www.amazon.de/Grundlegende-Untersuchungen-Formerfassung-Streifenprojektion-Strahltechnik/dp/3933762243/ref=sr_1_2?qid=1691575452&refinements=p_27%3AThorsten+B%C3%B6th&s=books&sr=1-2)\n\n<!---\n<a id="8">[8]</a>\n[Park,\n"A twodimensional phase-shifting method for deflectometry",\nInternational Symposium on Optomechatronic Technologies,\n2008.](https://doi.org/10.1117/12.816472)\n\n<a id="9">[9]</a>\n[Huang,\n"Color-encoded digital fringe projection technique for high-speed three-dimensional surface contouring",\nOptical Engineering,\n1999.](https://doi.org/10.1117/1.602151)\n\n<a id="10">[10]</a>\n[Trumper et al.,\n"Instantaneous phase shifting deflectometry",\nOptics Express,\n2016.](10.1364/OE.24.027993)\n\n<a id="11">[11]</a>\n[Liu et al.,\n"Dual-frequency pattern scheme for high-speed 3-D shape measurement",\nOptics Express,\n2010.](https://doi.org/10.1364/OE.18.005229)\n\n<a id="12">[12]</a>\n[Liu et al.,\n"Fast and accurate deflectometry with crossed fringes",\nAdvanced Optical Technologies,\n2014.](10.1515/aot-2014-0032)\n\n<a id="13">[13]</a>\n[Kludt and Burke,\n"Coding strategies for static patterns suitable for UV deflectometry",\nForum Bildverarbeitung 2018,\n2018.](https://publikationen.bibliothek.kit.edu/1000088264)\n\n#### [19] Inverse Laplace Filter\n--->\n',
    'author': 'Christian Kludt',
    'author_email': 'None',
    'maintainer': 'None',
    'maintainer_email': 'None',
    'url': 'https://github.com/comimag/fringes',
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'python_requires': '>=3.9,<3.13',
}


setup(**setup_kwargs)
