############################################################################################
#  Copyright (C) 2015 Hewlett-Packard Development Company, L.P.
# All Rights Reserved.
#
#    Licensed under the Apache License, Version 2.0 (the "License"); you may
#    not use this file except in compliance with the License. You may obtain
#    a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
#    Unless required by applicable law or agreed to in writing, software
#    distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
#    WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
#    License for the specific language governing permissions and limitations
#    under the License.
#
############################################################################################


"""
Backup job scheduler manages backup jobs


**Related Flags**

:backupjobs_topic:  What :mod:`rpc` topic to listen to (default:
                        `rmv-app`).
:backupjobs_manager:  The module name of a class derived from
                          :class:`manager.Manager` (default:
                          :class:`rmv.rmvjobs.manager.Manager`).

"""

from datetime import timedelta
import operator
from tarfile import _data

from sqlalchemy import *
from oslo_config import cfg
from rmv import context
from rmv import exception
from rmv import flags
from rmv import manager
from rmv.virt import driver
from rmv.openstack.common import log as logging
from rmv.apscheduler.scheduler import Scheduler
import memcache
import socket
from rmv.openstack.common import timeutils
from rmv.openstack.common import lockutils
from rmv.db.sqlalchemy import models

# from rmv.vault import swift

from rmv.virt.vmwareapi.vi_helper import ViHelper
from rmv.virt.vmwareapi.vi_helper import VmTaskHelper

from rmv.virt.vmwareapi import json_helper
from rmv import RMVUtils as rmv_utils
from rmv.RMVUtils import RmvLocks as rmv_locks
from rmv.virt.vmwareapi import vi_objects

from rmv.api.v1.mount import Mount
from rmv.openstack.common import jsonutils
from rmv.storage import rmc_wrapper
from rmv.storage import rset_migration

from rmv import rmv_structures
from rmv.rmv_structures import vm_plugin_web_operation_status_code as \
    plugin_status_code

from rmv import exception as rmv_exception
from rmv.virt.vmwareapi import vim

import threading, thread, Queue
import uuid

from rmv.rmvjobs import vmware_checks
from rmv.rmvjobs.webclient_cache import web_client_cache
from rmv.virt.vmwareapi import webserverhelper as webserver_helper
from rmv.rmvjobs.vmcenter_cache import vmcenter_cache
from rmv.rmvjobs.remotecopy_groups import RemoteCopyGroups as remotecopy_groups
from rmv.rmvjobs.remotecopy_snapshot import RemoteCopySnapshots as remote_copy_snapshots
from rmv.rmvjobs.single_generic_group_snapshot import SingleGenericGroupSnapshots as single_generic_group_snapshots
from rmv.rmvjobs import notification_util as nu
from rmv.rmvjobs import policy_util as policyutil
from rmv.rmvjobs import vmdk_operations as vmdkOps
from rmv.rmvjobs import validate_util
from datetime import datetime
# from rmv.openstack.common import jsonutils
from rmv import rmv_structures
# from rmv.openstack.common import timeutils
from datetime import timedelta
from rmv.db import base
from rmv.virt.vmwareapi import vim_util
from rmv.virt.vmwareapi import vm_util
from rmv.virt.vmwareapi.vi_objects import vm_vv_map as vm_vv_map_obj
from rmv.rmvjobs.vmware_objects import VmwareObjects as vmware_obj
from rmv.rmvjobs.uuid_manage import UuidManage as uuid_manage
from rmv.rmvjobs.manage_moref import ManageMoRef as moref_manage
from rmv.rmvjobs.rmv_server_manager import RmvServerManager
from rmv.virt.pyvmomi.pyvmomi_wrapper import pyvmomi_wrapper
from rmv.virt.pyvmomi import pyvmomi_util
from pyVmomi import vim as pyvmomi_vim
from rmv.rmvjobs.refresh import Refresh as refresh
from rmv.rmvjobs.hypervisor_operations import HypervisorServers as hypervisor_manager
import gc
import os
import re
from rmv.db_utils import DB_Util
import json
import copy
from rmv.rmvjobs.validator import ValidateVmwareObject as validate_vmware_obj_class
from rmv import upgrade
from rmv.hypervisorcacheutils import hypervisor_cache_operations
from rmv.rmvjobs.protection_group_operations import ProtectionGroupOperations as pg_operation_class
import time
from rmv.rmvjobs import rmvjobs_utils
import fs_crowler


LOG = logging.getLogger(__name__)
migration_log_path = "/var/www/html/rmv-gui/migration/"
backupjobs_manager_opts = [
    cfg.StrOpt('vault_service',
               default='rmv.vault.swift',
               help='Vault to use for backup jobs.'),
]

scheduler_config = {'standalone': 'True'}

date_time_format = "%Y-%m-%d %I:%M:%S %p"
rmv_object_type = "Remotecopy"
rc_separator = '|||'

FLAGS = flags.FLAGS
FLAGS.register_opts(backupjobs_manager_opts)
memcache_id_for_vm_lock = "rmcvlock"


def backupjob_callback(backupjob_id):
    """
    Callback
    """
    # TODO(gbasava): Implementation


class BackupJobManager(manager.SchedulerDependentManager):
    """Manages backup jobs """

    RPC_API_VERSION = '1.0'
    # TODO: if this "vi_helper" and "lock" not used, remove them
    vi_helper = None
    lock = None

    web_client_cache = web_client_cache()
    snaps_in_operation_dict = {}
    esx_host_in_dict = {}
    is_web_client_initialization_exists = False
    memcache_connection = '127.0.0.1:11211'
    backups_in_operation_dict = {}
    new_snapshot_uuid_lock_dict = {}

    def __init__(self, service_name=None, topic=None, *args, **kwargs):

        # self.service = importutils.import_module(FLAGS.vault_service)
        self.az = FLAGS.storage_availability_zone
        self.scheduler = Scheduler(scheduler_config)
        self.scheduler.start()
        self.topic = topic

        super(BackupJobManager, self).__init__(
            service_name='backupjobscheduler',
            *args, **kwargs)
        self.driver = driver.load_compute_driver(None, None)

        LOG.info(("Creating vCenter session ..."))

        rmv_applite = False
        LOG.info("topic...:" + topic)
        if (topic == 'rmv-applite'): rmv_applite = True
        ip_hostname, username, password, vcenteruid = self.get_vcenter_credentials()
        if ip_hostname and username:
            LOG.info("**************RMV-APPLITE*************************")
            try:
                self.vi_helper = ViHelper(ip_hostname, username, password,
                                          vcenteruid, rmv_applite)
            except Exception as e:
                LOG.exception(e)
                self.vi_helper = None
        else:
            self.vi_helper = None

        self.lock = threading.Lock()
        self._lock_migration = threading.Lock()
        self.snapshot_id_dict = {}
        self.backup_id_dict = {}
        # self.new_snapshot_uuid_lock_dict = {}
        self.snapshot_op_in_progress = False
        self.backup_op_in_progress = False
        self.db_base = base.Base()
        self.is_remote_copy_group_listed = False
        self.ret_rc_groups = dict()
        self.memcache_id = None
        mem_client = memcache.Client([self.memcache_connection])
        mem_client.set(memcache_id_for_vm_lock, self.new_snapshot_uuid_lock_dict)
        self.vv_map_obj = vm_vv_map_obj()
        self.promote_ds_moref_dict = {}
        self.db_utils = DB_Util()
        self.vmware_objects_class = vmware_obj(self.vi_helper)
        self.pg_helper = pg_operation_class(self.vi_helper)

        if topic == 'rmv-applite' and self.vi_helper is not None:
            refresh_thread = threading.Thread(target=self.refresh_vmware_objects, args=())
            refresh_thread.daemon = True
            refresh_thread.start()

        # if topic != 'rmv-applite' and self.vi_helper is not None:
        #     refresh_device_collection_thread = threading.Thread(target=self.refresh_device_collections_thread, args=())
        #     refresh_device_collection_thread.daemon = True
        #     refresh_device_collection_thread.start()

        # To avoid multiple initialization of hypervisor cache, checking for topic
        # so hypervisor cache service will be initialized on startup of rmv-app service
        if topic != 'rmv-applite' and self.vi_helper:
            hypervisor_cache_obj = hypervisor_cache_operations.HypervisorCacheOperations(None)
            hypervisor_cache_obj.initiate_rmcv_app_v2_hypervisor_cache()

        self.rmc_version = self.get_rmc_version()

    def refresh_vmware_objects(self):
        ctxt = context.get_admin_context()
        while True:
            try:
                self.refresh_rmv_vmware_objects(ctxt)
                time.sleep(rmv_utils.REFRESH_VMWARE_OBJECTS_DELAY)
            except:
                LOG.exception("Unable to update rmv vmware objects")

    def refresh_device_collections_thread(self):
        ctxt = context.get_admin_context()
        while True:
            try:
                self.refresh_device_collections(ctxt)
                LOG.info("Refresh device collection completed, sleeping for:%s secs",
                         FLAGS.refresh_device_collections_sleep_time)
                time.sleep(FLAGS.refresh_device_collections_sleep_time)
            except Exception as e:
                LOG.exception(e)

    def reset_rcgroup_parameters(self):
        self.is_remote_copy_group_listed = False
        self.ret_rc_groups = dict()

    def init_host(self):
        """
        Do any initialization that needs to be run if this is a standalone
        service.
        """

        ctxt = context.get_admin_context()

        LOG.info(("Cleaning up incomplete backup operations"))

    def create_rmv_snapshot(self, context, vmware_db_id, x_auth_token, task_id, copy_id,
                            request_body, isBackupCreation=False):
        '''
        Decides to create whether VMFS of VVOL snapshot
        Extracts the  VM info based on mo_ref
        '''
        # Step1: Using mo_ref in the request_body
        # Step2: Create Tasks (Vmware, TaskTracker, Newsfeed tasks)
        # Step3: if it is  Datastore call create_snapshot
        # Step4: else if its a VM, check the type using get_virtual_machine_details(mo_ref)
        # Step5: if VM type is VVOL then self.create_vvol_snapshot
        # Step6: Else call create_snapshot with the vmInfo from step5

        LOG.debug(_("create_rmv_snapshot : Enter"))
        # LOG.info(_("Snapshot-Set Id: '%s', CREATE Operation Started with backend:") % snapshot_id)

        start_time = time.time()
        LOG.info(
            "Snapshot create process, started in manager layer. RMV object Id :" + str(vmware_db_id) + " start time " +
            str(start_time) + " taskId : " + str(task_id))
        try:
            if not self.rmc_version:
                self.rmc_version = self.get_rmc_version()
        except Exception as e:
            pass

        rmv_snap_ret_info = self.create_rmv_snapshot_internal(context, vmware_db_id, x_auth_token, task_id, copy_id,
                                                              request_body, isBackupCreation=isBackupCreation)
        end_time = time.time()
        LOG.info("Snapshot create process, completed in manager layer. RMV object Id :" + str(
            vmware_db_id) + " end time " + str(end_time)
                 + " time taken : " + str((end_time - start_time)))

        return rmv_snap_ret_info

    def _update_task_tasktracker(self, rmc_wrapper_service, task_id, kwargs):
        """Update task status in RMC Tasktracker."""
        response_data = rmc_wrapper_service.update_task(task_id, kwargs)

    def _update_task_vmware(
            self, vm_task_helper, task_percentage, task_desc_string):
        """Update task status in vCenter Tasks Panel."""
        vm_task_helper.CustomVMwareTaskUpdate(
            task_percentage,
            task_desc_string)

    def _update_task(self, task_desc_string, task_percentage, task_state,
                     task_id, rmc_wrapper_service, vm_task_helper=None,
                     parent_task_id=None, output_of_task=None, total_steps=None, completed_steps=None,
                     notification=None, task_status=None, resource_uri=None, associated_data=None):
        """Update task status in RMC Tasktracker and vCenter Tasks Panel."""
        timeStamp = timeutils.utcnow()
        kwargs = {}
        kwargs['task_state'] = task_state
        kwargs['task_status'] = task_status
        kwargs['taskProgress'] = {'message': task_desc_string, 'timeStamp': timeStamp}
        kwargs['task_desc_string'] = task_desc_string
        kwargs['completed_percentage'] = task_percentage if task_percentage \
            else None
        kwargs['parent_task_id'] = parent_task_id if parent_task_id else None
        kwargs['output_of_task'] = output_of_task if output_of_task else None
        # kwargs['completed_steps'] = completed_steps if completed_steps else None
        kwargs['completed_steps'] = task_percentage if task_percentage else None
        if notification:
            kwargs['notification'] = notification

        if resource_uri:
            kwargs['resource_uri'] = resource_uri

        if associated_data:
            kwargs['associated_data'] = associated_data

        if rmc_wrapper_service:
            LOG.debug(_("Updating taskStatus  %s") % task_desc_string)
            self._update_task_tasktracker(rmc_wrapper_service, task_id, kwargs)
        if task_percentage:
            task_percentage = int(task_percentage)
        if vm_task_helper:
            self._update_task_vmware(
                vm_task_helper,
                task_percentage,
                task_desc_string)

    def _update_migration_task_success(self, kwargs):
        success_failed_count_msg = "success:" + str(kwargs['count_success']) + ", failed:" + str(
            kwargs['count_failed']) + ", invalid:" + str(kwargs['migration_body']['invalid_snapshots'])
        task_desc_string = "The " + kwargs['type_of_migration'] + " migration in progress..." + success_failed_count_msg
        if kwargs.get('VmWareObjectName', None):
            kwargs['output_of_task'] = "  The " + kwargs['type_of_migration'] + " '" + kwargs[
                'snapsnot_name_to_migrate'] + "' of '" + kwargs[
                                           'VmWareObjectName'] + "' is migrated successfully on RMC-V Appliance '" + \
                                       kwargs['moref_mapped_rmc_appliance'] + "'."
        else:
            kwargs['output_of_task'] = "  The " + kwargs['type_of_migration'] + " '" + kwargs[
                'snapsnot_name_to_migrate'] + "' is migrated successfully on RMC-V Appliance '" + kwargs[
                                           'moref_mapped_rmc_appliance'] + "'."
        task_status = "Ok"
        self._update_task(task_desc_string, kwargs['task_percentage'], kwargs['task_state'],
                          kwargs['task_id'], None, kwargs['vm_task_helper'],
                          kwargs['parent_task_id'], kwargs['output_of_task'], kwargs['local_snapshots_count'],
                          kwargs['completed_steps'], task_status=task_status)
        rmv_utils.write_in_migration_log_file(migration_log_path, kwargs['output_of_task'])

    def _update_migration_task_failed(self, kwargs):
        success_failed_count_msg = "success:" + str(kwargs['count_success']) + ", failed:" + str(
            kwargs['count_failed']) + ", invalid:" + str(kwargs['migration_body']['invalid_snapshots'])
        task_desc_string = "The " + kwargs['type_of_migration'] + " migration in progress..." + success_failed_count_msg
        if kwargs.get('VmWareObjectName', None):
            output_of_task = "  The " + kwargs['type_of_migration'] + " '" + kwargs[
                'snapsnot_name_to_migrate'] + "' of '" + kwargs[
                                 'VmWareObjectName'] + "' migration is failed on RMC-V Appliance '" + kwargs[
                                 'moref_mapped_rmc_appliance'] + "'. Reason: " + kwargs['err_args_msg']
        else:
            output_of_task = "  The " + kwargs['type_of_migration'] + " '" + kwargs[
                'snapsnot_name_to_migrate'] + "' migration is failed on RMC-V Appliance '" + kwargs[
                                 'moref_mapped_rmc_appliance'] + "'. Reason: " + kwargs['err_args_msg']
        if rmv_utils.is_import_retry_required(kwargs['err_args_msg']) is False:
            output_of_task = output_of_task + ". The import operation retry is not recommended for this snapshot."
        else:
            output_of_task = output_of_task + ". The import operation retry is recommended for this snapshot."
        task_status = "Ok"
        self._update_task(task_desc_string, kwargs['task_percentage'], kwargs['task_state'],
                          kwargs['task_id'], None, kwargs['vm_task_helper'],
                          kwargs['parent_task_id'], output_of_task, kwargs['local_snapshots_count'],
                          kwargs['completed_steps'], task_status=task_status)
        self.update_snapshot_migration_status_in_vcenter(kwargs, output_of_task)
        rmv_utils.write_in_migration_log_file(migration_log_path, output_of_task)

    def _update_migration_task_failed_end(self, kwargs):
        success_failed_count_msg = "success:" + str(kwargs['count_success']) + ", failed:" + str(
            kwargs['count_failed']) + ", invalid:" + str(kwargs['migration_body']['invalid_snapshots'])
        output_of_task = "  The migration of " + kwargs['type_of_migration'] + " is failed. Reason:" + kwargs[
            'err_args_msg']
        task_desc_string = "The migration of " + kwargs[
            'type_of_migration'] + " is failed. Reason: check logs." + success_failed_count_msg
        task_status = "Error"
        self._update_task(task_desc_string, kwargs['task_percentage'], "Error",
                          kwargs['task_id'], kwargs['rmc_wrapper_service'], kwargs['vm_task_helper'],
                          kwargs['parent_task_id'], output_of_task, kwargs['local_snapshots_count'],
                          kwargs['completed_steps'], task_status=task_status)
        kwargs['vm_task_helper'].CustomVMwareTaskEnd("error", task_desc_string)
        rmv_utils.write_in_migration_log_file(migration_log_path, output_of_task)

    def _update_migration_task_finished(self, kwargs):
        success_failed_count_msg = "success:" + str(kwargs['count_success']) + ", failed:" + str(
            kwargs['count_failed']) + ", invalid:" + str(kwargs['migration_body']['invalid_snapshots'])
        task_state = "Failed"
        vcenter_task_state = "error"
        task_desc_string = "Unknown error"
        if kwargs['count_failed'] == 0 and kwargs['count_success'] != 0:
            task_desc_string = "The migration of " + kwargs[
                'type_of_migration'] + " completed successfully." + success_failed_count_msg
            task_state = 'Completed'
            task_status = "Ok"
            vcenter_task_state = "success"
        if kwargs['count_failed'] != 0 and kwargs['count_success'] != 0:
            task_desc_string = "The migration of " + kwargs[
                'type_of_migration'] + " completed partially." + success_failed_count_msg
            task_state = 'Warning'
            task_status = "Warning"
            vcenter_task_state = "success"
        if kwargs['count_failed'] != 0 and kwargs['count_success'] == 0:
            task_desc_string = "The migration of " + kwargs[
                'type_of_migration'] + " is failed." + success_failed_count_msg
            task_state = 'Failed'  # Todo need to change it partial.
            task_status = "Error"
            vcenter_task_state = "error"
        if kwargs['count_failed'] == 0 and kwargs['count_success'] == 0:
            task_desc_string = "The migration of " + kwargs[
                'type_of_migration'] + " completed successfully. There is no " + kwargs[
                                   'type_of_migration'] + " available for migration. " + success_failed_count_msg
            task_state = 'Completed'
            task_status = "Ok"
            vcenter_task_state = "success"
        output_of_task = "  " + task_desc_string

        self._update_task(task_desc_string, kwargs['task_percentage'], task_state,
                          kwargs['task_id'], kwargs['rmc_wrapper_service'], kwargs['vm_task_helper'],
                          kwargs['parent_task_id'], output_of_task, kwargs['local_snapshots_count'],
                          kwargs['completed_steps'], task_status=task_status)
        kwargs['vm_task_helper'].CustomVMwareTaskEnd(vcenter_task_state, task_desc_string)
        rmv_utils.write_in_migration_log_file(migration_log_path, " ")
        rmv_utils.write_in_migration_log_file(migration_log_path, output_of_task)

    # TODO: This can be removed as it is now moved to vmware_checks.py
    def validate_virtualmachine_object(self, vmInfo, is_app_consistent):
        # Check the state of VM
        vmware_checks.check_vm_connection_state(vmInfo.ConnectionState, vmInfo)

        # Checks for the existence of VMFS snapshots
        # Commented as these checks raise an exception if any vmfs snapshots are present
        """
        if vmInfo.HasVmfsSnapshots and vmInfo.VmfsSnapshots and \
                vmInfo.VmfsSnapshots.__len__(
                ) > 0:
            LOG.info(('VM has VMFS snapshots'))
            vmware_checks.check_vmfs_snapshots(
                vmInfo.VmfsSnapshots,
                vmInfo.Name)
            vmware_checks.check_unnamed_vmfs_snapshot(vmInfo.VmfsSnapshots)
            vmware_checks.check_vmfs_snapshot_name(
                vmInfo.VmfsSnapshots,
                vmInfo.Name)
        """

        # Checks for VMwareTools' status and Physical RDM LUNs
        if (vmInfo.PowerState == "poweredOn") and is_app_consistent:
            vmware_checks.check_vmware_tools(vmInfo.VmWareToolsStatus,
                                             vmInfo.Name)
            vmware_checks.check_vm_physical_rdm(vmInfo.VirtualCopyPairList)

    def get_virtual_machine_details(self, mo_ref, vmLevelBackup=False):

        # Return value is Dict containing vmInfo and hostInfo
        vm_host_info_dict = self.vi_helper.GetVirtualMachineInfo(mo_ref, False, vmLevelBackup)
        vmInfo = None
        hostInfo = None
        ds_name_list = []
        if 'vm_info' in vm_host_info_dict:
            vmInfo = vm_host_info_dict['vm_info']
        if 'host_info' in vm_host_info_dict:
            hostInfo = vm_host_info_dict['host_info']

        # Collect the array name and disktype from all datastores
        # if array name is different or disk types different then raise exceptions in validate virtual machine disks
        array_name = set()
        disktype = set()
        vendor = None
        array_name, vendor, disktype, ds_name_list = self.get_array_details(hostInfo)

        if array_name:
            vmInfo.ArrayName = list(array_name).pop()
        if disktype:
            vmInfo.VmType = list(disktype).pop()
        vmInfo.DsNameList = ds_name_list
        vmInfo.Vendor = vendor

        return vmInfo, hostInfo

    def get_array_details(self, hostInfo):
        array_name = set()
        disktype = set()
        ds_name_list = []
        vendor = None
        for datastores in hostInfo.DatastoreDict:
            if hostInfo.DatastoreDict[datastores].DatstoreType == json_helper.TpdVmHostFileSystemType.VVol:
                array_name.update([hostInfo.DatastoreDict[datastores].VvolDS.storageArray[0].name])
                vendor = hostInfo.DatastoreDict[datastores].VvolDS.storageArray[0].vendorId
            if datastores in hostInfo.ds_list_having_vmdk:
                disktype.update([hostInfo.DatastoreDict[datastores].DatstoreType])
            ds_name_list.append(hostInfo.DatastoreDict[datastores].Name)
        return array_name, vendor, disktype, ds_name_list

    def validate_virtual_machine_disk_details(self, vmInfo, hostInfo):
        # Collect the array name and disktype from all datastores
        # if array name is different or disk types different then raise exceptions

        array_name = set()
        disktype = set()
        ds_name_list = []
        vendor = None
        array_name, vendor, disktype, ds_name_list = self.get_array_details(hostInfo)

        if len(array_name) > 1:
            msg = (_("All disks associated with the Virtual Machine does not \
                                belong to storage containers from same storage system"))
            LOG.error(_(msg))
            LOG.exception("Exception: %s", msg)
            raise Exception(msg)
        elif len(disktype) > 1:
            msg = (_("All disks belonging to Virtual Machine does not have same disk type"))
            LOG.error(_(msg))
            LOG.exception("Exception: %s", msg)
            raise rmv_exception.VMDifferentDiskTypeException(vm_name=vmInfo.Name)

    # TODO: This can be removed as it is now moved to vi_helper.py
    def validate_datastore_object(self, ds_info, mo_ref, scsi_luns):
        if not ds_info:
            raise rmv_exception.UnknownVMwareObjectError(
                type='Datastore',
                mo_ref=mo_ref)

        if ds_info.IsUnusable:
            raise rmv_exception.DatastoreUnusableError(
                error=ds_info.FatalErrors)

        if ds_info.DatstoreType != json_helper.TpdVmHostFileSystemType.Vmfs:
            raise rmv_exception.DatastoreUnsupportedTypeError(
                type=ds_info.DatstoreType)

        if scsi_luns.__len__() > 1:
            raise rmv_exception.DatastoreSpannedError()

        if scsi_luns.__len__() == 0:
            raise rmv_exception.DatastoreNon3parError()

        if not scsi_luns[0].Is3ParLun:
            if ("ok") in scsi_luns[0].State.lower():
                raise rmv_exception.DatastoreNon3parError()
            else:
                raise rmv_exception.DatastoreUnusableError(error='')

        if scsi_luns[0].VmfsVolumeUuidDict.__len__() > 1:
            raise rmv_exception.DatastoreMoreThanOneIn3parVolumeError()

    def get_vm_vendor_info(self, vmInfo):
        LOG.info("get_vm_vendor_info : Enter")
        vmVendor = None
        if vmInfo.VirtualCopyPairList:
            for VirtualCopyList in vmInfo.VirtualCopyPairList:
                if VirtualCopyList:
                    vmVendor = VirtualCopyList.Vendor
                    break
        LOG.info("get_vm_vendor_info : Exit")
        return vmVendor

    def get_vi_helper(self):
        """
        Return initialized vi_helper object
        :return:
        """
        if not self.vi_helper:
            self.initialize_vi_helper_object()
        return self.vi_helper

    def get_vcenter_logging_params(self, obj_type, mo_ref):
        type_for_vcenter_log_event = None
        mo_ref_for_vcenter_log_event = None
        obj_exists = self.check_if_object_exists(mo_ref, obj_type)
        if obj_exists:
            type_for_vcenter_log_event = obj_type
            mo_ref_for_vcenter_log_event = mo_ref
        else:
            LOG.info("The parent object has either been removed or deleted, so proceeding with folder level task")
            # These 2 values are used for vCenter Events and Tasks logging
            type_for_vcenter_log_event = "Folder"
            mo_ref_for_vcenter_log_event = "group-d1"
        return (type_for_vcenter_log_event, mo_ref_for_vcenter_log_event)

    def register_vm_snapshot(self, context, x_auth_token, copy_id, vm_list, object, task_id, esx_host_name,
                             register_folder, power_on, vmware_object_id, resource_list):
        LOG.info("Enter register_vm_snapshot")
        clone_info = None
        clone_id = None
        vmware_obj_info = None
        current_clone_status = None
        clone_status_json = json_helper.clone_status
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        task_state = 'Running'
        task_status = "Initiated"
        task_desc_string = "Initiate create clone"
        task_percentage = 10
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service, None,
                          task_status=task_status)
        if esx_host_name:
            copy_info = self.db.get_rmcv_copy_by_id(context, copy_id)
            rmc_copyset_id = copy_info.rmc_copyset_id
            LOG.info('Mounting snapshot')
            parse = object.split(':')
            if len(parse) < 1:
                msg = "Invalid object being passed"
                raise Exception(msg)
            objectType = parse[0]
            moref = parse[1]
            task_message = 'Mounting snapshot on Esxi'
            if objectType == rmv_utils.VMWARE_OBJECT_TYPE_REMOTECOPY or objectType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                vmware_obj_info = self.db_utils.get_vmware_object_by_object_type_and_moref(context, objectType, moref,
                                                                                           copy_id)
            else:
                vmware_obj_info = self.db_utils.get_vmware_object_by_object_type_and_moref(context, objectType, moref)
            obj_name = vmware_obj_info.name
            if obj_name is None:
                obj_name = "Vmware"
            parentResourceName = obj_name

            mount_task = self._create_task_recover(rmc_wrapper_service, 'Mount', parentResourceName, task_id,
                                                   task_message, copy_id, 'Snapshot', 'Snapshot')

            (clone_details, recovery_set_id) = self.mount_snapshot_esx(context, rmc_copyset_id, x_auth_token,
                                                                       esx_host_name, 'esxHostIP',
                                                                       mount_task, None, vmware_object_id, objectType,
                                                                       copy_id, None, None, None, None, None,
                                                                       resource_list)
            clone_info = self.db.get_rmcv_clone_by_recovery_set_id(context, recovery_set_id)
            clone_id = clone_info.id
            current_clone_status = clone_status_json.mounted
        else:
            # copy_id in this code path, actually represents clone_id
            clone_id = copy_id
            clone_info = self.db.get_rmcv_clone_by_id(context, clone_id)
            esx_host_name = clone_info.esxi_host_name
            copy_id = clone_info.parent_copy_id
            current_clone_status = clone_info.status
        hostname_ref = self.get_hostref_from_name(esx_host_name)
        resource_pool_moref = self.get_respool_from_host(hostname_ref)
        vm_dict = {}
        # host_info = self.get_esx_hot_inofo(esx_host_name)
        for vm in vm_list:
            parent_vm_id = vm['parent_vm_id']
            vm_info = self.db.get_virtual_machine_by_id(context, parent_vm_id)
            recover_vm = vm_info.name
            vm_dict[recover_vm] = vm_info.moref
        powerOn = False
        if power_on == "1":
            powerOn = True
        try:
            clone_details_resp = self.register_vm_from_restored_ds(context, x_auth_token, rmc_wrapper_service,
                                                                   esx_host_name, vm_dict,
                                                                   register_folder, copy_id, object,
                                                                   resource_pool_moref, clone_info, task_id, None,
                                                                   powerOn)
            clone_details = clone_details_resp['clone_details']
            status = current_clone_status
            if current_clone_status == clone_status_json.mounted:
                status = clone_status_json.cloned
            elif current_clone_status == clone_status_json.vmdk_attached:
                status = clone_status_json.cloned_attached
            values = {'status': status, 'clone_details': clone_details}
            self.db.update_rmcv_clone_by_clone_id(context, clone_id, values)
            task_state = 'Completed'
            task_status = "Ok"
            task_desc_string = "Clone creation is completed successfully."
            task_percentage = 100
        except Exception as e:
            LOG.exception('Failed to register vm, error: {0}'.format(str(e)))
            task_state = 'Failed'
            task_status = "Error"
            task_desc_string = "Clone creation was unsuccessful"
            task_percentage = 100
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service, None,
                          task_status=task_status)
        LOG.info("Exit register_vm_snapshot")
        return

    def create_single_snapshot_for_group(self, context, x_auth_token, task_id, type, moref, name, body):

        request_body = {
            "vmWareObjectType": type, "vmWareMoref": moref, "isAppConsistent": body.get('isAppConsistent', True),
            "snapExpiry": body.get('snapExpiry', 0), "snapRetention": body.get('snapRetention', 0), "vmNameList": [],
            "snapshotName": body.get('name', rmv_utils.get_object_name_by_time()), "snapCount": body.get("snapCount"),
            "removeOldestSnap": body.get("removeOldestSnap"), "protection_group_id": body.get("protection_group_id")
        }

        vmware_db_object = None
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        try:
            vmware_db_object = self.db_utils.get_vmware_object_by_object_type_and_moref(context, type, moref)
            LOG.info(_("DB record found with mo-ref: '%s'"), moref)
        except rmv_exception.DBRecordNotFound as e:
            LOG.info(_("DB record not found with mo-ref: '%s'"), moref)

        if not vmware_db_object:
            try:
                mo_table_obj = json_helper.mo_table()
                mo_table_obj.moref = moref
                vmware_db_object = self.db_utils.create_vmware_object(context, type, mo_table_obj.__dict__)
            except Exception as e:
                msg = "Please make sure if vCenter is added to RMC-V using " \
                      "HPE RMC Configuration options in the webclient."
                LOG.info(msg)
                LOG.error("Exception: %s", str(e))
                raise Exception(msg)

        kwargs = {}
        kwargs['name'] = rmv_utils.CREATE_SNAPSHOT_ACTIVITY_NAME
        kwargs['owner'] = 'RMC-V User'
        kwargs['task_state'] = 'New'
        kwargs['task_type'] = 'User'
        kwargs['resource_name'] = name
        kwargs['resource_category'] = 'Datastore'
        kwargs['association_type'] = 'IS_A'
        kwargs['resource_id'] = moref
        kwargs['action'] = 'Create'
        kwargs['resourceType'] = 'Snapshot'
        kwargs['parentTaskId'] = task_id

        res = rmc_wrapper_service.create_task(kwargs)
        child_task_id = res['id']

        copies_table_obj = json_helper.copies_table()
        copies_table_obj.point_in_time = timeutils.utcnow()
        copies_table_obj.type = rmv_utils.copy_type.SNAPSHOT
        copies_table_obj.status = "creating"
        copies_table_obj.name = request_body.get("snapshotName")
        copies_table_obj.group_id = body.get('protection_group_id')
        copies_table_response = self.db.create_rmcv_copy(copies_table_obj.__dict__)
        copy_id = copies_table_response.id

        if type == 'Datastore':
            ds_copies_assoc_obj = json_helper.ds_copies_assoc_table()
            ds_copies_assoc_obj.datastore_id = vmware_db_object.id
            ds_copies_assoc_obj.copy_id = copy_id
            self.db.create_rmcv_ds_copy_assoc(ds_copies_assoc_obj.__dict__)

        elif type == 'VirtualMachine':
            vm_copies_assoc_obj = json_helper.vm_copies_assoc_table()
            vm_copies_assoc_obj.virtual_machine_id = vmware_db_object.id
            vm_copies_assoc_obj.copy_id = copy_id
            self.db.create_rmcv_vm_copy_assoc(vm_copies_assoc_obj.__dict__)

        response = self.create_rmv_snapshot(context, vmware_db_object.id, x_auth_token, child_task_id, copy_id,
                                            request_body)

        LOG.info("This is bulk create snapshot : " + str(response))
        task_output = {"resourceId": response.get('snapshotSetId'), "parentResourceId": moref,
                       "parentResourceType": type, "resourceName": name}

        LOG.debug("Response of snapshot create: " + str(response))
        return task_output

    def start_queuing_snapshot_create(self, context, x_auth_token, task_id, vm_task_helper, body, workerThread,
                                      queue_size, snapshot_queue, success_list):
        while not snapshot_queue.empty():
            item = snapshot_queue.get()
            LOG.info("workerThread id : %s and moref: %s", workerThread, item.get('moref'))
            try:
                res = self.create_single_snapshot_for_group(context, x_auth_token, task_id, item.get('type'),
                                                            item.get('moref'), item.get('name'), body)
                resourceId = res.get('resourceId')

                if resourceId is not None and len(resourceId) > 0:
                    success_list.append(res)

                completed = queue_size - snapshot_queue.qsize()
                percent = 0 if queue_size == 0 else completed * 100 / queue_size
                rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
                self._update_task("",
                                  percent,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper=vm_task_helper, task_status='Initiated', output_of_task=str(res))
            except Exception as e:
                LOG.exception("An error occured while taking snapshot of item: %s", item.get('moref'))

            snapshot_queue.task_done()

    def create_folder_snapshots(self, context, x_auth_token, task_id, resource_id, body):
        """
        Finds all item in folder and start creating snapshot for each.
        :param context:
        :param x_auth_token:
        :param task_id:
        :param resource_id:
        :param copy_target_id:
        :param app_consistent:
        :return:
        """

        LOG.debug("in create_folder_snapshots(), Enter")
        vm_task_helper = VmTaskHelper(self.get_vi_helper())
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        snapshot_queue = Queue.Queue()
        success_list = []

        try:

            type_for_vcenter_log_event, mo_ref_for_vcenter_log_event = self.get_vcenter_logging_params('Folder',
                                                                                                       resource_id)
            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log_event,
                                                 mo_ref_for_vcenter_log_event,
                                                 "CreateVMVirtualCopyTask",
                                                 "CreateVMVirtualCopyFailedFault")
            name = self.vi_helper.get_vmware_name('Folder', resource_id)
            children = []
            self.vi_helper.list_items_in_folder_recursively(children,
                                                            moref_list=[pyvmomi_util.get_moref(resource_id, 'Folder')],
                                                            type_list=['datastore'])
            LOG.debug("all ds recursively : " + str(children))
            scsi_luns = []

            for child in children:
                try:
                    type = 'Datastore'
                    moref = child._moId
                    LOG.info("adding resource to snapshot type: " + str(type) + " moref: " + moref)

                    if 'datastore' in str(child).lower():
                        ds_info = self.vi_helper.get_datastore_details(moref, scsi_luns,
                                                                       save_hs_and_hss_properties=True)
                        snapshot_queue.put({'moref': moref, 'type': type, "name": ds_info.Name})

                except Exception as e:
                    msg = "Unable to proceed snapshot create for a Datastore, moref: " + moref
                    if hasattr(e, "msg"):
                        msg = e.msg
                    LOG.exception(msg)
                    self._update_task(msg,
                                      0,
                                      'Running',
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper=vm_task_helper, task_status='Initiated')
            count = snapshot_queue.qsize()
            task_desc_string = "Bulk Snapshot creation process started with " + str(count) + " sub resources in " \
                               + str(name) + " storage folder."

            self._update_task(task_desc_string,
                              0,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status='Initiated')

            if count < 1:
                task_desc_string = "No Datastore found in folder."
                return

            self._update_task("",
                              0,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status='Initiated',
                              output_of_task=str({"subResourceCount": count, "subResourceType": 'Datastore'}))

            LOG.info("Number of parallel threads allowed to be spawn: %s", FLAGS.max_snapshot_create_threads_grouping)
            LOG.info("Number of items which has to snapshot %s", count)

            for workerThread in range(FLAGS.max_snapshot_create_threads_grouping):
                worker = threading.Thread(target=self.start_queuing_snapshot_create,
                                          args=(context, x_auth_token, task_id,
                                                vm_task_helper, body, workerThread, count,
                                                snapshot_queue, success_list))
                worker.setDaemon(True)
                worker.start()

            snapshot_queue.join()
            task_desc_string = "Bulk Snapshot creation process completed, " + str(len(success_list)) + ' out of ' \
                               + str(count) + ' Passed.'
            LOG.debug('all success full snapshots: ' + str(success_list))

        except Exception as e:
            task_desc_string = (_("An error while creating snapshot for folder."))
            if (rmv_utils.get_error_message(e)):
                task_desc_string = rmv_utils.get_error_message(e)
            LOG.exception(e)

        finally:

            task_status = 'Ok'
            task_state = 'Completed'

            if len(success_list) == 0:
                task_status = 'Error'
                task_state = 'Failed'
                LOG.info('Moving task to Error state')

            elif len(success_list) < count:
                task_status = 'Warning'
                task_state = 'Warning'
                LOG.info('Moving task to Warning state')

            self._update_task(task_desc_string,
                              100,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status=task_status)

            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

    def snapshot_vms(self, context, x_auth_token, task_id, vm_task_helper, snapshot_queue, vmware_resource_type,
                     resources, container_name, body):
        """
        Snapshot all the vms
        :param context:
        :param x_auth_token:
        :param task_id:
        :param resources:
        :param body:
        :return:
        """
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        success_list = []

        for vm in resources:
            try:

                moref = vm.Moref
                type = vmware_resource_type

                if 'vm' in moref:
                    vmInfo, host = self.get_virtual_machine_details(moref)
                    LOG.debug("vmInfo: " + str(vmInfo))
                    LOG.info("Adding a VM to snapshot, moref: " + str(moref) + " name: " + str(
                        vmInfo.Name) + " ParentTask: " + str(task_id))
                    # Allow only vvol
                    if vmInfo.VmType == json_helper.TpdVmHostFileSystemType.VVol:
                        snapshot_queue.put({'moref': moref, 'type': type, "name": vmInfo.Name})

            except Exception as e:
                msg = "Unable to proceed snapshot create for a Virtual Machine, vm: " + str(vm)
                if hasattr(e, "msg"):
                    msg = e.msg
                LOG.exception(msg)
                self._update_task(msg,
                                  0,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper=vm_task_helper, task_status='Ok')

        count = snapshot_queue.qsize()

        if count < 1:
            task_desc_string = "No VM found in Resource Pool."
            LOG.info("No VM found in the Storage Container:'%s'" % container_name)
            return

        LOG.info("Number of parallel threads allowed to be spawn: %s",
                 body.get('qsize', FLAGS.max_snapshot_create_threads_grouping))
        LOG.info("Number of items which has to snapshot %s", count)

        for workerThread in range(FLAGS.max_snapshot_create_threads_grouping):
            worker = threading.Thread(target=self.start_queuing_snapshot_create, args=(context, x_auth_token, task_id,
                                                                                       vm_task_helper, body,
                                                                                       workerThread, count,
                                                                                       snapshot_queue, success_list))
            worker.setDaemon(True)
            worker.start()

        return (success_list, count)

    def create_resource_pool_snapshot(self, context, x_auth_token, task_id, resource_id, body):
        """
        this function initiate resource pool(ESX resourse, vApp) snapshot
        :param x_auth_token: api auth token
        :param task_id: rmc task
        :param resource_id: vapp moref
        :param body: params, like name, expiry, retaintion
        :return: None
        """

        LOG.debug("in create_resource_pool_snapshot(), Enter")
        vm_task_helper = VmTaskHelper(self.get_vi_helper())
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        snapshot_queue = Queue.Queue()
        success_list = []

        try:
            type_for_vcenter_log_event, mo_ref_for_vcenter_log_event = self.get_vcenter_logging_params('ResourcePool',
                                                                                                       resource_id)
            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log_event,
                                                 mo_ref_for_vcenter_log_event,
                                                 "CreateVMVirtualCopyTask",
                                                 "CreateVMVirtualCopyFailedFault")

            vapp_name = self.vi_helper.get_vmware_name('ResourcePool', resource_id)
            vms = self.vi_helper.get_virtual_machines_in_resource_pool(resource_id)
            LOG.info("no of vms in pool: " + str(len(vms)) + " pool name: " + str(vapp_name))
            for vm in vms:
                try:
                    moref = vm._moId
                    type = "VirtualMachine"

                    if 'vm' in moref:
                        vmInfo, host = self.get_virtual_machine_details(moref)
                        LOG.debug("vmInfo: " + str(vmInfo))
                        LOG.info("Adding a VM to snapshot, moref: " + str(moref) + " name: " + str(
                            vmInfo.Name) + " ParentTask: " + str(task_id))
                        snapshot_queue.put({'moref': moref, 'type': type, "name": vmInfo.Name})

                except Exception as e:
                    msg = "Unable to proceed snapshot create for a Virtual Machine, vm: " + str(vm)
                    if hasattr(e, "msg"):
                        msg = e.msg
                    LOG.exception(msg)
                    self._update_task(msg,
                                      0,
                                      'Running',
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper=vm_task_helper, task_status='Ok')

            count = snapshot_queue.qsize()
            task_desc_string = "Bulk Snapshot creation process started with " + str(
                count) + " Virtual Machines in resourcePool: " \
                               + str(vapp_name)
            self._update_task(task_desc_string,
                              0,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status='Ok')
            if count < 1:
                task_desc_string = "No VM found in Resource Pool."
                return

            self._update_task("",
                              0,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status='Ok',
                              output_of_task=str({"subResourceCount": count, "subResourceType": 'VirtualMachine'}))

            LOG.info("Number of parallel threads allowed to be spawn: %s", FLAGS.max_snapshot_create_threads_grouping)
            LOG.info("Number of items which has to snapshot %s", count)

            for workerThread in range(FLAGS.max_snapshot_create_threads_grouping):
                worker = threading.Thread(target=self.start_queuing_snapshot_create,
                                          args=(context, x_auth_token, task_id,
                                                vm_task_helper, body, workerThread, count,
                                                snapshot_queue, success_list))
                worker.setDaemon(True)
                worker.start()

            snapshot_queue.join()
            task_desc_string = "Bulk Snapshot creation process completed, " + str(len(success_list)) + ' out of ' \
                               + str(count) + ' Passed.'
            LOG.debug('success full snapshots: ' + str(success_list))

        except Exception as e:
            task_desc_string = (_("An error while creating snapshot for resourcePool."))
            if rmv_utils.get_error_message(e):
                task_desc_string = rmv_utils.get_error_message(e)
            LOG.exception(e)

        finally:

            task_status = 'Completed'
            task_state = 'Ok'

            if len(success_list) == 0:
                task_status = 'Failed'
                task_state = 'Error'
                LOG.info('Moving task to Error state')

            elif len(success_list) < count:
                task_status = 'Warning'
                task_state = 'Warning'
                LOG.info('Moving task to Warning state')

            self._update_task(task_desc_string,
                              100,
                              task_status,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status=task_state)

            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
            LOG.debug("create_resource_pool_snapshot(), Exit")

    def protect_all_vm_in_ds(self, context, x_auth_token, task_id, resource_id, body):
        """
        function get list of all vm in datastore, and call to snapshot create
        :param x_auth_toekn:
        :param task_id:
        :param resource_id:
        :param body:
        :return:
        """

        LOG.debug("in create_resource_pool_snapshot(), Enter")
        vm_task_helper = VmTaskHelper(self.get_vi_helper())
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        snapshot_queue = Queue.Queue()
        success_list = []

        try:
            type_for_vcenter_log_event, mo_ref_for_vcenter_log_event = self.get_vcenter_logging_params('Datastore',
                                                                                                       resource_id)
            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log_event,
                                                 mo_ref_for_vcenter_log_event,
                                                 "CreateVMVirtualCopyTask",
                                                 "CreateVMVirtualCopyFailedFault")

            name = self.vi_helper.get_vmware_name('Datastore', resource_id)
            vms = self.vi_helper.get_virtual_machine_in_datastore(resource_id, name)
            LOG.info("No of vms in DS: " + str(len(vms)) + " datastore name: " + str(name))
            success_list, count = self.snapshot_vms(context, x_auth_token, task_id, vm_task_helper, snapshot_queue,
                                                    "VirtualMachine", vms, name, body)
            task_desc_string = "Bulk Snapshot creation process started with " + str(
                count) + " Virtual Machines in Datastore " + str(name)
            self._update_task(task_desc_string,
                              0,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status='Ok')
            snapshot_queue.join()

            task_desc_string = "Bulk Snapshot creation process completed, " + str(len(success_list)) + ' out of ' \
                               + str(count) + ' Passed.'
            LOG.debug('success full snapshots: ' + str(success_list))


        except Exception as e:
            task_desc_string = (_("An error while creating snapshot for resourcePool."))
            if rmv_utils.get_error_message(e):
                task_desc_string = rmv_utils.get_error_message(e)
            LOG.exception(e)

        finally:

            task_status = 'Completed'
            task_state = 'Ok'

            if len(success_list) == 0:
                task_status = 'Failed'
                task_state = 'Error'
                LOG.info('Moving task to Error state')

            elif len(success_list) < count:
                task_status = 'Warning'
                task_state = 'Warning'
                LOG.info('Moving task to Warning state')

            self._update_task(task_desc_string,
                              100,
                              task_status,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status=task_state)

            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

    def pre_backup(self, context, x_auth_token, task_id, body):
        """
        Entry point of pre backup operation
        :param context:
        :param x_auth_token:
        :param task_id:
        :param body:
        :return:
        """
        LOG.debug("pre_backup(), in manager Enter")
        resource_type = body.get('resourceType')
        resource_id = body.get("resourceMoref")

        if resource_type == "VirtualMachine":
            copytarget_id = body.get("copyTargetId")
            current_rmv_backup_id = body.get('rmv_backup_id')
            app_consistenet = body.get('isAppConsistent', False)
            self.create_snapshot_nbd(context, x_auth_token, task_id, current_rmv_backup_id, resource_id, copytarget_id,
                                     app_consistenet)

        elif resource_type == 'storageFolder':
            self.create_folder_snapshots(context, x_auth_token, task_id, resource_id, body)

        elif resource_type == 'ProtectionGroup':
            self.create_protection_group_snapshot(context, x_auth_token, task_id, resource_id, body)

        elif resource_type == 'resourcePool':
            self.create_resource_pool_snapshot(context, x_auth_token, task_id, resource_id, body)

        elif resource_type == 'storageContainer':
            # This is datastore as a resource type, where vm will be children
            self.protect_all_vm_in_ds(context, x_auth_token, task_id, resource_id, body)

        else:
            LOG.error("This type of resource is not supported : %s" % resource_type)

        LOG.debug("pre_backup(), in manager Exit")

    def enable_cbt_if_not_enabled(self, rmc_wrapper_service, task_id, vm_task_helper, vm_info, prv_backup):
        """
        Enable cbt if not already enabled.
        :param rmc_wrapper_service:
        :param task_id:
        :param vm_task_helper:
        :param vm_info:
        :return:
        """
        # Check if snapshot is disabled for this VM
        LOG.debug("****** Check if CBT is enabled ******")
        vm_cbt_flag = self.check_if_CBT_enabled(vm_info)
        LOG.info("******* VM CBT FLAG value ****** : %s" % vm_cbt_flag)
        f = True
        try:
            if vm_cbt_flag == False:
                self.enable_CBT_for_VM(vm_info, vm_cbt_flag)
                LOG.info("CBT has been enabled for vm, name: " + vm_info.Name)
                self._update_task("CBT enabled successfully.",
                                  30,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status="Initiated")


        except Exception as e:
            self._update_task("Enabling CBT failed, will go for full backup",
                              30,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status="Warning")
            f = False

        return f

    def update_rmv_vmware_object_vm(self, context, vmware_obj):
        """
        updating DB record for vmware object
        :param context:
        :param vm_info:
        :return:
        """
        moref = vmware_obj.VmMoref
        name = vmware_obj.Name
        vcenter_config = self.db.vcenter_configuration_get_first(context)
        vcenter_uuid = vcenter_config.server_guid
        hostname = vmware_obj.HostName
        values = {
            'moref': moref,
            'vmware_uuid': vmware_obj.Uuid,
            'vcenter_uuid': vcenter_uuid,
            'name': name,
            'host_name': hostname,
        }
        rmv_vm_object = self.db.get_virtual_machine_by_moref(context, moref)

        if (rmv_vm_object is None):
            # creating object
            return self.db.create_rmcv_virtual_machines(context, values)
        else:
            # updating values
            return self.db.update_rmcv_virtual_machines(context, rmv_vm_object.id, values)
        return rmv_vm_object

    def get_or_create_rmv_vmdk(self, context, rmv_vmware_object, vmdk):
        """
        create vmdk record if not there other wise get that.
        :param context:
        :param rmv_vmware_object:
        :param vmdk:
        :return:
        """
        vmdkPath = vmdk.get('vmdkPath')
        d = {"virtualmachine_id": rmv_vmware_object.get('id'), "path": vmdkPath,
             "size": vmdk.get('diskSize'), "type": vmdk.get("vmdkType")}
        rmv_vmdk = self.db.get_vmdk_by_vmdk_path(context, vmdkPath)
        if rmv_vmdk is None:
            rmv_vmdk = self.db.create_rmcv_vmdk(context, d)
        else:
            rmv_vmdk = self.db.update_rmcv_vmdk(context, rmv_vmdk.get('id'), d)
        return rmv_vmdk

    def get_previous_rmv_nbd_backup(self, context, rmv_vmware_object_id, rmc_wrapper_service):
        """
        find the previous available backup for vm
        :param context:
        :param rmv_vmware_object_id:
        :param rmc_wrapper_service:
        :return:
        """
        try:
            rmv_backup_obj = self.db.get_latest_rmcv_backup_by_status_and_vm_id(context, rmv_vmware_object_id,
                                                                                'available')
            if (rmv_backup_obj is None):
                return None
            LOG.info("Previous backup relation: " + rmv_backup_obj.id)
            backup_set_id = rmv_backup_obj['rmc_copyset_id']
            backupSet = rmc_wrapper_service.get_backup_for_backupId(context, backup_set_id)
            if (backupSet['backupSet']['state'] != 'available'):
                return None
            return rmv_backup_obj
        except Exception as e:
            LOG.exception(str(e))
        return None

    def generate_cbt_map_for_vmdk(self, diskObj, vmuuid, prv_change_id, snap_moref, map_folder_name, vmType):
        """
        Genrate map file
        :param diskObj:
        :param vmuuid:
        :param prv_change_id: * if previous backup is not there, or change id of previous backup.
        :param snap_moref:
        :param map_folder_name:
        :param map_file_name:
        :param vmType:
        :return:
        """
        try:
            vmdk_path = diskObj.get('vmdkPath', None)
            deviceKey = diskObj.get('deviceKey')
            diskSize = diskObj.get('diskSize')
            mapFileName = str(uuid.uuid4())

            if (diskSize <= 0):
                # means not  proper disk can not get CBT, or even backup
                LOG.error("Disk size is 0 or less")
                raise rmv_exception.ZeroDiskSize(disk=vmdk_path)
            mapFilePath = self.vi_helper.query_change_disk_areas(vmuuid, deviceKey, prv_change_id,
                                                                 snap_moref, map_folder_name, mapFileName, vmType)

            LOG.info("genrated, mapFilePath:" + str(mapFilePath) + " vmdk: " + str(vmdk_path))
            return mapFilePath

        except Exception as e:
            LOG.error("Error while generating cbt map for " + str(vmdk_path))
            return None

    def create_input_file(self, file_name, input_dict):
        """
        create a file of input which can be used to take backup
        :param file_name:
        :param d:
        :return:
        """

        filePath = rmv_utils.FILE_INPUT_DIR + file_name
        if not os.path.exists(rmv_utils.FILE_INPUT_DIR):
            os.makedirs(rmv_utils.FILE_INPUT_DIR)

        with open(filePath, "w") as file:
            file.write(jsonutils.dumps(input_dict))
        LOG.info("Input file created" + filePath + " vm moref: " + input_dict['vmDetails'].get('vMuuid'))

        return filePath

    def delete_input_file(self, rmv_backup_id):
        filePath = rmv_utils.FILE_INPUT_DIR + rmv_backup_id
        if os.path.exists(filePath):
            os.remove(filePath)
            LOG.info("deleted input file: " + filePath)

    def create_vmdk_backups_entry(self, context, rmv_vmware_object, vmdk_list, prv_backup,
                                  current_backup_id, rmc_wrapper_service, copytarget_id, task_id):
        """
        this function will create individual file backup in rmv_vmdk_backup
        :param rmv_vmware_object:
        :param vmdk_list:
        :param prv_backup:
        :param current_backup:
        :return:
        """
        LOG.debug("create_vmdk_backups_entry(), Enter")
        # need to pass parent vm moref for the below query to get the details
        current_backup = self.db.get_rmcv_copy_by_id_with_vm_details(context, current_backup_id)
        vmfs_snap_moref = current_backup.vmfs_snap_moref
        LOG.debug("create_vmdk_backups_entry(), " + str(vmdk_list))
        vmdksBackupParam = []

        for vmdk in vmdk_list:
            vmdkFile = {'incremental': False, 'optimized': False}
            rmv_vmdk = self.get_or_create_rmv_vmdk(context, rmv_vmware_object, vmdk)
            LOG.info("rmv_vmdk id: " + str(rmv_vmdk.id))
            vmdkFile['filePath'] = vmdk.get('vmdkPath', None)
            vmdkFile['fileSize'] = vmdk.get('diskSize')

            prv_change_id = '*'
            if prv_backup:
                prv_vmdk_backup = self.db.rmv_vmdk_backup_get_by_rmv_backup_vmdk_id(context, prv_backup.id,
                                                                                    rmv_vmdk.id)
                prv_change_id = prv_vmdk_backup.cbt_change_id
                vmdkFile['incremental'] = True
            else:
                fileSystem = vmdk.get('vmdkType')
                vmdkFile['optimized'] = False if fileSystem == json_helper.TpdVmHostFileSystemType.Nfs else True

            map_path = self.generate_cbt_map_for_vmdk(vmdk, rmv_vmware_object.uuid, prv_change_id, vmfs_snap_moref,
                                                      map_folder_name=rmv_vmware_object.id, vmType=vmdk.get('vmdkType'))
            if (not map_path):
                vmdkFile['optimized'] = False
                vmdkFile['incremental'] = False
                self._update_task("Failed to query CBT Map for vmdk: " + vmdk.get('vmdkPath') + " Go for full backup",
                                  60,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Warning")

            LOG.info("cbt map file: " + str(map_path) + " for vmdk: " + vmdk.get('vmdkPath', ""))

            d = {"vmdk_id": rmv_vmdk.get('id'), "rmcv_backup_id": current_backup.id,
                 "cbt_change_id": vmdk.get('currentChangeId'), "backup_status": "running",
                 "copy_target_id": copytarget_id}
            rmv_vmdk_backup = self.db.rmv_vmdk_backup_create(context, d)
            vmdkFile['backupId'] = rmv_vmdk_backup.id
            vmdkFile['cbtMapFilePath'] = map_path
            vmdksBackupParam.append(vmdkFile)
        LOG.debug("create_vmdk_backups_entry(), Exit")

        return vmdksBackupParam

    def update_nbd_backup_process(self, context, rmv_vmware_backup_id, status):
        """
        if failed in prebackup itself than putting all resource in error state
        :param context:
        :param rmv_vmware_backup_rel_id:
        :return:
        """
        listOfvmdkBackups = self.db.rmv_vmdk_backups_get_by_rmvbackup_id(context, rmv_vmware_backup_id)
        for vmdk_backup in listOfvmdkBackups:
            self.db.rmv_vmdk_backup_update(context, vmdk_backup.id, {"backup_status": status})
        self.db.update_rmcv_copy(context, rmv_vmware_backup_id, {"status": status})

    def create_snapshot_nbd(self, context, x_auth_token, task_id, current_rmv_backup_id, mo_ref, copytarget_id,
                            is_app_consistent):
        """
        Create snapshot for nbd backup and information which is require to take backup.
        :param context:
        :param x_auth_token:
        :param task_id:
        :param request_body:
        :return:
        """
        LOG.debug("create_snapshot_nbd, Enter")
        obj_type = "VirtualMachine"
        vm_task_helper = VmTaskHelper(self.get_vi_helper())
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        task_percentage = 20
        ds_assoc_vm_new_snap_id_list = None
        vmDetails = {"vTransportMode": "nbd", "vmMoref": "moref=" + mo_ref}
        task_status = "Ok"

        try:

            type_for_vcenter_log_event, mo_ref_for_vcenter_log_event = self.get_vcenter_logging_params(obj_type, mo_ref)
            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log_event,
                                                 mo_ref_for_vcenter_log_event,
                                                 "CreateVMVirtualCopyTask",
                                                 "CreateVMVirtualCopyFailedFault")

            self._update_task("Getting Virtual Machine Information",
                              task_percentage,
                              "Running",
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status="Initiated")

            exist = self.check_if_object_exists(mo_ref, obj_type)
            if (not exist):
                LOG.error("No such vmware object found: " + str(mo_ref))
                raise rmv_exception.VMwareObjectnotfound(mo_ref)

            vmInfo, hostInfo = self.get_virtual_machine_details(mo_ref, vmLevelBackup=True)
            rmv_vmware_vm_object = self.update_rmv_vmware_object_vm(context, vmInfo)
            vmDetails['esxiMoref'] = hostInfo.HostSystemMoref
            vmDetails['vMuuid'] = vmInfo.Uuid
            LOG.info("Fetched vm detail moref: " + str(mo_ref) + " name: " + str(vmInfo.Name))

            # Validating disk and their types
            self.validate_virtual_machine_disk_details(vmInfo, hostInfo)

            # Validating permission
            self.acquire_lock_and_create_task(context, mo_ref, obj_type, task_id,
                                              rmc_wrapper_service, vm_task_helper, False)

            vmware_checks.check_snapshot_disabled(vmInfo.IsSnapshotDisabled, vmInfo.ReasonSnapshotDisabled)

            try:
                # validating app consistency
                self.validate_virtualmachine_object(vmInfo, is_app_consistent)
            except Exception as e:
                LOG.error("Cannot take app consistent snapshot, will go for crash, moref: " + mo_ref)
                is_app_consistent = False
                self._update_task("Failed to take App Consistent snapshot, Falling to crash Consistent",
                                  task_percentage,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status="Warning")

            # delete all vmfs snapshot if any is there.
            self.delete_all_vmfs_snapshot_vm(vmInfo, mo_ref)
            # finding prv backup for vm
            prv_rmv_backup_obj = self.get_previous_rmv_nbd_backup(context, x_auth_token, rmv_vmware_vm_object.id)

            # enable cbt if it is not already enabled
            self.enable_cbt_if_not_enabled(rmc_wrapper_service, task_id, vm_task_helper, vmInfo, prv_rmv_backup_obj)

            vm_mo_ref_list = [mo_ref]

            ds_assoc_vm_new_snap_id_list = \
                self.vi_helper.CreateVmfsSnapshot(
                    vm_mo_ref_list,
                    vi_objects.VmfsSnapshotName,
                    "For Non-Array Copy",
                    False,
                    is_app_consistent, {mo_ref: vmInfo.Name}, {mo_ref: vmInfo.Uuid})
            task_percentage = 40
            self._update_task("VMFS snapshot created successfully.",
                              task_percentage,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status="Initiated")

            snap_moref = ds_assoc_vm_new_snap_id_list[0]._moId
            vmDetails['snapshotMoref'] = snap_moref
            changeId_details_list = self.get_snapshot_changeId(snap_moref)

            if (prv_rmv_backup_obj):
                vmDetails['incremental'] = True
                vmDetails['optimized'] = False
            else:
                vmDetails['incremental'] = False
                # If vm sitting on nfs and no prv backup there, than first backup will be full
                vmDetails['optimized'] = False if vmInfo.VmType == json_helper.TpdVmHostFileSystemType.Nfs else True

            # update current backup
            vm_obj_id = rmv_vmware_vm_object.id
            backup_rel = {"vmfs_snap_moref": snap_moref}
            self.db.update_rmcv_copy(context, current_rmv_backup_id, backup_rel)
            vmdks = []
            vmdk_list = self.db.get_vmdk_by_vm_id(context, vm_obj_id)
            for vmdk in vmdk_list:
                if vmdk.type == 'datastore':
                    vm_vmdks_jsonb_obj = json_helper.vm_vmdks_jsonb()
                    vm_vmdks_jsonb_obj.vmdk_id = vmdk.id
                    vm_vmdks_jsonb_obj.datastore_id = vmdk.datastore_id
                    vmdks.append(vm_vmdks_jsonb_obj.__dict__)
            mo_assoc_table_obj = json_helper.vm_copies_assoc_table()
            mo_assoc_table_obj.virtual_machine_id = vm_obj_id
            mo_assoc_table_obj.copy_id = current_rmv_backup_id
            mo_assoc_table_obj.is_app_consistent = is_app_consistent
            mo_assoc_table_obj.vmdks = vmdks
            self.db.update_rmcv_vm_copy_assoc(context, current_rmv_backup_id, vm_obj_id, mo_assoc_table_obj.__dict__)
            vmdk_backup_params = self.create_vmdk_backups_entry(context, rmv_vmware_vm_object, changeId_details_list,
                                                                prv_rmv_backup_obj, current_rmv_backup_id,
                                                                rmc_wrapper_service, copytarget_id, task_id, mo_ref)

            vm_config = self.get_snapshot_config_obj(snap_moref)

            vCenterCredential = self.vi_helper.get_vCenter_credential_dict()

            input_dict = {"vmDetails": vmDetails, "vmdkFiles": vmdk_backup_params, "clientMetadata": vm_config,
                          "vmwareAccessSpecifier": vCenterCredential}
            LOG.debug("input dict: " + str(input_dict) + " vm: " + vmInfo.Name)
            file_path = self.create_input_file(vm_obj_id, input_dict)

            task_percentage = 100
            self._update_task("NBD Snapshot creation process completed.",
                              task_percentage,
                              'Completed',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status, output_of_task=str(mo_ref + ':' + file_path))

            LOG.info("create nbd snapshot completed. for vm: " + vmInfo.Name)
            LOG.debug("create_snapshot_nbd, Exit")

        except Exception as e:
            msg = (_("Exception while creating snapshot"))
            if (rmv_utils.get_error_message(e)):
                msg = rmv_utils.get_error_message(e)
            self.update_nbd_backup_process(context, current_rmv_backup_id, 'error')
            if (ds_assoc_vm_new_snap_id_list):
                LOG.error("Failure occurred now deleting vmfs snapshot")
                self.vi_helper.Delete_vmfs_snapshot(ds_assoc_vm_new_snap_id_list, True)

            task_state = 'Failed'
            task_status = "Error"
            self._update_task(msg,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            LOG.error(_(msg))
            LOG.exception("Exception: %s", str(e))

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(msg)

            vm_task_helper.CustomVMwareTaskEnd("error", msg)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_log_event, type_for_vcenter_log_event, msg)
            raise e
        finally:
            if mo_ref:
                rmv_utils.release_snapshot_create_lock(mo_ref)
                LOG.info(("Released Lock for object '%s'") % mo_ref)

    def refresh_protection_group(self, context, x_auth_token, task_id, protection_group_id):
        """
        Check presence of every resource, if not found/accessible than delete.
        :param context:
        :param x_auth_token:
        :param task_id:
        :param protection_group_id:
        :return:
        """
        LOG.debug("In refresh_protection_group(), Enter")
        task_percentage = 0
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        try:
            self._update_task("Refreshing protection group",
                              task_percentage,
                              "Running",
                              task_id,
                              rmc_wrapper_service,
                              task_status="Initiated")
            pg = self.db.get_protection_group(context, protection_group_id)
            i = 0
            for resource in pg.resources.get('resources'):
                try:
                    name = self.vi_helper.get_vmware_name(resource.get('type'), resource.get('vmwareId'))
                    resource['name'] = name
                    status = 'available' if resource['status'] == 'deleted' else resource['status']
                    msg = ""
                    LOG.info("resource: " + name + " successfully refreshed in protection group.")
                except rmv_exception.NotFound as e:
                    LOG.exception(e)
                    status = 'inactive' if status == 'active' else resource['status']
                    msg = "Couldn't find " + resource['type'] + " " + resource['name']
                    LOG.info("resource: " + name + " not found in VC.")
                i += 1
                resource['status'] = status
                pg = self.db.update_protection_group(context, protection_group_id, pg)
                task_percentage = i * 100 / len(pg.resources.get('resources'))
                # Task update to update percentage
                self._update_task(msg,
                                  task_percentage,
                                  "Running",
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Initiated")

            task_status = 'Ok'
            task_state = 'Completed'
            msg = "Protection Group refreshed successfully."


        except Exception as e:
            LOG.exception(e)
            task_state = 'Failed'
            task_status = "Error"
            msg = "An unknown error refreshing protection group."
            if rmv_utils.get_error_message(e):
                msg = rmv_utils.get_error_message(e)

        finally:
            LOG.info("Refresh protection group done. taskId: " + task_id)
            self._update_task(msg,
                              100,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              task_status=task_status)

    def validate_protection_group_resource(self, resource, rmc_wrapper_service=None, task_id=None):
        """
        Validate resource for protection group
        :param resource: one resource which has to validate
        :param rmc_wrapper_service:
        :param task_id:
        :return: True if resource is okay in validation, False if validation failed.
        """
        LOG.debug("In validate_protection_group_resource(), inside manager, Enter ")
        vu = validate_util.ValidatorUtil(self)
        f = True
        out = None
        if resource['type'] == rmv_utils.VMWARE_OBJECT_TYPE_DS:
            out = validate_util.ValidateDataStore(resource['vmwareId'], vu, ).validate()
            LOG.info("Datastore moref: " + resource['vmwareId'] + " validation status: " + str(out))

        elif resource['type'] == rmv_utils.VMWARE_OBJECT_TYPE_VM:
            out = validate_util.ValidateVirtualMachine(resource['vmwareId'], vu).validate()
            LOG.info("VM moref: " + resource['vmwareId'] + " validation status: " + str(out))

        elif resource['type'] == 'storageFolder':
            out = validate_util.ValidateFolder(resource['vmwareId'], vu).validate()
            LOG.info("Folder moref: " + resource['vmwareId'] + " validation status: " + str(out))

        if out: f = True if out.status is 'passed' else False

        if not f and task_id and out and rmc_wrapper_service:
            self._update_task(" ".join(out.msgs),
                              None,
                              "Running",
                              task_id,
                              rmc_wrapper_service,
                              task_status="Initiated")
        LOG.debug("In validate_protection_group_resource(), inside manager, Exit ")
        return f

    def create_protection_group(self, context, x_auth_token, task_id, body, cleanup_protection_group=False,
                                percentage_on_complete=100, update_hypervisor_cache=True):
        """
        Create protection group, if input resources found than validate,
        Otherwise will create empty protection group.
        :param context:
        :param x_auth_token:
        :param task_id:
        :param body:
        :return:
        """
        LOG.info("protection group create, body: " + str(body))
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        is_task_updated = False
        try:
            resources = body.get('resources', [])
            LOG.info("resources in pg: " + str(resources))
            validated_resources = filter(lambda x: self.validate_protection_group_resource(x, rmc_wrapper_service,
                                                                                           task_id), resources) if len(
                resources) > 0 else []
            if len(validated_resources) < len(resources):
                raise rmv_exception.InvalidParameterValue(err="{} resources failed in validation,"
                                                              " aborting the Protection Group creation"
                                                          .format(len(resources) - len(validated_resources)))

            capabilities = body.get('capabilities', ['generic'])
            if rmv_utils.PROTECTION_GROUP_CAPABILITY_REMOTE in capabilities:
                protection_group, cleanup_required = self.create_protection_group_for_remote_capability(context, body)
                cleanup_protection_group = cleanup_required
            else:
                pg_table_object = json_helper.protection_group_table()
                pg_table_object.name = body.get('name')
                pg_table_object.description = body.get('description', '')
                pg_table_object.job_type = body.get('jobType', 'multiple')
                pg_table_object.capabilities = body.get('capabilities', ['generic'])
                pg_table_object.notification_policy_id = body.get('notificationPolicyId')
                pg_table_object.resources = {"resources": []}
                protection_group = self.db.create_protection_group(context, pg_table_object.__dict__)
                try:
                    self.add_resources_in_protection_group(context, x_auth_token, task_id, protection_group.id,
                                                           validated_resources, validate=False,
                                                           update_hypervisor_cache=update_hypervisor_cache)
                except Exception as e:
                    self.cleanup_protection_group(context, rmc_wrapper_service, protection_group.id, True)
                    is_task_updated = True
                    raise e
                cleanup_protection_group = True
            task_status, task_state, msg = ('Ok', 'Completed', 'Protection Group created successfully.')
            LOG.info("Protection Group created name: " + body.get('name'))
            if update_hypervisor_cache:
                rmvjobs_utils.update_pg_to_hypervisor_cache(self.db, context, rmc_wrapper_service,
                                                            protection_group.id, 'createGroup', 'addToGroup')
            return protection_group, cleanup_protection_group

        except Exception as e:
            LOG.exception(e)
            msg = rmv_utils.get_error_message(e)
            task_status, task_state, msg = ('Error', 'Failed', msg if msg else "Failed to create Protection Group")
            LOG.info("Failed to create Protection Group, name: " + body.get('name'))
            raise e

        finally:
            if is_task_updated is False:
                self._update_task(msg,
                                  percentage_on_complete,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status=task_status)

    def create_protection_group_for_remote_capability(self, context, body):
        """ check and crate protection group for remote capability """
        LOG.debug("create_protection_group_for_remote_capability:Enter")
        resources = body.get('resources', [])
        device_collection_name, device_identifier = None, None
        type, volumes, role = None, None, None
        cleanup_protection_group = False
        for res in resources:
            pg_mandatory_elements = ["device_collection_name", "device_identifier"]
            keys = res.keys()
            rmv_utils.verify_mandatory_options(pg_mandatory_elements, keys)
            device_collection_name = res.get("device_collection_name")
            device_identifier = res.get("device_identifier")
            type = res.get("type")
            role = res.get("role")
            volumes = res.get("volumes")
            # there will be only one resource for remote capability
            break

        pg = self.db.get_protection_group_by_name_and_device_identifier(context, device_collection_name,
                                                                        device_identifier)

        if not pg:
            # create protection group for device collection
            pg_table_object = json_helper.protection_group_table()
            pg_resources = {"resources": []}
            pg_table_object.name = body.get('name')
            pg_table_object.description = body.get('description', '')
            pg_table_object.job_type = body.get('jobType', 'single')
            pg_table_object.capabilities = body.get('capabilities', ['remotecopy'])
            pg_table_object.notification_policy_id = body.get('notificationPolicyId')

            pg_resource_obj = json_helper.protection_group_resource()
            pg_resource_obj.device_collection_name = device_collection_name
            pg_resource_obj.device_identifier = device_identifier
            pg_resource_obj.type = type
            pg_resource_obj.role = role
            pg_resource_obj.volumes = volumes
            pg_resources['resources'].append(pg_resource_obj.__dict__)

            pg_table_object.resources = pg_resources
            pg_table_object.protected_resources = rmvjobs_utils.build_protected_resource_dict_for_remote_copy(
                self.vmware_objects_class, resources)
            LOG.info("Protection group DB entry:%s", pg_table_object.__dict__)
            pg = self.db.create_protection_group(context, pg_table_object.__dict__)
            cleanup_protection_group = True

        else:
            LOG.info("Protection group already exists return the same to create work flow")

        LOG.debug("create_protection_group_for_remote_capability:Exit")
        return pg, cleanup_protection_group

    def create_protection_group_workflow(self, context, x_auth_token, task_id, body):
        """
        Create workflow for protection group if protectionGroup already there,
        and can create new PG also.
        :param context:
        :param x_auth_token:
        :param task_id:
        :param body:
        :return:
        """
        try:
            resource_id = body.get("resource_id")
            resource_type = body.get("resource_type")
            work_flow_options = body.get("workFlowOptions")
            protection_group = body.get("protectionGroupOptions")
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            rmv_obj = None
            msgs = []
            associated_data = {}
            protection_group_id = None
            cleanup_protection_group = False
            operation_type = 'manageResources'
            if resource_id and resource_type == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                rmv_obj = self.db.get_protection_group(context, resource_id)
                if protection_group:
                    pg_table_object = json_helper.protection_group_table()
                    pg_resources = {"resources": []}
                    pg_table_object.name = protection_group.get("name")
                    pg_table_object.job_type = protection_group.get("jobType", "single")
                    pg_table_object.capabilities = protection_group.get("capabilities", ["remotecopy"])
                    notification_policy_id = protection_group.get("notificationPolicyId")
                    if notification_policy_id:
                        pg_table_object.notification_policy_id = notification_policy_id

                    resources = protection_group.get("resources", [])
                    pg_table_object.protected_resources = rmvjobs_utils.build_protected_resource_dict_for_remote_copy(
                        self.vmware_objects_class, resources, rmv_obj.protected_resources)

                    pg_resource_obj = json_helper.protection_group_resource()
                    for res in resources:
                        volumes = res.get("volumes", [])
                        pg_resource_obj.device_collection_name = res.get("device_collection_name")
                        pg_resource_obj.device_identifier = res.get("device_identifier")
                        pg_resource_obj.type = res.get("type")
                        pg_resource_obj.role = res.get("role")
                        pg_resource_obj.volumes = volumes
                        pg_resources['resources'].append(pg_resource_obj.__dict__)
                        pg_table_object.resources = pg_resources
                    self.db.update_protection_group(context, resource_id, pg_table_object.__dict__)

            elif protection_group:
                # create protection group
                operation_type = 'createGroup'
                rmv_obj, cleanup_required = self.create_protection_group(context, x_auth_token, task_id,
                                                                         protection_group, cleanup_protection_group,
                                                                         percentage_on_complete=50,
                                                                         update_hypervisor_cache=False)
                protection_group_id = rmv_obj.id
                cleanup_protection_group = cleanup_required

            associated_data = {'resourceType': resource_type, 'resourceName': rmv_obj.name, 'resourceId': rmv_obj.id,
                               'resourceUri': rmv_utils.get_resource_uri('protection-groups', rmv_obj.id)
                               }

            work_flow_options['workFlowOptions']['protectionResource']['appResourceId'] = rmv_obj.id
            work_flow_options['workFlowOptions']['protectionResource']['appResourceType'] = resource_type

            # TODO remove below setting value resource type once core supports "ProtectionGroup" resource type
            if rmv_utils.PROTECTION_GROUP_CAPABILITY_REMOTE in rmv_obj.capabilities \
                    and rmv_obj.job_type == rmv_utils.PROTECTION_GROUP_JOB_TYPE_SINGLE:
                work_flow_options['workFlowOptions']['protectionResource']['appResourceType'] = "RcGroup"

            # TODO: Fix this correctly after getting landing api from core for resource type to "ProtectionGroup"
            elif rmv_utils.PROTECTION_GROUP_CAPABILITY_GENERIC in rmv_obj.capabilities \
                    and rmv_obj.job_type == rmv_utils.PROTECTION_GROUP_JOB_TYPE_SINGLE:
                # work_flow_options['workFlowOptions']['protectionResource']['appResourceType'] = "ProtectionGroup"
                work_flow_options['workFlowOptions']['protectionResource']['appResourceType'] = "RcGroup"

            try:
                # create work flow
                res = rmc_wrapper_service.create_workflows(context, work_flow_options)
                LOG.info("workflow res: " + str(res))
                task_status, task_state, msg = (
                'Ok', 'Completed', 'Workflow successfully created on protection group: ' + str(rmv_obj.name))
                rmvjobs_utils.update_pg_to_hypervisor_cache(self.db, context, rmc_wrapper_service, rmv_obj.id,
                                                            operation_type, 'addToGroup')
            except Exception as e:
                LOG.error("Failed to create workflow for : %s", work_flow_options)
                LOG.exception(e)
                self.cleanup_protection_group(context, rmc_wrapper_service, protection_group_id,
                                              cleanup_protection_group)
                raise e
            # if res.get('taskUri'):
            #     #making workflow a child task.
            #     workflow_task_id = res['taskUri'].split('/')[-1]
            #
            #     self._update_task("",
            #                       None,
            #                       task_state,
            #                       workflow_task_id,
            #                       rmc_wrapper_service,
            #                       task_status = task_status, parent_task_id=task_id)


        except Exception as e:
            LOG.exception(e)
            msg = rmv_utils.get_error_message(e)
            task_status, task_state, msg = (
            'Error', 'Failed', msg if msg else "Failed to create Protection Group or workflow.")

        finally:
            if task_state == 'Completed':
                self._update_task(msg,
                                  100,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status=task_status, associated_data=[associated_data])
            else:
                self._update_task(msg,
                                  100,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status=task_status)

    def cleanup_protection_group(self, context, rmc_wrapper_service, protection_group_id, cleanup_protection_group):
        LOG.info("cleanup_protection_group:Enter")
        try:
            LOG.info("protection_group_id :%s cleanup_protection_group:%s", protection_group_id,
                     cleanup_protection_group)
            if protection_group_id and cleanup_protection_group:

                workflow_resp = rmc_wrapper_service.get_work_flow_by_app_resource_id(protection_group_id)
                if workflow_resp:
                    count = workflow_resp.get("count", 0)
                    if count > 0:
                        msg = "protection group is assigned with protection policy, delete not allowed"
                        LOG.error("%s", msg)
                        raise rmv_exception.DeleteProtectionGroupNotAllowed(msg=msg)
                pg = self.db.delete_protection_group(context, protection_group_id)
        except Exception as e:
            LOG.exception(e)
        LOG.info("cleanup_protection_group:Exit")

    def validate_resouces_in_protection_group(self, x_auth_token, protection_group_id, resources, pg_capability):
        LOG.debug("validate_resouces_in_protection_group : enter")
        query_params = dict()
        query_params['resource_id'] = protection_group_id
        query_params['resources'] = resources
        if pg_capability == rmv_utils.PROTECTION_GROUP_CAPABILITY_GENERIC:
            query_params['validationType'] = rmv_utils.validation_types.SINGLE_GENERIC
        elif pg_capability == rmv_utils.PROTECTION_GROUP_CAPABILITY_REMOTE:
            query_params['validationType'] = rmv_utils.validation_types.RCG

        validate_class_obj = validate_vmware_obj_class(mgr=self, vi_helper=self.vi_helper)
        try:
            validated_vmware_object = validate_class_obj.validate_vmware_object(context, x_auth_token, query_params)
        except Exception as e:
            raise e

        ret = rmv_utils.convert_object_to_dict_recursively(validated_vmware_object)
        if ret['validator_status'].lower() != "success":
            raise rmv_exception.InvalidParameterValue(err=ret['validator_error'])
        LOG.debug("validate_resouces_in_protection_group : exit")

    def add_resources_in_protection_group(self, context, x_auth_token, task_id, protection_group_id, resources,
                                          validate=True, update_hypervisor_cache=True):
        """
        Check presence of every resource and add to protection group
        :param context:
        :param x_auth_token:
        :param task_id:
        :param protection_group_id:
        :param resources:
        :return:
        """
        LOG.info("In add_resources_in_protection_group(), Enter")
        task_percentage = 0

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        try:
            mandatory = ['type', 'vmwareId']

            pg = self.db.get_protection_group(context, protection_group_id)
            pg_capability = pg.capabilities[0]

            if pg.job_type != 'multiple':
                msg = "Validating resources"
                self._update_task(msg,
                                  task_percentage,
                                  "Running",
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Initiated")

                self.validate_resouces_in_protection_group(x_auth_token, protection_group_id, resources, pg_capability)
            i = 0
            protected_ds = []
            protected_vm = []
            for resource in resources:
                LOG.info("Adding new resource in protection group: " + str(protection_group_id) + " Resource"
                         + str(resource))
                supported_types = [rmv_utils.VMWARE_OBJECT_TYPE_VM, rmv_utils.VMWARE_OBJECT_TYPE_DS, 'storageFolder',
                                   'ResourcePool']
                if resource.get('type') not in supported_types:
                    raise ValueError(
                        resource.get('type') + " is not supported as resource type, supported types: " + str(
                            supported_types))

                if validate and not self.validate_protection_group_resource(resource, rmc_wrapper_service, task_id):
                    raise rmv_exception.InvalidParameterValue(err="resource failed in validation,"
                                                                  " moref: " + str(resource.get('vmwareId')))
                r = self.db.get_protection_group_resource_by_vmware_id(protection_group_id, resource.get('vmwareId'))

                if r and len(r) > 0:
                    # raise rmv_exception.InvalidParameterValue(err="Resource already exist in Protection Group,"
                    #                                               " moref: "+str(resource.get('vmwareId')))
                    LOG.info("Resource already exist in Protection Group moref:" + str(resource.get('vmwareId')))
                    continue

                if resource.get('type') == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                    vm_name = self.vi_helper.get_vmware_name(rmv_utils.VMWARE_OBJECT_TYPE_VM, resource.get('vmwareId'))
                    mo_table_obj = json_helper.vm_table()
                    mo_table_obj.moref = resource.get('vmwareId')
                    mo_table_obj.name = vm_name

                    rmv_vm = self.db.create_or_update_rmcv_vm(context,
                                                              resource.get('vmwareId'),
                                                              mo_table_obj.__dict__)
                    resource['id'] = rmv_vm.id
                    resource['status'] = "active"
                    resource['name'] = vm_name
                    protected_vm.append({"id": rmv_vm.id, "name": vm_name, "vmwareId": resource.get('vmwareId')})

                elif resource.get('type') == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                    ds_name = self.vi_helper.get_vmware_name(rmv_utils.VMWARE_OBJECT_TYPE_DS, resource.get('vmwareId'))
                    ds_table_obj = json_helper.ds_table()
                    ds_table_obj.moref = resource.get('vmwareId')
                    ds_table_obj.vcenter_uuid = self.vi_helper.vcenteruid
                    ds_table_obj.name = ds_name
                    rmv_ds = self.db.create_or_update_rmcv_ds(context,
                                                              resource.get('vmwareId'),
                                                              ds_table_obj.__dict__)
                    resource['id'] = rmv_ds.id
                    resource['status'] = "active"
                    resource['name'] = ds_name
                    protected_ds.append({"id": rmv_ds.id, "name": ds_name, "vmwareId": resource.get('vmwareId')})

                elif resource.get('type') == 'storageFolder':
                    # Since this is a folder so no rmv table would be there.
                    name = self.vi_helper.get_vmware_name('Folder', resource.get('vmwareId'))
                    resource['name'] = name
                    resource['status'] = "active"
                    resource['id'] = resource.get('vmwareId')
                    protected_ds, protected_vm = rmvjobs_utils.get_ds_and_vm_by_folder_moref(self.vi_helper,
                                                                                             resource.get('vmwareId'))

                elif resource.get('type') == 'ResourcePool':
                    # Resource pool can be vApp, Host
                    name = self.vi_helper.get_vmware_name('ResourcePool', resource.get('vmwareId'))
                    resource['name'] = name
                    resource['status'] = 'active'
                    resource['id'] = resource.get('vmwareId')
                    # ToDo find protected_ds, protected_vm by ResourcePool moref, currently we are not using it

                pg.resources.get('resources').append(resource)
                pg_existing_protected_resources = pg.protected_resources
                pg.protected_resources = rmvjobs_utils.build_protected_resource_dict(pg_existing_protected_resources,
                                                                                     protected_ds, protected_vm)
                LOG.info("resources after adding one: " + str(pg.resources))
                LOG.info("protected_resources after adding one: " + str(pg.protected_resources))
                pg = self.db.update_protection_group(context, protection_group_id, pg)
                LOG.info("PG: " + str(pg.__dict__))
                msg = ""
                # Task update to update percentage
                i += 1
                task_percentage = i * 100 / len(resources)
                self._update_task(msg,
                                  task_percentage,
                                  "Running",
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Initiated")

            task_status = 'Ok'
            task_state = 'Completed'
            msg = "Resource(s) added in Protection Group."
            LOG.info(msg)

            if update_hypervisor_cache:
                rmvjobs_utils.update_pg_to_hypervisor_cache(self.db, context, rmc_wrapper_service,
                                                            pg.id, 'manageResources', 'addToGroup')

        except rmv_exception.NotFound as e:
            LOG.exception(e)
            task_state = 'Failed'
            task_status = "Error"
            msg = "Resource Not found in vCenter."
            raise e

        except Exception as e:
            LOG.exception(e)
            task_state = 'Failed'
            task_status = "Error"
            msg = "An unknown error while adding resource in protection group."
            if rmv_utils.get_error_message(e):
                msg = rmv_utils.get_error_message(e)
            raise e

        finally:
            self._update_task(msg,
                              100,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              task_status=task_status)

    def create_protection_group_snapshot(self, context, x_auth_token, task_id, protection_group_id, body):
        """
        Function create snapshot of resources in protection group, and write information on task-output.
        :param context:
        :param x_auth_token:
        :param task_id:
        :param protection_group_id:
        :return:
        """
        LOG.debug("In create_protection_group_snapshot:(), Enter")
        try:
            pg = self.db.get_protection_group(context, protection_group_id)
            vm_task_helper = VmTaskHelper(self.get_vi_helper())
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            resources = pg.resources.get('resources')
            capabilities = pg.capabilities
            job_type = pg.job_type

            if rmv_utils.PROTECTION_GROUP_CAPABILITY_REMOTE in capabilities and job_type == rmv_utils.PROTECTION_GROUP_JOB_TYPE_SINGLE:
                self.create_protection_group_snapshot_type_single(context, x_auth_token, task_id, protection_group_id,
                                                                  body)
            elif rmv_utils.PROTECTION_GROUP_CAPABILITY_GENERIC in capabilities and job_type == rmv_utils.PROTECTION_GROUP_JOB_TYPE_SINGLE:
                self.create_protection_group_snapshot_type_single_capability_generic(context, x_auth_token, task_id,
                                                                                     protection_group_id,
                                                                                     body)
            else:
                self.create_protection_group_snapshot_type_multiple(context, x_auth_token, task_id, protection_group_id,
                                                                    body)

        except Exception as e:
            task_desc_string = (_("An error while creating snapshot for Protection Group."))
            LOG.error(task_desc_string)
            LOG.exception(e)

    def create_protection_group_snapshot_type_single_capability_generic(self, context, x_auth_token, task_id,
                                                                        protection_group_id,
                                                                        body):
        LOG.debug("create_protection_group_snapshot_type_single_capability_generic:Enter")
        # making snapshot copy entry here, if any error while creating snapshot then we can update
        copies_table_obj = json_helper.copies_table()
        copies_table_obj.point_in_time = timeutils.utcnow()
        copies_table_obj.name = body.get("snapshotName", None)
        copies_table_obj.status = "creating"
        copies_table_obj.group_id = protection_group_id
        copies_table_obj.type = rmv_utils.copy_type.SNAPSHOT
        copies_table_obj.version = self.rmc_version
        copies_table_response = self.db.create_rmcv_copy(copies_table_obj.__dict__)
        copy_id = copies_table_response.id
        self.create_group_level_snapshot_single_generic(context, protection_group_id, x_auth_token, task_id, copy_id,
                                                        body)
        LOG.debug("create_protection_group_snapshot_type_single_capability_generic:Exit")

    def create_protection_group_snapshot_type_single(self, context, x_auth_token, task_id, protection_group_id,
                                                     body):
        LOG.debug("create_protection_group_snapshot_single_type:Enter")
        # making snapshot copy entry here, if any error while creating snapshot then we can update
        is_remote_snap = body.get('remoteSnap', True)
        copies_table_obj = json_helper.copies_table()
        copies_table_obj.point_in_time = timeutils.utcnow()
        copies_table_obj.name = body.get("snapshotName")
        copies_table_obj.status = "creating"
        copies_table_obj.group_id = protection_group_id
        copies_table_obj.version = self.rmc_version
        if is_remote_snap:
            copies_table_obj.type = rmv_utils.copy_type.REMOTE_SNAPSHOT
        else:
            copies_table_obj.type = rmv_utils.copy_type.SNAPSHOT
        copies_table_response = self.db.create_rmcv_copy(copies_table_obj.__dict__)
        copy_id = copies_table_response.id
        self.create_group_level_snapshot_single(context, protection_group_id, x_auth_token, task_id, copy_id, body,
                                                self.rmc_version)
        LOG.debug("create_protection_group_snapshot_single_type:Exit")

    def create_protection_group_snapshot_type_multiple(self, context, x_auth_token, task_id, protection_group_id, body):
        """
        Function create snapshot of resources in protection group, and write information on task-output.
        :param context:
        :param x_auth_token:
        :param task_id:
        :param protection_group_id:
        :return:
        """
        LOG.debug("In create_protection_group_snapshot_type_multiple(), Enter")
        success_list = []
        notification_policy_id = None
        count = 0
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        task_desc_string = None
        vm_task_helper = None
        pg = None
        try:
            pg = self.db.get_protection_group(context, protection_group_id)
            notification_policy_id = pg.notification_policy_id
            vm_task_helper = VmTaskHelper(self.get_vi_helper())
            resources = pg.resources.get('resources')
            snapshot_queue = Queue.Queue()
            body['protection_group_id'] = protection_group_id

            resouce_ds_vm_list = self.pg_helper.get_ds_vm_from_folder_pg_resources(resources)
            for resouce_dict in resouce_ds_vm_list:
                snapshot_queue.put(resouce_dict)

            count = snapshot_queue.qsize()
            task_desc_string = "Protection Group Snapshot creation process started with " + str(
                count) + " sub resources in " \
                         "protection group: " + pg.name
            if count < 1:
                task_desc_string = "No resource found in Protection Group."
                return
            self._update_task(task_desc_string,
                              0,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status='Initiated',
                              output_of_task=str({"subResourceCount": count}))

            LOG.info("Number of parallel threads allowed to be spawn: %s", FLAGS.max_snapshot_create_threads_grouping)
            LOG.info("Number of items which has to snapshot %s", count)

            for workerThread in range(FLAGS.max_snapshot_create_threads_grouping):
                worker = threading.Thread(target=self.start_queuing_snapshot_create, args=(context, x_auth_token,
                                                                                           task_id, vm_task_helper,
                                                                                           body,
                                                                                           workerThread, count,
                                                                                           snapshot_queue,
                                                                                           success_list))
                worker.setDaemon(True)
                worker.start()

            snapshot_queue.join()
            task_desc_string = "Protection Group Snapshot creation process completed, " + str(
                len(success_list)) + ' out of ' \
                               + str(count) + ' Passed.'
            protected_res = {}
            LOG.info('all successful snapshots: ' + str(success_list))
            snapshot_set_list = map(lambda d: d['resourceId'], success_list)
            if snapshot_set_list:
                protected_vms = self.db.get_protected_vm_by_rmc_copyset_list(snapshot_set_list)
                protected_ds = self.db.get_protected_datastore_by_rmc_copyset_list(snapshot_set_list)
                protected_res['virtualmachines'] = map(
                    lambda vm: {"name": vm.name, "vmwareId": vm.moref, "id": vm.id, }, protected_vms)
                protected_res['datastores'] = map(lambda ds: {"name": ds.name, "vmwareId": ds.moref, "id": ds.id},
                                                  protected_ds)
                self.db.update_protection_group(context, protection_group_id, {'protected_resources': protected_res})
            LOG.info("protected resources in PG: " + str(protected_res))

        except Exception as e:
            task_desc_string = (_("An error while creating snapshot for Protection Group."))
            if (rmv_utils.get_error_message(e)):
                task_desc_string = rmv_utils.get_error_message(e)
            LOG.exception(e)

        finally:

            task_status = 'Ok'
            task_state = 'Completed'

            if len(success_list) == 0:
                task_status = 'Error'
                task_state = 'Failed'
                LOG.info('Moving task to Error state')

            elif len(success_list) < count:
                task_status = 'Warning'
                task_state = 'Warning'
                LOG.info('Moving task to Warning state')

            self._update_task(task_desc_string,
                              100,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper=vm_task_helper, task_status=task_status)

            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
            if notification_policy_id:
                email_notification = nu.SnapshotNotification(context, task_id, rmc_wrapper_service, pg, None,
                                                             "ProtectionGroup", "createSnapshot")
                email_notification.start()

    # Sachin VVOL Changes
    def create_rmv_snapshot_internal(self, context, vmware_db_id, x_auth_token, task_id, copy_id,
                                     request_body, isBackupCreation=False):
        '''
        Decides to create whether VMFS of VVOL snapshot
        Extracts the  VM info based on mo_ref
        '''
        # Step1: Using mo_ref in the request_body
        # Step2: Create Tasks (Vmware, TaskTracker, Newsfeed tasks)
        # Step3: if it is  Datastore call create_snapshot
        # Step4: else if its a VM, check the type using get_virtual_machine_details(mo_ref)
        # Step5: if VM type is VVOL then self.create_vvol_snapshot
        # Step6: Else call create_snapshot with the vmInfo from step5

        LOG.debug(_("create_rmv_snapshot : Enter"))
        try:
            if not self.vi_helper:
                self.initialize_vi_helper_object()
            vm_task_helper = VmTaskHelper(self.vi_helper)
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            rmv_snap_ret_info = {
                '_type': None,
                'snapshotSetId': None,
                'snapConfigObj': None,
                'snap_moref_list': None,
                'nonVolume': False,
                'recoverySetId': None,
                'snapInfo': None
            }
            obj_type = request_body['vmWareObjectType']
            mo_ref = request_body['vmWareMoref']
            type_for_vcenter_logevent = obj_type
            mo_ref_for_vcenter_logevent = mo_ref
            vmware_db_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, obj_type, mo_ref)
            recoverySetId = vmware_db_obj.get("recovery_set_id")
            # snapshot_db = self.db.get_record_based_on_mo_ref(context, mo_ref)
            # recoverySetId = snapshot_db.get('recoverysetid', None)
            notification_kwargs = {}

            notification_kwargs['snapshotName'] = request_body.get('snapshotName', 'No Name')
            task_percentage = 5
            vmInfo = None
            hostInfo = None
            ssID = None
            rmv_copy_id = None
            snap_config_obj = None
            vmVendor = None
            snap_moref_list = None
            ret_dict = {}

            obj_exists = self.check_if_object_exists(mo_ref, obj_type)
            if obj_exists:
                type_for_vcenter_logevent = obj_type
                mo_ref_for_vcenter_logevent = mo_ref
            else:
                LOG.debug("The parent object has either been removed or deleted, so proceeding with folder level task")
                # These 2 values are used for vCenter Events and Tasks logging
                type_for_vcenter_logevent = "Folder"
                mo_ref_for_vcenter_logevent = "group-d1"

            if obj_type == 'Datastore':
                vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_logevent,
                                                     mo_ref_for_vcenter_logevent,
                                                     "CreateVMVirtualCopyTask",
                                                     "CreateVMVirtualCopyFailedFault")
                task_state = 'Running'
                task_desc_string = "Initiating Datastore Snapshot Creation"
                task_percentage = 10
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                ret_dict = self.create_snapshot(context,
                                                vmware_db_id,
                                                x_auth_token,
                                                task_id,
                                                copy_id,
                                                request_body,
                                                hostInfo,
                                                vmInfo,
                                                isBackupCreation,
                                                vm_task_helper)

                if ret_dict:
                    ssID = ret_dict.get('snapshot_guid')
                    snap_config_obj = ret_dict.get('snap_config')
                    rmv_copy_id = ret_dict.get('rmvCopyId')

                rmv_snap_ret_info['_type'] = 'Datastore'
                rmv_snap_ret_info['snapshotSetId'] = ssID

            elif obj_type == 'VirtualMachine':

                # Create the tasks
                # Create a VMware Task
                vmLevelBackup = True
                vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_logevent,
                                                     mo_ref_for_vcenter_logevent,
                                                     "CreateVMVirtualCopyTask",
                                                     "CreateVMVirtualCopyFailedFault")

                task_state = 'Running'
                task_desc_string = "Getting Virtual Machine Information"
                task_percentage = 10
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                LOG.debug(_("Getting Virtual Machine information"))
                vmInfo, hostInfo = self.get_virtual_machine_details(mo_ref, vmLevelBackup)
                self.validate_virtual_machine_disk_details(vmInfo, hostInfo)

                vmType = vmInfo.VmType

                if vmType == json_helper.TpdVmHostFileSystemType.Vmfs:
                    LOG.debug(_("Calling Snapshot for VMFS"))

                    ret_dict = self.create_snapshot(context,
                                                    vmware_db_id,
                                                    x_auth_token,
                                                    task_id,
                                                    copy_id,
                                                    request_body,
                                                    hostInfo,
                                                    vmInfo,
                                                    isBackupCreation,
                                                    vm_task_helper)

                    if ret_dict:
                        ssID = ret_dict.get('snapshot_guid')
                        snap_config_obj = ret_dict.get('snap_config')
                        snap_moref_list = ret_dict.get('snap_moref_list')
                        rmv_copy_id = ret_dict.get('rmvCopyId')

                    # ssID is SnapshotSetId  used to get the snapshot info for backup
                    rmv_snap_ret_info['snapshotSetId'] = ssID
                    rmv_snap_ret_info['snap_moref_list'] = snap_moref_list

                elif vmType == json_helper.TpdVmHostFileSystemType.VVol:

                    task_state = 'Running'
                    task_desc_string = "Queued snapshot creation job"
                    task_percentage = 30
                    task_status = "Initiated"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    LOG.debug(_("Calling Snapshot create for VVOL"))
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_logevent, task_desc_string)
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_logevent,
                                            "Operation queued as the resource is busy")

                    self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_logevent,
                                            "Creating Snapshot for VM started")
                    ret_dict = self.create_vvol_snapshot(context,
                                                         vmware_db_id,
                                                         x_auth_token,
                                                         task_id,
                                                         copy_id,
                                                         request_body,
                                                         vmInfo,
                                                         vm_task_helper,
                                                         rmc_wrapper_service,
                                                         hostInfo)
                    if ret_dict:
                        rmv_snap_ret_info['snapshotSetId'] = ret_dict.get('snapshotSetId')
                        ssID = ret_dict.get('snapshotSetId')
                        rmv_copy_id = ret_dict.get('rmvCopyId')

                else:

                    task_desc_string = "Failed to create array Snapshot. Invalid datastore type. " \
                                       "Only 'VMFS or 'VVOL' type is supported."

                    # Bug Fix : 102546. In case of VM with no VMDK attached, is not supported.
                    if not vmType:
                        LOG.info("vmType is empty. No disks are attached to VM")
                        task_desc_string = "This VirtualMachine is not supported as it does " \
                                           "not have any virtual disk attached."
                    elif vmType == json_helper.TpdVmHostFileSystemType.Local:
                        vmType = rmv_utils.LOCAL_DISK_TYPE
                        task_desc_string = "The VM is not hosted on a 3PAR volume."
                    # elif vmType == json_helper.TpdVmHostFileSystemType.Nfs:
                    #    vmType = rmv_utils_DISK_TYPE
                    #    task_desc_string = "The VM is hosted on NFS Datastore which is not supported. RMC supports VMFS or VVOL Datastore."
                    else:
                        vmType = rmv_utils.UNKNOWN

                    task_state = 'Failed'
                    task_status = "Error"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    LOG.error(_("Invalid Diskformat - %s " % vmType))
                    # LOG.exception("Exception: %s", str(vmType))

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

                    # Commenting below LogEvent call, as the same event is logged using PostEvent
                    # self.vi_helper.LogEvent(mo_ref, obj_type, task_desc_string)

                rmv_snap_ret_info['_type'] = vmType
                # ssID is SnapshotSetId  used to get the snapshot info for backup
                rmv_snap_ret_info['snapshotSetId'] = ssID
                rmv_snap_ret_info['snapConfigObj'] = snap_config_obj
                rmv_snap_ret_info['snap_moref_list'] = snap_moref_list

        except Exception as e:
            msg = (_("Exception while creating snapshot"))
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
                LOG.exception("Exception: %s", str(e.msg))
            elif hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                msg = e.message
                LOG.exception("Exception: %s", str(msg))

            # If Exception the update Copy and Assoc table with error status
            snap_copy = self.db.get_rmcv_copy_by_id(context, copy_id)
            snap_copy.status = json_helper.copy_status.error
            snap_copy.name = request_body.get('snapshotName')
            self.db.update_rmcv_copy(context, copy_id, snap_copy)

            obj_type = request_body.get('vmWareObjectType')

            task_state = 'Failed'
            task_status = "Error"
            task_percentage = 100
            self._update_task(msg,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            LOG.error(_(msg))
            LOG.exception("Exception: %s", str(e))

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(msg)

            vm_task_helper.CustomVMwareTaskEnd("error", msg)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_logevent, msg)
            raise e

        finally:
            # incase of protection group we should not send notification on object level
            pg_id = None
            try:
                snap_copy = self.db.get_rmcv_copy_by_id(context, copy_id)
                pg_id = snap_copy.group_id
            except Exception as e:
                LOG.exception(e)
            if not pg_id:
                email_notification = nu.SnapshotNotification(context, task_id, rmc_wrapper_service, vmware_db_obj,
                                                             rmv_copy_id, obj_type, "createSnapshot")
                email_notification.send()

        LOG.debug(_("create_rmv_snapshot : Exit"))
        return rmv_snap_ret_info

    # TODO: Create kwargs for the list of params, to look neater
    def create_vvol_snapshot(self, context, vmware_db_id, x_auth_token, task_id, copy_id,
                             request_body, vmInfo, vm_task_helper, rmc_wrapper_service, host_info):
        '''
        Create snapshot of a VVOl type Virtual Machine
        '''

        LOG.debug(_("create_vvol_snapshot: Enter"))

        mo_ref = request_body['vmWareMoref']
        obj_type = request_body['vmWareObjectType']
        task_percentage = 35
        snap_id_list = None
        snapshotSet_id = None
        rmv_copy_id = None
        associated_data_list = []
        try:
            # RMC-V copy is already created in API layer only, so updating Associated data here
            # updating the associated_data for vvol vm snapshot creation task
            # This data we are using for listing tile count in UI, as we are not listing any copies on vvol container level
            # We should not update the associated data with vvol DS/container
            associated_data = {}
            associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_VM
            associated_data['resourceName'] = vmInfo.Name
            associated_data['resourceUri'] = vmInfo.VmMoref
            associated_data_list.append(associated_data)

            config_key = "config.hardware"
            snapshot_name = request_body['snapshotName']
            if request_body['isAppConsistent']:
                is_app_consistent = True
            else:
                is_app_consistent = False

            self.check_expiry_retention(request_body)

            LOG.info("Acquiring Create Snapshot lock on : '%s'" % mo_ref)
            lock_response = None
            lock_response = rmv_utils.acquire_snapshot_create_lock(mo_ref,
                                                                   self.vi_helper.validated_username, mo_ref)
            if lock_response:
                LOG.error("Could not acquire snapshot create lock.")
                raise rmv_exception.SnapshotLockException(error=lock_response)

            LOG.info("Locked Create Snapshot on : '%s'" % mo_ref)

            LOG.info(_("The vmware tools is vmInfo.VmWareToolsStatus %s") % vmInfo.VmWareToolsStatus)
            if (vmInfo.PowerState == "poweredOn") and is_app_consistent:
                vmware_checks.check_vmware_tools(vmInfo.VmWareToolsStatus,
                                                 vmInfo.Name)

            task_state = 'Running'
            task_status = "Initiated"
            task_desc_string = "Validating vCenter Registration and User Permissions"
            task_percentage = 40
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            self.vi_helper.LogEvent(mo_ref, obj_type, task_desc_string)

            # check whether vCenter is registered or not
            self.vcenter_registration_check()

            # check whether user has the permission to operate on the object
            self.vi_helper.has_required_entity_permission(obj_type, mo_ref)

            # Get the Virtual machine properties using the mo_ref.
            task_desc_string = "Getting the VM object property"
            task_status = "Initiated"
            self.vi_helper.LogEvent(mo_ref, obj_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            vm_prop_dict = self.vi_helper.get_object_prop_dict_pyvmomi(mo_ref,
                                                                       obj_type,
                                                                       config_key)

            # Extract WWN list of the base Datadisk of the VM.
            wwn_list = self.get_object_wwn_list_pyvmomi(vm_prop_dict,
                                                        config_key)
            LOG.info("Creating vvol snapshot of these wwns: " + str(wwn_list))

            array_name = vmInfo.ArrayName

            # Get the details of the registered array using array name.
            storage_system_details = self.get_rmc_registered_array_list(x_auth_token, array_name)

            # Extract the array information.
            array_ID = storage_system_details['ArrayID']
            array_Serial_Number = storage_system_details['ArraySerialNumber']
            array_IP = storage_system_details['ArrayIP']
            array_user = storage_system_details['ArrayUserName']
            device_type = storage_system_details['deviceType']

            license_status = \
                rmc_wrapper_service.check_array_license_by_appType_wrapper(
                    array_ID)
            LOG.info(_("The license status is %s") % license_status)
            if (not license_status):
                raise rmv_exception.RMCStorageSystemNotLicensedException(serial_num=array_ID)

            # Extract storage pool id
            storage_pools_list = rmc_wrapper_service.get_storage_pools(array_ID)
            # extract storage pool details from storage pool list
            storage_pool_id = self.select_pool_id(storage_pools_list, array_ID)

            # Get the database information based on mo_ref
            # snapshot_db = self.db.get_record_based_on_mo_ref(context, mo_ref)
            vmware_db_object = self.db_utils.get_vmware_object_by_object_type_and_moref(context,
                                                                                        rmv_utils.VMWARE_OBJECT_TYPE_VM,
                                                                                        mo_ref)

            recovery_set_id = vmware_db_object.get('recovery_set_id')

            # recoveryset_name = rmc_wrapper_service._get_recovery_set_name(vmInfo.Name, rmv_utils.VMWARE_OBJECT_TYPE_VM)
            recoveryset_name = rmv_utils.get_recoveryset_name(vmInfo.Name, rmv_utils.VMWARE_OBJECT_TYPE_VM)
            vmType = vmInfo.VmType

            # Define string constants in  RMVUtils
            if vmType == json_helper.TpdVmHostFileSystemType.VVol:
                vmType = rmv_utils.VVOL_DISK_TYPE

            if not recovery_set_id:
                task_state = 'Running'
                task_status = "Initiated"
                task_desc_string = "Setting up dependencies for snapshot creation"
                task_percentage = 60
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                self.vi_helper.LogEvent(mo_ref, obj_type, task_desc_string)
                recovery_set_details = rmc_wrapper_service.create_recovery_set(recoveryset_name,
                                                                               wwn_list,
                                                                               storage_pool_id,
                                                                               vmType,
                                                                               task_id=task_id,
                                                                               device_type=device_type)
                recovery_set_id = recovery_set_details['id']
                # mo_uuid = vmInfo.InstanceUUID
                # update DB with recovery set ID and VM/DS UUID
                # options = { 'recoverysetid': recovery_set_id, 'mo_uuid': mo_uuid }
                # self.db.snapshot_update(context, snapshot_id, options)
                options = {'recovery_set_id': recovery_set_id, 'recovery_set_name': recoveryset_name}
                self.db_utils.update_vmware_object(context, vmware_db_id, rmv_utils.VMWARE_OBJECT_TYPE_VM, options)
                LOG.debug(_("Updated the recovery set id to the rmv snapshot database"))
            else:
                # If it is a nimble vvol, rmc core will be adding vm config lun automatically in the recovery set during recovery set creation
                # so during second time onwards snapshot creation  we should not remove this lun from recovery set
                if device_type.lower() == rmv_utils.storage_device_types.NIMBLE:
                    response_data = rmc_wrapper_service.get_recovery_set(recovery_set_id)
                    recovery_set_details = response_data['recoverySet']
                    volumes = recovery_set_details.get("volumes", [])
                    for vol in volumes:
                        name = vol.get("name", "")
                        if ".vmdk" in name:
                            continue
                        else:
                            if vol.get("app_uuid", ""):
                                wwn_list.append(vol.get("app_uuid", ""))
                    LOG.info("Final wwn list:%s", wwn_list)

                rmc_wrapper_service.update_rmc_recovery_set(recovery_set_id, wwn_list, vm_type=vmType)

                # TODO: Get Full config details and update to the RMV database. Needed for backup

            task_state = 'Running'
            task_status = "Initiated"
            task_desc_string = "Creating VM snapshot"
            task_percentage = 70
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            LOG.debug(_("recovery_set_id: %s") % recovery_set_id)
            vm_name_moref_dict = dict()
            vm_mo_ref_uuid_dict = dict()
            # As the function needs moref in list, converting the input param moref to list
            vm_mo_ref_list = [mo_ref]
            vm_name_moref_dict[mo_ref] = vmInfo.Name
            vm_mo_ref_uuid_dict[mo_ref] = vmInfo.Uuid

            # create VMFS snapshot
            # Get the snapshot name if not create it with default format
            # If Snapshot name is not given then create a snapshot name and
            # assign it to VcSetName
            if not snapshot_name:
                snapshot_name = rmc_wrapper_service.get_recovery_set_snapshot_name(vmInfo.Name)

            ## Applying numeric policy if it is set

            snap_id_list = self.vi_helper.CreateVmfsSnapshot(
                vm_mo_ref_list,
                snapshot_name,
                rmv_utils.VVOL_SNAPSHOT_DESCRIPTION,
                False,
                is_app_consistent, vm_name_moref_dict, vm_mo_ref_uuid_dict)

            task_state = 'Running'
            task_status = "Initiated"
            task_desc_string = "Getting properties of the snapshot created"
            task_percentage = 80
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            snapshot_moref = None
            snapshot_type = None
            for snap in snap_id_list:
                snapshot_moref = snap._moId
                snapshot_type = snap._wsdlName
                LOG.info(_("Getting properties for the snapshot %s") % snap)
                snap_obj_prop = self.vi_helper.get_object_prop_dict_pyvmomi(snap._moId, snap._wsdlName, config_key)
                snap_wwn_list = self.get_object_wwn_list_pyvmomi(snap_obj_prop,
                                                                 config_key)
                LOG.info(_("Snapshot WWN to be imported %s" % snap_wwn_list))
                # Build the client data for the snapshotId

            # Call RMC Import with the snap_wwn_list
            # Calling the snapshotset import function to RMC
            import_snap_resp = rmc_wrapper_service.import_vvol_snapshot(snapshot_name,
                                                                        recovery_set_id,
                                                                        snap_wwn_list,
                                                                        x_auth_token, task_id)

            # snapshotSet_id = import_snap_resp['task']['associatedResource']['resourceUri'].split('/')[5]
            # LOG.info(_("Sanpshot set ID is : %s" % snapshotSet_id))

            resource_uri = import_snap_resp['task']['associatedResource']['resourceUri']
            snapshotSet_id = resource_uri.split('/')[5]
            LOG.info("Sanpshot set ID is : %s" % snapshotSet_id)

            # task_state = 'Running'
            # task_status = "Ok"
            # task_desc_string = "Updating the metadata"
            # task_percentage = 90
            # self._update_task(task_desc_string,
            #                  task_percentage,
            #                  task_state,
            #                  task_id,
            #                  rmc_wrapper_service,
            #                  vm_task_helper,task_status=task_status,
            #                  resource_uri=resource_uri)

            # Pull the details and update clientdata to the snapshot

            # TODO: To be looked into this block when we refactor the client_data for snapshot
            # clientdata_info_dict = {}
            # clientdata_info_dict['SnapshotsetID'] = snapshotSet_id
            # clientdata_info_dict['ArrayID'] = array_ID
            # clientdata_info_dict['ArrayIP'] = array_IP
            # clientdata_info_dict['ArraySerialNumber'] = array_Serial_Number
            # clientdata_info_dict['BasewwnList'] = wwn_list
            # clientdata_info_dict['SnapwwnList'] = snap_wwn_list
            # clientdata_info_dict['IsAppConsistent'] = is_app_consistent
            # clientdata_info_dict['vmType'] = vmType
            # clientdata_info_dict['snapshot_moref'] = snapshot_moref
            # clientdata_info_dict['CreatedArrayUserName'] = array_user
            # clientdata_info_dict['Vendor'] = vmInfo.Vendor
            # clientdata_info_dict['snapshot_type'] = snapshot_type
            #
            # self.build_client_data_for_vvol(context,
            #                                 x_auth_token,
            #                                 clientdata_info_dict,
            #                                 vmInfo)

            # try:
            snapshot_details = rmc_wrapper_service.get_snapshot(snapshotSet_id)
            snapshot_set = snapshot_details.get('snapshotSet')
            if not snapshot_set:
                pass  # TODO:6.0 decide what to do here

            ds_list_in_vm = host_info.DatastoreDict.values()

            # Constructing object to insert into table
            vm_table_obj = json_helper.vm_table()
            vm_table_obj.moref = vmInfo.VmMoref
            vm_table_obj.name = vmInfo.Name
            vm_table_obj.vmware_uuid = vmInfo.InstanceUUID
            vm_table_obj.volume_type = vmType
            vm_table_obj.vcenter_uuid = self.vi_helper.vcenteruid
            vm_table_obj.host_name = ds_list_in_vm[0].host_name
            vm_table_obj.host_id = ds_list_in_vm[0].host_mo_id
            vm_table_obj.datacenter_name = ds_list_in_vm[0].datacenter_name
            vm_table_obj.datacenter_id = ds_list_in_vm[0].datacenter_mo_id
            vm_table_obj.status = json_helper.copy_status.available
            vm_table_obj.guest_os = vmInfo.guest_os

            vm_table_response = self.db.create_or_update_rmcv_vm(context, vmInfo.VmMoref, vm_table_obj.__dict__)

            # in case od VM snap, updating its corresponding DS entry in table
            for ds_info in ds_list_in_vm:
                ds_type = rmv_utils.DISK_TYPE.get(ds_info.DatstoreType)
                if ds_type != rmv_utils.VVOL_DISK_TYPE:
                    LOG.info("vvol vm must have only vvol ds, found: " + str(ds_type) + " so ignoring")
                    continue
                ds_table_obj = json_helper.ds_table()
                ds_table_obj.volume_type = ds_type
                ds_table_obj.moref = ds_info.DatastoreMoref
                ds_table_obj.vcenter_uuid = self.vi_helper.vcenteruid
                ds_table_obj.vmware_uuid = ds_info.vvolUuid
                ds_table_obj.storage_vendor = vmInfo.Vendor
                ds_table_obj.status = json_helper.copy_status.available
                ds_table_obj.host_name = ds_info.host_name
                ds_table_obj.host_id = ds_info.host_mo_id
                ds_table_obj.datacenter_name = ds_info.datacenter_name
                ds_table_obj.datacenter_id = ds_info.datacenter_mo_id
                ds_table_response = self.db.create_or_update_rmcv_ds(context,
                                                                     ds_info.DatastoreMoref,
                                                                     ds_table_obj.__dict__)

            # copies_table_obj = json_helper.copies_table()
            copies_table_obj = self.db.get_rmcv_copy_by_id(context, copy_id)
            copies_table_obj.name = snapshot_name  # TODO:6.0 we should get it from RMC as RMC is creating it. Verify.
            copies_table_obj.rmc_copyset_id = snapshotSet_id
            copies_table_obj.point_in_time = snapshot_set.get('createdAt')
            copies_table_obj.array_name = vmInfo.ArrayName
            copies_table_obj.array_serial_number = array_Serial_Number
            copies_table_obj.vmfs_snap_moref = snapshot_moref
            copies_table_obj.type = rmv_utils.copy_type.SNAPSHOT
            copies_table_obj.status = snapshot_set.get('status')
            copies_table_obj.vmfs_snap_count = request_body.get('snapCount')
            copies_table_obj.version = self.rmc_version
            # copies_table_obj.base_vol_wwn_list = wwn_list

            # copies_table_response = self.db.create_rmcv_copy(copies_table_obj.__dict__)
            self.db.update_rmcv_copy(context, copy_id, copies_table_obj)

            for associated_data in associated_data_list:
                associated_data['status'] = snapshot_set.get('status')
                associated_data['errorReason'] = None

            rmv_copy_id = copy_id
            resource_uri = "/rest/rm-central/rmv/v1/copies/" + copy_id
            task_state = 'Running'
            task_status = "Initiated"
            task_desc_string = "Updating the metadata"
            task_percentage = 90
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status,
                              resource_uri=resource_uri)
            # TODO:6.0 update vmdk table once clarity on WWN list updation
            # VVOL snapshot is specific to a VM and we can't refer this to other VM or DS as partial snapshots.
            # So updating only VM assoc table.
            mo_assoc_table_obj = json_helper.vm_copies_assoc_table()
            mo_assoc_table_obj.virtual_machine_id = vm_table_response.id
            mo_assoc_table_obj.copy_id = copy_id
            mo_assoc_table_obj.is_app_consistent = is_app_consistent
            # mo_assoc_table_obj.vmdks = None

            # This assoc entry in already created in API layer. So updating it here.
            self.db.update_rmcv_vm_copy_assoc(context, copy_id, mo_assoc_table_obj.virtual_machine_id,
                                              mo_assoc_table_obj.__dict__)

            # # TODO:6.0 need to handle the exception properly.
            # except Exception as e:
            #     # Just log the exception and do not raise it back. Once we remove CD then Exception can be handled.
            #     LOG.exception(e)

            self.apply_numeric_policy(context,
                                      request_body,
                                      recovery_set_id,
                                      rmc_wrapper_service,
                                      x_auth_token,
                                      task_id)

            # update DB with snap details

            task_state = 'Completed'
            task_status = "Ok"
            task_desc_string = "Snapshot created successfully"
            task_percentage = 100
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status,
                              resource_uri=resource_uri,
                              associated_data=associated_data_list)
            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
            self.vi_helper.LogEvent(mo_ref, obj_type, task_desc_string)

        except Exception as e:
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                # Giving a appropriate error message to user instead of Snapshot hierarchy is too deep error message
                if rmv_utils.VVOL_SNAPSHOT_CREATE_FAILED in e.msg:
                    task_desc_string = rmv_utils.VVOL_SNAPSHOT_EXCEPTION_MSG
                    LOG.exception("Exception: %s", task_desc_string)
                else:
                    task_desc_string = e.msg
                    LOG.exception("Exception: %s", str(e.msg))
            elif hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                if rmv_utils.VVOL_SNAPSHOT_CREATE_FAILED in e.message:
                    task_desc_string = rmv_utils.VVOL_SNAPSHOT_EXCEPTION_MSG
                    LOG.exception("Exception: %s", task_desc_string)
                else:
                    task_desc_string = e.message
                    LOG.exception("Exception: %s", str(e.message))
            else:
                LOG.error(('%s'), str(e))
                task_desc_string = "VVOL Snapshot creation failed. Cleaning-Up..."
                LOG.exception("Exception: %s", task_desc_string)
            task_state = 'Failed'
            task_status = "Error"
            LOG.error(_(task_desc_string))

            for associated_data in associated_data_list:
                associated_data['status'] = "error"
                associated_data['errorReason'] = task_desc_string

            # If Exception the update Copy and Assoc table with error status
            snap_copy = self.db.get_rmcv_copy_by_id(context, copy_id)
            snap_copy.status = json_helper.copy_status.error

            snapshot_set = {}
            if snapshotSet_id:
                try:
                    rmc_wrapper_service = rmc_wrapper.rmc_wrapper(None)
                    snapshot_details = rmc_wrapper_service.get_snapshot(snapshotSet_id)
                    snapshot_set = snapshot_details.get('snapshotSet')
                    snap_copy.name = snapshot_set.get('name')
                    snap_copy.point_in_time = snapshot_set.get('createdAt')

                except Exception as e:
                    LOG.exception(e)

            snap_copy.rmc_copyset_id = snapshotSet_id
            self.db.update_rmcv_copy(context, copy_id, snap_copy)

            # vm_copies_assoc_list = self.db.get_all_rmcv_vm_copy_assoc_by_copy_id(context, copy_id)
            #
            # if vm_copies_assoc_list:
            #     # If Assoc entries is already present then no need to update again
            #     # as its copies table is updated with 'error' status
            #     pass
            # else:
            #     # If no assoc then add an entry for the object on which the snapshot operation is requested.
            #     vm_copies_assoc_obj = json_helper.vm_copies_assoc_table()
            #     vm_copies_assoc_obj.virtual_machine_id = vmware_db_id
            #     vm_copies_assoc_obj.copy_id = copy_id
            #     self.db.create_rmcv_vm_copy_assoc(vm_copies_assoc_obj.__dict__)

            if snapshotSet_id:
                self.delete_snapshot(context, snapshotSet_id, obj_type, mo_ref, x_auth_token, task_id)
            elif snap_id_list:
                self.vi_helper.Delete_vmfs_snapshot(snap_id_list, False)

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status, associated_data=associated_data_list)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            # Commenting below LogEvent call, as the same event is logged using PostEvent
            # self.vi_helper.LogEvent(mo_ref, obj_type, task_desc_string)
            return
        finally:
            if mo_ref:
                rmv_utils.release_snapshot_create_lock(mo_ref)
                LOG.info(("Released Lock for object '%s'") % mo_ref)
        LOG.debug(_("create_vvol_snapshot: Exit"))
        return {'snapshotSetId': snapshotSet_id, 'rmvCopyId': rmv_copy_id}

    def get_snapshot_notification(self, context, rmc_wrapper_service,
                                  notification_kwargs):

        """
        creates Notification object including Email msg for rmcv snapshot

        :param kwargs: list of args as dict
        :return: notifaction obj

        """
        LOG.info("getting Notification contents for snapshot")
        notification_body = None
        notificationType = 'info'
        try:
            eventType = notification_kwargs.get('eventType', None)
            vmwObjType = notification_kwargs.get('vmwObjType', None)
            vmwObjName = notification_kwargs.get('vmwObjName', None)
            rmcvTaskId = notification_kwargs.get('rmcvTaskId', None)
            snapshotName = notification_kwargs.get('snapshotName', 'No Name').strip()

            if snapshotName is None or snapshotName == '':
                snapshotName = 'No Name'
            recoverySetId = notification_kwargs.get('recoverySetId', None)

            if not recoverySetId:
                LOG.error('No recovery set Id returning')
                return None
            msg_dict = {}
            if eventType is None:
                LOG.error('No event type returning')
                return None
            eventType = eventType.strip()
            if eventType == 'deleteSnapshot':
                event_name = 'Delete Snapshot'
            elif eventType == 'createSnapshot':
                event_name = 'Create Snapshot'
            elif eventType == 'restoreSnapshot':
                event_name = 'Restore from Snapshot'
            else:
                event_name = eventType
            subject = str(event_name)

            if vmwObjType and vmwObjName:
                vmwObjName = vmwObjName.strip()
                vmwObjType = vmwObjType.strip()
                partialSub = " for " + str(vmwObjType) + ": " + str(vmwObjName)
                if vmwObjType == 'Datastore':
                    msg_dict['Datastore Name'] = vmwObjName
                elif vmwObjType == 'VirtualMachine':
                    msg_dict['Virtual machine name'] = vmwObjName
                elif vmwObjType.lower() == 'remotecopy':
                    LOG.info('RC snap notification...')
                    partialSub = " for RC group:" + str(vmwObjName)
                else:
                    msg_dict[vmwObjType] = vmwObjName
                subject = subject + partialSub

            if rmcvTaskId:
                rmcvTaskResponse = \
                    rmc_wrapper_service.get_copy_task_status(rmcvTaskId)[
                        'task']
                # msg_dict['Task state'] = rmcvTaskResponse.get('taskState')
                # msg_dict['Task name'] = rmcvTaskResponse.get('name')
                # msg_dict['description'] = 'Notification from RMC-V'
                if rmcvTaskResponse.get('taskState').lower() == 'error':
                    msg_dict['Error'] = nu.getLatestProgressMsg(rmcvTaskResponse)
                else:
                    msg_dict['Status'] = nu.getLatestProgressMsg(rmcvTaskResponse)
                # msg_dict['Percentage completed'] = rmcvTaskResponse.get('completedPercentage')

            taskState = rmcvTaskResponse.get('taskState', 'completed').lower()

            msg_dict['Snapshot Name'] = snapshotName
            stateMsg = taskState
            if taskState == 'error':
                notificationType = 'error'
                stateMsg = 'Failed'
            else:
                notificationType = 'info'

            subject = "RMCV task [" + str(stateMsg).lower() + "]: " + subject

            if recoverySetId:
                rs_body = rmc_wrapper_service.get_recovery_set(
                    recoverySetId)['recoverySet']

            notificationId = rs_body['notificationPolicyId']
            if notificationId is None or notificationId == "":
                LOG.error('No notification for RSId: ' + str(recoverySetId))
                notification_body = None
                return notification_body
            notification_body = {
                "notificationPolicyId": notificationId,
                "subject": subject,
                "messageBody": self.get_notification_msg_by_dict(msg_dict),
                'notificationType': notificationType,
                'rmcvTaskBody': rmcvTaskResponse

            }
        except Exception as e:
            LOG.exception(e)

        finally:
            LOG.debug("Notification Body: " + str(notification_body))
            return notification_body

    def get_object_wwn_list(self, prop_dict, config_key):
        '''
        Get the list of WWNs from object property
        object may be cfg/dat/snp
        '''

        LOG.debug(_("get_object_wwn_list : Enter "))

        wwn_list = []
        ret_wwn = []
        try:
            for x in prop_dict[config_key].device:
                vDisk = x
                # If Type of current vDisk is not equal to "VirtualDisk", then
                #  do not process the vDisk
                if vDisk.__class__.__name__ != "VirtualDisk":
                    continue

                if operator.ne(vDisk, None):
                    boID = vDisk.backing.backingObjectId
                    if boID.startswith(rmv_utils.NIMBLE_APP_UUID_BEGIN):
                        # A specific string indicate nimble  app_uuid
                        wwn_list.append(boID)
                    else:
                        boID = vDisk.backing.backingObjectId[4:]
                        wwn_list.append(boID)

            for wwn in wwn_list:
                ret_wwn.append(wwn.upper())
            LOG.info(_("The wwn is ret_wwn %s") % ret_wwn)

        except Exception as e:
            msg = (_("Exception while getting wwn list"))
            LOG.error(_(msg))
            LOG.exception("Exception: %s", str(e))
            raise Exception(rmv_utils.VVOL_VM_WITH_RDM_LUN)

        return ret_wwn

    def get_object_wwn_list_pyvmomi(self, prop_dict, config_key):
        '''
        Get the list of WWNs from object property
        object may be cfg/dat/snp
        '''

        LOG.debug(_("get_object_wwn_list : Enter "))

        wwn_list = []
        ret_wwn = []
        try:
            for x in prop_dict[config_key].device:
                vDisk = x
                # If Type of current vDisk is not equal to "VirtualDisk", then
                #  do not process the vDisk
                if vDisk.__class__.__name__ != "vim.vm.device.VirtualDisk":
                    continue

                if operator.ne(vDisk, None):
                    boID = vDisk.backing.backingObjectId
                    if boID.startswith(rmv_utils.NIMBLE_APP_UUID_BEGIN):
                        # A specific string indicate nimble  app_uuid
                        wwn_list.append(boID)
                    else:
                        boID = vDisk.backing.backingObjectId[4:]
                        wwn_list.append(boID)

            for wwn in wwn_list:
                ret_wwn.append(wwn.upper())
            LOG.info(_("The wwn is ret_wwn %s") % ret_wwn)

        except Exception as e:
            msg = (_("Exception while getting wwn list"))
            LOG.error(_(msg))
            LOG.exception("Exception: %s", str(e))
            raise Exception(rmv_utils.VVOL_VM_WITH_RDM_LUN)

        return ret_wwn

    def get_rmc_registered_array_list(self, x_auth_token, ArrayName):
        '''
        Here we match the array registered in the RMC with array registered in vCenter
        using the name of the array (array_Name)
        '''

        LOG.debug(_("get_associated_array_details : Enter "))

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            storagelist = rmc_wrapper_service.get_storage_system_details()

            storage_system_details = {}
            LOG.info("Storage Array name from the vCenter:'%s'" % ArrayName)
            for list_item in storagelist:
                for storage_array in storagelist[list_item]:
                    LOG.info("Storage Array name from the RMC:'%s'" % storage_array.get('name'))
                    if ArrayName.lower() == storage_array.get('name', "").lower():
                        storage_system_details['ArraySerialNumber'] = storage_array['serialNumber']
                        storage_system_details['ArrayIP'] = storage_array['ipHostname']
                        storage_system_details['ArrayID'] = storage_array['id']
                        storage_system_details['ArrayUserName'] = storage_array['username']
                        storage_system_details['deviceType'] = storage_array['deviceType']
                        break

            # This would enable us to raise if there is no
            # storage system registered in the RMC
            if not storage_system_details:
                raise

        except Exception as e:
            msg = (_("Exception in getting the RMC registered array list"))
            LOG.error(_(msg))
            LOG.exception("Exception: %s", str(e))

            raise rmv_exception.RMCStorageSystemNotRegisteredException(
                serial_num=ArrayName)

        LOG.debug(_("get_associated_array_details : Exit "))

        return storage_system_details

    def get_storage_system_pool_id(self, storage_pools_details, protocol_used=rmv_utils.FC_PROTOCOL):
        '''
        Extract the storage pool id from storage pools list
        Depending on the protocol(FC) of the corresponding PE
        '''

        LOG.debug(_("get_storage_provider_pool_id : Enter "))
        pool_id = None

        try:
            for storage_pool in storage_pools_details:
                # TODO try to get the protocol from PE and then get the corresponding pool id.
                if storage_pool['protocol'] == protocol_used:
                    pool_id = storage_pool['id']
                    break
            if pool_id is None:
                raise

        except Exception as e:
            msg = (_("Received an exception while inspecting the storage pools"))
            LOG.error(_(msg))
            LOG.exception("Exception: %s", str(e))
            raise Exception(msg)

        LOG.debug(_("get_storage_provider_pool_id : Exit "))
        return pool_id

    def select_pool_id(self, storage_pools_details, array_serial_number):
        '''
        Select the 1st pool id in the storage pool list
        :param storage_pools_details: List of storage pools from the array
        :param array_serial_number: array serial number
        :return: pool id
        '''
        LOG.info(_("select_pool_id : Enter"))
        pool_id = None
        if len(storage_pools_details) > 0:
            pool_id = storage_pools_details[0]['id']
        else:
            raise rmv_exception.StoragePoolNotAvailableException(
                serial_num=array_serial_number)
        LOG.info(_("select_pool_id : Exit "))
        return pool_id

    def vcenter_registration_check(self):
        '''
        check whether vCenter is registered or not
        '''

        try:
            if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                LOG.info("vCenter not initialized. Let's do it")
                with self.lock:
                    self.vi_helper = ViHelper()

                    # DB could be empty
                    if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                        msg = "Please make sure vCenter is registered with RMC-V"
                        LOG.error(msg)
                        raise Exception(msg)
            return True
        except Exception as e:
            msg = "vCenter session could not be initialized. Please make sure" \
                  " vCenter is registered with RMC-V and accessible"
            raise Exception(msg)

    # def build_client_data_for_vvol(self, context, x_auth_token, clientdata_info_dict, vmInfo):
    #     '''
    #     Building client data for vvol snapshot
    #     '''
    #
    #     LOG.debug(_('Building Client Data for snapshot: Enter'))
    #
    #     try:
    #         rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
    #         vm_type = "VirtualMachine"
    #         snap_info = rmv_structures.SnapshotInfo()
    #         snap_info.CreatedVcUserName = self.vi_helper.validated_username
    #         snap_info.VirtualCenterUrl = self.vi_helper.service_url
    #         snap_info.VmWareObjectName = vmInfo.Name
    #         snap_info.VmWareObjectType = vm_type
    #         snap_info.ObjectUUID = vmInfo.Uuid
    #         snap_info.ObjectRefID =  vmInfo.VmMoref
    #         # snap_info.ExpiryInSeconds = None
    #         # snap_info.RetentionInSeconds = None
    #         snap_info.SnapshotGuid = clientdata_info_dict['SnapshotsetID']
    #         # snap_info.Expirable = False
    #         snap_info.ArrayName = vmInfo.ArrayName
    #         #snap_info.ArrayId = clientdata_info_dict['ArrayID']
    #         #snap_info.ArrayIp = clientdata_info_dict['ArrayIP']
    #         snap_info.ArraySerialNum = clientdata_info_dict['ArraySerialNumber']
    #         snap_info.ArrayBaseVolumeWwnDict = clientdata_info_dict['BasewwnList']
    #         snap_info.ArraySnapVolumeWwnDict = clientdata_info_dict['SnapwwnList']
    #         snap_info.IsAppConsistent = clientdata_info_dict['IsAppConsistent']
    #         snap_info.VmType = clientdata_info_dict['vmType']
    #         snap_info.SnapshotMoref = clientdata_info_dict['snapshot_moref']
    #         snap_info.CreatedArrayUserName = clientdata_info_dict['CreatedArrayUserName']
    #         snap_info.DsNameList = vmInfo.DsNameList
    #         snap_info.snapshot_type = clientdata_info_dict['snapshot_type']
    #
    #         VirtualCopyList = []
    #         for wwn in range(len(clientdata_info_dict['BasewwnList'])):
    #             VirtualCopyList.append({clientdata_info_dict['BasewwnList'][wwn] : clientdata_info_dict['SnapwwnList'][wwn]})
    #         VirtualCopyList.append({'Vendor':clientdata_info_dict['Vendor']})
    #
    #         snap_info.VirtualCopyList = VirtualCopyList
    #
    #         #Get Snapshot details by doing a get on snapshotSet
    #         # TODO: Need to revisit this GET for VVOL Type function
    #
    #         snapshot_details = rmc_wrapper_service.get_snapshot(snap_info.SnapshotGuid)
    #         snap_info.snapshot_timestamp = snapshot_details['snapshotSet']['createdAt']
    #         snap_info.CreationTime = snapshot_details['snapshotSet']['createdAt']
    #         snap_info.VcSetName = snapshot_details['snapshotSet']['name']
    #         json_snap_info = jsonutils.dumps(snap_info.__dict__)
    #         LOG.info(_('Update Client Data in RMC'))
    #         rmc_wrapper_service.update_snapshot(snap_info.SnapshotGuid, snapshotClientData=json_snap_info)
    #
    #     except Exception as e:
    #         if hasattr(e, "msg"):
    #             LOG.error(('%s'), e.msg)
    #             msg = e.msg
    #         else:
    #             LOG.error(('%s'), e)
    #             msg = "Received an exception while building snapshot metadata information"
    #         raise Exception(msg)
    #
    #     LOG.debug(_('Building CLient Data for snapshot: Exit'))
    #
    #     return True

    def check_expiry_retention(self, request_body):
        """
        VVOL does not support expiryInSeconds and retentionInSeconds
        """

        LOG.debug(_('check_expiry_retention: Enter'))

        if not (('expiryInSeconds' in request_body) or ('retentionInSeconds' in request_body)):
            return True
        else:
            if ((request_body['expiryInSeconds'] == -1) or (request_body['retentionInSeconds'] == -1)):
                LOG.info(_("Specified the expiryInSeconds or retentionInSeconds may be a call from scheduler"))
                # deleting the keys from the request body
                request_body.pop("expiryInSeconds", None)
                request_body.pop("retentionInSeconds", None)
            else:
                msg = "Expiry and retention policies are not supported for snapshots of vvol volume type"
                raise Exception(msg)

    def sort_by_date(self, ret_snapshot):
        # Need to look @ created-at coloumn instead of client_data
        if 'CreationTime' in ret_snapshot:
            return ret_snapshot['CreationTime']
        else:
            return

    def get_snapshots_sorted(self, response_data):
        """
        Returns the List of Snapshots
        """
        LOG.debug("get_snapshots : Enter")
        # default_repo_username = "rm"
        snapshot_result = {}
        snapshot_list = []
        # response_data is a List of all records.
        for temp in response_data['snapshotSets']:
            if 'clientData' in temp:
                json_client_data = temp['clientData']
                dict_client_data = jsonutils.loads(json_client_data)
                LOG.info(_('The client data is %s') % dict_client_data)
                snapshot_list.append(dict_client_data)
        # Sorting Snapshots based on Creation Time.
        ret_snapshots_sorted = sorted(snapshot_list, key=self.sort_by_date)
        snapshot_result["SnapshotArray"] = ret_snapshots_sorted

        LOG.debug("Snapshot Result List '%s'", snapshot_result)
        LOG.debug("get_snapshots : Exit")
        return ret_snapshots_sorted

    def apply_numeric_policy(self, context,
                             request_body,
                             recoveryset_id,
                             rmc_wrapper_service,
                             x_auth_token,
                             task_id,
                             snap_count=None):
        LOG.info(_("apply numeric policy enter"))

        try:
            LOG.debug(_("Trying to apply numeric policy"))
            # refresh the recovery set before start applying policy
            response_data = None
            try:
                response_data = rmc_wrapper_service.array_refresh(context, recoveryset_id)
            except Exception as exc:
                if hasattr(exc, "message"):
                    LOG.error(('%s'), exc.message)
                else:
                    LOG.error(('Caught Exception in Recovery set refresh - %s'), exc)

            if response_data:
                response_data = rmc_wrapper_service.rmc_low_level.wait_on_task(response_data)

            # From 6.0, snapCount and removeOldestSnap is sent in request body by executor.
            if not snap_count:
                snap_count = request_body.get('snapCount')
            remove_oldest = request_body.get('removeOldestSnap')
            mo_ref = request_body['vmWareMoref']
            obj_type = request_body['vmWareObjectType']

            if snap_count == 0:
                LOG.info(_("Numeric Policy is not set"))
                return True

            LOG.info(_("The snap_count is %s") % snap_count)

            # Time to delete all older snapshots
            # snapshots_in_db = rmc_wrapper_service.get_snapshots_by_recoveryset(recoveryset_id)
            # num_of_snapshot_exist = int(len(snapshots_in_db['snapshotSets']))
            vmware_db_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, obj_type, mo_ref)
            vmware_obj_id = vmware_db_obj.id
            copy_type = rmv_utils.copy_type.SNAPSHOT
            snapshots_in_rmcv_db = self.db.get_vm_copies_by_id(context, vmware_obj_id, copy_type)
            snapshots_in_db = [snap for snap in snapshots_in_rmcv_db]
            num_of_snapshot_exist = int(len(snapshots_in_db))

            if not snapshots_in_db:
                LOG.info(_("There is no snapshot to delete"))
                return True

            if num_of_snapshot_exist < snap_count:
                LOG.info(_("The number of snapshot is less than max snapshot"))
                return True

            # delete the oldest snapshot from vmfs
            LOG.info(_("The number of snapshots in db is %s") % num_of_snapshot_exist)
            LOG.info(_("The numeric policy set is %s") % snap_count)

            snapshot_to_delete = num_of_snapshot_exist - snap_count
            # snapshot_list = []
            # snapshotSets = snapshots_in_db['snapshotSets']

            # ret_snapshots_sorted = self.get_snapshots_sorted(snapshots_in_db)
            # LOG.info(_("The ret_sapshot_sorted is %s")%ret_snapshots_sorted)

            if snapshot_to_delete != 0 and remove_oldest == False:
                msg = "Snapshot count exceeds the set numeric policy"
                raise Exception(msg)

            for snaps in snapshots_in_db:
                if snapshot_to_delete != 0:
                    LOG.info(_("Applying Numeric Policy **** %s") % snapshot_to_delete)
                    LOG.info(_("Applying Numeric Policy ****** %s") % snaps)
                    # snapshot_guid_to_del = snaps['SnapshotGuid']
                    snapshot_guid_to_del = snaps.id
                    task_input = dict()
                    task_input['name'] = 'RMC-V Snapshot Deletion'
                    task_input['action'] = 'Delete'
                    task_input['resourceType'] = 'Snapshot'
                    task_input['resource_category'] = 'snapshots'
                    task_input['resource_id'] = snapshot_guid_to_del
                    task_input['resource_name'] = self.db_utils.get_resource_name(context, snapshot_guid_to_del,
                                                                                  rmv_utils.rmcv_copy_types.COPY)
                    task_input['parentResourceName'] = vmware_db_obj.name if vmware_db_obj else "Vmware"

                    snap_del_task = self._create_child_task(rmc_wrapper_service, task_id, task_input)
                    self.delete_snapshot(context, snapshot_guid_to_del, obj_type, mo_ref, x_auth_token, snap_del_task)
                    snapshot_to_delete = snapshot_to_delete - 1
                else:
                    break

        except Exception as e:
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Caught Exception in apply_numeric_policy"
            raise Exception(msg)

        LOG.debug(_("apply numeric policy: Exit"))
        return

    def _create_child_task(self, rmc_wrapper_service, parent_task_id, task_input):
        kwargs = {}
        kwargs['name'] = task_input.get('name')
        kwargs['owner'] = 'RMC-V User'
        kwargs['task_state'] = 'New'
        kwargs['task_type'] = 'User'
        kwargs['association_type'] = 'IS_A'
        kwargs['resource_id'] = task_input.get('resource_id')
        kwargs['action'] = task_input.get('action')
        kwargs['resourceType'] = task_input.get('resourceType')
        kwargs['resource_name'] = task_input.get('resource_name')
        kwargs['resource_category'] = task_input.get('resource_category')
        kwargs['total_steps'] = rmv_utils.TOTAL_TASK_TRACKER_STEPS
        kwargs['parentTaskId'] = parent_task_id
        kwargs['parentResourceName'] = task_input.get('parentResourceName')
        created_task_id = ''

        try:
            response_data = rmc_wrapper_service.create_task(kwargs)
            created_task_id = response_data['id']
        except Exception as e:
            LOG.exception(e)
            msg = "Failed to create sub task. Please check if TaskTracker service is running"
            raise Exception(msg)
        return created_task_id

    def check_vmfs_snapshot_present(self, mo_ref):
        """
        This function checks for the presence of the snapshot property attribute
        in mob.
        :param mo_ref:
        :return: True if VMFS snapshots are present, false if no  VMFS snapshots
        """
        LOG.debug("Enter : check_vmfs_snapshot_present")
        # vm_ref = vim.get_moref(mo_ref,"VirtualMachine")
        # snap_prop = self.vi_helper.GetObjectProperties(vm_ref,"snapshot")
        vm_ref = pyvmomi_util.get_moref(mo_ref, "VirtualMachine")
        snap_prop = self.vi_helper.get_object_properties(vm_ref, "snapshot")
        if hasattr(snap_prop[0], 'propSet') and len(snap_prop[0].propSet) > 0:
            snap_conf_obj_list = pyvmomi_util.extract_properties(snap_prop[0])
            snapTree = snap_conf_obj_list.get('snapshot').rootSnapshotList[0]
            if snapTree:
                LOG.debug("Exit : check_vmfs_snapshot_present")
                return True
            else:
                LOG.debug("Exit : check_vmfs_snapshot_present")
                return False
        else:
            LOG.debug("Exit : check_vmfs_snapshot_present")
            return False

    def assign_new_notifcation_policy(self, new_notification_id, recovery_set_id, rmc_wrapper_service):
        """
        Till here, there is difference between old value and new value so
        this function decide which notificationPolicy suites to recovery_set

        if no policy given by end user, then use default.
        if '0' given instead of policy id then stop all kind of notifications
        for VM or RecoverySet
        if any policy given then use that

        :param old_notification_policy_id:
        :param new_notification_id:
        :return:
        """
        LOG.info("Assigning new notification policy: " + str(new_notification_id) + " and recovery-set: " + str(
            recovery_set_id))
        if new_notification_id == None or new_notification_id == "":
            rmc_wrapper_service.associate_recovery_set_to_notification(
                recovery_set_id, None)
        else:
            rmc_wrapper_service.associate_recovery_set_to_notification(
                recovery_set_id, new_notification_id)

    def construct_objects(self, context, snapshot_id, rmc_wrapper_service, task_id, request_body,
                          vmInfo=None, vm_task_helper=None, array_flow=False):

        LOG.info("construct_objects : Enter")
        # Get the database record object based on ID
        snapshot_db = self.db.snapshot_get(context, snapshot_id)

        protectionPolicyId = request_body.get("protectionPolicyId", None)
        vm_name_list = request_body['vmNameList']
        is_app_consistent = request_body['isAppConsistent']
        snapshot_name = request_body['snapshotName']
        mo_ref = request_body['vmWareMoref']
        object_type = request_body['vmWareObjectType']
        # This flag is added to disable the feature until the integration is completed
        vm_level_backup = request_body.get('vmLevelBackup', False)
        transportMode = request_body.get('transportMode', None)

        expiry_in_seconds = None
        retention_in_seconds = None
        if 'expiryInSeconds' in request_body:
            expiry_in_seconds = request_body['expiryInSeconds']
        if 'retentionInSeconds' in request_body:
            retention_in_seconds = request_body['retentionInSeconds']

        select_all_vm = None
        if 'selectAllVM' in request_body:
            select_all_vm = request_body['selectAllVM']
            LOG.info("selectAllVM : '%s'" % select_all_vm)

        # Get the database record object based on mo_ref
        snapshot_db = self.db.get_record_based_on_mo_ref(context, mo_ref)
        # Read the recovery-set-id
        recovery_set_id = snapshot_db['recoverysetid']
        del_nonexpirable_snap = snapshot_db['del_nonexpirable_snap']
        vcenter_instance_id = snapshot_db['vcenteruid']
        LOG.info(("recovery_set_id: %s"), recovery_set_id)

        if array_flow is False and recovery_set_id is None:
            recovery_set_id = self.create_empty_recoveryset(context, snapshot_id, task_id,
                                                            rmc_wrapper_service,
                                                            mo_ref, protectionPolicyId,
                                                            vmInfo,
                                                            vm_task_helper)

        LOG.info(("Object Type: %s"), object_type)
        LOG.info(("mo ref: %s"), mo_ref)
        LOG.info(("App consistent: %s"), is_app_consistent)
        LOG.info(("Snapshot name: %s"), snapshot_name)

        # Change the policy for Scheduled Job triggered snapshot, if required.
        # If Global policy is numeric, and even if scheduler sends the Expiry/Retention values then reset those
        # values to None and proceed with snapshot creation. If Global policy is Expiry/Retention then continue with
        # snapshot creation as it is without resetting the values.
        if recovery_set_id:
            recovery_set_details = rmc_wrapper_service.get_recovery_set(recovery_set_id)
            recovery_set = recovery_set_details['recoverySet']
            snap_count = recovery_set['snapCount']
            if snap_count and snap_count != 0:
                expiry_in_seconds = None
                retention_in_seconds = None

        # vmType : added to support VmType field for RMCV 1.2.0
        vmType = vmInfo.VmType

        ret_use_dict = {}
        ret_use_dict['mo_ref'] = mo_ref
        ret_use_dict['object_type'] = object_type
        ret_use_dict['vm_level_backup'] = vm_level_backup
        ret_use_dict['vm_name_list'] = vm_name_list
        ret_use_dict['select_all_vm'] = select_all_vm
        ret_use_dict['vcenter_instance_id'] = vcenter_instance_id
        ret_use_dict['snapshot_name'] = snapshot_name
        ret_use_dict['vmType'] = vmType
        ret_use_dict['is_app_consistent'] = is_app_consistent
        ret_use_dict['expiry_in_seconds'] = expiry_in_seconds
        ret_use_dict['retention_in_seconds'] = retention_in_seconds
        ret_use_dict['recovery_set_id'] = recovery_set_id
        ret_use_dict['protectionPolicyId'] = protectionPolicyId
        ret_use_dict['transportMode'] = transportMode
        ret_use_dict['del_nonexpirable_snap'] = del_nonexpirable_snap

        LOG.info("construct_objects : Exit")

        return ret_use_dict

    def acquire_lock_and_create_task(self, context, mo_ref, object_type, task_id, rmc_wrapper_service, vm_task_helper,
                                     array_flow=False):

        # Support for scheduler.
        # It does not come through web client session initialization.

        LOG.info("acquire_lock_and_create_task : Enter")

        try:
            if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                LOG.info("vCenter not initialized. Let's do it")
                with self.lock:
                    self.vi_helper = ViHelper()

                    # DB could be empty
                    if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                        msg = "Please make sure vCenter is registered with RMC-V"
                        LOG.error(msg)
                        if array_flow:
                            task_desc_string = "HPE Array snapshot creation failed: %s" % msg
                        else:
                            task_desc_string = "Snapshot creation failed: %s" % msg
                        task_status = "Error"
                        task_state = 'Failed'
                        task_percentage = 0

                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)
                        return

        except Exception as e:
            msg = "vCenter session could not be initialized. Please make sure" \
                  " vCenter is registered with RMC-V and accessible"
            LOG.error(msg)
            LOG.error("Exception: %s", str(e))
            task_desc_string = "HPE Array snapshot creation failed: %s" % msg
            task_state = 'Failed'
            task_percentage = 100
            task_status = "Error"

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            return

        LOG.info(("Waiting to acquire lock ..."))

        # Synchronizing using Python Lock object to allow one instance of
        # "create_snapshot()" method at a time

        # with rmv_locks.snapshot_op_lock:

        # LOG.info(("Got the lock ..."))

        # Create an instance of VMware Task Helper to populate vCenter
        # Tasks

        # TODO: check user's vSphere permissions (implement
        # vihelper::HasRequiredEntityPermission())
        # TODO: License check will be handled by RMC. re-confirm.

        LOG.info("Acquiring Create Snapshot lock on : '%s'" % mo_ref)
        lock_response = None
        lock_response = rmv_utils.acquire_snapshot_create_lock(mo_ref,
                                                               self.vi_helper.validated_username, mo_ref)
        if lock_response:
            LOG.error("Could not acquire snapshot create lock.")
            raise rmv_exception.SnapshotLockException(error=lock_response)

        LOG.info("Locked Create Snapshot on : '%s'" % mo_ref)

        # Check if this user has vShpere permissions
        msg = "Please make sure user has appropriate permissions."
        try:
            is_privileged = self.vi_helper.has_required_entity_permission(object_type, mo_ref)
        except (rmv_exception.VmwareException) as e:
            LOG.exception(e)
            is_privileged = False
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
            raise e
        except Exception as e:
            LOG.exception(e)
            is_privileged = False
        if not is_privileged:
            raise rmv_exception.RMCAPINotAPrivilegedUser(msg=msg)

        # Step # 1 : Create Tasks (Vmware, TaskTracker, Newsfeed tasks)
        # ###

        # Validate the given Managed Object Reference
        if array_flow:
            msg = "HPE Array snapshot create task - Validating VMware " \
                  "Object, " \
                  "Type:'%s' Id:'%s'" % (object_type, mo_ref)
        else:
            msg = "snapshot create task - Validating VMware " \
                  "Object, " \
                  "Type:'%s' Id:'%s'" % (object_type, mo_ref)
        self.vi_helper.LogEvent(mo_ref, object_type, msg)

        # Log an event in vCenter
        if array_flow:
            msg = 'HPE Array snapshot create task begins'
        else:
            msg = 'snapshot create task begins'
        self.vi_helper.LogEvent(mo_ref, object_type, msg)

        LOG.info("acquire_lock_and_create_task : Exit")

    def create_empty_recoveryset(self, context, snapshot_id, task_id, rmc_wrapper_service,
                                 mo_ref, protectionPolicyId=None, vmInfo=None, vm_task_helper=None):

        LOG.info("create_empty_recoveryset : Enter")
        recoveryset_name = rmv_utils.get_recoveryset_name(vmInfo.Name, rmv_utils.VMWARE_OBJECT_TYPE_VM)
        vmType = "vDisk"

        objType = "VirtualMachine"

        wwn_list = None
        storage_pool_id = None
        task_state = 'Running'
        task_status = "Initiated"
        task_desc_string = "Setting up dependencies for snapshot creation"
        task_percentage = 20
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)
        self.vi_helper.LogEvent(mo_ref, objType, task_desc_string)
        recovery_set_details = rmc_wrapper_service.create_recovery_set(recoveryset_name,
                                                                       wwn_list,
                                                                       storage_pool_id,
                                                                       vmType,
                                                                       protectionPolicyId=protectionPolicyId,
                                                                       task_id=task_id)
        recovery_set_id = recovery_set_details['id']
        # update DB with recovery set ID
        options = {'recoverysetid': recovery_set_id}
        self.db.snapshot_update(context, snapshot_id, options)
        LOG.debug(_("Updated the recovery set id to the rmv snapshot database"))

        LOG.info("create_empty_recoveryset : Exit")

        return recovery_set_id

    def update_task_and_enable_cbt_for_VM(self, isBackupCreation, rmc_wrapper_service,
                                          snapshot_task_max_progress, starting_rate, task_id,
                                          vm_task_helper, vmInfo, vmObject_Uuid, is_app_consistent,
                                          object_type, mo_ref, vm_level_backup, array_flow=False):

        LOG.info("update_task_and_enable_cbt_for_VM : Enter")

        # Update Tasks (Task Tracker and VMware Task)
        task_desc_string = 'Getting Virtual Machine Information'
        task_status = "Initiated"

        if array_flow:
            task_percentage = current_relative_progress = 0
        else:
            task_percentage = current_relative_progress = 40
        if (isBackupCreation):
            task_percentage = \
                rmc_wrapper_service.get_progress_rate(
                    snapshot_task_max_progress,
                    current_relative_progress, starting_rate)

        task_state = 'Running'
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)

        # Lock based on UUID of VM
        if vmInfo.Uuid:
            LOG.info("Acquiring Create Snapshot lock on : '%s'" % vmInfo.Uuid)
            locked_vm_name = "VM - " + vmInfo.Name
            lock_response = None
            lock_response = rmv_utils.acquire_snapshot_create_lock(vmInfo.Uuid, self.vi_helper.validated_username,
                                                                   locked_vm_name)
            if lock_response:
                LOG.error("Could not acquire snapshot create lock.")
                raise rmv_exception.SnapshotLockException(error=lock_response)
            else:
                vmObject_Uuid.append(vmInfo.Uuid)
                LOG.info("Locked Create Snapshot on : '%s'" % vmInfo.Uuid)

        # Check if snapshot is disabled for this VM
        vmware_checks.check_snapshot_disabled(
            vmInfo.IsSnapshotDisabled,
            vmInfo.ReasonSnapshotDisabled)

        self.validate_virtualmachine_object(vmInfo, is_app_consistent)

        # If there are any old VMFS snapshot left then delete it.
        # After deleting old snapshot, we are not retriving vmInfo again.
        # So property "HasVmfsSnapshots"
        # will have the old value "True" and cannot be used later in code.

        if array_flow:
            self.check_and_delete_vmfs_sapshots_vm(is_app_consistent,
                                                   vmInfo,
                                                   object_type,
                                                   mo_ref)

        vmObject = json_helper.vmware_object(object_type,
                                             mo_ref,
                                             vmInfo.Name,
                                             vmInfo.Uuid,
                                             vmInfo.InstanceUUID)

        vm_cbt_flag = False

        if isBackupCreation and vm_level_backup:
            self.delete_all_vmfs_snapshot_vm(vmInfo, mo_ref)
            LOG.info("****** Check if CBT is enabled ******")
            vm_cbt_flag = self.check_if_CBT_enabled(vmInfo)
            LOG.info("******* VM CBT FLAG value ****** : %s" % vm_cbt_flag)
            if vm_cbt_flag == False:
                self.enable_CBT_for_VM(vmInfo, vm_cbt_flag)
                vm_cbt_flag = True

        LOG.info("update_task_and_enable_cbt_for_VM : Exit")
        return vmObject, vm_cbt_flag

    def create_snapshot_db_record(self, vmObject, is_app_consistent, vcenter_instance_id,
                                  object_type, vmType, vmInfo, snapshot_name,
                                  rmc_wrapper_service, hasVmfsSnapList=[]):

        LOG.info("create_snapshot_db_record : Enter")

        snap_info = rmv_structures.SnapshotInfo()
        snap_info.CreatedVcUserName = self.vi_helper.validated_username
        snap_info.VirtualCenterUrl = self.vi_helper.service_url
        snap_info.VmWareObjectName = vmObject.Name
        snap_info.VmWareObjectType = vmObject.Type
        snap_info.ObjectUUID = vmObject.Uuid
        snap_info.ObjectRefID = vmObject.Moref
        snap_info.MoUuid = vmObject.MoUuid
        snap_info.IsAppConsistent = is_app_consistent
        # snap_info.ExpiryInSeconds = -1
        # snap_info.RetentionInSeconds = -1
        snap_info.VirtualCenterInstanceId = vcenter_instance_id
        if object_type == 'VirtualMachine':
            snap_info.VmType = vmType
            snap_info.HasVmfsSnapshots = vmInfo.HasVmfsSnapshots
        elif object_type == 'Datastore':
            if True in hasVmfsSnapList:
                snap_info.HasVmfsSnapshots = True
            else:
                snap_info.HasVmfsSnapshots = False

        # If Snapshot name is not given then create a snapshot name and
        # assign it to VcSetName
        if not snapshot_name:
            snapshot_name = \
                rmc_wrapper_service.get_recovery_set_snapshot_name(vmObject.Name)

        snap_info.VcSetName = snapshot_name

        LOG.info("create_snapshot_db_record : Exit")

        return snap_info

    def update_client_data_for_vm_level_backup(self, vmInfo, snap_info, vm_cbt_flag, ds_assoc_vm_new_snap_id_list,
                                               x_auth_token, transportMode, recovery_set_id=None, array_flow=False):

        LOG.info("update_client_data_for_vm_level_backup : Enter")

        LOG.info("******* VM LEVEL BACKUP ---- UPDATE CLIENT DATA ********")
        snap_info.IsCBTEnabled = vm_cbt_flag
        snap_moref = ds_assoc_vm_new_snap_id_list[0]._moId
        LOG.info("Snapshot moref of the VM created is : %s" % snap_moref)
        changeId_details_list = self.get_snapshot_changeId(snap_moref)
        snap_info.changeIdPerDisk = changeId_details_list
        snap_info.vmLevelBackup = 'True'
        snap_info.SnapshotMoref = snap_moref
        snap_info.vmdkPathList = self.get_vmDiskDetails_from_SnapshotObj(snap_moref)
        snap_info.transportMode = transportMode
        snap_info.vmUuid = vmInfo.Uuid
        snap_info.VmType = vmInfo.VmType

        if array_flow:
            map_folderName = snap_info.SnapshotGuid
        else:
            map_folderName = recovery_set_id
        LOG.info("Will create with the folder name .... : %s" % map_folderName)
        """
        Check if VM has any previous backups.
        If VM has previous backups, create query map using changeId and details from backup
        Else use * for changeId, and do full vm backup
        """
        backup_exists, backup_details = self.check_if_vm_backup_exists(x_auth_token, recovery_set_id)
        if backup_exists:
            # get the previous backup details  and use that details to get the query change block
            vmdkMapList = self.get_CBT_map_file_for_vm(map_folderName, backup_details, snap_moref,
                                                       backup_exists, vmInfo.VmType, vmInfo.Uuid, None)
        else:
            # Case of full backup
            LOG.info("************* CASE OF FULL BACKUP OF VM *****************")

            vmdkMapList = self.get_CBT_map_file_for_vm(map_folderName, backup_details, snap_moref,
                                                       backup_exists, vmInfo.VmType, vmInfo.Uuid,
                                                       changeId_details_list)

        snap_info.vmdkMapList = vmdkMapList
        snap_config = self.get_snapshot_config_obj(snap_moref)

        LOG.info("update_client_data_for_vm_level_backup : Exit")

        return snap_config

    def create_vmfs_snapshot(self, context, snapshot_id, x_auth_token, task_id,
                             request_body, vmInfo=None, isBackupCreation=False, vm_task_helper=None):

        LOG.info("Enter create_vmfs_snapshot")
        snapshot_task_max_progress = 0
        starting_rate = 0
        if (isBackupCreation == True):
            snapshot_task_max_progress = 20

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        if not vm_task_helper:
            vm_task_helper = VmTaskHelper(self.vi_helper)

        ret_use_dict = self.construct_objects(context, snapshot_id, rmc_wrapper_service,
                                              task_id, request_body, vmInfo,
                                              vm_task_helper, False)

        if ret_use_dict:
            mo_ref = ret_use_dict.get('mo_ref')
            object_type = ret_use_dict.get('object_type')
            vm_level_backup = ret_use_dict.get('vm_level_backup')
            vmType = ret_use_dict.get('vmType')
            vcenter_instance_id = ret_use_dict.get('vcenter_instance_id')
            is_app_consistent = ret_use_dict.get('is_app_consistent')
            snapshot_name = ret_use_dict.get('snapshot_name')
            recovery_set_id = ret_use_dict.get('recovery_set_id')
            transportMode = ret_use_dict.get('transportMode')

        try:
            self.acquire_lock_and_create_task(context, mo_ref, object_type, task_id,
                                              rmc_wrapper_service, vm_task_helper, False)
            vmObject_Uuid = list()
            ds_assoc_vm_new_snap_id_list = []

            vmObject, vm_cbt_flag = self.update_task_and_enable_cbt_for_VM(isBackupCreation, rmc_wrapper_service,
                                                                           snapshot_task_max_progress, starting_rate,
                                                                           task_id,
                                                                           vm_task_helper, vmInfo, vmObject_Uuid,
                                                                           is_app_consistent,
                                                                           object_type, mo_ref, vm_level_backup, False)

            # Step # 4 : Create Snapshot DB record ###

            snap_info = self.create_snapshot_db_record(vmObject, is_app_consistent, vcenter_instance_id, object_type,
                                                       vmType, vmInfo, snapshot_name, rmc_wrapper_service)

            snapshot_name = snap_info.VcSetName

            # Step # 5 : Create VMFS snapshot ###

            if is_app_consistent:

                task_desc_string = 'Creating VMFS snapshot'
                task_status = "Initiated"

                task_percentage = current_relative_progress = 85
                if (isBackupCreation):
                    task_percentage = \
                        rmc_wrapper_service.get_progress_rate(
                            snapshot_task_max_progress,
                            current_relative_progress, starting_rate)

                task_state = 'Running'
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                LOG.info("Creating VMFS snapshot")
                vm_mo_ref_list = []
                vm_name_moref_dict = dict()
                vm_mo_ref_uuid_dict = dict()
                vm_mo_ref_list = [mo_ref]
                vm_name_moref_dict[mo_ref] = vmInfo.Name
                vm_mo_ref_uuid_dict[mo_ref] = vmInfo.Uuid

                ds_assoc_vm_new_snap_id_list = \
                    self.vi_helper.CreateVmfsSnapshot(
                        vm_mo_ref_list,
                        vi_objects.VmfsSnapshotName,
                        "For Non-Array Copy",
                        False,
                        True, vm_name_moref_dict, vm_mo_ref_uuid_dict)
                LOG.info("VMFS snap created: %s" % ds_assoc_vm_new_snap_id_list)

            elif is_app_consistent == False and isBackupCreation:
                """
                This block is for creating a VMFS snapshot even in case of crash consistent snapshot
                for a Virtual Machine as we need the snapshot changeID  for querying change block area.
                The quiesce flag is set to false in CreateVMFSSnapshot call while creating crash consistent snapshot.
                """
                LOG.info("****** This is a VMFS snapshot for VM in case of crash consistent "
                         "snapshot *******")

                vm_mo_ref_list = []
                vm_name_moref_dict = dict()
                vm_mo_ref_uuid_dict = dict()

                vm_mo_ref_list = [mo_ref]
                vm_name_moref_dict[mo_ref] = vmInfo.Name
                vm_mo_ref_uuid_dict[mo_ref] = vmInfo.Uuid
                ds_assoc_vm_new_snap_id_list = \
                    self.vi_helper.CreateVmfsSnapshot(
                        vm_mo_ref_list,
                        vi_objects.VmfsSnapshotName,
                        "For Non-Array Copy",
                        False,
                        False, vm_name_moref_dict, vm_mo_ref_uuid_dict)
            task_desc_string = "VMFS Snapshot created successfully"

            task_state = 'Completed'
            task_status = "Ok"

            task_percentage = current_relative_progress = 100
            if (isBackupCreation):
                task_percentage = rmc_wrapper_service.get_progress_rate(
                    snapshot_task_max_progress,
                    current_relative_progress, starting_rate)

            LOG.info(('%s'), task_desc_string)

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            if isBackupCreation and vm_level_backup:
                snap_config = self.update_client_data_for_vm_level_backup(vmInfo, snap_info, vm_cbt_flag,
                                                                          ds_assoc_vm_new_snap_id_list,
                                                                          x_auth_token, transportMode, recovery_set_id,
                                                                          False)

            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)

            ret_dict = {}
            ret_dict['recovery_set_id'] = recovery_set_id
            ret_dict['snap_config'] = snap_config
            ret_dict['snap_info'] = snap_info
            ret_dict['snap_moref_list'] = ds_assoc_vm_new_snap_id_list

            return ret_dict

        except (rmv_exception.StorageSystemVirtualCopyCreationException,
                rmv_exception.SnapshotDisabledException,
                rmv_exception.VMInaccessibleException,
                rmv_exception.VMwareToolsNotRunningException,
                rmv_exception.PhysicalRDMException,
                rmv_exception.VMhasNoLunsException,
                rmv_exception.VMFSsnapshotExistsException,
                rmv_exception.VMFSUnnamedSnapshotException,
                rmv_exception.VMFSsnapshotExistsException,
                rmv_exception.UnknownVMwareObjectError,
                rmv_exception.DatastoreUnusableError,
                rmv_exception.DatastoreUnsupportedTypeError,
                rmv_exception.DatastoreSpannedError,
                rmv_exception.DatastoreMoreThanOneIn3parVolumeError,
                rmv_exception.DatastoreDoesNotContainVMError,
                rmv_exception.DatastoreVMMoreThanOneVVError,
                rmv_exception.vCenterMoRefError,
                rmv_exception.TaskError,
                rmv_exception.VmUnusableError,
                rmv_exception.VmMorefMissmatch,
                rmv_exception.CreateVMFSSnapshotException,
                rmv_exception.VmwareException,
                rmv_exception.PyVmomiException,
                rmv_exception.VMwareObjectnotfound,
                Exception
                ) as e:
            if hasattr(e, "msg"):
                LOG.exception(('%s'), e.msg)
                msg = e.msg
            elif hasattr(e, "message"):
                msg = e.message
                LOG.exception("Exception: %s", str(e.message))
            else:
                LOG.exception(('%s'), e)
                msg = "Internal error"
            task_desc_string = "Snapshot creation failed: " \
                               "%s" % msg
            task_state = 'Failed'
            task_status = "Error"

            task_percentage = current_relative_progress = 100
            if (isBackupCreation):
                task_percentage = rmc_wrapper_service.get_progress_rate(snapshot_task_max_progress,
                                                                        current_relative_progress,
                                                                        starting_rate)

            LOG.error(('%s'), task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            raise e

        finally:
            # Release the acquired snapshot create lock
            if mo_ref:
                rmv_utils.release_snapshot_create_lock(mo_ref)
                LOG.info(("Released Lock for object '%s'") % mo_ref)
            # Release the aquired snapshot create lock, by checking the vmObject
            for uuid in vmObject_Uuid:
                if uuid:
                    rmv_utils.release_snapshot_create_lock(uuid)
                    LOG.info(("Released Lock for snapshot '%s'") % snapshot_id)

            # Host details is stored in the below Dict while creating the snapshot. Details can be removed.
            LOG.info("hs_and_hss_properties - '%s' Before " % len(pyvmomi_util.hs_and_hss_properties))
            pyvmomi_util.hs_and_hss_properties.clear()
            LOG.info("hs_and_hss_properties - '%s' After " % pyvmomi_util.hs_and_hss_properties)

        return

    def check_if_CBT_enabled(self, vmInfo):
        """

        :param vmInfo:
        :return:
        """
        vm_cbt_flag = False
        vm_obj = self.vi_helper.get_vm_obj_from_uuid(vmInfo.Uuid)
        vm_cbt_flag = vm_obj.config.changeTrackingEnabled
        return vm_cbt_flag

    def enable_CBT_for_VM(self, vmInfo, vm_cbt_flag):
        """
        This function is used to enable the changeBlockTracking on a VM
        :param vmInfo: The virtual machine information object
        :param vm_cbt_flag: This is the flag to identify if CBT is enabled or not
        :return:
        """
        LOG.info("enable_CBT_for_VM : Enter")
        try:
            vm_obj = self.vi_helper.get_vm_obj_from_uuid(vmInfo.Uuid)
            if vm_cbt_flag == False:
                vm_spec = pyvmomi_vim.VirtualMachineConfigSpec()
                vm_spec.changeTrackingEnabled = True
                self.vi_helper.reconfigVM_task(vmInfo.Uuid, vm_spec)
            LOG.info("enable_CBT_for_VM : Exit")
        except Exception as e:
            LOG.exception("Exception while reconfiguring the VM : %s" % e)
            raise rmv_exception.ReconfigureVmException(e.message)

    def get_snapshot_config_obj(self, snapshot_moref):
        try:
            LOG.info("get_snapshot_config_obj : Enter")
            snap_moref_obj = vim.get_moref(snapshot_moref, "VirtualMachineSnapshot")
            LOG.debug(_('Retrieving the configuration information for the snapshot'))
            snap_config_info = self.vi_helper.GetObjectProperties(snap_moref_obj, "config")
            conf_prop_dict = vim_util.extract_properties(snap_config_info.objects[0])
            snap_config_obj = self.process_config_object(conf_prop_dict)
            """
            Use the Below code while migrating to pyvmomi
            """
            # snap_moref_obj = pyvmomi_util.get_moref(snapshot_moref, "VirtualMachineSnapshot")
            # snap_config_info = self.vi_helper.get_object_properties(snap_moref_obj, "config")
            # conf_prop_obj = pyvmomi_util.extract_properties(snap_config_info[0])
            # snap_config_dict = pyvmomi_util.process_config_obj(conf_prop_obj)
            LOG.info("get_snapshot_config_obj : Exit")
        except Exception as e:
            LOG.exception("Exception occurred while retrieving the snapshot configuration information: %s" % e)
            raise rmv_exception.VmVddkBackupException(e.message)
        return snap_config_obj

    def get_snapshot_changeId(self, snap_moref):
        """
        This function is used to get the changeID from the snapshot config info
        This changeId will be used for incremental backup
        :param snap_moref: Moref of the snapshot created
        :return: current snapshot's changeId and its associated details
        """
        try:
            LOG.info("get_snapshot_changeId : Enter")
            changeId_details_list = []
            current_changeId = None
            snap_config_obj = self.get_snapshot_config_obj(snap_moref)
            hw = snap_config_obj['hardware']
            for device in range(len(hw)):
                for hkeys in hw[device]:
                    LOG.debug("Keys in hardware of config ...... : %s" % hw[device].keys())
                    if rmv_utils.VMWARE_VM_VIRTUAL_DISK == hkeys:
                        changeId_path_dict = {}
                        h_dict = hw[device].values()[0]
                        dev_key = h_dict.get('key', None)
                        diskSize = h_dict.get('capacityInBytes', None)
                        deviceBacking = h_dict.get('backing', None)
                        current_changeId = deviceBacking.get('changeId')
                        # If this is the 1st backup after enabling CBT, then the value of change ID is unset.
                        if current_changeId == None:
                            """
                            This is for the optimized backup... Make the changeId as '*'
                            """
                            LOG.info("This is for the Optimized backup... Make the changeId as '*'")
                        parentDevice = deviceBacking.get('parent', None)
                        if parentDevice:
                            vmdkPath = parentDevice.get('fileName', None)
                        else:
                            vmdkPath = deviceBacking['fileName']
                        datastore = deviceBacking.get('datastore')
                        ds_moref = datastore.get('value')
                        dsType = self.vi_helper.get_datastore_type(ds_moref)
                        changeId_path_dict['deviceKey'] = dev_key
                        changeId_path_dict['currentChangeId'] = current_changeId
                        changeId_path_dict['vmdkPath'] = vmdkPath
                        changeId_path_dict['diskSize'] = diskSize
                        changeId_path_dict['vmdkType'] = dsType
                        changeId_details_list.append(changeId_path_dict)
            LOG.info("get_snapshot_changeId : Exit")
        except Exception as e:
            LOG.exception("Exception occurred while retrieving the snapshot changeId details: %s" % e)
            raise rmv_exception.VmVddkBackupException(e.message)
        return changeId_details_list

    def get_vmDiskDetails_from_SnapshotObj(self, snap_moref):
        """
        This function returns the list of VMDKS to be backed up
        :param snap_moref:
        :return: List of VMDKs to backup
        """
        try:
            LOG.info("get_vmDiskDetails_from_SnapshotObj : Enter")
            snap_config_obj = self.get_snapshot_config_obj(snap_moref)
            hw = snap_config_obj['hardware']
            vmdkPathList = []
            for device in range(len(hw)):
                for hkeys in hw[device]:
                    if rmv_utils.VMWARE_VM_VIRTUAL_DISK == hkeys:
                        h_dict = hw[device].values()[0]
                        deviceBacking = h_dict.get('backing', None)
                        parentDevice = deviceBacking.get('parent', None)
                        if parentDevice:
                            vmdkPath = parentDevice.get('fileName', None)
                            LOG.info("Parent device: " + str(vmdkPath))
                        else:
                            vmdkPath = deviceBacking.get('fileName', None)  # just return vmdk path....
                            LOG.info("Backing device: " + str(vmdkPath))
                        vmdkPathList.append(vmdkPath)
            LOG.info("get_vmDiskDetails_from_SnapshotObj : Exit")
        except Exception as e:
            LOG.exception("Exception occurred while retrieving the VMDK list for backup: %s" % e)
            raise rmv_exception.VmVddkBackupException(e.message)
        LOG.info("vmdk path list: " + str(vmdkPathList))
        return vmdkPathList

    def check_if_vm_backup_exists(self, x_auth_token, recoverySetId):
        """
        This function checks if any previous backup exists on the given recovery set
        :param x_auth_token:
        :param recoverySetId:
        :return: backup_exists and backup_details of the previous parent backup
        """
        try:
            LOG.info("check_if_vm_backup_exists : Enter")
            backup_exists = False
            backup_details = None
            if recoverySetId == None:
                return backup_exists, backup_details
            backup_resp_dict = self.get_backup_for_recoveryset(context, recoverySetId, x_auth_token)
            # By default backups are returned in descending order
            if backup_resp_dict:
                backup_list = backup_resp_dict.get('backupSets', None)
                # Check if backup exists on the VM. If yes then fetch the vmLevelBackup flag from appMetadata
                if backup_list:
                    for backupSet in backup_list:
                        if backupSet['status'] == 'available' and backupSet.get('backupSetId') is None:
                            bkp_appMetadata = backupSet.get('appMetadata', None)
                            if bkp_appMetadata:
                                vm_level_backup = bkp_appMetadata.get('vmLevelBackup', False)
                                # if vm level backup, get the change id from backup
                                if vm_level_backup:
                                    backup_exists = True
                                    backup_details = backupSet
                                    break
                else:
                    # if there are no backups on this VM, then this is a optimized backup
                    LOG.info("Lets take optimized backup... change Id will be *")
                    backup_exists = False
            else:
                # if there are no backups on this VM, then this is a optimized backup
                LOG.info("Lets take optimized backup... change Id will be *")
                backup_exists = False
            LOG.info("check_if_vm_backup_exists : Exit")
        except Exception as e:
            LOG.exception("Exception occurred while retrieving the previous backup details: %s" % e)
            raise rmv_exception.VmVddkBackupException(e.message)
        return backup_exists, backup_details

    def build_vmdk_dict(self, vmdkPath, filePath, deviceKey, diskSize):
        """
        Structure will be volMetadata key and value will be list of dict.
        That list of dict will have vmdk as key and wwn as value.
        :param mapFolderName:
        :param metaFileName:
        :param vmdkPath:
        :return:
        """
        LOG.info("build_vmdk_dict : Enter")
        vmdkMapFile_dict = {}
        vmdkMapFile_dict['vmdk'] = vmdkPath
        vmdkMapFile_dict['deviceKey'] = deviceKey
        vmdkMapFile_dict['filePath'] = filePath
        vmdkMapFile_dict['diskSize'] = diskSize
        return vmdkMapFile_dict
        LOG.info("build_vmdk_dict : Exit")

    # TODO: Break this method into two functions
    def get_CBT_map_file_for_vm(self, mapFolderName, backup_details, snap_moref, backup_exists, VmType,
                                vmUuid, changeId_details_list=None):
        """
        This function gets the changed block information from the VMFS snapshot for each VMDK
        :param mapFolderName: SnapshotGuid will the folder name
        :param backup_details: Details of previous backup in case of incremental backup
        :param snap_moref: VMFS snapshot moref
        :param backup_exists: flag to makr if backup exists
        :param vmUuid: instance uuid of the VM
        :param changeId_details_list: This is list of VMDKs in case of inc backup
        :return:
        """
        try:
            # This snap response is the backup data
            LOG.info("get_CBT_map_file_for_vm : Enter")
            # if snapshot_response:
            changeId_path_list = []
            deviceKey = None
            changeId = None
            mapFileName = None
            vmdkMapFile_dictList = []

            if backup_exists:
                # Case of incremental. Get change details from backup metadata
                bkp_appMetadata = backup_details.get('appMetadata', None)
                # Change Id details are from previous backup, used for CBT.
                changeId_path_list = bkp_appMetadata.get('changeIdPerDisk', None)
            else:
                # Case of optimized full backup. So get from snapshot config information
                changeId_path_list = changeId_details_list
            if changeId_path_list:
                LOG.info("Change path list details ..... : %s" % changeId_path_list)
                for disks in range(len(changeId_path_list)):
                    deviceKey = changeId_path_list[disks].get('deviceKey', None)
                    vmdkPath = changeId_path_list[disks].get('vmdkPath', None)
                    diskSize = changeId_path_list[disks].get('diskSize', None)
                    if (diskSize <= 0):
                        # means not  proper disk can not get CBT, or even backup
                        LOG.info("Disk size is 0 or less")
                        raise rmv_exception.ZeroDiskSize(disk=vmdkPath)

                    if backup_exists:
                        changeId = changeId_path_list[disks].get('currentChangeId', None)
                    else:
                        changeId = '*'

                    # In case of new disk, make it a full optimized backup
                    if changeId == None:
                        changeId = '*'

                    LOG.info("vmdk: " + str(vmdkPath))
                    # mapFileName = vmdkPath.split("/")[1].split(".")[0]
                    mapFileName = str(uuid.uuid4());
                    LOG.info("Map file to be created is ...... : %s" % mapFileName)

                    filePath = self.vi_helper.query_change_disk_areas(vmUuid, deviceKey,
                                                                      changeId, snap_moref, mapFolderName, mapFileName,
                                                                      VmType)

                    vmdkMapFile_dictList.append(self.build_vmdk_dict(vmdkPath, filePath, deviceKey, diskSize))
                LOG.info("vmdk wwn list ................. : %s" % vmdkMapFile_dictList)

        except Exception as e:
            LOG.exception("Exception occurred while retrieving the previous backup details or querying cbt map: %s" % e)
            raise rmv_exception.VmVddkBackupException(e.message)

        return vmdkMapFile_dictList

    def create_snapshot(self, context, vmware_db_id, x_auth_token, task_id, copy_id,
                        request_body, host_info, vmInfo=None, isBackupCreation=False, vm_task_helper=None):
        '''Create snapshot of a VirtualMachine or Datastore.'''

        # Step # 0 : Construct necessary objects
        # Step # 1 : Create Tasks (Vmware, TaskTracker, Newsfeed tasks)
        # Step # 2 : Mapping VM to array entity
        # Step # 3 : Checks at VM and DS level
        # Step # 4 : Create Snapshot DB record
        # Step # 5 : Create VMFS snapshot
        # Step # 6 : Create 3PAR snapshot
        # Step # 7 : Delete VMFS snapshot
        # Step # 8 : Post creation book keeping

        LOG.debug("Enter create_snapshot")

        # Step # 0 : Construct necessary objects ###

        # Get the database record object based on ID
        # snapshot_db = self.db.snapshot_get(context, snapshot_id)

        # From 6.0 By default "ignore_vmfs_snapshot_exceptions" is True.
        # Till 5.0 its value was decided based on the field "continueOnVMwareError" - set by user in GUI.
        ignore_vmfs_snapshot_exceptions = FLAGS.ignore_vmfs_snapshot_exceptions
        ignore_validate_vm = FLAGS.ignore_validate_vm

        protectionPolicyId = request_body.get("protectionPolicyId", None)
        vm_name_list = request_body['vmNameList']
        is_app_consistent = request_body['isAppConsistent']
        snapshot_name = request_body['snapshotName']
        mo_ref = request_body['vmWareMoref']
        object_type = request_body['vmWareObjectType']
        protection_group_id = request_body.get("protection_group_id", "")
        already_locked_vm_uuid_list = list()
        vm_obj_name = ""
        ds_mount_path_dict = {}
        vmObject_Uuid = list()
        hasVmfsSnap = None
        hasVmfsSnapList = []
        vm_cbt_flag = False
        snap_config = None
        rmv_copy_id = None
        vm_level_backup = None
        transportMode = request_body.get('transportMode', None)
        snapshot_set_id = None

        # Executor will always send "snapExpiry" and "snapRetention" in request body. It will always be in Hours.
        snap_expiry = request_body.get('snapExpiry')
        snap_retention = request_body.get('snapRetention')

        # TODO:6.0 do similar changes in granular code
        # As "continueOnVMwareError" field in removed in 6.0. commenting below code.
        # By default "ignore_vmfs_snapshot_exceptions" is False
        # if 'continueOnVMwareError' in request_body:
        #    ignore_vmfs_snapshot_exceptions = request_body['continueOnVMwareError']
        # LOG.info("ignore_vmfs_snapshot_exceptions : '%s'" % ignore_vmfs_snapshot_exceptions)

        # TODO:6.0 remove this "select_all_vm" dependency as it is doesn't make any sense now
        # As "select_all_vm" field in removed in 6.0. commenting below code and setting default value to true.
        select_all_vm = True
        # if 'selectAllVM' in request_body:
        #     select_all_vm = request_body['selectAllVM']
        #     LOG.info("selectAllVM : '%s'" %select_all_vm)

        # Get the database record object based on mo_ref
        vmware_db_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, object_type, mo_ref)
        recovery_set_id = vmware_db_obj.get("recovery_set_id")

        vcenter_instance_id = self.vi_helper.vcenteruid

        LOG.info((
                     "TaskId: %s, Object Type: %s, name %s , moref: %s , is_app_consitent: %s , snapshot name : %s, recovery_set_id : %s"),
                 task_id, object_type, vmware_db_obj.get('name'), mo_ref, is_app_consistent, snapshot_name,
                 recovery_set_id)

        # Create an instance of RMC Wrapper to make any RMC or TaskTracker calls
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        if not vm_task_helper:
            vm_task_helper = VmTaskHelper(self.vi_helper)

        # Support for scheduler.
        # It does not come through web client session initialization.
        vmObject = None
        try:
            if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                LOG.info("vCenter not initialized. Let's do it, TaskId: " + str(task_id))
                with self.lock:
                    self.vi_helper = ViHelper()

                    # DB could be empty
                    if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                        msg = "Please make sure vCenter is registered with RMC-V"
                        LOG.error(msg, "TaskId: " + str(task_id))
                        task_desc_string = "HPE Array snapshot creation failed: %s" % msg
                        task_status = "Error"
                        task_state = 'Failed'
                        task_percentage = 0

                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)
                        return

        except Exception as e:
            msg = "vCenter session could not be initialized. Please make sure" \
                  " vCenter is registered with RMC-V and accessible"
            LOG.exception(msg)
            task_desc_string = "HPE Array snapshot creation failed: %s" % msg
            task_state = 'Failed'
            task_percentage = 0
            task_status = "Error"

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            return

        LOG.debug(" Waiting to acquire lock...")

        # Synchronizing using Python Lock object to allow one instance of
        # "create_snapshot()" method at a time
        ds_assoc_vm_new_snap_id_list = []
        vm_name_in_snap_list = []
        vm_list_in_ds = []
        virtual_copy_luns = []
        vmObject = None
        array_serial_number = None
        scsi_luns = []
        ds_info = None
        ds_assoc_vm_list = []
        lun_wwn = None
        vm_moref_to_db_id_dict = {}
        ds_moref_to_db_id_dict = {}
        ds_list_in_vm = []
        vms_to_exclude_to_add_in_db = []
        associated_data_list = []

        try:
            LOG.info("Acquiring Create Snapshot lock on " + object_type + " " + str(
                vmware_db_obj.get('name')) + " moref " + str(mo_ref))
            lock_response = None
            lock_response = rmv_utils.acquire_snapshot_create_lock(mo_ref,
                                                                   self.vi_helper.validated_username, mo_ref)
            if lock_response:
                LOG.error(" Could not acquire snapshot create lock. " + object_type + " " + str(
                    vmware_db_obj.get('name')) + " moref " + str(mo_ref))
                raise rmv_exception.SnapshotLockException(error=lock_response)

            LOG.info(
                " Locked Create Snapshot on " + object_type + " " + str(vmware_db_obj.get('name')) + " moref: " + str(
                    mo_ref))

            # Check if this user has vShpere permissions
            msg = "Please make sure user has appropriate permissions."
            try:
                is_privileged = self.vi_helper.has_required_entity_permission(object_type, mo_ref)
            except (rmv_exception.VmwareException) as e:
                is_privileged = False
                if hasattr(e, "msg"):
                    LOG.exception(str(e.msg) + " TaskId: " + str(task_id) + " " + str(object_type) + " : " + str(
                        vmware_db_obj.get('name')))
                else:
                    LOG.exception(
                        e + " TaskId: " + task_id + " " + str(object_type) + " : " + str(vmware_db_obj.get('name')))

                raise e
            except Exception as e:
                LOG.exception(
                    e + " TaskId: " + task_id + " " + str(object_type) + " : " + str(vmware_db_obj.get('name')))
                is_privileged = False
            if not is_privileged:
                raise rmv_exception.RMCAPINotAPrivilegedUser(msg=msg)

            # Step # 1 : Create Tasks (Vmware, TaskTracker, Newsfeed tasks)
            # ###

            # Validate the given Managed Object Reference
            msg = "HPE Array snapshot create task - Validating VMware " \
                  "Object, " \
                  "Type:'%s' Id:'%s'" % (object_type, mo_ref)
            self.vi_helper.LogEvent(mo_ref, object_type, msg)

            # Log an event in vCenter
            msg = 'HPE Array snapshot create task begins'
            self.vi_helper.LogEvent(mo_ref, object_type, msg)

            # Step # 3 : Checks at VM and DS level ###

            if object_type == 'VirtualMachine':
                vm_level_backup = True
                # Update Tasks (Task Tracker and VMware Task)
                task_desc_string = 'Getting Virtual Machine Information'
                task_status = "Initiated"
                task_percentage = 0
                task_state = 'Running'
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                # vmType : added to support VmType field for RMCV 1.2.0
                if vmInfo.VmType == json_helper.TpdVmHostFileSystemType.Vmfs:
                    volume_type = rmv_utils.VMFS_DISK_TYPE

                # Lock based on UUID of VM
                if vmInfo.Uuid:
                    LOG.debug("Acquiring Create Snapshot lock on : '%s'" % vmInfo.Uuid)
                    locked_vm_name = "VM - " + vmInfo.Name
                    lock_response = None
                    lock_response = rmv_utils.acquire_snapshot_create_lock(vmInfo.Uuid,
                                                                           self.vi_helper.validated_username,
                                                                           locked_vm_name)
                    if lock_response:
                        LOG.error(
                            "Could not acquire snapshot create lock." + " TaskId: " + task_id + " " + object_type + " : " +
                            str(vmware_db_obj.get('name')))
                        raise rmv_exception.SnapshotLockException(error=lock_response)
                    else:
                        vmObject_Uuid.append(vmInfo.Uuid)
                        LOG.info(
                            "Locked Create Snapshot on : '%s'" % vmInfo.Uuid + " TaskId: " + task_id + " " + object_type + " : " + str(
                                vmware_db_obj.get('name')))

                vmObject = json_helper.vmware_object(object_type,
                                                     mo_ref,
                                                     vmInfo.Name,
                                                     vmInfo.Uuid,
                                                     vmInfo.InstanceUUID)
                vm_obj_name = vmInfo.Name
                virtual_copy_luns = vmInfo.VirtualCopyPairList

                # Get Serial Number of the 3par storage system
                array_serial_number = vmInfo.InservSerialNumbers[0]

                ds_list_in_vm = host_info.DatastoreDict.values()

                ds_mount_path_dict = vmInfo.DatastoreMountPathDict

                # DB Update Start *****************************************************************
                # Constructing object to insert into table
                mo_table_obj = json_helper.vm_table()
                mo_table_obj.moref = vmObject.Moref
                mo_table_obj.name = vmObject.Name
                mo_table_obj.vmware_uuid = vmObject.MoUuid
                mo_table_obj.volume_type = volume_type
                mo_table_obj.vcenter_uuid = vcenter_instance_id
                mo_table_obj.host_name = ds_list_in_vm[0].host_name
                mo_table_obj.host_id = ds_list_in_vm[0].host_mo_id
                mo_table_obj.datacenter_name = ds_list_in_vm[0].datacenter_name
                mo_table_obj.datacenter_id = ds_list_in_vm[0].datacenter_mo_id
                mo_table_obj.status = json_helper.copy_status.available
                mo_table_obj.guest_os = vmInfo.guest_os

                LOG.info("VM table entries: %s " % mo_table_obj.__dict__)
                mo_table_response = self.db.create_or_update_rmcv_vm(context, vmObject.Moref, mo_table_obj.__dict__)

                vm_moref_to_db_id_dict[mo_table_obj.moref] = mo_table_response.id

                associated_data = {}
                associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_VM
                associated_data['resourceName'] = vmObject.Name
                associated_data['resourceUri'] = vmObject.Moref
                associated_data_list.append(associated_data)

                # in case of VM snap, updating its corresponding DS entry in table
                for ds in ds_list_in_vm:
                    mo_table_obj = json_helper.ds_table()
                    mo_table_obj.moref = ds.DatastoreMoref
                    mo_table_obj.name = ds.Name
                    mo_table_obj.vmware_uuid = ds.VmfsUuid
                    mo_table_obj.vcenter_uuid = vcenter_instance_id
                    mo_table_obj.volume_type = volume_type
                    mo_table_obj.storage_vendor = virtual_copy_luns[0].Vendor
                    mo_table_obj.host_name = ds.host_name
                    mo_table_obj.host_id = ds.host_mo_id
                    mo_table_obj.datacenter_name = ds.datacenter_name
                    mo_table_obj.datacenter_id = ds.datacenter_mo_id
                    mo_table_obj.status = json_helper.copy_status.available
                    mo_table_obj.array_sno = array_serial_number

                    LOG.info("DS table entries: %s " % mo_table_obj.__dict__)
                    mo_table_response = self.db.create_or_update_rmcv_ds(context,
                                                                         ds.DatastoreMoref,
                                                                         mo_table_obj.__dict__)

                    ds_moref_to_db_id_dict[mo_table_obj.moref] = mo_table_response.id

                    associated_data = {}
                    associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_DS
                    associated_data['resourceName'] = ds.Name
                    associated_data['resourceUri'] = ds.DatastoreMoref
                    associated_data_list.append(associated_data)

                """
                TODO:6.0
                As of now we are adding peer VMs entries only if the VM(on which the snapshot is requested)
                has VMDKs from one DS. If VM has VMDKs from more then one DS then we need to add VM entries
                for both the DS. This will create problem while restore. So this case will be taken care later.
                """
                if len(ds_list_in_vm) == 1:
                    # for ds in ds_list_in_vm:
                    vm_list = ds_list_in_vm[0].VmList

                    vm_obj_list = []
                    for vm in vm_list:
                        vm_obj_list.append(pyvmomi_util.get_moref(vm.Moref, rmv_utils.VMWARE_OBJECT_TYPE_VM))

                    if vm_obj_list:
                        prop_list = ["name", "config.instanceUuid", "config.hardware", "config.template",
                                     "guest.guestFullName"]
                        vm_oc_list = self.vi_helper.get_object_properties(vm_obj_list, prop_list)
                        for vm_oc in vm_oc_list:
                            vm_prop = pyvmomi_util.extract_properties(vm_oc)

                            vm_moref = vm_oc.obj._moId

                            # We should not consider the Template VM.
                            if vm_prop.get("config.template") or vmObject.Moref == vm_moref:
                                vms_to_exclude_to_add_in_db.append(vm_moref)
                                continue

                            # Below is to get the proerties of each VM's attached VMDK.
                            vc_info_list = self.extract_virtual_copy_info(vm_prop, vm_moref)

                            # If VM has VMDK from more then one DS or RDM attached then we will not add this VM.
                            if len(vc_info_list) != 1:
                                vms_to_exclude_to_add_in_db.append(vm_moref)
                            else:
                                associated_data = {}
                                associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_VM
                                associated_data['resourceName'] = vm_prop.get("name")
                                associated_data['resourceUri'] = vm_moref
                                associated_data_list.append(associated_data)

                            # if vc_info_list is empty then there is no VMDKs attached to this VM.
                            # This VM is of no use. So no need of adding this to VM table.
                            if vc_info_list:
                                mo_table_obj = json_helper.vm_table()
                                mo_table_obj.moref = vm_moref
                                mo_table_obj.name = vm_prop.get("name")
                                mo_table_obj.vmware_uuid = vm_prop.get("config.instanceUuid")
                                mo_table_obj.vcenter_uuid = vcenter_instance_id
                                mo_table_obj.volume_type = volume_type  # TODO:6.0 check this variable
                                mo_table_obj.host_name = ds_list_in_vm[0].host_name
                                mo_table_obj.host_id = ds_list_in_vm[0].host_mo_id
                                mo_table_obj.datacenter_name = ds_list_in_vm[0].datacenter_name
                                mo_table_obj.datacenter_id = ds_list_in_vm[0].datacenter_mo_id
                                mo_table_obj.status = json_helper.copy_status.available
                                guest_os = vm_prop.get("guest.guestFullName")
                                mo_table_obj.guest_os = guest_os if guest_os else "Not available"

                                LOG.info("Peer VM : '%s' " % vm_prop.get("name"))
                                mo_table_response = self.db.create_or_update_rmcv_vm(context, vm_moref,
                                                                                     mo_table_obj.__dict__)
                                vm_moref_to_db_id_dict[mo_table_obj.moref] = mo_table_response.id

                            for vc_info in vc_info_list:
                                if virtual_copy_luns[0].DatastoreMoref == vc_info.DatastoreMoref:
                                    # Appending the VMDKs peer VMs to original virtual_copy_luns
                                    virtual_copy_luns[0].RestorableItemsList.extend(vc_info.RestorableItemsList)

                # DB Update End *****************************************************************

                # TODO:6.0 Try to do all these validation in one method
                # Check if snapshot is disabled for this VM
                vmware_checks.check_snapshot_disabled(vmInfo.IsSnapshotDisabled, vmInfo.ReasonSnapshotDisabled)

                self.validate_virtualmachine_object(vmInfo, is_app_consistent)

                # If there are any old VMFS snapshot left then delete it.
                # After deleting old snapshot, we are not retriving vmInfo again.
                # So property "HasVmfsSnapshots"
                # will have the old value "True" and cannot be used later in code.
                self.check_and_delete_vmfs_sapshots_vm(is_app_consistent,
                                                       vmInfo,
                                                       object_type,
                                                       mo_ref)

            elif object_type == 'Datastore':

                skip_ac_err = ignore_vmfs_snapshot_exceptions or ignore_validate_vm;
                # Update Tasks (Task Tracker and VMware Task)
                task_desc_string = 'Getting Datastore Information'
                task_status = "Initiated"
                task_percentage = 0
                task_state = 'Running'
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                save_hs_and_hss_properties = True
                ds_info = self.vi_helper.get_datastore_details(mo_ref, scsi_luns, save_hs_and_hss_properties)
                if ds_info.DatastoreUrl:
                    ds_mount_path = rmv_utils.extract_ds_mount_path(ds_info.DatastoreUrl)
                    if ds_mount_path:
                        ds_mount_path_dict[ds_info.Name] = ds_mount_path

                volume_type = rmv_utils.DISK_TYPE.get(ds_info.DatstoreType)

                virtual_copy_info = json_helper.plugin_virtual_copy_info()
                virtual_copy_info.Is3ParLun = scsi_luns[0].Is3ParLun
                virtual_copy_info.ItemName = ds_info.Name
                virtual_copy_info.LunUsedAs = json_helper.virtual_copy_item_type.Datastore
                virtual_copy_info.DatastoreMoref = ds_info.DatastoreMoref
                # Consider all luns in datastore(datastore can have more than one lun)
                Wwn_list = list()
                for lun in scsi_luns:
                    Wwn_list.append(lun.Wwn)
                virtual_copy_info.InServBaseVolumeWwn = Wwn_list
                virtual_copy_info.Vendor = scsi_luns[0].Vendor

                # lun_wwn is required to update the rmv_snapshots table
                lun_wwn = scsi_luns[0].Wwn

                vmObject = json_helper.vmware_object(object_type,
                                                     mo_ref,
                                                     ds_info.Name,
                                                     ds_info.VmfsUuid,
                                                     ds_info.VmfsUuid)
                vm_obj_name = ds_info.Name
                array_serial_number = scsi_luns[0].InServSerialNumber()

                # DB Update Start *****************************************************************

                mo_table_obj = json_helper.ds_table()
                mo_table_obj.moref = vmObject.Moref
                mo_table_obj.name = vmObject.Name
                mo_table_obj.vmware_uuid = vmObject.MoUuid
                mo_table_obj.vcenter_uuid = vcenter_instance_id
                mo_table_obj.volume_type = volume_type
                mo_table_obj.storage_vendor = virtual_copy_info.Vendor
                # TODO:6.0 Handle the scenario(for both DS and VM) if Datastore is from two hosts.
                mo_table_obj.host_name = ds_info.host_name
                mo_table_obj.host_id = ds_info.host_mo_id
                mo_table_obj.datacenter_name = ds_info.datacenter_name
                mo_table_obj.datacenter_id = ds_info.datacenter_mo_id
                mo_table_obj.status = json_helper.copy_status.available
                mo_table_obj.array_sno = array_serial_number

                LOG.info("DS table entries: %s " % mo_table_obj.__dict__)
                mo_table_response = self.db.create_or_update_rmcv_ds(context,
                                                                     vmObject.Moref,
                                                                     mo_table_obj.__dict__)

                ds_moref_to_db_id_dict[mo_table_obj.moref] = mo_table_response.id

                associated_data = {}
                associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_DS
                associated_data['resourceName'] = vmObject.Name
                associated_data['resourceUri'] = vmObject.Moref
                associated_data_list.append(associated_data)

                # DB Update End *****************************************************************

                vm_list_in_ds = self.vi_helper.get_virtual_machine_in_datastore(mo_ref, ds_info.Name)
                # if vm_name_list and vm_name_list.__len__() > 0:
                #     for vm_name in vm_name_list:
                #         vm_entry = rmv_utils.first_or_default(vm_list_in_ds, lambda i: i.Name == vm_name)
                #         # Bug Fix : 86993. If App Consistent VM, which is added in scheduler is deleted then
                #         # while creating snapshot ignore the deleted VM instead of throwing exception.
                #         if not vm_entry:
                #             LOG.warning("VM '%s' may be removed or moved to different Datastore. So ignoring this "
                #                         "VM." % vm_name)

                # DB Update Start *****************************************************************

                for vm_obj in vm_list_in_ds:
                    mo_table_obj = json_helper.vm_table()
                    mo_table_obj.moref = vm_obj.Moref
                    mo_table_obj.name = vm_obj.Name
                    mo_table_obj.vmware_uuid = vm_obj.MoUuid
                    mo_table_obj.volume_type = volume_type
                    mo_table_obj.vcenter_uuid = vcenter_instance_id
                    mo_table_obj.host_name = ds_info.host_name
                    mo_table_obj.host_id = ds_info.host_mo_id
                    mo_table_obj.datacenter_name = ds_info.datacenter_name
                    mo_table_obj.datacenter_id = ds_info.datacenter_mo_id
                    mo_table_obj.status = json_helper.copy_status.available
                    mo_table_obj.guest_os = vm_obj.guest_os

                    LOG.info("VM table entries - Name: '%s', MoRef: '%s' " % (vm_obj.Name, vm_obj.Moref))
                    mo_table_response = self.db.create_or_update_rmcv_vm(context,
                                                                         vm_obj.Moref,
                                                                         mo_table_obj.__dict__)

                    vm_moref_to_db_id_dict[mo_table_obj.moref] = mo_table_response.id

                # DB Update End *****************************************************************

                for vm_item in vm_list_in_ds:
                    # Making the call in try block to ignore the exception when VMInaccessible expection is raised
                    try:
                        vmInfo, hostInfo = self.get_virtual_machine_details(vm_item.Moref)
                    except rmv_exception.PyVmomiException as e:
                        LOG.exception("Inaccesible vm moref : " + str(vm_item.Moref) + " TaskId: " + task_id +
                                      " while taking snapshot of " + object_type + " : " + str(
                            vmware_db_obj.get('name')))
                        continue
                    vmInfo.VmMoref = vm_item.Moref

                    vm_selection_info = vi_objects.TpdVmVirtualMachineSelectionInfo(vm_item.Moref)

                    if select_all_vm and is_app_consistent:
                        vm_selection_info.vmInfo = vmInfo
                        vm_selection_info.bIsSelected = True

                    elif (vm_name_list is None) or (
                            vm_name_list.__len__() == 0) or \
                            (rmv_utils.first_or_default(vm_name_list,
                                                        lambda
                                                                i: i ==
                                                                   vmInfo.Name)
                             is not None):
                        if is_app_consistent:
                            vm_selection_info.vmInfo = vmInfo
                            vm_selection_info.bIsSelected = True
                        else:
                            vm_selection_info.vmInfo = vmInfo
                            vm_selection_info.bIsSelected = False
                    else:
                        vm_selection_info.vmInfo = vmInfo
                        vm_selection_info.bIsSelected = False

                    vm_ref = vm_item.Moref
                    hasVmfsSnap = self.check_vmfs_snapshot_present(vm_ref)
                    vmInfo.HasVmfsSnapshots = hasVmfsSnap
                    hasVmfsSnapList.append(hasVmfsSnap)

                    # set flag to indicate if app-consistency validations
                    # are required for the VM
                    app_consistency_check_required = False
                    if select_all_vm:
                        app_consistency_check_required = True
                    elif is_app_consistent and vm_name_list and vm_item.Name in vm_name_list:
                        app_consistency_check_required = True

                    if len(vmInfo.VirtualCopyPairList) > 1:
                        vms_to_exclude_to_add_in_db.append(vmInfo.VmMoref)
                    else:
                        associated_data = {}
                        associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_VM
                        associated_data['resourceName'] = vmInfo.Name
                        associated_data['resourceUri'] = vmInfo.VmMoref
                        associated_data_list.append(associated_data)

                    try:
                        # Allow crash consistent snapshot even if the VM has a combination of Disks
                        if app_consistency_check_required:
                            self.validate_virtual_machine_disk_details(vmInfo, hostInfo)
                        LOG.debug("about to validate VM: " + str(vmInfo.Name))
                        self.validate_virtualmachine_object(vmInfo, app_consistency_check_required)
                        ds_assoc_vm_list.append(vm_selection_info)
                        if is_app_consistent:
                            # Check if snapshot is disabled for this VM
                            vmware_checks.check_snapshot_disabled(vmInfo.IsSnapshotDisabled,
                                                                  vmInfo.ReasonSnapshotDisabled)
                    except rmv_exception.VMInaccessibleException as e:
                        LOG.exception("Inaccesible vm %s", e)
                        vm_selection_info.bIsSelected = False
                        ds_assoc_vm_list.append(vm_selection_info)
                        continue
                    except (rmv_exception.VMDifferentDiskTypeException, Exception) as e:
                        LOG.exception(e)
                        if skip_ac_err and rmv_utils.can_skip_app_consistent_error(e):
                            msg = "Failed to put the VM: " + str(vmInfo.Name) + " into application consistent " \
                                                                                "state. Reason: " + rmv_utils.get_event_msg_by_error(
                                e)
                            self.vi_helper.LogEvent(mo_ref, object_type, msg)
                            vm_selection_info.bIsSelected = False
                            ds_assoc_vm_list.append(vm_selection_info)
                            continue
                        else:
                            raise e

                    # Lock based on UUID of vm
                    if vmInfo.Uuid:
                        LOG.info("Acquiring Create Snapshot lock on : '%s'" % vmInfo.Uuid + " TaskId: " + task_id +
                                 " " + object_type + " : " + str(vmware_db_obj.get('name')))

                        locked_vm_name = "VM - " + vmInfo.Name
                        lock_response = None
                        lock_response = \
                            rmv_utils.acquire_snapshot_create_lock(
                                vmInfo.Uuid, self.vi_helper.validated_username, locked_vm_name, protection_group_id)
                        if lock_response:
                            if lock_response == "Object is in use":
                                already_locked_vm_uuid_list.append(vmInfo.Uuid)
                            else:
                                LOG.error("Could not acquire snapshot create lock.")
                                raise rmv_exception.SnapshotLockException(error=lock_response)
                        else:
                            vmObject_Uuid.append(vmInfo.Uuid)
                            LOG.info("Locked Create Snapshot on : '%s'" % vmInfo.Uuid + " TaskId: " + task_id +
                                     " while taking snapshot of " + object_type + " : " + str(
                                vmware_db_obj.get('name')))

                # If there are any old VMFS snapshot left then delete it.
                # After deleting old snapshot, we are not retriving vmInfo
                # again. So property "HasVmfsSnapshots" will have the old
                # value "True" and cannot be used later in code.
                rmvjobs_utils.check_and_delete_vmfs_sapshots_ds(is_app_consistent,
                                                                ds_assoc_vm_list,
                                                                object_type,
                                                                mo_ref, self.vi_helper,
                                                                skip_ac_check=skip_ac_err,
                                                                already_locked_vm_uuid_list=already_locked_vm_uuid_list)

                if is_app_consistent:
                    for vm_item in ds_assoc_vm_list:
                        if not vm_item.bIsSelected:
                            continue
                        if vm_item.vmInfo.VirtualCopyPairList.__len__() > 1:
                            if skip_ac_err:
                                self.vi_helper.LogEvent(mo_ref, object_type, "Failed to put the VM: "
                                                        + str(vmInfo.Name) + " into application consistent state, "
                                                                             "Reason: VM is associated more than one volumes")
                            else:
                                raise rmv_exception.DatastoreVMMoreThanOneVVError(vm_name=vm_item.vmInfo.Name)

                virtual_copy_info = vmware_checks.setup_restorable_items(mo_ref, vmObject.Name, virtual_copy_info,
                                                                         ds_assoc_vm_list, self.vi_helper)

                virtual_copy_luns.append(virtual_copy_info)

            # Check for the existence of 3PAR LUN
            vmware_checks.check_vm_luns(virtual_copy_luns)

            # Step # 4 : Create Snapshot DB record ###
            # TODO:6.0 Search for snap_info and delete all entries after CD removal
            # snap_info = rmv_structures.SnapshotInfo()
            # snap_info.CreatedVcUserName = self.vi_helper.validated_username
            # snap_info.VirtualCenterUrl = self.vi_helper.service_url
            # snap_info.VmWareObjectName = vmObject.Name
            # snap_info.VmWareObjectType = vmObject.Type
            # snap_info.ObjectUUID = vmObject.Uuid
            # snap_info.ObjectRefID = vmObject.Moref
            # snap_info.MoUuid = vmObject.MoUuid
            # snap_info.IsAppConsistent = is_app_consistent
            # snap_info.snapExpiry = snap_expiry
            # snap_info.snapRetention = snap_retention
            # snap_info.VirtualCenterInstanceId = vcenter_instance_id

            # TODO:6.0 this field is required in Backup app metadata. So adding it here. After ClientData optimization below will be removed.
            # snap_info.isERTEnabled = True

            has_vmfs_snapshots = False
            if object_type == 'VirtualMachine':
                has_vmfs_snapshots = vmInfo.HasVmfsSnapshots
            # TODO:6.0 For DS level snapshots, it is better to update for individual VMs.
            elif object_type == 'Datastore':
                if True in hasVmfsSnapList:
                    has_vmfs_snapshots = True
                else:
                    has_vmfs_snapshots = False

            # If Snapshot name is not given then create a snapshot name and assign it to VcSetName
            if not snapshot_name:
                snapshot_name = rmc_wrapper_service.get_recovery_set_snapshot_name(vmObject.Name)

            # snap_info.VcSetName = snapshot_name

            # Step # 5 : Create VMFS snapshot ###
            if is_app_consistent:

                task_desc_string = 'Creating VMFS snapshot for data consistency'
                task_status = "Initiated"
                task_percentage = 25
                task_state = 'Running'
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                LOG.info("Creating VMFS snapshot for data consistency")

                vm_mo_ref_list = []
                vm_name_moref_dict = dict()
                vm_mo_ref_uuid_dict = dict()
                if object_type == 'VirtualMachine':
                    vm_mo_ref_list = [mo_ref]
                    vm_name_moref_dict[mo_ref] = vmInfo.Name
                    vm_mo_ref_uuid_dict[mo_ref] = vmInfo.Uuid
                elif object_type == 'Datastore':
                    for vm_item in ds_assoc_vm_list:
                        if vm_item.bIsSelected:
                            vm_mo_ref_list.append(vm_item.vmInfo.VmMoref)
                            vm_name_moref_dict[vm_item.vmInfo.VmMoref] = vm_item.vmInfo.Name
                            vm_mo_ref_uuid_dict[vm_item.vmInfo.VmMoref] = vm_item.vmInfo.Uuid

                LOG.debug("ignore_vmfs_snapshot_exceptions value : '%s'" % ignore_vmfs_snapshot_exceptions)
                # If "ignore_vmfs_snapshot_exceptions" is True then ignore all the quiesce error for any VMs
                # and continue with snapshot creation. For VMs with quiesce errors will be considered for
                # crash consistent snapshot instead of App consistent.
                if ignore_vmfs_snapshot_exceptions and object_type == 'Datastore':
                    ds_assoc_vm_new_snap_id_list, vm_name_in_snap_list = \
                        self.vi_helper.CreateVmfsSnapshot_Ex(
                            vm_mo_ref_list,
                            vi_objects.VmfsSnapshotName,
                            "For HPE Array Volume Copy",
                            False,
                            True,
                            ignore_vmfs_snapshot_exceptions,
                            vm_name_moref_dict, vm_mo_ref_uuid_dict)
                else:
                    ds_assoc_vm_new_snap_id_list = \
                        self.vi_helper.CreateVmfsSnapshot(
                            vm_mo_ref_list,
                            vi_objects.VmfsSnapshotName,
                            "For HPE Array Volume Copy",
                            False,
                            True, vm_name_moref_dict, vm_mo_ref_uuid_dict)
                LOG.debug("vm_name_in_snap_list : '%s'" % vm_name_in_snap_list)
                LOG.info("VMFS snap created: %s" % ds_assoc_vm_new_snap_id_list)

            # Step # 6 : Create 3PAR snapshot ###
            try:
                task_desc_string = 'Creating Snapshot in the Storage system'
                task_percentage = 50
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                wwn_list = rmc_wrapper_service._get_wwn_list(virtual_copy_luns)
                wwn_list = list(set(wwn_list))

                # send user event to device
                if recovery_set_id:
                    rmc_wrapper_service.send_callhome_user_event(recovery_set_id, "info",
                                                                 'Start HPE RMC Snapshot creation for ' + object_type + ' ' + vm_obj_name + '. ')

                LOG.info("Creating HPE Array snapshot....")
                ret_snap_info = rmc_wrapper_service.create_3par_snapshot(
                    array_serial_number,
                    wwn_list,
                    vmObject.Name,
                    snapshot_name,
                    vmware_db_id,
                    context,
                    snap_expiry,
                    snap_retention,
                    recovery_set_id,
                    object_type,
                    protectionPolicyId=protectionPolicyId,
                    task_id=task_id,
                    mo_uuid=vmObject.MoUuid,
                    lun_wwn=lun_wwn)

                snapshot_set_id = ret_snap_info.snapshot_guid

                copies_table_obj = self.db.get_rmcv_copy_by_id(context, copy_id)
                copies_table_obj.name = snapshot_name  # TODO:6.0 we should get it from RMC as RMC is creating it. Verify.
                copies_table_obj.rmc_copyset_id = ret_snap_info.snapshot_guid
                copies_table_obj.point_in_time = ret_snap_info.creation_time
                copies_table_obj.array_name = ret_snap_info.array_name
                copies_table_obj.array_serial_number = ret_snap_info.array_serial_num
                copies_table_obj.expiry = snap_expiry
                copies_table_obj.retention = snap_retention
                copies_table_obj.ds_mount_path_dir = jsonutils.dumps(
                    ds_mount_path_dict)  # TODO:6.0 this needs to br changed.
                copies_table_obj.type = rmv_utils.copy_type.SNAPSHOT
                copies_table_obj.status = ret_snap_info.State
                copies_table_obj.has_vmfs_snapshots = has_vmfs_snapshots
                copies_table_obj.version = self.rmc_version

                LOG.info("Copy details : %s " % copies_table_obj.__dict__)
                self.db.update_rmcv_copy(context, copy_id, copies_table_obj)
                rmv_copy_id = copy_id
                resource_uri = "/rest/rm-central/rmv/v1/copies/" + copy_id

                for associated_data in associated_data_list:
                    associated_data['status'] = ret_snap_info.State
                    associated_data['errorReason'] = None

                task_desc_string = 'Snapshot creation in the Storage system is completed'
                task_percentage = 65
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(
                    task_desc_string,
                    task_percentage,
                    task_state,
                    task_id,
                    rmc_wrapper_service,
                    None, task_status=task_status,
                    resource_uri=resource_uri,
                    associated_data=associated_data_list)

                virtual_copy_luns_list = []
                for virtual_copy in virtual_copy_luns:

                    for i in range(len(virtual_copy.RestorableItems)):

                        if object_type == 'VirtualMachine':
                            # virtual_copy.RestorableItems[i].OriginalVMName = vmObject.Name
                            # virtual_copy.RestorableItems[i].vm_moref = vmObject.Moref
                            if (is_app_consistent):
                                virtual_copy.RestorableItems[i].IsAppConsistent = True
                            else:
                                virtual_copy.RestorableItems[i].IsAppConsistent = False

                        # TODO:6.0 As of now keep this logic as it is.
                        # For VMs with quiesce error, update the client data with IsAppConsistent field to False.
                        # Meaning for these VMs instead of App consistent, Crash consistent snapshot is taken.
                        if ignore_vmfs_snapshot_exceptions and object_type == 'Datastore':  # TODO Datastore can be removed to support for VM
                            if virtual_copy.RestorableItems[i].OriginalVMName not in vm_name_in_snap_list:
                                virtual_copy.RestorableItems[i].IsAppConsistent = False

                    virtual_copy_luns_list.append(virtual_copy)

                try:

                    vm_vmdks_json_dict = {}
                    ds_vmdks_json_dict = {}
                    ds_to_wwn_dict = {}
                    app_consistent_info_dict = {}

                    for virtual_copy in virtual_copy_luns_list:
                        vmdk_id = None
                        ds_id = ds_moref_to_db_id_dict.get(virtual_copy.DatastoreMoref)
                        for restore_items in virtual_copy.RestorableItemsList:

                            if not restore_items.OriginalVMName:
                                continue

                            vmdk_table_obj = json_helper.vmdks_table()
                            vmdk_table_obj.path = restore_items.FileName

                            if virtual_copy.LunUsedAs == json_helper.virtual_copy_item_type.Datastore:
                                vmdk_table_obj.type = json_helper.lun_type.datastore
                            elif virtual_copy.LunUsedAs == json_helper.virtual_copy_item_type.RDMLun:
                                vmdk_table_obj.type = json_helper.lun_type.rdm
                                if restore_items.Properties[0] == \
                                        json_helper.TpdVmVirtualMachineItemProperty.VirtualDiskRDMIsInVirtualCompatableMode:
                                    vmdk_table_obj.rdm_type = "virtualMode"
                                elif restore_items.Properties[0] == \
                                        json_helper.TpdVmVirtualMachineItemProperty.VirtualDiskRDMIsInPhysicalCompatableMode:
                                    vmdk_table_obj.rdm_type = "physicalMode"

                            vmdk_table_obj.disk_mode = str(restore_items.disk_mode)
                            vmdk_table_obj.sharing_mode = str(restore_items.sharing_mode)
                            vmdk_table_obj.virtualmachine_id = vm_moref_to_db_id_dict.get(restore_items.vm_moref)
                            vmdk_table_obj.datastore_id = ds_id
                            vmdk_table_obj.uuid = restore_items.disk_uuid
                            vmdk_table_obj.capacity_in_bytes = restore_items.capacity_in_bytes
                            vmdk_table_obj.name = restore_items.disk_name

                            LOG.info("VMDK DB entries : %s " % vmdk_table_obj.__dict__)
                            # check_if_vmdk_entry_already_present()
                            vmdk = self.db.get_vmdk_by_vmdk_properties(context,
                                                                       vmdk_table_obj.virtualmachine_id,
                                                                       vmdk_table_obj.datastore_id,
                                                                       vmdk_table_obj.path,
                                                                       vmdk_table_obj.type,
                                                                       vmdk_table_obj.rdm_type,
                                                                       vmdk_table_obj.disk_mode,
                                                                       vmdk_table_obj.sharing_mode,
                                                                       vmdk_table_obj.capacity_in_bytes,
                                                                       vmdk_table_obj.name)
                            vmdk_db_id = None
                            if vmdk:
                                vmdk_db_id = vmdk.id
                            else:
                                LOG.info("First VMDK entry or its properties got changed.")
                                vmdk_table_response = self.db.create_rmcv_vmdk(context, vmdk_table_obj.__dict__)
                                vmdk_db_id = vmdk_table_response.id

                            # TODO:6.0 verify if ds doesnt have any VMs
                            vm_vmdks_jsonb_obj = json_helper.vm_vmdks_jsonb()
                            vm_vmdks_jsonb_obj.vmdk_id = vmdk_db_id
                            vm_vmdks_jsonb_obj.datastore_id = ds_id

                            vm_dict_key = vm_moref_to_db_id_dict.get(restore_items.vm_moref)
                            if vm_vmdks_json_dict.has_key(vm_dict_key):
                                vm_vmdks_json_dict[vm_dict_key].append(vm_vmdks_jsonb_obj.__dict__)
                            else:
                                vm_vmdks_json_dict[vm_dict_key] = [vm_vmdks_jsonb_obj.__dict__]

                            ds_vmdks_jsonb_obj = json_helper.ds_vmdks_jsonb()
                            ds_vmdks_jsonb_obj.vmdk_id = vmdk_db_id
                            ds_vmdks_jsonb_obj.vm_id = vm_moref_to_db_id_dict.get(restore_items.vm_moref)
                            ds_vmdks_jsonb_obj.is_app_consistent = restore_items.IsAppConsistent

                            # Below will be used to update the is_app_consistent column in Assoc table.
                            app_consistent_info_dict[restore_items.vm_moref] = restore_items.IsAppConsistent

                            if ds_vmdks_json_dict.has_key(ds_id):
                                ds_vmdks_json_dict[ds_id].append(ds_vmdks_jsonb_obj.__dict__)
                            else:
                                ds_vmdks_json_dict[ds_id] = [ds_vmdks_jsonb_obj.__dict__]

                            if virtual_copy.LunUsedAs == json_helper.virtual_copy_item_type.RDMLun:
                                vmdk_id = vmdk_db_id

                        wwn_details_obj = json_helper.wwn_details_json()
                        wwn_details_obj.wwn = virtual_copy.InServBaseVolumeWwn
                        if virtual_copy.LunUsedAs == json_helper.virtual_copy_item_type.Datastore:
                            wwn_details_obj.lun_used_as = json_helper.lun_type.datastore
                        elif virtual_copy.LunUsedAs == json_helper.virtual_copy_item_type.RDMLun:
                            wwn_details_obj.lun_used_as = json_helper.lun_type.rdm
                            wwn_details_obj.vmdk_id = vmdk_id

                        if ds_to_wwn_dict.has_key(ds_id):
                            ds_to_wwn_dict[ds_id].append(wwn_details_obj.__dict__)
                        else:
                            ds_to_wwn_dict[ds_id] = [wwn_details_obj.__dict__]

                    if object_type == 'VirtualMachine':
                        mo_assoc_table_obj = json_helper.vm_copies_assoc_table()
                        mo_assoc_table_obj.virtual_machine_id = vm_moref_to_db_id_dict.get(vmObject.Moref)
                        mo_assoc_table_obj.copy_id = copy_id
                        mo_assoc_table_obj.vmdks = vm_vmdks_json_dict.get(mo_assoc_table_obj.virtual_machine_id)
                        mo_assoc_table_obj.is_app_consistent = app_consistent_info_dict.get(vmObject.Moref)

                        # This assoc entry in already created in API layer. So updating it here.
                        self.db.update_rmcv_vm_copy_assoc(context, copy_id, mo_assoc_table_obj.virtual_machine_id,
                                                          mo_assoc_table_obj.__dict__)

                        for ds in ds_list_in_vm:
                            mo_assoc_table_obj = json_helper.ds_copies_assoc_table()
                            mo_assoc_table_obj.datastore_id = ds_moref_to_db_id_dict.get(ds.DatastoreMoref)
                            mo_assoc_table_obj.copy_id = copy_id
                            mo_assoc_table_obj.vmdks = ds_vmdks_json_dict.get(mo_assoc_table_obj.datastore_id)
                            mo_assoc_table_obj.wwn_details = ds_to_wwn_dict.get(mo_assoc_table_obj.datastore_id)

                            mo_assoc_table_obj.is_app_consistent = False if False in app_consistent_info_dict.values() \
                                else True

                            self.db.create_rmcv_ds_copy_assoc(mo_assoc_table_obj.__dict__)

                        # Below will add Assoc enries for the Peer VMs of the VM on which Snapshot is being taken.
                        if len(ds_list_in_vm) == 1:
                            # for ds in ds_list_in_vm:
                            vm_list = ds_list_in_vm[0].VmList

                            for vm in vm_list:

                                if vm.Moref in vms_to_exclude_to_add_in_db:
                                    LOG.info("VM : '%s', has VMDK/RDM from another DS. So not adding this to VM "
                                             "assoc table." % vm.Moref)
                                    continue

                                mo_assoc_table_obj = json_helper.vm_copies_assoc_table()
                                mo_assoc_table_obj.virtual_machine_id = vm_moref_to_db_id_dict.get(vm.Moref)
                                mo_assoc_table_obj.copy_id = copy_id
                                mo_assoc_table_obj.vmdks = vm_vmdks_json_dict.get(mo_assoc_table_obj.virtual_machine_id)
                                mo_assoc_table_obj.is_app_consistent = app_consistent_info_dict.get(vm.Moref)

                                self.db.create_rmcv_vm_copy_assoc(mo_assoc_table_obj.__dict__)

                    elif object_type == 'Datastore':
                        mo_assoc_table_obj = json_helper.ds_copies_assoc_table()
                        mo_assoc_table_obj.datastore_id = ds_moref_to_db_id_dict.get(vmObject.Moref)
                        mo_assoc_table_obj.copy_id = copy_id
                        mo_assoc_table_obj.vmdks = ds_vmdks_json_dict.get(mo_assoc_table_obj.datastore_id)
                        mo_assoc_table_obj.wwn_details = ds_to_wwn_dict.get(mo_assoc_table_obj.datastore_id)

                        mo_assoc_table_obj.is_app_consistent = False if False in app_consistent_info_dict.values() \
                            else True

                        self.db.update_rmcv_ds_copy_assoc(context, copy_id, mo_assoc_table_obj.datastore_id,
                                                          mo_assoc_table_obj.__dict__)

                        # Updating corresponding VM entries in the Assoc table
                        for vm_obj in vm_list_in_ds:
                            """
                            In this loop we are adding the VM assoc entries for a snapshot taken on DS.
                            As DS snapshot is considered as a full snapshot for all its VMs, then if any extra
                            VMDK/RDM attached from another DS to any one VM then DS snapshot will not be considered
                            as full snapshot for this VM. So we are not adding this VM Assoc entry to DB
                            """
                            if vm_obj.Moref in vms_to_exclude_to_add_in_db:
                                LOG.info("VM : '%s', has VMDK/RDM from another DS. So not adding this to VM "
                                         "assoc table." % vm_obj.Name)
                                continue

                            mo_assoc_table_obj = json_helper.vm_copies_assoc_table()
                            mo_assoc_table_obj.virtual_machine_id = vm_moref_to_db_id_dict.get(vm_obj.Moref)
                            mo_assoc_table_obj.copy_id = copy_id
                            mo_assoc_table_obj.vmdks = vm_vmdks_json_dict.get(mo_assoc_table_obj.virtual_machine_id)
                            mo_assoc_table_obj.is_app_consistent = app_consistent_info_dict.get(vm_obj.Moref)

                            self.db.create_rmcv_vm_copy_assoc(mo_assoc_table_obj.__dict__)

                # TODO:6.0 need to handle the exception properly.
                except Exception as e:
                    LOG.exception(e)
                    raise e

            except (rmv_exception.StoragePoolNotAvailableException,
                    rmv_exception.RMCRecoverySetSnapshotStatusException,
                    rmv_exception.RMCRecoverySetSnapshotCreationException,
                    rmv_exception.RMCRecoverySetStatusException,
                    rmv_exception.RMCRecoverySetCreationException,
                    rmv_exception.RMCStorageSystemNotRegisteredException,
                    rmv_exception.RMCAPIError,
                    rmv_exception.RMCAPIUnknownError,
                    rmv_exception.RMCFieldNotFoundException,
                    rmv_exception.RMCStorageSystemNotLicensedException,
                    rmv_exception.TaskError, rmv_exception.VmwareException,
                    Exception
                    ) as e:
                LOG.exception("Failed to create snapshot in storage system:%s", e)
                if hasattr(e, "msg"):
                    msg = e.msg
                elif hasattr(e, "message"):
                    msg = e.message
                else:
                    msg = "Internal error"

                task_percentage = 75

                if is_app_consistent and transportMode == None:
                    task_desc_string = "Deleting VMFS snapshot"
                    task_status = "Initiated"
                    task_state = 'Running'
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)
                    LOG.info("Deleting VMFS snapshot")
                    self.vi_helper.Delete_vmfs_snapshot(
                        ds_assoc_vm_new_snap_id_list,
                        False)
                    ds_assoc_vm_new_snap_id_list = []

                raise rmv_exception.StorageSystemVirtualCopyCreationException(msg=msg)

            # Step # 7 : Delete VMFS snapshot ###
            task_percentage = 75
            if is_app_consistent and transportMode == None:
                task_desc_string = "Deleting VMFS snapshot"
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                LOG.info("Deleting the VMFS snapshot : %s" % ds_assoc_vm_new_snap_id_list)
                self.vi_helper.Delete_vmfs_snapshot(ds_assoc_vm_new_snap_id_list, False)
            keys = request_body.keys()
            # nanditha
            try:
                if 'fileIndex' in keys and request_body['fileIndex']:
                    LOG.info('file index value found true')
                    req_obj_type = request_body['vmWareObjectType']
                    copy_info = self.db.get_rmcv_copy_by_id(context, copy_id)
                    rmc_copyset_id = copy_info.rmc_copyset_id
                    snapInfo={'id':rmc_copyset_id,'name':copy_info.name}
                    vmware_obj_info = self.db_utils.get_vmware_object_by_object_type_and_moref(context, req_obj_type,
                                                                                               mo_ref)
                    vm_db_obj = self.db_utils.get_virtual_machine_by_moref(context, mo_ref)
                    vmware_object_id = vm_db_obj['id']
                    (clone_details, recovery_set_id) = self.mount_snapshot_esx(context, rmc_copyset_id, x_auth_token,
                                                                               '172.17.10.89', 'esxHostIP',
                                                                               task_id, None, vm_db_obj.id,
                                                                               req_obj_type, copy_id, None, None, None,
                                                                               None,
                                                                               None, [])
                    clone_info=self.db.get_rmcv_clone_by_recovery_set_id(context,recovery_set_id)
                    LOG.info("clone details after mount %s",clone_details)
                    cloned_objects_details = clone_info.clone_details['cloned_ds_details'][0]
                    attachvmdk_input={}
                    attachvmdk_input[rmv_utils.SOURCE_DATASTORE_NAME] =cloned_objects_details["name"]
                    attachvmdk_input[rmv_utils.PARENT_DATASTORE_NAME]=cloned_objects_details["parent_ds_name"]
                    attachvmdk_input["virtualMachineMoref"]="vm-102521"
                    #vmdk_path=cloned_objects_details["parent_vmdk_path"]
                    #split_path=vmdk_path.split('] ')
                    attachvmdk_input[rmv_utils.VMDK_SOURCE_FILE]='VM_1_ON_DS_200G/VM_1_ON_DS_200G.vmdk'
                    attachvmdk_input[rmv_utils.VMDK_ID]="81e6d01e-d043-482c-931f-700447475775"
                    LOG.info("attach_vmdk_input values %s",attachvmdk_input)
                    self.attachvmdk_snapshot(context,
                                        clone_info.id,
                                        x_auth_token,
                                        attachvmdk_input,
                                        task_id)
                    #get vmdkid
                    vm_host_info_dict = self.vi_helper.GetVirtualMachineInfo("vm-102521", True, False)
                    LOG.info("Virtual machine info %s",vm_host_info_dict)
                    copy_list=vm_host_info_dict['vm_info'].VirtualCopyPairList
                    found= False
                    diskUuid=''
                    for copy in copy_list:
                        LOG.info("copy.DatastoreMoref %s", copy.DatastoreMoref )
                        if copy.DatastoreMoref == cloned_objects_details["moref"]:
                            restoreList = copy.RestorableItemsList
                            for retore in restoreList:
                                if retore.FileName and 'VM_1_ON_DS_200G/VM_1_ON_DS_200G.vmdk' in retore.FileName:
                                    found= True
                                    diskUuid=retore.disk_uuid
                                    break
                            if found:
                                break
                    LOG.info("Disk uuid is %s",diskUuid)
                    LOG.info("calling mount_and_crowl")
                    fs_crowler.mount_and_crowl('6000C295-791b-2135-6824-3083ddb5ad6c',[diskUuid],snapInfo)
                    LOG.info("called mount_and_crowl")

                else:
                    LOG.info('file index value found false')
            except (Exception) as e:
                LOG.exception("failed during mounting %s", str(e))

            task_desc_string = "HPE RMC Snapshot created successfully"
            task_state = 'Completed'
            task_status = "Ok"
            task_percentage = 100
            LOG.info(('%s'), task_desc_string)

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper,
                              ret_snap_info.snapshot_guid, task_status=task_status)

            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            # send user event to device

            if recovery_set_id:
                rmc_wrapper_service.send_callhome_user_event(recovery_set_id, "info",
                                                             'HPE RMC Snapshot created successfully for ' + object_type + ' ' + vm_obj_name + '. ')

            ret_dict = {}
            ret_dict['snapshot_guid'] = ret_snap_info.snapshot_guid
            ret_dict['snap_config'] = snap_config
            ret_dict['snap_moref_list'] = ds_assoc_vm_new_snap_id_list
            ret_dict['rmvCopyId'] = rmv_copy_id
            return ret_dict

        except (rmv_exception.StorageSystemVirtualCopyCreationException,
                rmv_exception.SnapshotDisabledException,
                rmv_exception.VMInaccessibleException,
                rmv_exception.VMwareToolsNotRunningException,
                rmv_exception.PhysicalRDMException,
                rmv_exception.VMhasNoLunsException,
                rmv_exception.VMFSsnapshotExistsException,
                rmv_exception.VMFSUnnamedSnapshotException,
                rmv_exception.VMFSsnapshotExistsException,
                rmv_exception.UnknownVMwareObjectError,
                rmv_exception.DatastoreUnusableError,
                rmv_exception.DatastoreUnsupportedTypeError,
                rmv_exception.DatastoreSpannedError,
                rmv_exception.DatastoreNon3parError,
                rmv_exception.DatastoreMoreThanOneIn3parVolumeError,
                rmv_exception.DatastoreDoesNotContainVMError,
                rmv_exception.DatastoreVMMoreThanOneVVError,
                rmv_exception.vCenterMoRefError,
                rmv_exception.TaskError,
                rmv_exception.VmUnusableError,
                rmv_exception.VmMorefMissmatch,
                rmv_exception.CreateVMFSSnapshotException,
                rmv_exception.VmwareException,
                rmv_exception.PyVmomiException,
                rmv_exception.ReconfigureVmException,
                rmv_exception.VmVddkBackupException,
                Exception
                ) as e:
            LOG.exception("Failed to create snapshot, TaskId: " + task_id + " /n " + str(e))
            if hasattr(e, "msg"):
                msg = e.msg
            elif hasattr(e, "message"):
                msg = e.message
            else:
                msg = "Internal error"
            task_desc_string = "HPE RMC Snapshot creation failed: %s" % msg
            task_state = 'Failed'
            task_status = "Error"
            task_percentage = 100

            for associated_data in associated_data_list:
                associated_data['status'] = "error"
                associated_data['errorReason'] = task_desc_string

            LOG.error(task_desc_string + ", taskId: " + task_id)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status,
                              associated_data=associated_data_list)

            # Associating the vCenter Task with User Logged Event. Error message which is displayed in the
            # Task detail will be displayed in User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            if ds_assoc_vm_new_snap_id_list and ds_assoc_vm_new_snap_id_list.__len__() > 0:
                self.vi_helper.Delete_vmfs_snapshot(ds_assoc_vm_new_snap_id_list, False)
                ds_assoc_vm_new_snap_id_list = []

            # Commented LogEvent call as same event has been triggered through PostEvent call.
            # self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)

            # send user event to device
            if recovery_set_id:
                rmc_wrapper_service.send_callhome_user_event(recovery_set_id, "info",
                                                             'HPE RMC Snapshot creation failed for ' + object_type + ' ' + vm_obj_name + '. ')

            self.update_rmcv_db_with_error_details(context, task_id, copy_id, object_type, vmware_db_id, vm_list_in_ds,
                                                   task_desc_string, snapshot_name, vms_to_exclude_to_add_in_db)

        finally:
            # Release the acquired snapshot create lock
            if mo_ref:
                rmv_utils.release_snapshot_create_lock(mo_ref)
                LOG.info(("Released Lock for object '%s'") % mo_ref)
            # Release the aquired snapshot create lock, by checking the vmObject
            for uuid in vmObject_Uuid:
                if uuid:
                    rmv_utils.release_snapshot_create_lock(uuid)
                    LOG.info(("Released Lock for snapshot '%s'") % vmware_db_id)

            # Host details is stored in the below Dict while creating the snapshot. Details can be removed.
            LOG.debug("hs_and_hss_properties - '%s' Before " % len(pyvmomi_util.hs_and_hss_properties))
            pyvmomi_util.hs_and_hss_properties.clear()
            LOG.debug("hs_and_hss_properties - '%s' After " % pyvmomi_util.hs_and_hss_properties)


    def update_rmcv_db_with_error_details(self,
                                          context=None,
                                          task_id=None,
                                          copy_id=None,
                                          object_type=None,
                                          vmware_db_id=None,
                                          vm_list_in_ds=None,
                                          error_details=None,
                                          snapshot_name=None,
                                          vms_to_exclude_to_add_in_db=list()):
        try:

            # tsk.get('task').get('subTasks').get('tasks')[0].get('associatedResource').get('resourceUri')

            # If Exception the update Copy and Assoc table with error status
            snap_copy = self.db.get_rmcv_copy_by_id(context, copy_id)
            snap_copy.status = json_helper.copy_status.error
            snap_copy.name = snapshot_name
            snap_copy.error_details = error_details.replace("\n", "")

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(None)
            copy_set_id = self.get_rmc_copy_set_id_in_task_id(rmc_wrapper_service, task_id)

            if copy_set_id:
                try:
                    snapshot_details = rmc_wrapper_service.get_snapshot(copy_set_id)
                    snapshot_set = snapshot_details.get('snapshotSet')

                    snap_copy.point_in_time = snapshot_set.get('createdAt')
                    snap_copy.rmc_copyset_id = copy_set_id
                except Exception as e:
                    LOG.exception(e)

            self.db.update_rmcv_copy(context, copy_id, snap_copy)

            if object_type == 'Datastore':
                vm_copies_assoc_list = self.db.get_all_rmcv_vm_copy_assoc_by_copy_id(context, copy_id)

                if not vm_list_in_ds:
                    ds_db_obj = self.db.get_datastore_by_id(context, vmware_db_id)
                    vm_list_in_ds = self.vi_helper.get_virtual_machine_in_datastore(ds_db_obj.moref, ds_db_obj.name)

                if vm_copies_assoc_list and (len(vm_copies_assoc_list) == len(vm_list_in_ds)):
                    # If VM Assoc entries is already present then no need to update again
                    pass
                else:
                    for vm_obj in vm_list_in_ds:
                        mo_table_response = self.db.get_rmcv_virtual_machines_by_moref(context, vm_obj.Moref)

                        if not mo_table_response:
                            mo_table_obj = json_helper.vm_table()
                            mo_table_obj.moref = vm_obj.Moref
                            mo_table_obj.name = vm_obj.Name
                            mo_table_obj.vmware_uuid = vm_obj.MoUuid
                            mo_table_obj.status = json_helper.copy_status.available

                            mo_table_response = self.db.create_or_update_rmcv_vm(context,
                                                                                 vm_obj.Moref,
                                                                                 mo_table_obj.__dict__)

                        if vm_obj.Moref in vms_to_exclude_to_add_in_db:
                            LOG.info("VM : '%s', has VMDK/RDM from another DS. So not adding this to VM "
                                     "assoc table." % vm_obj.Name)
                            continue

                        mo_assoc_table_obj = json_helper.vm_copies_assoc_table()
                        mo_assoc_table_obj.virtual_machine_id = mo_table_response.id
                        mo_assoc_table_obj.copy_id = copy_id
                        self.db.create_rmcv_vm_copy_assoc(mo_assoc_table_obj.__dict__)

        except Exception as e:
            LOG.exception(e)
            # No need to raise exception here.
            pass

    # TODO: This method has been moved to rmvutils file , delete later on
    def get_rmc_copy_set_id_in_task_id(self, rmc_wrapper_service, task_id):

        # tsk.get('task').get('subTasks').get('tasks')[0].get('associatedResource').get('resourceUri')
        copy_set_id = None
        try:
            task_response = rmc_wrapper_service.get_copy_task_status(task_id)

            sub_tasks = task_response.get('task').get('subTasks')
            if sub_tasks:
                tasks_in_sub_tasks = sub_tasks.get('tasks')
                if tasks_in_sub_tasks:
                    resource_uri = tasks_in_sub_tasks[0].get('associatedResource').get('resourceUri')
                    copy_set_id = resource_uri.split('/')[5]
                    LOG.info("Failed RMC Copy set ID : %s " % copy_set_id)

        except Exception as e:
            LOG.exception("Unable to retrieve copy_set_id from Task. %s" % e)
            # No need to raise Exception here.If exception here then we will not update our Db with RMC copy_set_id.
            pass

        return copy_set_id

    def extract_virtual_copy_info(self, vm_prop, vm_moref):

        LOG.debug("extract_virtual_copy_info : enter")

        vc_list = []
        try:
            vm_hardware_info = vm_prop.get("config.hardware")
            if vm_hardware_info._wsdlName == "VirtualHardware":

                tmp_ds_dict = {}
                for virtual_device in vm_hardware_info.device:

                    if virtual_device and virtual_device._wsdlName != "VirtualDisk":
                        continue

                    vmdk_info = json_helper.virtual_machine_item()

                    virtual_disk = virtual_device.backing
                    if virtual_disk._wsdlName == "VirtualDiskFlatVer2BackingInfo":
                        vmdk_info.ItemType = json_helper.virtual_machine_config_item_type.FlatVirtualHarddisk
                        file_name = None
                        # From 6.0 we will always add core VMDK path if there are delta VMDKs.
                        if virtual_disk.parent:
                            file_name = self.get_parent_disk_file_name(virtual_disk.parent)

                        vmdk_info.FileName = file_name if file_name else virtual_disk.fileName
                        vmdk_info.vm_moref = vm_moref
                        vmdk_info.OriginalVMName = vm_prop.get('name')
                        vmdk_info.IsAppConsistent = False
                        vmdk_info.disk_mode = virtual_disk.diskMode
                        vmdk_info.sharing_mode = virtual_disk.sharing
                        vmdk_info.disk_uuid = virtual_disk.uuid
                        vmdk_info.capacity_in_bytes = virtual_device.capacityInBytes
                        vmdk_info.disk_name = virtual_device.deviceInfo.label
                        if virtual_disk.datastore:
                            ds_moref = virtual_disk.datastore._moId

                            virtual_copy_info = tmp_ds_dict.get(ds_moref)

                            if not virtual_copy_info:
                                virtual_copy_info = json_helper.plugin_virtual_copy_info()
                                virtual_copy_info.DatastoreMoref = ds_moref
                                virtual_copy_info.LunUsedAs = json_helper.virtual_copy_item_type.Datastore

                                tmp_ds_dict[ds_moref] = virtual_copy_info
                                vc_list.append(virtual_copy_info)

                            virtual_copy_info.RestorableItemsList.append(vmdk_info)

                    elif virtual_disk._wsdlName == "VirtualDiskRawDiskMappingVer1BackingInfo":
                        vmdk_info.ItemType = json_helper.virtual_machine_config_item_type.RDMVirtualHardisk
                        vmdk_info.FileName = virtual_disk.fileName
                        vmdk_info.disk_mode = virtual_disk.diskMode
                        vmdk_info.sharing_mode = virtual_disk.sharing
                        vmdk_info.disk_uuid = virtual_disk.uuid
                        vmdk_info.capacity_in_bytes = virtual_device.capacityInBytes
                        vmdk_info.disk_name = virtual_device.deviceInfo.label
                        if rmv_utils.has_attribute(virtual_disk, "lunUuid"):
                            if virtual_disk.lunUuid:
                                # 0002AC is Unique Identification given by IEEE to 3par
                                # 000EB3 is Unique Identification given by IEEE to LEFTHAND
                                # 6C9CE9 is Unique Identification given by IEEE to Nimble
                                # UI is used to identify weather the scsi lun is 3par or LEFTHAND(Store Virtul)
                                # in case of nimble lun, length of lun uuid will be 86
                                if virtual_disk.lunUuid.upper().__contains__(
                                        json_helper.unique_identification_for_storage_device.STORESERV) \
                                        or virtual_disk.lunUuid.upper().__contains__(
                                    json_helper.unique_identification_for_storage_device.LEFTHAND) \
                                        or virtual_disk.lunUuid.upper().__contains__(
                                    json_helper.unique_identification_for_storage_device.NIMBLE) \
                                        or len(virtual_disk.lunUuid) == 86:

                                    virtual_copy_info = json_helper.plugin_virtual_copy_info()
                                    virtual_copy_info.LunUsedAs = json_helper.virtual_copy_item_type.RDMLun
                                    virtual_copy_info.RestorableItemsList.append(vmdk_info)

                                    if virtual_disk.datastore:
                                        virtual_copy_info.DatastoreMoref = virtual_disk.datastore._moId

                                    vc_list.append(virtual_copy_info)
        except Exception as e:
            LOG.exception("Unable to extract the VC Info. %s " % e)

        LOG.debug("extract_virtual_copy_info : enter")
        return vc_list

    def get_parent_disk_file_name(self, disk_parent):

        while disk_parent.parent:
            disk_parent = disk_parent.parent

        file_name = disk_parent.fileName

        return file_name

    def mounted_ds_name_for_vm(self, context, parent_copy_id, vm_name):
        vm_list = []
        ds_name = None
        clone = self.db.get_rmcv_clone_by_parent_copy_id(context, parent_copy_id)
        ds_info = clone.clone_details
        for ds_dict in ds_info:
            LOG.info(type(ds_dict))
            vm_list = self.vi_helper.get_virtual_machine_in_datastore(ds_dict['ds_moref'], ds_dict['ds_name'])
            LOG.info(vm_list)
            LOG.info(vm_name)
            if vm_name in vm_list:
                ds_name = ds_dict['ds_name']
                break

        # get_virtual_machine_in_datastore is returning emtpy on the mounted ds
        # for now assuming the first ds
        ds_dict = ds_info[0]
        ds_name = ds_dict['ds_name']
        return ds_name

    def get_mounted_vmx_path_for_vm(self, context, recovery_set_id, vm_name, vm_moref):
        vmx_path = None
        clone = self.db.get_rmcv_clone_by_recovery_set_id(context, recovery_set_id)
        clone_info = clone.clone_details
        ds_info = clone_info['cloned_ds_details']
        for ds_dict in ds_info:
            vmx_path = self.get_recoverable_vm_vmx_file_path(ds_dict['moref'], ds_dict['name'], vm_name, vm_moref)
            if vmx_path:
                break
        return vmx_path

    def get_recoverable_vm_vmx_file_path(self, mountedDatastoreMoref, mountedDatastoreName, virtual_machine_name,
                                         vm_moref):

        """
        Getting the mounted vmx path and vmx name

        :param mountedDatastoreMoref: mounted Datastore Moref
        :param mountedDatastoreName: mounted  Datastore Name
        :param vm_name: Virtual Machine name to be recovered
        :param vm_moref: Virtual Machine moref id to be recovered
        """
        LOG.debug("get recoverable vm vmx file path called:start")

        vmx_path = None
        vmx_name = ""

        try:
            DatastoreName = "[" + mountedDatastoreName + "] "
            ds_mo = vim.get_moref(mountedDatastoreMoref, "Datastore")
            oc_list = self.vi_helper.GetObjectProperties(ds_mo, "browser")
            oc_datastore = oc_list.objects[0]
            property_dict = vim_util.extract_properties(oc_datastore)
            LOG.debug("Creating HostDatastoreBrowserSearchSpec")
            search_spec = vim_util.get_host_datastore_VMX_search_spec(self.vi_helper.client_factory)
            mo_obj_browser = property_dict["browser"]
            res = self.vi_helper.vmops_obj.search_datastore_sub_folders_task(mo_obj_browser, DatastoreName, search_spec)
            search_res_list = res.HostDatastoreBrowserSearchResults

            try:
                vm_mo = pyvmomi_util.get_moref(vm_moref, "VirtualMachine")
                vm_oc_list = self.vi_helper.get_object_properties(vm_mo, "config.files.vmPathName")
                vm_prop = pyvmomi_util.extract_properties(vm_oc_list[0])
                vmPathName = vm_prop.get("config.files.vmPathName")
                vmx_name = vmPathName.split('/')[-1]
            except Exception as e:
                LOG.exception("Error occured on get vm properties: %s " % e)

            for search_res in search_res_list:
                if not rmv_utils.has_attribute(search_res, 'file'):
                    continue
                for file in search_res.file:
                    vm_name = (file.path).rsplit(".vmx")[0]
                    # if virtual_machine_name == vm_name:

                    # TODO : not a right exact way of doing this. May right way is to read the content of vmx file
                    # read the value of displayname and then check if value is same as virtual_machine_name.

                    # TODO: Making this change since after vm is relocted using snapshot of vm, the name of vmx
                    # changes to something like "clone_<vm_name>_<timestamp>". Because of this issue, previously taken
                    # snaphosts will not be recoverable since vmx name are different.
                    # Assuming that default new cloned vm names are always kept as "clone_<vm_name>_<timestamp>,
                    # using split to get the vm name

                    # if vmx name is starting with 'clone_', only then only splitting the string
                    vm_name = rmv_utils.get_vm_name_from_cloned_vm_name(vm_name)

                    if virtual_machine_name == vm_name:
                        vmx_path = search_res.folderPath + file.path
                        return vmx_path
                    elif file.path == vmx_name:
                        vmx_path = search_res.folderPath + file.path
                        return vmx_path
        except Exception as e:
            LOG.exception("Exception occurred in get recoverable vm vmx file path: %s" % e)

        LOG.debug("get recoverable vm vmx file path called:Exit")
        return vmx_path

    def get_rmcv_copy_wwn_details_by_resource_list(self, context, copy_id, resource_list):
        """
        This function will returns list of wwns for a copy by using resource_list
        :param context:
        :param copy_id: rmcv copy id
        :param object_list: list of the objects(["Datastore":"moref"},{"virtualmachine":"moref"},-----])
        :return: list of wwns
        """
        LOG.debug("get_rmcv_copy_wwn_detaisl_by_object_list::Enter")
        response_dict = dict()
        wwn_list = list()
        object_type = ""
        object_moref = ""
        resources = dict()
        vm_id_list_from_db = []
        ds_id_list_from_db = []
        for rmcv_object in resource_list:
            object_type = rmcv_object.keys()[0]
            object_moref = rmcv_object.values()[0]
            try:
                if object_type == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                    ds_obj = self.db.get_rmcv_ds_with_base_wwn_by_copy_id_and_ds_moref(context, copy_id, object_moref)
                    for row in ds_obj:
                        if row.id not in ds_id_list_from_db:
                            ds_id_list_from_db.append(row.id)
                        wwn_details_list = jsonutils.loads(row.wwn_details)
                        wwn_list.extend(rmv_utils.extract_wwn_list(wwn_details_list))
                        vm_id_list_from_db.extend(rmv_utils.extarct_vmware_id_list(jsonutils.loads(row.vmdks)))
                elif object_type == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                    vmdks_response = self.db.get_vmdk_details_by_copy_id_and_vm_moref(context, copy_id, object_moref)
                    for vmdk_row in vmdks_response:
                        if vmdk_row.id not in vm_id_list_from_db:
                            vm_id_list_from_db.append(vmdk_row.id)
                        vmdk_list = jsonutils.loads(vmdk_row.vmdks)
                        ds_id_list = rmv_utils.extarct_vmware_id_list(vmdk_list)
                        for ds_id in ds_id_list:
                            db_obj = self.db.get_datastore_by_id(context, ds_id)
                            ds_obj = self.db.get_rmcv_ds_with_base_wwn_by_copy_id_and_ds_moref(context, copy_id,
                                                                                               db_obj.moref)
                            for row in ds_obj:
                                if row.id not in ds_id_list_from_db:
                                    ds_id_list_from_db.append(row.id)
                                wwn_details_list = jsonutils.loads(row.wwn_details)
                                wwn_list.extend(rmv_utils.extract_wwn_list(wwn_details_list))
                                vm_id_list_from_db.extend(rmv_utils.extarct_vmware_id_list(jsonutils.loads(row.vmdks)))
                else:
                    continue

            except Exception as e:
                LOG.exception(e)
                msg = ("Unable to get the wwn details of %s with moref '%s' and copy is '%s'" % (
                object_type, object_moref, copy_id))
                LOG.error(msg)
        # get all vms/ds details this clone belongs to
        vm_id_list_from_db = set(vm_id_list_from_db)
        ds_id_list_from_db = set(ds_id_list_from_db)
        for vm_id in vm_id_list_from_db:
            try:
                # TODO : Need to handle if vm contains vmdks from multiple datastores
                vm_obj = self.db.get_virtual_machine_by_id(context, vm_id)
                vm_list = resources.get('vm_list', list())
                resource_details = self.construct_clone_resource_json(vm_obj)
                vm_list.append(resource_details.__dict__)
                resources['vm_list'] = vm_list
            except Exception as e:
                LOG.exception(e)

        for ds_id in ds_id_list_from_db:
            try:
                ds_obj = self.db.get_datastore_by_id(context, ds_id)
                ds_list = resources.get('ds_list', list())
                resource_details = self.construct_clone_resource_json(ds_obj)
                ds_list.append(resource_details.__dict__)
                resources['ds_list'] = ds_list
            except Exception as e:
                LOG.exception(e)
        clone_resource_json = json_helper.clone_resource_json()
        clone_resource_json.VirtualMachines = resources.get('vm_list', list())
        clone_resource_json.Datastores = resources.get('ds_list', list())

        LOG.info("wwn_list to perform partial clone:'%s'" % wwn_list)
        LOG.info("partial clone will be applicable for the resources:'%s'" % resources)
        response_dict['wwn_list'] = list(set(wwn_list))
        response_dict['cloned_resources'] = clone_resource_json.__dict__
        LOG.debug("get_rmcv_copy_wwn_detaisl_by_object_list::Exit")
        return response_dict

    def construct_clone_resource_json(self, vmware_obj):
        resource_details = json_helper.clone_resource()
        resource_details.id = vmware_obj.id
        resource_details.moref = vmware_obj.moref
        resource_details.name = vmware_obj.name
        return resource_details

    def mount_snapshot_esx(
            self, context, snapshot_id, x_auth_token, esxHostName,
            esxHostAddFormat, task_id, register_vm, vmware_obj_id,
            vmware_obj_type, copy_id, recover_vm, vm_name, register_folder, object, power_on, resource_list,
            is_vm_relocate_task=False):
        LOG.debug("Mount Snapshot : Enter")
        mount = Mount()

        exception_lock_mount = False
        wwn_response_dict = {}
        if not snapshot_id:
            raise exception.SnapshotNotFound(snapshot_id=snapshot_id)

        LOG.info("Locking for snapshot operations")
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        mo_ref = "group-d1"
        object_type = 'Folder'
        vm_task_helper = VmTaskHelper(self.vi_helper)
        vm_task_helper.CustomVMwareTaskBegin(
            object_type,
            mo_ref,
            "MountVirtualCopyTask",
            "MountVirtualCopyFailedFault")
        try:
            lock_response = rmv_utils.acquire_esx_operation_lock(self.esx_host_in_dict, esxHostName,
                                                                 self.vi_helper.validated_username)
            if lock_response:
                exception_lock_mount = True
                LOG.error("Could not acquire snapshot lock.")
                task_desc = 'Mount or unmount operation is already in progress on the esxi' + lock_response
                task_percentage = 100
                task_state = 'Failed'
                task_status = 'Error'
                self._update_task(task_desc,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("error", task_desc)
                raise rmv_exception.SnapshotLockException(error=lock_response)
            LOG.debug("Locked Esxi : '%s'" % esxHostName)

            # vcenter_datastore_list = self.get_all_datastores_in_vcenter(vm_vv_map_cache)
            # if not vcenter_datastore_list:
            #     msg = "Unable to fetch VCenter datastore Information. Please retry the operation after sometime"
            #     LOG.error("vCenter datastore list returned empty from cache. %s", msg)
            #     raise exception.EsxMountException(msg)
            if resource_list:
                wwn_response_dict = self.get_rmcv_copy_wwn_details_by_resource_list(context, copy_id, resource_list)

            task_complete_flag = 1
            if register_vm == "1":
                task_complete_flag = 0
            (clone_details, recovery_set_id) = mount.mount_on_esxhost(
                context,
                snapshot_id,
                x_auth_token,
                esxHostName,
                esxHostAddFormat,
                task_id,
                self.vi_helper,
                self.db,
                vmware_obj_id,
                vmware_obj_type,
                copy_id,
                task_complete_flag,
                vm_task_helper,
                wwn_response_dict)
        except Exception as e:
            LOG.exception(("Exception in Mount on ESX : '%s'") % e)
            raise e
        finally:
            if not exception_lock_mount:
                rmv_utils.release_esx_operation_lock(self.esx_host_in_dict, esxHostName)
                LOG.info(("Released Lock for snapshot '%s'") % esxHostName)

        if register_vm == "1":
            mounted_ds_name_list = []
            try:
                clone = self.db.get_rmcv_clone_by_recovery_set_id(context, recovery_set_id)
                clone_info = clone.clone_details
                ds_info = clone_info['cloned_ds_details']
                for ds_dict in ds_info:
                    mounted_ds_name_list.append(ds_dict.get('name').encode('ascii', 'ignore'))

                response_data = self.get_vcenter_details(context, x_auth_token, esxHostName, True)
                resource_pool_dict = response_data['EsxHostToResourcePoolList'][0]
                resource_pool_moref = resource_pool_dict['ResourcePoolMoref']
                vmx_path = self.get_mounted_vmx_path_for_vm(context, recovery_set_id, recover_vm, object.split(':')[1])
                vmx_file = vmx_path.split("] ")[1]
                # mounted_ds_name = vmx_path.split(" ")[0]
                mounted_ds_name = vmx_path.split("] ")[0]
                mounted_ds_name = mounted_ds_name.replace("[", "")
                mounted_ds_name = mounted_ds_name.replace("]", "")
                powerOnVM = False
                if power_on == "1":
                    powerOnVM = True
                registervm_input = {'esxHostName': esxHostName,
                                    'sourceDatastoreName': mounted_ds_name,
                                    'powerOnVM': powerOnVM,
                                    'redirectIODatastoreName': False,
                                    'asTemplate': False,
                                    'inventoryMoref': register_folder,
                                    'resourcePoolMoref': resource_pool_moref,
                                    'vmName': vm_name,
                                    'inventoryType': "Folder",
                                    'vmxFilePath': vmx_file,
                                    'objectId': object}
                register_vm_task = self._create_task_recover(rmc_wrapper_service, 'Create', recover_vm, task_id,
                                                             'Registering the VM on mounted DS', copy_id, vm_name,
                                                             'Clone')
                task_desc_string = None
                task_percentage = None
                registered_moref = None
                clone_status = json_helper.clone_status
                task_percentage = 100

                registered_details = self.register_vm_operations(context, copy_id,
                                                                 x_auth_token,
                                                                 registervm_input,
                                                                 register_vm_task,
                                                                 clone, is_vm_relocate_task)
                if registered_details:
                    task_state = 'Completed'
                    task_status = "Ok"
                    task_desc_string = "VM sucessfully recovered"
                    vm_info = self.db.get_virtual_machine_by_id(context, vmware_obj_id)
                    new_clone_details = {'cloned_virtual_machines': [
                        {'name': registered_details['vm_name'], 'moref': registered_details['vm_moref'],
                         'parent_id': vmware_obj_id, 'parent_vm_name': vm_info.name, 'parent_vm_moref': vm_info.moref}],
                        'cloned_ds_details': clone_details.cloned_ds_details}
                    values = {'status': clone_status.cloned, 'clone_details': new_clone_details}
                    self.db.update_rmcv_clone_by_cloned_recovery_set_id(context, recovery_set_id, values)
                else:
                    task_state = 'Failed'
                    task_status = "Error"
                    task_desc_string = "Could not register the Virtual Machine to vCenter. \
                                        However, recovering data is completed successfully \
                                        and Virtual Machine can be registered from the cloned datastore(s):%s" % mounted_ds_name_list
                    # self.unmount_snapshot_esx(context, recovery_set_id, x_auth_token, esxHostName,
                    #                    esxHostAddFormat, task_id, 1, copy_id)
            except Exception as e:
                LOG.exception(e)
                task_state = 'Failed'
                task_status = "Error"
                task_percentage = 100
                task_desc_string = "Could not register the Virtual Machine to vCenter. \
                                    However, recovering data is completed successfully \
                                    and Virtual Machine can be registered from the cloned datastore(s):%s" % mounted_ds_name_list
                # self.unmount_snapshot_esx(context, recovery_set_id, x_auth_token, esxHostName,
                #                        esxHostAddFormat, task_id, 1, copy_id)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              None, task_status=task_status)
        LOG.debug("Mount Snapshot : Exit")
        return (clone_details, recovery_set_id)

    def acquire_backup_operation_lock(self,
                                      backup_id,
                                      operation):
        """
        Add backup object ID into operation dictionary and acquire operation lock on backup object

        :param backup_id: backup-id
        :param task_id: RMC task ID
        :param x_auth_token: auth-token
        :param operation: operation on the Object
        :return: None
        """
        try:
            # Add backup_id to operation dictionary and change status to 'busy'
            self.backup_op_in_progress = True
            if backup_id not in self.backups_in_operation_dict:
                self.backups_in_operation_dict[backup_id] = "busy"

            # Acquire operation lock on backup object
            LOG.debug("Locking Backup Object [%s] for operation: %s", backup_id, operation)
            lock_response = rmv_utils.acquire_backup_operation_lock(self.backup_id_dict,
                                                                    backup_id,
                                                                    self.vi_helper.validated_username)
            if lock_response:
                LOG.error("Backup Object already in use. Unable to acquire "
                          "operation lock on backup: %s", backup_id)
                raise rmv_exception.BackupLockException(error=lock_response)

            LOG.debug("Locked Backup Object [%s] for operation: %s", backup_id, operation)

        except Exception as e:
            LOG.exception("Exception occurred acquiring Backup Object operation lock[%s] : %s", backup_id, e)
            raise e

    def release_backup_operation_lock(self,
                                      backup_id):
        """
        Remove backup ID from operation dictionary and release backup object lock

        :param backup_id: backup-id
        :return: None
        """
        # Remove backup object from operation dictionary
        if backup_id in self.backups_in_operation_dict:
            LOG.debug("Removing backup_id : '%s' entry from backups_in_operation_dict", backup_id)
            del self.backups_in_operation_dict[backup_id]
        # Release operation lock on backup object
        rmv_utils.release_backup_operation_lock(self.backup_id_dict, backup_id)
        LOG.debug("Releasing Lock on backup object [%s] ...", backup_id)
        self.backup_op_in_progress = False

    def update_backup_operation_task_error(self,
                                           x_auth_token,
                                           vcenter_task_id,
                                           vcenter_task_fault_id,
                                           task_id,
                                           task_desc_string):
        """
        Update RMC and VCenter Tasks with backup operation error status

        :param x_auth_token: auth-token
        :param vcenter_task_id: VCenter Operation Task ID
        :param vcenter_task_fault_id: VCenter Operation Task Fault ID
        :param task_id: RMC Operation Task ID
        :param task_desc_string: Task description string
        :return: None
        """

        LOG.debug("Enter : update_backup_operation_task_error")
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vm_task_helper = VmTaskHelper(self.vi_helper)

        task_state = 'Failed'
        task_percentage = 100
        object_type = "Folder"
        mo_ref = "group-d1"
        task_status = "Error"

        vm_task_helper.CustomVMwareTaskBegin(object_type,
                                             mo_ref,
                                             vcenter_task_id,
                                             vcenter_task_fault_id)
        # Update VMware and RMC Task with Task Status.
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)

        # End VMware RMC Task with Task Error Smessage.
        msg = "Operation Failed : " + task_desc_string

        # Associating the vCenter Task with User Logged Event.
        vm_task_helper.post_general_user_event(msg)

        vm_task_helper.CustomVMwareTaskEnd("error", msg)
        LOG.debug("Exit : update_backup_operation_task_error")

    def _create_task_recover(self, rmc_wrapper_service, action, parentResourceName, parent_task_id, desc, backup_id,
                             clone_name, resource_type):
        kwargs = {}
        kwargs['name'] = desc
        kwargs['owner'] = 'RMC-V User'
        kwargs['task_state'] = 'New'
        kwargs['task_type'] = 'User'

        kwargs['association_type'] = 'IS_A'
        kwargs['resource_id'] = backup_id
        kwargs['action'] = action
        kwargs['resourceType'] = resource_type
        kwargs['resource_name'] = clone_name
        kwargs['resource_category'] = resource_type
        kwargs['total_steps'] = rmv_utils.TOTAL_TASK_TRACKER_STEPS
        kwargs['parentTaskId'] = parent_task_id
        kwargs['parentResourceName'] = parentResourceName
        created_task_id = ''
        try:
            response_data = rmc_wrapper_service.create_task(kwargs)
            created_task_id = response_data['id']
        except:
            msg = ("Failed to create sub task. Please check if TaskTracker service is running")
            raise Exception(msg)
        return created_task_id

    def recover_vm(self, context, copy_id, x_auth_token, objectType, object_id,
                   esx_host_name,
                   newVmName,
                   redirectIODatastoreName,
                   inventoryMoref,
                   powerOnVM,
                   recreateVM,
                   vm_name_dict,
                   task_id, host_iqn_name, host_hba_device_name,
                   is_vm_relocate_task=False):
        LOG.debug("Recover VM Manager:: Enter")

        esx_host_add_format = rmv_utils.REQUEST_BODY_PARAM_ESX_HOST_IP
        is_recover_task_successful = True
        cloned_details = None
        try:
            copy_info = self.db.get_rmcv_copy_by_id(context, copy_id)
            ds_mount_path_dir = copy_info.ds_mount_path_dir
            rmc_copyset_id = copy_info.rmc_copyset_id

            # update copy status to restoring
            copy_info.status = rmv_utils.copy_states.RESTORING
            self.db.update_rmcv_copy(context, copy_id, copy_info)

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            object_type = objectType
            object_id = object_id
            vmware_object = self.db_utils.get_vmware_object_by_object_type_and_moref(context, object_type, object_id)
            parentResourceName = vmware_object.name
            vmware_obj_id = vmware_object.id
            if object_type == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                vm_name_dict[parentResourceName] = vmware_object.moref
            response = self.get_backup_for_backupId(context, rmc_copyset_id, x_auth_token)
            backup_details = response.get('backupSet')
            attachStatus = backup_details.get('attachStatus')
            # check for the backup attach status, if it is not attached then will attach before perform register operation
            if not attachStatus:
                mount_task_id = self._create_task_recover(rmc_wrapper_service, 'Mount', parentResourceName, task_id,
                                                          'Express protect backup object mount operation', copy_id,
                                                          'Express Protect', 'Express Protect')
                task_desc_string = ' Mounting backup: ' + copy_id
                task_percentage = 10
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  '', task_status=task_status)
                try:
                    self.mount_backup_esx(context,
                                          copy_id,
                                          x_auth_token,
                                          esx_host_name,
                                          esx_host_add_format,
                                          mount_task_id,
                                          object_type,
                                          object_id,
                                          ds_mount_path_dir,
                                          rmc_copyset_id,
                                          vmware_obj_id, host_iqn_name, host_hba_device_name)

                    task_uri = "/rest/rm-central/v2/tasks/" + mount_task_id
                    mount_with_taskuri = {"taskUri": task_uri}
                    resp = rmc_wrapper_service.rmc_low_level.wait_on_task(mount_with_taskuri)
                except (rmv_exception.RMCAPIError, rmv_exception.TaskError) as e:
                    if hasattr(e, "msg"):
                        pattern = 'already mounted'
                        if re.match(pattern, e.msg):
                            task_desc_string = e.msg
                            LOG.info("%s", task_desc_string)
                        else:
                            is_recover_task_successful = False
                            LOG.error("%s", task_desc_string)
                    else:
                        is_recover_task_successful = False
                        task_desc_string = "Unexpected error"
                        LOG.error("%s", task_desc_string)
                    LOG.exception(e)

                response = self.get_backup_for_backupId(context, rmc_copyset_id, x_auth_token)
                backup_details = response.get('backupSet')
                mountStatus = backup_details.get('attachStatus')
                if mountStatus:
                    task_desc_string = ' Mounted backup: ' + copy_id
                    task_percentage = 50
                    task_state = 'Running'
                    task_status = "Initiated"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      '', task_status=task_status)
                else:
                    is_recover_task_successful = False
                    task_desc_string = ' Mount failed for backup: ' + copy_id
                    task_percentage = 100
                    task_state = 'Failed'
                    task_status = "Error"
                    LOG.error('Backup mount has failed')
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      '', task_status=task_status)
                    return is_recover_task_successful, cloned_details

            # if we are planning to support multiple VM registration and
            if recreateVM:
                clone = self.db.get_rmcv_clone_by_parent_copy_id_clone_type(context, copy_id, rmv_utils.CLONE_TYPE_ERT)
                clone_info = clone.clone_details
                clone_id = clone.id
                pre_register_clone_info = clone_info.copy()
                pre_registered_vm_list = pre_register_clone_info.get('cloned_virtual_machines', list())
                pre_register_vm_count_from_clone = len(pre_registered_vm_list)
                objectId = object_type + ':' + object_id
                cloned_details = self.register_vm_from_restored_ds(context, x_auth_token,
                                                                   rmc_wrapper_service, esx_host_name,
                                                                   vm_name_dict, inventoryMoref, copy_id, objectId,
                                                                   None, clone, task_id, newVmName, powerOnVM,
                                                                   redirectIODatastoreName,
                                                                   is_vm_relocate_task=is_vm_relocate_task)
                post_register_clone_info = cloned_details['clone_details']
                post_registered_vm_list = post_register_clone_info.get('cloned_virtual_machines', list())
                post_register_vm_count = len(post_registered_vm_list)
                attached_vmdk_list = post_register_clone_info.get('attached_vmdks_details', list())
                clone_status = json_helper.clone_status
                if post_register_vm_count > pre_register_vm_count_from_clone:
                    if len(attached_vmdk_list) == 0:
                        cloned_details['status'] = clone_status.cloned
                    self.db.update_rmcv_clone_by_clone_id(context, clone_id, cloned_details)
                    task_desc_string = 'VM recovery completed successfully'
                    task_percentage = 100
                    task_state = 'Completed'
                    task_status = "Ok"
                elif len(post_registered_vm_list) == len(pre_registered_vm_list):
                    is_recover_task_successful = False
                    task_desc_string = 'Failed to register the vm '
                    task_state = 'Failed'
                    task_status = "Error"
                    task_percentage = 100

                    backup_unmount_task_id = self._create_task_recover(rmc_wrapper_service, 'Unmount',
                                                                       parentResourceName,
                                                                       task_id, 'Unmount backup object', copy_id,
                                                                       'Express Protect', 'Express Protect')
                    try:
                        self.unmount_backup_esx(context,
                                                copy_id,
                                                x_auth_token,
                                                esx_host_name,
                                                esx_host_add_format,
                                                backup_unmount_task_id,
                                                True,
                                                rmc_copyset_id,
                                                ds_mount_path_dir, clone_id)
                    except Exception as ex:
                        LOG.exception(ex)
            else:
                task_percentage = 100
                task_state = 'Completed'
                task_status = "Ok"
        except Exception as ex:
            is_recover_task_successful = False
            LOG.exception("Exception in recreating VM using ert clone %s" % ex)
            if hasattr(ex, "msg"):
                msg = e.msg
            else:
                msg = "Internal Error"
            task_desc_string = 'ERT clone operation was unsuccessful'
            task_state = 'Failed'
            task_status = "Error"
            task_percentage = 100
        finally:

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              '', task_status=task_status)
        return is_recover_task_successful, cloned_details

    def mount_backup_esx(self,
                         context,
                         copy_id,
                         x_auth_token,
                         esx_host_name,
                         esx_host_add_format,
                         task_id,
                         objectType,
                         objectId,
                         ds_mount_path_dir,
                         rmc_copyset_id,
                         vmware_obj_id, host_iqn_name=None, host_hba_device_name=None):
        """
        Validate backup object, acquire operation lock on backup object and
        initiate Express Protect Backup Object Mount operation

        :param context: context
        :param backup_id: backup-id
        :param x_auth_token: auth-token
        :param esx_host_name: ESXi host name
        :param esx_host_add_format: backup object presentation format
        :param task_id: RMC Operation Task ID
        :return: None
        """

        LOG.debug("Enter : mount_backup_esx")
        backup_id = rmc_copyset_id
        if not backup_id:
            raise exception.BackupNotFound(backup_id=backup_id)

        backup_operation_lock = False
        initiate_mount_operation = False
        exception_mount = False
        esx_lock = True
        LOG.debug("Acquiring lock mount operation on backup object")

        try:
            with rmv_locks.backup_op_lock:
                # Acquire operation lock on backup object
                self.acquire_backup_operation_lock(backup_id, "backup_mount")
                backup_operation_lock = True
            LOG.debug("Locked Backup Object for Mount operation: '%s'" % backup_id)

            esx_lock_response = rmv_utils.acquire_esx_operation_lock(self.esx_host_in_dict, esx_host_name,
                                                                     self.vi_helper.validated_username)
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            if esx_lock_response:
                vm_task_helper = VmTaskHelper(self.vi_helper)
                esx_lock = False
                task_desc = 'Mount or unmount operation is already in progress on the esxi' + esx_lock_response
                task_percentage = 100
                task_state = 'Failed'
                task_status = 'Error'
                self._update_task(task_desc,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  None, task_status=task_status)
                raise Exception(esx_lock_response)
            LOG.info("Locked Esxi : '%s'" % esx_host_name)

            mount = Mount()
            # Cache usage removed in 4.0 release
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map

            # Get backup object details
            num_vmfs_volumes = self.get_num_vmfs_volumes(objectType, objectId)

            # vcenter_datastore_list = self.get_all_datastores_in_vcenter(vm_vv_map_cache)
            # if not vcenter_datastore_list:
            #     msg = "Unable to fetch VCenter datastore Information. Please retry the operation after sometime"
            #     LOG.error("vCenter datastore list returned empty from cache. %s", msg)
            #     LOG.error("vCenter datastore list returned empty from cache. %s", msg)
            #     raise exception.EsxMountException(msg)

            # Initiate backup object mount operation
            initiate_mount_operation = True
            values = {'status': 'mounting'}
            self.db.update_rmcv_copy(context, copy_id, values)
            mount.mount_backup_on_esxhost(copy_id,
                                          x_auth_token,
                                          esx_host_name,
                                          esx_host_add_format,
                                          num_vmfs_volumes,
                                          task_id,
                                          self.vi_helper,
                                          ds_mount_path_dir,
                                          rmc_copyset_id,
                                          vmware_obj_id,
                                          context,
                                          objectType,
                                          self.db,
                                          host_iqn_name, host_hba_device_name)

        except Exception as e:
            LOG.exception("Exception occurred Mounting Backup Object [%s] : %s", backup_id, e)
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal Error"
            exception_mount = True
        finally:
            if backup_operation_lock:
                with rmv_locks.backup_op_lock:
                    # Release operation lock on backup object
                    self.release_backup_operation_lock(backup_id)
            if esx_lock:
                rmv_utils.release_esx_operation_lock(self.esx_host_in_dict, esx_host_name)

            rmc_copy_details = rmc_wrapper_service.get_backup_for_backupId(context, backup_id)
            copy_set = rmc_copy_details.get('backupSet')
            if copy_set:
                attach_status = copy_set.get("attachStatus", None)

                values = {'status': 'available'}
                if attach_status == 'attached' and not exception_mount:
                    values = {'status': 'mounted'}
                self.db.update_rmcv_copy(context, copy_id, values)

            if not initiate_mount_operation:
                # If unable to acquire lock on backup object,
                # update VCenter and RMC task with error
                if not msg:
                    msg = "Internal Error"
                task_desc_string = msg
                if not backup_operation_lock:
                    task_desc_string = "HPE Express Protect Backup Object is currently in use. " \
                                       "Please retry after sometime."
                self.update_backup_operation_task_error(x_auth_token,
                                                        "MountExpressProtectBackupTask",
                                                        "MountExpressProtectBackupFailedFault",
                                                        task_id,
                                                        task_desc_string)
        LOG.debug("Exit : mount_backup_esx")
        return

    def mount_snapshot_proxy(
            self, context, copy_id, x_auth_token, esxHostName,
            esxHostAddFormat, task_id, rmc_copyset_id, array_serial_number, resource_list):
        LOG.debug("mount_snapshot_proxy  : Enter")
        snapshot_id = rmc_copyset_id
        mount = Mount()
        wwn_response_dict = dict()
        exception_lock_mount_proxy = False
        # snapshot_id = snapshot_id1
        #         snapshot_id = req_snapshot_id
        #         x_auth_token = req_x_auth_token
        #         esxHostName = req_esxHostName
        #         esxHostAddFormat = req_esxHotAddFormat
        # mount.do_snapshot_inner(snapshot_id,x_auth_token,esxHotAddFormat,
        # esxHostName,task_id)
        try:
            # Cache usage removed in 4.0 release
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map
            if resource_list:
                wwn_response_dict = self.get_rmcv_copy_wwn_details_by_resource_list(context, copy_id, resource_list)
            mount.mount_on_proxyhost(
                context,
                copy_id,
                x_auth_token,
                esxHostName,
                esxHostAddFormat,
                task_id,
                self.vi_helper,
                rmc_copyset_id,
                self.db,
                array_serial_number,
                wwn_response_dict)

        except Exception as e:
            LOG.exception(("Exception in Mount on Proxy : '%s'") % e)
            raise e

        LOG.debug("mount_snapshot_proxy : Exit")

    def worker_init_web_client_session_async(self, context, x_auth_token, webclinet_body_, memcache_id):
        # TODO: This requires optimization. There is some dead code
        # TODO: We can get rid of vm_plugin_web_operation_status_code

        LOG.info("worker_init_web_client_session_async manager enter")

        # By default "check_user_permissions_in_vcenter" is False
        check_user_permissions_in_vcenter = FLAGS.check_user_permissions_in_vcenter
        if not type(check_user_permissions_in_vcenter) is bool:
            if check_user_permissions_in_vcenter == 'True':
                check_user_permissions_in_vcenter = True
            elif check_user_permissions_in_vcenter == 'False':
                check_user_permissions_in_vcenter = False
        LOG.info("check_user_permissions_in_vcenter : '%s'" % check_user_permissions_in_vcenter)

        self.memcache_id = memcache_id
        recreate_vi_helper_object = False
        webclient_user_name = ""
        LOG.info("self.memcache_id:%s", self.memcache_id)
        mem_client = memcache.Client([self.memcache_connection])

        # creating vCenter session
        if not self.vi_helper:
            LOG.info("Creating vCenter Session...")
            ip_hostname, username, password, vcenteruid = self.get_vcenter_credentials()
            if ip_hostname and username:
                try:
                    self.vi_helper = ViHelper(ip_hostname, username, password)
                except Exception as e:
                    err_msg = 'Error.. vCenter object not initialized'
                    LOG.exception(e)
                    if hasattr(e, "msg"):
                        err_msg = e.msg
                    elif hasattr(e, "message"):
                        err_msg = e.message
                    LOG.error("%s", err_msg)
                    mem_client.set(str(self.memcache_id),
                                   json_helper.TpdVmPluginWebOperationStatusCode.VCConnectionFailure)
                    raise e
            else:
                LOG.error("There is no vCenter registered. Please register a vCenter using HPE RMC "
                          "Configuration options in the webclient.")
                BackupJobManager.web_client_cache.refresh_status \
                    = json_helper.TpdVmPluginWebOperationStatusCode.NoVcenterFound

                mem_client.set(str(self.memcache_id),
                               json_helper.TpdVmPluginWebOperationStatusCode.NoVcenterFound)

                raise rmv_exception.VcenterNotFound

        vm_task_helper = VmTaskHelper(self.vi_helper)
        object_type = "Folder"
        mo_ref = "group-d1"
        try:

            vm_task_helper.CustomVMwareTaskBegin(object_type, mo_ref, "RefreshcacheTask", "RefreshcacheFailedFault")

            webclient_user_name = webclinet_body_['userSession']['userName']

            if check_user_permissions_in_vcenter:

                user_name_wb = None
                user_privilege_list = []
                # TODO Move below logic to utility class in 2.0
                if "@" in webclient_user_name:
                    user_name_wb = webclient_user_name[0:webclient_user_name.lower().strip().find("@")]
                elif "\\" in webclient_user_name:
                    user_name_wb = webclient_user_name[webclient_user_name.lower().strip().find("\\") + 1:]
                else:
                    user_name_wb = webclient_user_name

                task_desc_string = "Verifying the access permission of the user : '%s'" % webclient_user_name
                vm_task_helper.CustomVMwareTaskUpdate(10, task_desc_string)

                # Lock is used to avoid any session conflicts, while checking permissions of user.
                LOG.info("Acquiring check_user_permission_lock...")
                with rmv_locks.check_user_permission_lock:

                    # Get user session list from vCneter
                    obj_content = self.vi_helper.GetObjectProperties(
                        self.vi_helper.vim_object._service_content.sessionManager, "sessionList")
                    obj = obj_content.objects[0]
                    property_dict = vim_util.extract_properties(obj)
                    previous_user_session = None
                    for user_session in property_dict['sessionList'].UserSession:
                        if "@" in user_session['userName']:
                            user_name_in_session = user_session['userName'][
                                                   0:user_session['userName'].lower().strip().find("@")]
                        elif "\\" in user_session['userName']:
                            user_name_in_session = user_session['userName'][
                                                   user_session['userName'].lower().strip().find("\\") + 1:]
                        else:
                            user_name_in_session = user_session['userName']
                        # To get Session ID, check logged-in user name is equal to UserSession's username.
                        if user_name_in_session.lower() == user_name_wb.lower():
                            # Session list in vCenter may have multiple sessions for a user. Consider latest session.
                            if previous_user_session:
                                if user_session.loginTime < previous_user_session.loginTime:
                                    continue

                            LOG.info(("Checking required privilege for the user : '%s' having Session ID : '%s'") % (
                            user_session.userName, user_session.key))
                            user_privilege_list = self.vi_helper.check_user_privilege(user_session.key)

                            previous_user_session = user_session
                    # In user_privilege_list, if there is atleast one entry of False then it means user doesn't have required privilege.
                    if user_privilege_list:
                        if False in user_privilege_list:

                            msg = "User '%s' doesn't have required Privileges to access RMC-V" % webclient_user_name
                            raise rmv_exception.InvalidUser(error=msg)

                        else:
                            task_desc_string = "User '%s' has the required Privileges to access RMC-V." % webclient_user_name
                            LOG.info(task_desc_string)
                            vm_task_helper.CustomVMwareTaskUpdate(15, task_desc_string)

                    else:
                        msg = "User '%s' doesn't have required Privileges to access RMC-V" % webclient_user_name
                        raise rmv_exception.InvalidUser(error=msg)

        except rmv_exception.InvalidLogin as e:
            LOG.exception(e)
            mem_client.set(str(self.memcache_id),
                           json_helper.TpdVmPluginWebOperationStatusCode.VcenterInvalidCredentials)
            BackupJobManager.web_client_cache.refresh_status = json_helper.TpdVmPluginWebOperationStatusCode.VcenterInvalidCredentials
            raise e
        except (Exception, rmv_exception.InvalidUser) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                message = e.msg
            else:
                message = ("Exception in evaluating the permissions of the User '%s'. Exception : '%s'") % (
                webclient_user_name, e)

            LOG.error(message)

            BackupJobManager.web_client_cache.refresh_status \
                = json_helper.TpdVmPluginWebOperationStatusCode.InvalidUser

            mem_client.set(str(self.memcache_id),
                           json_helper.TpdVmPluginWebOperationStatusCode.InvalidUser)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(message)

            vm_task_helper.CustomVMwareTaskUpdate(100, message)
            vm_task_helper.CustomVMwareTaskEnd("error", message)

            raise e

        if not self.is_web_client_initialization_exists:
            web_session = webserver_helper.vm_web_service()
            web_session.set_user_session(webclinet_body_)
        else:
            if BackupJobManager.web_client_cache \
                    .web_client_rmv_sessions_dict.values():
                web_session = \
                    BackupJobManager.web_client_cache.web_client_rmv_sessions_dict \
                        .values()[0]
        if ((webclinet_body_['userSession']['clientId'] in
             BackupJobManager.web_client_cache.web_client_rmv_sessions_dict)
                and (BackupJobManager.web_client_cache.refresh_status ==
                     json_helper.TpdVmPluginWebOperationStatusCode.Ready)):
            mem_client.set(str(self.memcache_id),
                           json_helper.TpdVmPluginWebOperationStatusCode.Ready)
            LOG.info("RMC-V webclient session already initialized")
            task_desc_string = "RMC-V webclient session already initialized."
            vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
            vm_task_helper.CustomVMwareTaskEnd("success",
                                               task_desc_string)
            return

        BackupJobManager.web_client_cache.refresh_status = \
            json_helper.TpdVmPluginWebOperationStatusCode.Initializing
        mem_client.set(str(self.memcache_id),
                       json_helper.TpdVmPluginWebOperationStatusCode.Initializing)
        # vm_task_helper = VmTaskHelper(self.vi_helper)
        # object_type = "Folder"
        # mo_ref = "group-d1"
        # vm_task_helper.CustomVMwareTaskBegin(object_type,
        #                                      mo_ref,
        #                                      "RefreshcacheTask",
        #                                      "RefreshcacheFailedFault")
        # #There will just be one unlike legacy RMV
        # webclient_user_name = webclinet_body_['userSession']['userName']
        for vc in webclinet_body_['userSession']['serverInfoList']:
            try:
                LOG.info(
                    "Process session Cookie: " + vc['SessionCookie'] +
                    ", vCenter guid: " + vc['ServerGuid'] + ", vCenter url: " +
                    vc['ServiceUrl'])

                if not vc['SessionCookie']:
                    LOG.info("SessionCookie is null for vCenter " +
                             vc['ServiceUrl'] + ". Will be excluded.")
                    with rmv_locks.web_client_operation_lock:
                        web_session.web_service_operation_status[
                            vc['ServiceUrl']] = \
                            rmv_structures. \
                                vm_plugin_web_operation_status_code. \
                                SessionCookieIsNull
                    continue
                if not self.is_web_client_initialization_exists:
                    # There should just be one in database
                    BackupJobManager.web_client_cache.cached_vm_centers.clear()

                    BackupJobManager.web_client_cache.cached_vm_centers = \
                        BackupJobManager.web_client_cache.read_vcenters_new()
                else:
                    BackupJobManager.web_client_cache \
                        .check_and_update_vcenter_cache_user_details(
                        BackupJobManager.web_client_cache.cached_vm_centers)

                if not BackupJobManager.web_client_cache.cached_vm_centers:
                    LOG.error("There is no vCenter registered. Please "
                              "register a vCenter using HPE RMC Configuration options in the webclient.")
                    task_desc_string = "There is no vCenter registered. " \
                                       "Please register a vCenter using HPE RMC Configuration options in the webclient."
                    with rmv_locks.web_client_operation_lock:
                        BackupJobManager.web_client_cache.refresh_status = \
                            json_helper.TpdVmPluginWebOperationStatusCode.NoVcenterFound
                        mem_client.set(str(self.memcache_id),
                                       json_helper.TpdVmPluginWebOperationStatusCode.NoVcenterFound)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

                    raise rmv_exception.VcenterNotFound

                ip_hostname, username, password, vcenteruid = \
                    self.get_vcenter_credentials()
                LOG.info("ip_hostname:%s, username:%s, vcenteruid:%s",
                         ip_hostname, username, vcenteruid)
                if vcenteruid:
                    if vc['ServerGuid'].lower() != vcenteruid.lower():
                        msg = "Server GUID from Webclient does not match " \
                              "vCenter information present in RMC-V " \
                              "repository. Please register the vCenter " \
                              "server using HPE RMC configuration options in the vCenter webclient"
                        LOG.error("%s ServerGuid:%s", msg, vc['ServerGuid'])
                        task_desc_string = msg
                        with rmv_locks.web_client_operation_lock:
                            BackupJobManager.web_client_cache.refresh_status \
                                = json_helper.TpdVmPluginWebOperationStatusCode.VcenterMismatch
                            mem_client.set(str(self.memcache_id),
                                           json_helper.TpdVmPluginWebOperationStatusCode.VcenterMismatch)

                        # Associating the vCenter Task with User Logged Event.
                        vm_task_helper.post_general_user_event(task_desc_string)

                        vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
                        vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

                        raise rmv_exception.VcenterServerGuidNotFound(
                            server_guid=vc['ServerGuid'])

                if not check_user_permissions_in_vcenter:
                    if BackupJobManager.web_client_cache.cached_vm_centers.keys():
                        vcenter_ip = \
                            BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
                        user_name = \
                            BackupJobManager.web_client_cache.cached_vm_centers[vcenter_ip].username
                        is_valid_user = True
                        if webclient_user_name.lower().strip() != \
                                user_name.lower().strip():
                            LOG.error("Did not match user name at first level: "
                                      "web client username:%s, DB(cache) "
                                      "username:%s",
                                      webclient_user_name.lower().strip(), user_name.lower().strip())
                            is_valid_user = False
                            if "@" in webclient_user_name.lower().strip():
                                striped_username = webclient_user_name[0:
                                                                       webclient_user_name.find("@")]
                                LOG.info("striped_username:%s, user_name:%s",
                                         striped_username.lower().strip(), user_name.lower().strip())
                                if striped_username.lower().strip() != \
                                        user_name.lower().strip():
                                    is_valid_user = False
                                    if "@" in user_name:
                                        striped_username_db = user_name[
                                                              0:user_name.find(
                                                                  "@")]
                                        LOG.info("striped_username:%s, "
                                                 "striped_username_db:%s",
                                                 striped_username.lower().strip(

                                                 ), striped_username_db.lower().strip())
                                        if striped_username.lower().strip() != \
                                                striped_username_db.lower().strip():
                                            is_valid_user = False
                                            LOG.error("Did not match user name at second level")
                                        else:
                                            is_valid_user = True
                                            LOG.info("matched user name at second level")
                                else:
                                    is_valid_user = True
                        if not is_valid_user:
                            msg = "Please login with the user credentials that " \
                                  "was used for registering RMC-V using HPE RMC Configuration options in the webclient."
                            task_desc_string = msg
                            LOG.error(msg)
                            with rmv_locks.web_client_operation_lock:
                                BackupJobManager.web_client_cache.refresh_status \
                                    = json_helper.TpdVmPluginWebOperationStatusCode.VcenterUserMismatch
                                mem_client.set(str(self.memcache_id),
                                               json_helper.TpdVmPluginWebOperationStatusCode.VcenterUserMismatch)

                            # Associating the vCenter Task with User Logged Event.
                            vm_task_helper.post_general_user_event(task_desc_string)

                            vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
                            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                            raise rmv_exception.VcenterUserMismatch

                cached_vcenter = None
                for vcenter in BackupJobManager. \
                        web_client_cache.cached_vm_centers.values():
                    if vcenteruid.lower() == \
                            vcenter.vi_helper.instance_uuid.lower():
                        cached_vcenter = vcenter
                        # BackupJobManager.web_client_cache.refresh_vcenter_webclient()
                        break
                    else:
                        LOG.info("vcenteruid from DB:%s cahced instance "
                                 "uuid:%s", vcenteruid,
                                 vcenter.vi_helper.instance_uuid.lower())

                if not cached_vcenter:
                    # LOG.info(self.vi_helper.__dict__)
                    LOG.info("Going to override vi_helper object")
                    # need refresh cache since vcenter got changed
                    recreate_vi_helper_object = True
                    self.vi_helper.reset_vihelper_singleton_object()
                    # LOG.info(self.vi_helper.__dict__)
                if not self.is_web_client_initialization_exists or recreate_vi_helper_object:
                    # From RMC-V 4.0 vCenter cache is not initialized. So commenting below line.
                    # BackupJobManager.web_client_cache.refresh_vcenter_webclient(vm_task_helper)
                    cached_vcenter = \
                        BackupJobManager.web_client_cache.cached_vm_centers.values()[0]

                svc = None
                # Now add this webSess to web server dict
                with rmv_locks.web_client_state_lock:
                    web_session.web_service_dict[vc['SessionCookie']] = svc

                with rmv_locks.web_client_state_lock:
                    web_session.async_op_percent_completed = 100
                    web_session.async_op_progress_message = "WebClient session " \
                                                            "initialization complete."
                    web_session.my_state = plugin_status_code.Ready
                    self.is_web_client_initialization_exists = True

                    self.vi_helper = cached_vcenter.vi_helper

                    BackupJobManager.web_client_cache.refresh_status = \
                        json_helper.TpdVmPluginWebOperationStatusCode.Ready
                    mem_client.set(str(self.memcache_id),
                                   json_helper.TpdVmPluginWebOperationStatusCode.Ready)
                    task_desc_string = "WebClient session initialization complete."
                    vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
                    vm_task_helper.CustomVMwareTaskEnd("success",
                                                       task_desc_string)

            except (rmv_exception.VcenterNotFound,
                    rmv_exception.VcenterServerGuidNotFound, rmv_exception.VcenterUserMismatch) \
                    as ex:
                # Unexpected error
                # How do we get this error message to the user?
                # We want to send a erro code back so that the front end can
                #  get localized error message
                # In this case there is an un expected / OS related error.
                # We will log the error and will not send to the front end.
                LOG.error("Webclient session initialization failed for " +
                          vc['ServiceUrl'] + ". " + str(ex))
                task_desc_string = "Webclient session initialization failed " \
                                   "for " + vc['ServiceUrl']
                with rmv_locks.web_client_operation_lock:
                    web_session.web_service_operation_status[
                        vc['ServiceUrl']] = plugin_status_code.UnexpectedFailure

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            except rmv_exception.VcenterIntializationFailed as ex:
                LOG.exception("Webclient session initialization failed for " +
                              vc['ServiceUrl'] + ". " + str(ex))
                task_desc_string = "Webclient session initialization failed " \
                                   "for " + vc['ServiceUrl']

                with rmv_locks.web_client_operation_lock:
                    web_session.web_service_operation_status[
                        vc['ServiceUrl']] = plugin_status_code.InitializeVCFailed
                    BackupJobManager.web_client_cache.refresh_status = \
                        json_helper.TpdVmPluginWebOperationStatusCode.InitializeVCFailed
                    mem_client.set(str(self.memcache_id),
                                   json_helper.TpdVmPluginWebOperationStatusCode.InitializeVCFailed)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            except Exception as ex:
                LOG.exception("Webclient session initialization failed for " +
                              vc['ServiceUrl'] + ". " + str(ex))

                with rmv_locks.web_client_operation_lock:
                    web_session.web_service_operation_status[
                        vc['ServiceUrl']] = plugin_status_code.UnexpectedFailure
                    BackupJobManager.web_client_cache.refresh_status = \
                        json_helper.TpdVmPluginWebOperationStatusCode.UnexpectedFailure
                    mem_client.set(str(self.memcache_id),
                                   json_helper.TpdVmPluginWebOperationStatusCode.UnexpectedFailure)
                    task_desc_string = "Webclient session initialization " \
                                       "failed for " + vc['ServiceUrl']

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            finally:
                web_session.async_op_percent_completed = 100
                if ((web_session.my_state != plugin_status_code.Ready) and
                        (web_session.my_state != plugin_status_code.UnexpectedFailure)):
                    web_session.my_state = plugin_status_code.UnexpectedFailure

                BackupJobManager.web_client_cache.web_client_rmv_sessions_dict[ \
                    webclinet_body_['userSession']['clientId']] = web_session

        LOG.audit("worker_init_web_client_session_async manager exit")

    def unregister_vms_detach_vmdks(self, context, x_auth_token, clone_id, task_id, copy_type):
        """ If unmount trigger with the option unregister all the vms and detach all vmdks
            Thi smethod will be called from unmount operation.
            will get all the registerd vms and vmdks attached from rmcv clones
            Then perform unregistering the vms and detaching the vmdks"""
        LOG.debug("unregister vms detach vmdks  :: Enter")
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            clone_info = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_details = clone_info.get("clone_details")
            registered_vm_info = clone_details.get('cloned_virtual_machines', list())
            attached_vmdks_details = clone_details.get('attached_vmdks_details', list())
            resource_name = clone_info.get("name")
            vm_moref_dict_list = []
            operation_input = {}
            for registeredVm in registered_vm_info:
                moref_dict = {}
                moref_dict['vmMoref'] = registeredVm.get('moref')
                vm_moref_dict_list.append(moref_dict)
            operation_input['vmMorefList'] = vm_moref_dict_list

            if (len(vm_moref_dict_list) > 0):
                unregister_vm_task = self._create_vm_unregister_task(rmc_wrapper_service, "Delete", resource_name,
                                                                     task_id,
                                                                     "Unregistering VMs from cloned object", clone_id,
                                                                     "Virtualmachines")
                self.unregister_vm_from_clone(context, clone_id, x_auth_token, operation_input, unregister_vm_task)

            for attachvmdk in attached_vmdks_details:
                operation_input = {}
                operation_input[rmv_utils.VMDK_SOURCE_FILE] = attachvmdk.get("source_vmdk_path")

                detach_vmdk_task = self._create_vm_unregister_task(rmc_wrapper_service, "DetachVMDK", resource_name,
                                                                   task_id,
                                                                   "Detaching attached VMDKs from cloned object",
                                                                   clone_id,
                                                                   "Virtualmachine")
                if copy_type == rmv_utils.copy_type.EXPRESS_PROTECT:

                    self.backup_attach_detach_vmdk_operations(context, clone_id, x_auth_token, operation_input,
                                                              rmv_utils.ACTION_DETACH_VMDK_TO_VM, detach_vmdk_task)
                elif copy_type == rmv_utils.copy_type.SNAPSHOT:
                    self.detachvmdk_snapshot(context, clone_id, x_auth_token, operation_input, detach_vmdk_task)
        except Exception as e:
            LOG.exception(e)

        LOG.debug("unregister vms detach vmdks :: Exit")

    def unmount_snapshot_esx(
            self, context, cloned_recoveryset_id, x_auth_token, esxHostName,
            esxHostAddFormat, task_id, is_esxHost_mount, copy_id, clone_id=None, detach_vms_vmdks=False,
            unregister_skip_vm_moref_list=None):
        LOG.info("Inside unmount_snapshot_esx")

        exception_lock_unmount = False

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            vm_task_helper = VmTaskHelper(self.vi_helper)
            if is_esxHost_mount:
                LOG.debug("Locking Esxi host : '%s'" % esxHostName)
                lock_response = rmv_utils.acquire_esx_operation_lock(self.esx_host_in_dict, esxHostName,
                                                                     self.vi_helper.validated_username)
                if lock_response:
                    exception_lock_unmount = True
                    LOG.error("Could not acquire lock on clone. Unmount operation is in progress for %s", esxHostName)

                    task_state = 'Failed'
                    task_status = "Error"
                    task_desc_string = "The mount or unmount operation is in progress on Esxi. Retry after sometime."
                    task_percentage = 100
                    object_type = "Folder"
                    mo_ref = "group-d1"
                    vm_task_helper.CustomVMwareTaskBegin(
                        object_type,
                        mo_ref,
                        "UNMountVirtualCopyTask",
                        "UNMountVirtualCopyFailedFault")
                    LOG.debug("vcenter action start ")
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    msg = "Could not perform unmount. " + \
                          task_desc_string

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(msg)

                    vm_task_helper.CustomVMwareTaskEnd(
                        "error",
                        msg)
                    LOG.debug("vcenter action :Exit")

                    raise rmv_exception.SnapshotLockException(error=lock_response)

                LOG.info("Locked Esxi : '%s'" % esxHostName)

            if detach_vms_vmdks:
                # first will unregister all the vms and detach all attached vmdks then
                # initiate unmount operation
                self.unregister_vms_detach_vmdks(context, x_auth_token, clone_id, task_id, rmv_utils.copy_type.SNAPSHOT)

            mount = Mount()
            # Cache usage removed in 4.0 release
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map
            clone_info = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_status = clone_info.status
            values = {'status': 'deleting'}
            self.db.update_rmcv_clone_by_cloned_recovery_set_id(context, cloned_recoveryset_id, values)
            mount.unmount_from_esxhost(
                cloned_recoveryset_id,
                context,
                x_auth_token,
                esxHostName,
                esxHostAddFormat,
                task_id,
                self.vi_helper, is_esxHost_mount, self.db, copy_id, unregister_skip_vm_moref_list)
        except Exception as e:
            values = {'status': clone_status}
            self.db.update_rmcv_clone_by_cloned_recovery_set_id(context, cloned_recoveryset_id, values)
            LOG.exception("Exception during unmount : '%s'" % e)
            raise e
        finally:
            if is_esxHost_mount and not exception_lock_unmount:
                rmv_utils.release_esx_operation_lock(self.esx_host_in_dict, esxHostName)
                LOG.info(("Released Lock for esxHostName '%s'") % esxHostName)
        LOG.debug("unmount_snapshot_esx :Exit")
        return

    def unmount_backup_esx(self,
                           context,
                           copy_id,
                           x_auth_token,
                           esx_host_name,
                           esx_host_add_format,
                           task_id,
                           is_esx_host_mount,
                           rmc_copyset_id,
                           ds_mount_path_dir,
                           clone_id, detach_vms_vmdks=False,
                           unregister_skip_vm_moref_list=None):
        """
        Validate backup object, acquire operation lock on backup object and
        initiate Express Protect Backup Object UnMount operation

        :param context: context
        :param backup_id: backup-id
        :param x_auth_token: auth-token
        :param esx_host_name: ESXi host name
        :param esx_host_add_format: backup object presentation format
        :param task_id: RMC Operation Task ID
        :param is_esx_host_mount: ESXi host attach status
        :return: None
        """

        LOG.debug("Enter: unmount_backup_esx")
        backup_id = rmc_copyset_id
        if not backup_id:
            raise exception.BackupNotFound(backup_id=backup_id)

        backup_operation_lock = False
        esx_lock = True
        LOG.debug("Acquiring lock un-mount operation on backup object")
        try:
            with rmv_locks.backup_op_lock:
                # Acquire operation lock on backup object
                self.acquire_backup_operation_lock(backup_id, "backup_unmount")
                backup_operation_lock = True
            LOG.debug("Locked Backup Object for Un-mount Operation : '%s'" % backup_id)

            esx_lock_response = rmv_utils.acquire_esx_operation_lock(self.esx_host_in_dict, esx_host_name,
                                                                     self.vi_helper.validated_username)
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            if esx_lock_response:
                vm_task_helper = VmTaskHelper(self.vi_helper)
                esx_lock = False
                task_desc = 'Mount or unmount operation is already in progress on the esxi' + esx_lock_response
                task_percentage = 100
                task_state = 'Failed'
                task_status = 'Error'
                self._update_task(task_desc,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  None, task_status=task_status)
                raise Exception(esx_lock_response)
            LOG.info("Locked Esxi : '%s'" % esx_host_name)

            if detach_vms_vmdks:
                # first will unregister all the vms and detach all attached vmdks then
                # initiate unmount operation
                self.unregister_vms_detach_vmdks(context, x_auth_token, clone_id, task_id,
                                                 rmv_utils.copy_type.EXPRESS_PROTECT)

            mount = Mount()
            # Cache usage removed in 4.0 release
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map
            # Initiate backup object un-mount operation

            mount.unmount_backup_from_esxhost(backup_id,
                                              x_auth_token,
                                              esx_host_name,
                                              esx_host_add_format,
                                              task_id,
                                              self.vi_helper,
                                              is_esx_host_mount,
                                              self.db,
                                              context,
                                              clone_id,
                                              unregister_skip_vm_moref_list)


        except Exception as e:
            LOG.exception("Exception occurred Un-mounting Backup Object [%s] : %s", backup_id, e)
            raise e
        finally:
            if backup_operation_lock:
                with rmv_locks.backup_op_lock:
                    # Release operation lock on backup object
                    self.release_backup_operation_lock(backup_id)
            else:
                # If unable to acquire lock on backup object,
                # update VCenter and RMC task with error
                task_desc_string = "HPE Express Protect Backup Object is currently in use. " \
                                   "Please retry after sometime."
                self.update_backup_operation_task_error(x_auth_token,
                                                        "UnMountExpressProtectBackupTask",
                                                        "UnMountExpressProtectBackupFailedFault",
                                                        task_id,
                                                        task_desc_string)
            if esx_lock:
                rmv_utils.release_esx_operation_lock(self.esx_host_in_dict, esx_host_name)
            rmc_copy_details = rmc_wrapper_service.get_backup_for_backupId(context, backup_id)
            copy_set = rmc_copy_details.get('backupSet')
            if copy_set:
                attach_status = copy_set.get("attachStatus", "unknown")
                values = {'status': 'available'}
                if attach_status == 'attached':
                    values = {'status': 'mounted'}
                self.db.update_rmcv_copy(context, copy_id, values)
        LOG.debug("Exit: unmount_backup_esx")
        return

    def update_vcenter_cache(self, context, client_id, x_auth_token, task_id):
        """
        Update vCenter cache
        """

        LOG.info("Enter update_cache in manager layer")
        # Rest performance related parameters.
        # Reinitializing it if recovery manage cache refresh is called.
        # If any Vcenter configuration is changed than user is calling cache refresh.
        with rmv_locks.update_vcenter_cache:
            # reset rc group parameters
            self.reset_rcgroup_parameters()
        # Update Tasks (Task Tracker and VMware Task)
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vm_task_helper = VmTaskHelper(self.vi_helper)
        object_type = "Folder"
        mo_ref = "group-d1"
        vm_task_helper.CustomVMwareTaskBegin(object_type,
                                             mo_ref,
                                             "RefreshcacheTask",
                                             "RefreshcacheFailedFault")

        try:
            with rmv_locks.web_client_operation_lock:
                LOG.info("Number of clients with RMV: " +
                         str(len(
                             BackupJobManager.
                                 web_client_cache.web_client_rmv_sessions_dict)))
                """if client_id not in BackupJobManager. \
                        web_client_cache.web_client_rmv_sessions_dict:
                    LOG.error(
                        "Web client session is not found for client ID: %s",
                        client_id)

                    task_desc_string = 'Client_id: ' + client_id + \
                                       ' not found in HPE StoreOnce Recovery ' \
                                       'Manager Central for Vmware. Please ' \
                                       'logoff and login to the vCenter again.'
                    task_percentage = 100
                    task_state = 'Failed'
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper)
                    vm_task_helper.CustomVMwareTaskEnd("error",
                                                       task_desc_string)
                    return"""

                task_desc_string = 'Updating cache for client_id: ' + client_id
                task_percentage = 10
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                # web_session =
                # BackupJobManager.web_client_cache.web_client_rmv_sessions_dict[client_id]
                if BackupJobManager.web_client_cache \
                        .web_client_rmv_sessions_dict.keys():
                    web_session = \
                        BackupJobManager.web_client_cache.web_client_rmv_sessions_dict.values()[0]
                    LOG.info("Number of vCenters in web_service_dict: " +
                             str(len(web_session.web_service_dict)))
                else:
                    LOG.audit("Web client session not found")

                # Not sure why for loop is required as there should only be
                # one element
                # leaving it legacy way to avoid any surprises in future

                # try:
                #     moref_manage_obj = moref_manage(self.vi_helper)
                #     # moref_manage_obj.update_changed_moref(context, x_auth_token)
                #     moref_manage_obj.check_and_update_mo_ref_if_srm_configured(context, x_auth_token)
                # except Exception as e:
                #     LOG.exception("Unable to update the changed MoRef. %s " % e)

                # TODO: Do it the below way when we move to multi vCenter
                # support
                """
                #key is session key and value is whole vCeneter session
                for vcenter_session in web_session.web_service_dict.values():
                    if vcenter_session:
                        vcenter_session.refresh_vcenter_webclient()
                """
                # TODO: Remove the below 'for loop' block when we implement
                # multi vCenter block.

                # From 4.0 release, vCenter Cache is not used in the code. So commenting below code which updates the cache.
                # Right now there is only one vCenter in
                # BackupJobManager.web_client_cache.cached_vm_centers
                # for vcenter in BackupJobManager. \
                #         web_client_cache.cached_vm_centers.values():
                #     # if vcenter.vi_helper.instance_uuid.lower() ==
                #     # web_session['user_session']['userSession']
                #     LOG.info(
                #         "Refreshing cache for vCenter: " +
                #         vcenter.host_name)
                #     vcenter.refresh_cache(True, vm_task_helper)
                #
                #     LOG.info("processing_errors: " +
                #              str(len(vcenter.vm_vv_map.processing_errors)))
                #     LOG.info("processing_warnings: " +
                #              str(len(vcenter.vm_vv_map.processing_warnings)))
                #     LOG.info("esx_hosts: " +
                #              str(len(vcenter.vm_vv_map.esx_hosts)))
                #     LOG.info("datastores: " +
                #              str(len(vcenter.vm_vv_map.datastores)))
                #     LOG.info("virtual_machines: " +
                #              str(len(vcenter.vm_vv_map.virtual_machines)))
                #     LOG.info("array_cab_id_list: " +
                #              str(len(vcenter.vm_vv_map.array_cab_id_list)))

                task_desc_string = 'Cache refresh completed for client_id: ' \
                                   + \
                                   client_id
                task_percentage = 100
                task_state = 'Completed'
                task_status = "Ok"
                timeStamp = timeutils.utcnow()
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success",
                                                   task_desc_string)
        except Exception as ex:
            LOG.exception('Exception while refreshing cache: ' + str(ex))
            task_desc_string = 'Exception while updating cache for ' \
                               'Client_id: ' + \
                               client_id
            task_percentage = 100
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

        LOG.info("Exit update_cache")
        return

    def get_backupjobs_service_status(self, context):
        return BackupJobManager.web_client_cache.refresh_status

    def get_restorable_vms_list(self, mountedDatastoreMoref, mountedDatastoreName, backup_info, esx_hosts,
                                datastoreLevel):

        """
        Getting the mounted vmx path and vmx name

        :param mountedDatastoreMoref: mounted Datastore Moref
        :param mountedDatastoreName: mounted  Datastore Name
        :param backup_info: Data structure used for storing information
        :param vm_vv_map_cache: vmware cache - Cache is removed from RMC-V 4.0
        :param esx_hosts: ESX Host info with VM and DS list
        :param datastoreLevel: datastoreLevel
        """
        LOG.info("get_restorable_vms_list called:start")

        myList = []

        try:
            DatastoreName = "[" + mountedDatastoreName + "] "
            ds_mo = vim.get_moref(mountedDatastoreMoref, "Datastore")
            summary = self.vi_helper.GetObjectProperties(ds_mo, "summary")
            oc_list = self.vi_helper.GetObjectProperties(ds_mo, "browser")
            oc_datastore = oc_list.objects[0]
            property_dict = vim_util.extract_properties(oc_datastore)
            LOG.debug("Creating HostDatastoreBrowserSearchSpec")
            search_spec = vim_util.get_host_datastore_VMX_search_spec(self.vi_helper.client_factory)
            mo_obj_browser = property_dict["browser"]
            res = self.vi_helper.vmops_obj.search_datastore_sub_folders_task(mo_obj_browser, DatastoreName, search_spec)
            search_res_list = res.HostDatastoreBrowserSearchResults

            flag = False
            for search_res in search_res_list:
                if not rmv_utils.has_attribute(search_res, 'file'):
                    continue
                for file in search_res.file:
                    vm_name = (file.path).rsplit(".vmx")[0]
                    vmx_path = search_res.folderPath + file.path
                    (registerStatus,
                     redirectIODatastoreName,
                     registeredVMName, registeredVMMoref) = self.populate_registered_vm_details(esx_hosts, backup_info,
                                                                                                vm_name)
                    if backup_info['VmWareObjectName'] == vm_name:
                        restorable_obj = self.vv_map_obj.put_vmxpath_in_restorable_vm_list(vm_name, vmx_path,
                                                                                           registerStatus,
                                                                                           redirectIODatastoreName,
                                                                                           registeredVMName,
                                                                                           registeredVMMoref)
                        myList.append(restorable_obj)
                        flag = True
                        break
                    elif datastoreLevel:
                        restorable_obj = self.vv_map_obj.put_vmxpath_in_restorable_vm_list(vm_name, vmx_path,
                                                                                           registerStatus,
                                                                                           redirectIODatastoreName,
                                                                                           registeredVMName,
                                                                                           registeredVMMoref)
                        myList.append(restorable_obj)

                if flag:
                    break

        except Exception as e:
            LOG.exception("Exception occurred in get_restorable_vms_list [%s] ", e)

        LOG.info("get_restorable_vms_list called:Exit")
        return myList

    # TODO 6.0 rename this method
    def populate_backup_mount_details_new(
            self, context, request_body, x_auth_token):
        """
        populate_backup_mount_details

        Function to get the backup details for mounting express protect backup object
        This will populate backup appMetadata with mountable ESX hosts info, attachable VMs,
        datastores available for copying vmdks and mount info (mounted esxi host name , mounted datastore name)
        for backup object
        :param context:
        :param request_body: response from get_backup_id RMC rest call
        :return: Updated request_body appMetadata field with mount details
        """

        LOG.info("populate_backup_mount_details_new : enter")

        ret = {}

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        response_backup = rmc_wrapper_service.get_backup_for_backupId(context, request_body['copy_set_id'],
                                                                      x_auth_token)

        # LOG.info("response_backup........%s:", response_backup)
        if not response_backup:
            LOG.debug("Unable to get backupset information.")
            return request_body

        # Check if backups available if not return request_body
        if not response_backup['backupSet']['backups']:
            LOG.debug("Unable to get backups info from RMC.")
            return request_body

        backups = response_backup['backupSet']['backups']

        # Check if ERT feature enabled and update app_metadata appropriately to support older backups taken before
        # RMC 1.2.0
        # if not backup_appmetadata.has_key('isERTEnabled'):
        #     if not backup_appmetadata.has_key('VmType'):
        #         # Call method to update app_metadata with a dummy VirtualCopyList object
        #         # This is for supporting ERT on older backups taken before RMC 1.2.0
        #         backup_appmetadata['VirtualCopyList'] = \
        #             self.update_app_metadata_with_virtual_copy_list(backup_appmetadata, backups)
        #         backup_appmetadata['isERTEnabled'] = True
        #     else:
        #         LOG.debug("Not populating mount details as ERT not enabled for this backup.")
        #         return request_body

        try:
            # Accessing Cache
            # LOG.debug("Accessing Cache info")
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map

            # Retrieve required properties of host from vCenter
            prop_list = ["name", "config.storageDevice.hostBusAdapter", "configManager.storageSystem", "vm",
                         "datastore"]
            esx_hosts = self.vi_helper.get_esx_host_info(prop_list)

            backup_response_data_ret = {}
            # getting host info for mounting backup
            backup_appmetadata = self.get_host_info_for_backup(
                backup_response_data_ret,
                esx_hosts)

            if not backup_appmetadata:
                LOG.debug("Unable to get host information for mounting backup object")
                return request_body

            backup_response_data_ret = rmv_utils.convert_object_to_dict_recursively(backup_response_data_ret)
            attach_status = response_backup['backupSet']['attachStatus']
            if not attach_status:
                LOG.debug("Unable to get the attachStatus information %s", attach_status)

            # getting mounted info for backup
            # backup_response_data_ret = self.get_mount_info_for_backup(
            #     backup_response_data_ret,
            #     backups,
            #     attach_status,
            #     esx_hosts)
            # backup_response_data_ret =self.get_restorable_list_from_backup(backup_response_data_ret,esx_hosts)
            # if not backup_response_data_ret:
            #     LOG.debug("Unable to get mount information for backup" )
            #     return request_body

        except (Exception, rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(e.msg)
                LOG.error("Exception caught. Unable to get mount information for backup")

        ret.update(backup_response_data_ret)
        ret['backupSet'] = response_backup

        ret = rmv_utils.convert_object_to_dict_recursively(ret)

        LOG.info("populate_backup_mount_details_new : exit")
        return ret

    # TODO 6.0 remove this method later, populate_backup_mount_details_new is used instead
    def populate_backup_mount_details(
            self, context, request_body):
        """
        populate_backup_mount_details

        Function to get the backup details for mounting express protect backup object
        This will populate backup appMetadata with mountable ESX hosts info, attachable VMs,
        datastores available for copying vmdks and mount info (mounted esxi host name , mounted datastore name)
        for backup object
        :param context:
        :param request_body: response from get_backup_id RMC rest call
        :return: Updated request_body appMetadata field with mount details
        """

        LOG.info("populate_backup_mount_details : enter")
        ret = {}
        response_backup = request_body['backupSet']
        if not response_backup:
            LOG.debug("Unable to get backupset information.")
            return request_body

        # Check if appMetadata available if not return request_body
        backup_appmetadata = response_backup['appMetadata']
        if not backup_appmetadata:
            LOG.debug("Unable to get application metadata for this backup.")
            return request_body

        # Check if backups available if not return request_body
        backups = response_backup['backups']
        if not backups:
            LOG.debug("Unable to get backups info from RMC.")
            return request_body

        # Check if ERT feature enabled and update app_metadata appropriately to support older backups taken before
        # RMC 1.2.0
        if not backup_appmetadata.has_key('isERTEnabled'):
            if not backup_appmetadata.has_key('VmType'):
                # Call method to update app_metadata with a dummy VirtualCopyList object
                # This is for supporting ERT on older backups taken before RMC 1.2.0
                backup_appmetadata['VirtualCopyList'] = \
                    self.update_app_metadata_with_virtual_copy_list(backup_appmetadata, backups)
                backup_appmetadata['isERTEnabled'] = True
            else:
                LOG.debug("Not populating mount details as ERT not enabled for this backup.")
                return request_body

        try:
            # Accessing Cache
            # LOG.debug("Accessing Cache info")
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map

            # Retrieve required properties of host from vCenter
            prop_list = ["name", "config.storageDevice.hostBusAdapter", "configManager.storageSystem", "vm",
                         "datastore"]
            esx_hosts = self.vi_helper.get_esx_host_info(prop_list)

            # getting host info for mounting backup
            backup_appmetadata = self.get_host_info_for_backup(
                backup_appmetadata,
                esx_hosts)

            if not backup_appmetadata:
                LOG.debug("Unable to get host information for mounting backup object")
                return request_body

            backup_appmetadata = rmv_utils.convert_object_to_dict_recursively(backup_appmetadata)
            attach_status = response_backup['attachStatus']
            if not attach_status:
                LOG.debug("Unable to get the attachStatus information %s", attach_status)

            # getting mounted info for backup
            backup_appmetadata = self.get_mount_info_for_backup(
                backup_appmetadata,
                backups,
                attach_status,
                esx_hosts)
            backup_appmetadata = self.get_restorable_list_from_backup(backup_appmetadata, esx_hosts)
            if not backup_appmetadata:
                LOG.debug("Unable to get mount information for backup")
                return request_body

        except (Exception, rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(e.msg)
                LOG.error("Exception caught. Unable to get mount information for backup")

        response_backup['appMetadata'] = backup_appmetadata
        ret['backupSet'] = response_backup

        ret = rmv_utils.convert_object_to_dict_recursively(ret)

        LOG.info("populate_backup_mount_details : exit")
        return ret

    def get_respool_from_host(self, host_ref):
        """
        Function returns default resource pool
        :param host_ref:
        :return:
        """
        LOG.info("get_respool_from_host : ENTER")
        try:
            respool_moref = None
            host_moref = vim.get_moref(host_ref, "HostSystem")
            respool_moref = self.vi_helper.get_respool(host_moref)
            LOG.debug("respool_moref : %s" % respool_moref)
            if not respool_moref:
                msg = "failed in getting resource pool moref"
                raise exception.RegisterVmException(msg)
            LOG.info("get_respool_from_host : EXIT")
            return respool_moref.value

        except Exception as e:
            LOG.exception("Failed to get respool from host :%s", e)
            raise e

    def populate_registered_vm_details(self, esx_hosts, backup_appmetadata, vm_name):
        """
        populate_registered_vm_details

        Function to get the registered vm details from the backup.
        :param vm_vv_map_cache:vm_vv_map_cache used for the cache
        :param backup_appmetadata: backup_appmetadata backup meta data
        :param vm_name:vm_name registered vm name
        :return: Updated registered status
        """
        LOG.info("populate_registered_vm_details:ENTER")
        registerStatus = None
        redirectIODatastoreName = None
        registeredVMName = None
        registeredVMMoref = None
        ds_moref = None
        try:

            if backup_appmetadata:
                backup_VCList = backup_appmetadata['VirtualCopyList']
                for virtual_copy_data in backup_VCList:
                    snapdatastore = virtual_copy_data['SnapshotDatastoreName']
                    registeredvm = vm_name + "_" + snapdatastore
                    mountStatus = virtual_copy_data['IsMounted']
                    if mountStatus:
                        # Get DS moref from the esx_hosts list based on name
                        for esx_host in esx_hosts.values():
                            if esx_host.DatastoreDict:
                                for ds in esx_host.DatastoreDict.values()[0]:
                                    if ds.Name == snapdatastore:
                                        ds_moref = ds.Moref
                                        break

                        # add function call to find vms in a datastore
                        backup_datastoretoVMListDict = self.vi_helper.find_all_vms_in_datastore(snapdatastore, ds_moref)
                        for item in backup_datastoretoVMListDict:
                            for vmname, vmmoref in item.iteritems():
                                if vmname == registeredvm:
                                    registeredVMName = registeredvm
                                    registerStatus = "Registered"
                                    registeredVMMoref = vmmoref
                                    vm_moref = vim.get_moref(vmmoref, "VirtualMachine")
                                    vmconfiginfo = self.vi_helper.GetObjectProperties(vm_moref, "config")
                                    snapshot_directory_path = self.vi_helper.get_vm_snapshot_directory(
                                        registeredVMMoref)
                                    if snapshot_directory_path:
                                        redirectIODatastoreName = snapshot_directory_path.split("]")[0].split("[")[1]
                                        if redirectIODatastoreName.startswith("snap-"):
                                            redirectIODatastoreName = None
                            break

        except Exception as e:
            LOG.exception("Exception occured fetching object properties in populate_registered_vm_details: %s", e)

        LOG.info("populate_registered_vm_details:EXIT")
        return (registerStatus, redirectIODatastoreName, registeredVMName, registeredVMMoref)

    def update_app_metadata_with_virtual_copy_list(self, backup_appmetadata, backups):
        """
        This method will update the app_metadata field of older express protect backups
        (backups taken before RMC 1.2.0) with a virtualcopylist having metadata info that are required for ERT.

        :param backup_appmetadata: metadata for backups
        :param backups: backups info returned from RMC GET
        :return: virtual copy list with update metadata information
        """

        LOG.info("update_app_metadata_with_virtual_copy_list : enter")
        virtual_copy_list_tmp = []
        try:
            for backup in backups:
                virtual_copy_info_tmp = json_helper.plugin_virtual_copy_info()
                # virtual_copy_info_tmp.InServROVolume = "N/A"
                if backup_appmetadata.has_key('VmWareObjectName'):
                    virtual_copy_info_tmp.ItemName = backup_appmetadata['VmWareObjectName']
                else:
                    virtual_copy_info_tmp.ItemName = "N/A"
                virtual_copy_info_tmp.id = backup['id']
                virtual_copy_info_tmp.LunUsedAs = 0
                virtual_copy_list_tmp.append(virtual_copy_info_tmp)
        except Exception as ex:
            LOG.exception(
                "Unable to udpate app_metadata with VirtualCopyList for older backups taken before RMC 1.2.0 :%s", ex)
        LOG.info("update_app_metadata_with_virtual_copy_list : exit")
        return virtual_copy_list_tmp

    def get_snapshot_details(
            self, context, snapshot_id, x_auth_token, request_body):
        LOG.info("get_snapshot_details : enter")
        mount_info = True

        ret = {}
        ret["SnapshotUuid"] = snapshot_id

        response_snapshot = request_body['SnapshotArray'][0]

        if not response_snapshot:
            ret[
                "StatusCode"] = \
                json_helper.TpdVmPluginWebOperationStatusCode.ObjectNotFound
            ret[
                "StatusDescription"] = "Could not retrive snapshot record " \
                                       "from repository for '%s' " % \
                                       snapshot_id
            return ret

        # TODO Once we get client data from RMC, response_snapshot should
        # come from RMC and response_snapshot.clientdata should be assigned
        # to snap_info
        # snap_info = response_snapshot.clientdata
        snap_info = response_snapshot
        # snap_info["VirtualCopyList"] = []

        if not snap_info:
            ret[
                "StatusCode"] = \
                json_helper.TpdVmPluginWebOperationStatusCode.ObjectNotFound
            ret[
                "StatusDescription"] = "Could not retrive snapshot " \
                                       "information from record client data " \
                                       "for '%s' " % snapshot_id
            return ret

        # TODO : validation for InServCabId Field

        # TODO : validation for PreviousState Field

        virtual_copy_list = snap_info['VirtualCopyList']

        snaps_in_operation_dict = {}

        # TODO if (not virtual_copy_list and not mount_info) will never satisfy
        # as mount_info is always true. This condition can be removed.
        if (not virtual_copy_list and not mount_info) or (
                snapshot_id in snaps_in_operation_dict):
            if snapshot_id in snaps_in_operation_dict:
                snap_info['State'] = snaps_in_operation_dict[snapshot_id]
                ret[
                    "StatusCode"] = \
                    json_helper.TpdVmPluginWebOperationStatusCode.Busy
            else:
                ret[
                    "StatusCode"] = \
                    json_helper.TpdVmPluginWebOperationStatusCode.Success
            return ret

        # TODO : validation for InServCabId Field. Currently this field is not
        # available.

        temp_virtual_copy_list = []
        LOG.debug(_("The virtual_copy_list is %s") % virtual_copy_list)
        VmType = None
        if 'VmType' in snap_info:
            VmType = snap_info['VmType']

        if ((virtual_copy_list) and (VmType != rmv_utils.VVOL_DISK_TYPE)):
            for virtual_copy in virtual_copy_list:
                try:
                    # inServ.InServHelper.ShowVV(vc.InServROVolume) is called for
                    # each virtual_copy_list of client data.
                    # In RMC GET Snapshots
                    virtual_copy['State'] = json_helper.TpdVmPluginVirtualCopyState.Available
                    if ((not 'InServROVolume' in virtual_copy) and (not virtual_copy['InServROVolume'])):
                        LOG.error(("Snapshot volume is missing in StoreServ "))
                        virtual_copy['State'] = json_helper.TpdVmPluginVirtualCopyState.Missing
                    temp_virtual_copy_list.append(virtual_copy)
                except Exception as ex:
                    LOG.exception('Exception while GetSnapshot Details: ' + str(ex))
                    continue

            snap_info['VirtualCopyList'] = temp_virtual_copy_list

            missing = sum(
                x['State'] == json_helper.TpdVmPluginVirtualCopyState.Missing for x
                in virtual_copy_list)

            if missing == len(virtual_copy_list):
                snap_info['State'] = str(
                    json_helper.TpdVmPluginVirtualCopyState.Missing)
                if snap_info['Expirable']:
                    snap_info['State'] = "Expired"

            snap_info = self.get_snapshot_mount_info(snap_info,
                                                     snapshot_id,
                                                     x_auth_token)

        ret['SnapshotInfo'] = snap_info
        ret["StatusCode"] = json_helper.TpdVmPluginWebOperationStatusCode.Success

        ret = rmv_utils.convert_object_to_dict_recursively(ret)

        LOG.info("get_snapshot_details : exit")
        return ret

    def get_copies_details(self, context, x_auth_token, request_body):

        copy_type = request_body['copy_type']

        if copy_type == 'snapshot' or copy_type == "remote_snapshot":
            return self.get_snapshot_mount_info_new(context, request_body,
                                                    x_auth_token)
        else:
            return self.populate_backup_mount_details_new(context, request_body,
                                                          x_auth_token)

    def get_snapshot_mount_info(self, snap_info, snapshot_id, x_auth_token):
        LOG.info("get_snapshot_mount_info : enter")

        # TODO validation for InServCabId
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            attach_status = ""
            rs_v_luns = []
            # TO get all hosts details from RMC
            LOG.info("Retriving Host details from RMC")
            array_serial_number = snap_info['ArraySerialNum']
            # check if the array is registered in RMC
            response_data = rmc_wrapper_service.check_array_registration(array_serial_number)
            storage_system_id = response_data['id']

            storage_pools = rmc_wrapper_service.get_storage_pools(storage_system_id)
            host_list = []
            for storage_pool in storage_pools:
                pool_id = storage_pool['id']
                hosts = rmc_wrapper_service.get_all_registered_hosts_by_pool_id(pool_id)
                host_list.extend(hosts['hosts'])
                break  # Breaking the loop. Both iSCSI and FC Hosts will be fetched from any one storage pool.

            # Get the attached host details from RMC
            LOG.info("Retriving Attach details from RMC")
            snapshot_details = rmc_wrapper_service.get_snapshot(snapshot_id)
            v_luns = snapshot_details['snapshotSet']['volumes']
            client_data = snapshot_details['snapshotSet']['clientData']
            snapshot_client_data = jsonutils.loads(client_data)
            cloned_recovery_set_id = snapshot_client_data.get("cloned_recovery_set_id", None)
            if cloned_recovery_set_id:
                recovery_set_resposne = rmc_wrapper_service.get_recovery_set(cloned_recovery_set_id)
                attach_status = recovery_set_resposne['recoverySet']['attachStatus']
                rs_v_luns = recovery_set_resposne['recoverySet']['volumes']

                # attach_status = snapshot_details['snapshotSet']['attachStatus']

            # Accessing Cache
            # LOG.info("Accessing Cache info")
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map

            # Retrieve required properties of host from vCenter
            prop_list = ["name", "config.storageDevice.hostBusAdapter", "configManager.storageSystem", "vm",
                         "datastore", "runtime"]
            esx_hosts = self.vi_helper.get_esx_host_info(prop_list)

            snap_info = self.get_host_info(snap_info, host_list, esx_hosts)

            snap_info = self.get_mount_list(
                snap_info,
                host_list,
                v_luns,
                attach_status,
                rmc_wrapper_service,
                esx_hosts, rs_v_luns)

            LOG.info("get_snapshot_mount_info : exit")
        except (Exception, rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError) as e:
            LOG.exception("Failed to get snapshot mount info:%s", e)
            raise e
        return snap_info

    # TODO 6.0: Rename later
    def get_snapshot_mount_info_new(self, context, request_body, x_auth_token):
        LOG.debug("get_snapshot_mount_info_new : enter")

        # snapshot_id = request_body['copy_set_id']
        array_serial_number = request_body['array_serial_number']
        # copy_id = request_body['copy_id']
        # copy_type = request_body['copy_type']

        snap_info = {}
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            # attach_status = ""
            # rs_v_luns = []
            # TO get all hosts details from RMC
            LOG.info("Retrieving Host details from RMC")
            # check if the array is registered in RMC
            response_data = rmc_wrapper_service.check_array_registration(array_serial_number)
            storage_system_id = response_data['id']

            storage_pools = rmc_wrapper_service.get_storage_pools(storage_system_id)
            host_list = []
            for storage_pool in storage_pools:
                pool_id = storage_pool['id']
                hosts = rmc_wrapper_service.get_all_registered_hosts_by_pool_id(pool_id)
                host_list.extend(hosts['hosts'])
                break  # Breaking the loop. Both iSCSI and FC Hosts will be fetched from any one storage pool.

            # LOG.info("Retrieving Attach details from RMC")
            # snapshot_details = rmc_wrapper_service.get_snapshot(snapshot_id)
            # v_luns = snapshot_details['snapshotSet']['volumes']
            #
            # try:
            #     clones = self.db.get_clone_by_parent_copy_id(context, copy_id)
            #
            #     if clones and clones.recovery_set_id:
            #
            #         recovery_set_response = rmc_wrapper_service.get_recovery_set(clones.recovery_set_id)
            #         attach_status = recovery_set_response['recoverySet']['attachStatus']
            #         rs_v_luns = recovery_set_response['recoverySet']['volumes']
            #
            # except Exception as e:
            #     err_args_msg = (_("%s") % e.msg if hasattr(e, 'msg') else str(e))
            #     LOG.error(err_args_msg)

            # Retrieve required properties of host from vCenter
            prop_list = ["name", "config.storageDevice.hostBusAdapter", "configManager.storageSystem", "vm",
                         "datastore", "runtime"]
            esx_hosts = self.vi_helper.get_esx_host_info(prop_list)

            snap_info = rmvjobs_utils.get_host_info(host_list, esx_hosts)

            # copy_info = self.db.get_rmcv_ds_with_base_wwn_by_copy_id(context, copy_id)
            #
            # ds_moref_wwn_dict = {}
            # if copy_info:
            #     for copy_row in copy_info:
            #         wwn_details_list = jsonutils.loads(copy_row.wwn_details)
            #         ds_moref_wwn_dict[copy_row.moref] = rmv_utils.extract_wwn_list(wwn_details_list)

            # mount_info = self.get_mount_list_new(
            #     snapshot_details,
            #     host_list,
            #     v_luns,
            #     attach_status,
            #     rmc_wrapper_service,
            #     esx_hosts,
            #     rs_v_luns,
            #     ds_moref_wwn_dict)

            # snap_info['mountDetails'] = mount_info

            LOG.debug("get_snapshot_mount_info_new : exit")
        except (Exception, rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError) as e:
            LOG.exception("Failed to get snapshot mount info:%s", e)
            raise e

        ret = rmv_utils.convert_object_to_dict_recursively(snap_info)
        return ret

    # TODO : Remove later
    def get_host_info(self, snap_info, hosts, esx_hosts):
        """
        For each hosts in RMC, Compare it with Esx hosts from cache using
        WWNs. If match found then update "MountableEsxHostList" else update
        "MountableOtherHostList"
        snap_info - client data from RMV database
        hosts - All Esx Hosts info from RMC
        Host_info - ESX Host information from Cache
        """
        LOG.info("get_host_info : enter")

        try:
            snap_info['EsxHostToDatastoreListDict'] = {}
            snap_info['EsxHostToVmListDict'] = {}
            # TODO Check whether this can be added while creating snapshot
            snap_info['MountableEsxHostList'] = []
            # TODO Check whether this can be added while creating snapshot
            snap_info['MountableOtherHostList'] = []

            if hosts:
                for host in hosts:

                    if not host['name']:
                        LOG.info("Host is Null or Empty")
                        continue

                    ret_value = rmvjobs_utils.try_get_esx_host_name(host, esx_hosts)

                    if ret_value["status"]:
                        hst = ret_value["o_esx"]
                        hst.is_esx_host = True
                        hst.array_name = snap_info['ArrayName']

                        h1 = rmv_utils.first_or_default(
                            snap_info['MountableEsxHostList'],
                            lambda
                                i: i.esx_host_name.lower() ==
                                   hst.esx_host_name.lower())

                        esx_host = esx_hosts.get(hst.esx_host_moref)
                        if not h1:
                            snap_info['MountableEsxHostList'].append(hst)
                            if esx_host.VMDict:
                                snap_info['EsxHostToVmListDict'].update(
                                    {hst.esx_host_name: esx_host.VMDict.values()[0]})
                            if esx_host.DatastoreDict:
                                snap_info['EsxHostToDatastoreListDict'].update(
                                    {hst.esx_host_name: esx_host.DatastoreDict.values()[0]})
                        else:
                            LOG.warning(
                                (
                                    "Esx Host '%s' has more than one array "
                                    "host "
                                    "names: '%s' ") %
                                (hst.esx_host_name, host['name']))

                    else:
                        hst = vi_objects.vm_snapshot_mountable_host()
                        hst.array_name = snap_info['ArrayName']
                        hst.array_host_name = host['name']
                        hst.is_esx_host = False
                        snap_info['MountableOtherHostList'].append(hst)

            return snap_info

        except Exception as e:
            LOG.exception(e)

        LOG.info("get_host_info : exit")

    def get_host_info_for_vcenter_detail(self, backup_info, esx_hosts):
        """
        get_host_info_for_vcenter_detail
        Function to get Esx Host list and Data store list in that Esx host from the cache.

        :param backup_info: The appMetaData returned from GET backupId RMC REST call
        :param vm_vv_map_cache: vmware cache information - removed cache from RMC-V 4.0
        :return: populated Esx list and Datastore list
        """
        LOG.info("get_host_info_for_vcenter_detail : enter")

        try:
            backup_info['EsxHostToDatastoreListDict'] = {}
            backup_info['EsxHostList'] = []

            # Get all esx host names from vm cache info
            esx_host_names = self.get_all_esx_host_names(esx_hosts)
            if not esx_host_names:
                LOG.debug("Unable to get esx host names from vm cache")
                return backup_info

            for esx_host in esx_host_names:
                backup_info['EsxHostList'].append(esx_host)

                # Get all the datastores associated with host and update the datastore list dictionary
                esx_hst = esx_hosts.get(esx_host.esx_host_moref)
                if esx_hst.DatastoreDict:
                    backup_info['EsxHostToDatastoreListDict'].update({
                        esx_host.esx_host_name: esx_hst.DatastoreDict.values()[0]})

        except Exception as e:
            LOG.exception("Unable to populate ESXi host information and Datastore from VM cache:%s", e)
            raise e

        LOG.info("get_host_info_for_vcenter_detail : exit")
        return backup_info

    def get_host_info_for_backup(self, backup_info, esx_hosts):
        """
        get_host_info_for_backup
        Function to get backup appMetadata updated with mountable ESX hosts info, attachable VMs on the ESX hosts,
        datastore list available for copying vmdks. For Backups, we will not get registered hosts details from RMC
        (which internally calls get_storage_pools from StoreServ) instead get the available esx host info directly
        rom vm cache.This is to avoid dependency with StoreServ for ERT recovery for express backups.)

        :param backup_info: The appMetaData returned from GET backupId RMC REST call
        :param vm_vv_map_cache: vmware cache information
        :return: populated appMetaData with mountable host info
        """
        LOG.info("get_host_info_for_backup : enter")

        try:
            backup_info['candidateDatastores'] = {}
            backup_info['candidateVms'] = {}
            backup_info['candidateEsxHosts'] = []

            # Get all esx host names from vm cache info
            esx_host_names = self.get_all_esx_host_names(esx_hosts)
            if not esx_host_names:
                LOG.debug("Unable to get esx host names from vm cache")
                return backup_info

            for esx_host in esx_host_names:
                esx_host_info = esx_hosts.get(esx_host.esx_host_moref)
                backup_info['candidateEsxHosts'].append(esx_host)

                if esx_host_info.VMDict:
                    # Get all the VMs associated with host and update the VM list dictionary
                    backup_info['candidateVms'].update(
                        {
                            esx_host.esx_host_name: esx_host_info.VMDict.values()[0]})

                if esx_host_info.DatastoreDict:
                    # Get all the datastores associated with host and update the datastore list dictionary
                    backup_info['candidateDatastores'].update(
                        {
                            esx_host.esx_host_name: esx_host_info.DatastoreDict.values()[0]})

        except Exception as e:
            LOG.exception("Unable to populate ESXi host information from VM cache:%s", e)
            raise e

        LOG.info("get_host_info_for_backup : exit")
        return backup_info

    # TODO: This method needs a complete revamp in 6.0. adding this method so UI is unblocked. Relook into this later
    def get_mount_list_new(self, snapshot_details, hosts, v_luns,
                           attach_status, rmc_wrapper_service, esx_hosts, rs_v_luns, ds_moref_wwn_dict):
        """
        If snapshot is mounted then get the mount information and add it to
        client data
        snapshot_details - snapshot details from RM-Core
        hosts - ESX Host details from RMC
        v_luns - Snapshot volume details from RMC
        attach_details - Details of attached ESX hosts
        host_info - HostInfo details from vCenter
        """
        LOG.info("get_mount_list_new : enter")

        vc_list = []
        tgt_volume_mnt_info_dict = {}
        esx_host_moref_dict = {}
        host_info = None
        mnt_info = vi_objects.vm_snapshot_volume_mount_info()
        # mnt_info.is_esx_host_mount = False
        volume = {}
        mnt_info_list = []
        LOG.debug("attach_status............... : %s", attach_status)
        if attach_status == "attached" or attach_status == "partial":
            for base_volume_wwn_list in ds_moref_wwn_dict.values():
                volume['IsMounted'] = False  # initially set IsMounted to False

                # InServROCopyOfId_list = list()
                # inserv_ro_copyid = volume.get('copyOfVolumeId')
                # if inserv_ro_copyid:
                #     if type(inserv_ro_copyid) is list:
                #         InServROCopyOfId_list = inserv_ro_copyid
                #     else:
                #         InServROCopyOfId_list.append(inserv_ro_copyid)

                # base_volume_wwn_list_temp = ["60002AC00000000008000FA500004445"]
                # if InServROCopyOfId not in tgt_volume_mnt_info_dict:
                # run through all the vluns (luns that were
                # exported/presented) returned by RMC for a given snapshot
                # ID
                LOG.info("v_luns............... : %s", v_luns)
                for v in v_luns:
                    snapshot_metadata = self.get_snapshot_metadata(
                        rmc_wrapper_service,
                        v)
                    # we expect this to be same as the snapshot name we
                    # have saved when we have created the snapshots.
                    # we will get the attachment/exported/presentation
                    # information if it is attached.
                    LOG.info("v.................... : %s", v)
                    # if v['copyOfVolumeWwn'] == InServROCopyOfId:
                    # LOG.info("InServROCopyOfId............... : %s", InServROCopyOfId)
                    for rs_lun in rs_v_luns:
                        # "array_snap_id" is from snapshot and "parentSnapshotId" is from cloned recovery set
                        if v['array_snap_id'] == rs_lun['parentSnapshotId']:
                            if 'name' in rs_lun:
                                mnt_info.rw_volume_name = rs_lun['name']
                            if 'wwn' in rs_lun:
                                mnt_info.rw_volume_wwn = rs_lun['wwn']
                            # mnt_info.array_host_name = attach_details['host']
                            mnt_info.array_host_name = rs_lun['attach']['hosts'][0]['hostname']
                            mnt_info.rw_volume_lunid = None  # TODO v.lun
                            mnt_info.ro_volume_name = v['name']
                            if 'copyOfVolumeName' in v:
                                mnt_info.base_volume_name = v['copyOfVolumeName']
                            # mnt_info.array_name = snapshot_details['ArrayName']
                            mnt_info.is_esx_host_mount = False
                            mnt_info_list.append(mnt_info)
                # tgt_volume_mnt_info_dict[InServROCopyOfId] = mnt_info

            if mnt_info_list.__len__() == 0:
                pass

            if mnt_info_list.__len__() > 1:
                LOG.info(
                    (
                        "Virtual copy '%s' is mounted on more than one "
                        "host. "
                        "Not supported") %
                    v['wwn'])

            for mount in mnt_info_list:
                volume['IsMounted'] = True
                volume['IsMountedOnEsxHost'] = False
                volume['MountInfo'] = mount

                array_host = rmv_utils.first_or_default(
                    hosts,
                    lambda i: i['name'] == mount.array_host_name)

                ret_value = rmvjobs_utils.try_get_esx_host_name(
                    array_host,
                    esx_hosts)
                o_esx = ret_value['o_esx']
                if not array_host or not ret_value['status']:
                    continue

                volume['IsMountedOnEsxHost'] = True
                mount.is_esx_host_mount = True
                mount.esx_host_name = o_esx.esx_host_name
                mount.esx_host_moref = o_esx.esx_host_moref
                volume['SnapshotDatastoreName'] = ""
                host_exists = False
                if o_esx.esx_host_moref in esx_host_moref_dict:
                    host_exists = True
                    host_info = esx_host_moref_dict[o_esx.esx_host_moref]
                else:
                    host_exists = False

                if not host_info or not host_exists:
                    host_info = self.vi_helper.get_host_system_complete_info(o_esx.esx_host_moref)
                    esx_host_moref_dict[o_esx.esx_host_moref] = host_info

                if not host_info or host_info.IsUnusable or not \
                        host_info.ScsiLuns:
                    continue
                lun = None
                if mount.rw_volume_name:
                    lun = rmv_utils.first_or_default(
                        host_info.ScsiLuns,
                        lambda i: i.Is3ParLun and str(
                            i.Wwn) and (
                                          i.Wwn.lower() ==
                                          mount.rw_volume_wwn.lower()))

                if not lun or not lun.VmfsVolumeUuidDict:
                    continue

                if lun.VmfsVolumeUuidDict.__len__() > 1:
                    LOG.info(
                        (
                            "Virtual Copy LUN '%s' has more than one VMFS "
                            "volume on it. Host = '%s'. This is "
                            "unsupported") %
                        (lun.Wwn, mount.esx_host_name))

                for vol in lun.VmfsVolumeUuidDict.values():
                    volume['SnapshotDatastoreName'] = operator.iconcat(
                        str(volume['SnapshotDatastoreName']), vol + " ")

                    ds_info = rmv_utils.first_or_default(
                        host_info.DatastoreDict.values(),
                        lambda i: i.Name == vol)
                    if not ds_info:
                        raise exception.DatastoreNotFound()

                    mount.virtual_copy_datastore_moref = \
                        ds_info.DatastoreMoref
                    mount.virtual_copy_datastore_name = ds_info.Name

                    if ds_info.VmList and ds_info.VmList.__len__() != 0:
                        for vm in ds_info.VmList:
                            vm_info = host_info.VMDict.get(vm.Moref)
                            if not vm_info:
                                continue

                            if not vm_info.VirtualCopyPairList or \
                                    vm_info.VirtualCopyPairList.__len__(
                                    ) == 0:
                                continue

                            vm_v_copy = rmv_utils.first_or_default(
                                vm_info.VirtualCopyPairList,
                                lambda
                                    i: volume['MountInfo'].rw_volume_wwn in i.InServBaseVolumeWwn
                            )
                            if not vm_v_copy or not \
                                    vm_v_copy.RestorableItemsList or \
                                    vm_v_copy.RestorableItemsList.__len__() \
                                    == 0:
                                continue

                            vmdk_list = []
                            for vmdk in volume.get('RestorableItemsList', []):
                                if not vmdk['FileName']:
                                    continue

                                name = vmdk['FileName']
                                if name.__contains__(
                                        "[") and name.__contains__("]"):
                                    sa = name.split("]")
                                    if not sa or sa.__len__() != 2:
                                        continue
                                    name = sa[1].strip()

                                vm_vmdk = rmv_utils.first_or_default(
                                    vm_v_copy.RestorableItemsList,
                                    lambda i: i.FileName.__contains__(
                                        name))

                                if vm_vmdk:
                                    vmdk['IsMountedOnVm'] = True
                                    vmdk['MountedOnVmMoref'] = vm_info.VmMoref
                                    vmdk['MountedOnVmName'] = vm_info.Name
                                    vmdk['MountedOnVmdkPathName'] = vm_vmdk.FileName

                                vmdk_list.append(vmdk)

                            volume['RestorableItemsList'] = vmdk_list
                            break
                    break
                vc_list.append(volume)

            # snapshot_details['VirtualCopyList'] = vc_list
        LOG.info("get_mount_list_new : exit")
        return vc_list

    def get_mount_list(self, snap_info, hosts, v_luns,
                       attach_status, rmc_wrapper_service, esx_hosts, rs_v_luns):
        """
        If snapshot is mounted then get the mount information and add it to
        client data
        snap_info - Client Data
        hosts - ESX Host details from RMC
        v_luns - Snapshot volume details from RMC
        attach_details - Details of attached ESX hosts
        host_info - HostInfo details from vCenter
        """
        LOG.info("get_mount_list : enter")

        if not snap_info['VirtualCopyList'] and len(
                snap_info['VirtualCopyList']) == 0:
            return
        vc_list = []
        tgt_volume_mnt_info_dict = {}
        esx_host_moref_dict = {}
        host_info = None
        mnt_info = vi_objects.vm_snapshot_volume_mount_info()
        # mnt_info.is_esx_host_mount = False
        if attach_status == "attached" or attach_status == "partial":
            for vc in snap_info['VirtualCopyList']:
                vc['IsMounted'] = False  # initially set IsMounted to False
                mnt_info_list = []
                InServROCopyOfId_list = list()
                inserv_ro_copyid = vc.get('InServROCopyOfId')
                if inserv_ro_copyid:
                    if type(inserv_ro_copyid) is list:
                        InServROCopyOfId_list = inserv_ro_copyid
                    else:
                        InServROCopyOfId_list.append(inserv_ro_copyid)
                for InServROCopyOfId in InServROCopyOfId_list:
                    if InServROCopyOfId not in tgt_volume_mnt_info_dict:
                        # run through all the vluns (luns that were
                        # exported/presented) returned by RMC for a given snapshot
                        # ID
                        for v in v_luns:
                            snapshot_metadata = self.get_snapshot_metadata(
                                rmc_wrapper_service,
                                v)
                            # we expect this to be same as the snapshot name we
                            # have saved when we have created the snapshots.
                            # we will get the attachment/exported/presentation
                            # information if it is attached.
                            if v['copyOfVolumeId'] == InServROCopyOfId:
                                for rs_lun in rs_v_luns:
                                    # "array_snap_id" is from snapshot and "parentSnapshotId" is from cloned recovery set
                                    if v['array_snap_id'] == rs_lun['parentSnapshotId']:
                                        if 'name' in rs_lun:
                                            mnt_info.rw_volume_name = rs_lun['name']
                                        if 'wwn' in rs_lun:
                                            mnt_info.rw_volume_wwn = rs_lun['wwn']
                                        # mnt_info.array_host_name = attach_details['host']
                                        mnt_info.array_host_name = rs_lun['attach']['hosts'][0]['hostname']
                                        mnt_info.rw_volume_lunid = None  # TODO v.lun
                                        mnt_info.ro_volume_name = v['name']
                                        if 'copyOfVolumeName' in v:
                                            mnt_info.base_volume_name = v['copyOfVolumeName']
                                        mnt_info.array_name = snap_info['ArrayName']
                                        mnt_info.is_esx_host_mount = False
                                        mnt_info_list.append(mnt_info)
                        tgt_volume_mnt_info_dict[InServROCopyOfId] = mnt_info

                if mnt_info_list.__len__() == 0:
                    continue

                if mnt_info_list.__len__() > 1:
                    LOG.info(
                        (
                            "Virtual copy '%s' is mounted on more than one "
                            "host. "
                            "Not supported") %
                        vc['InServROVolume'])

                for mount in mnt_info_list:
                    vc['IsMounted'] = True
                    vc['IsMountedOnEsxHost'] = False
                    vc['MountInfo'] = mount

                    array_host = rmv_utils.first_or_default(
                        hosts,
                        lambda i: i['name'] == mount.array_host_name)

                    ret_value = rmvjobs_utils.try_get_esx_host_name(
                        array_host,
                        esx_hosts)
                    o_esx = ret_value['o_esx']
                    if not array_host or not ret_value['status']:
                        continue

                    vc['IsMountedOnEsxHost'] = True
                    mount.is_esx_host_mount = True
                    mount.esx_host_name = o_esx.esx_host_name
                    mount.esx_host_moref = o_esx.esx_host_moref
                    vc['SnapshotDatastoreName'] = ""
                    host_exists = False
                    if o_esx.esx_host_moref in esx_host_moref_dict:
                        host_exists = True
                        host_info = esx_host_moref_dict[o_esx.esx_host_moref]
                    else:
                        host_exists = False

                    if not host_info or not host_exists:
                        host_info = self.vi_helper.get_host_system_complete_info(o_esx.esx_host_moref)
                        esx_host_moref_dict[o_esx.esx_host_moref] = host_info

                    if not host_info or host_info.IsUnusable or not \
                            host_info.ScsiLuns:
                        continue
                    lun = None
                    if mount.rw_volume_name:
                        lun = rmv_utils.first_or_default(
                            host_info.ScsiLuns,
                            lambda i: i.Is3ParLun and str(
                                i.Wwn) and (
                                              i.Wwn.lower() ==
                                              mount.rw_volume_wwn.lower()))

                    if not lun or not lun.VmfsVolumeUuidDict:
                        continue

                    if lun.VmfsVolumeUuidDict.__len__() > 1:
                        LOG.info(
                            (
                                "Virtual Copy LUN '%s' has more than one VMFS "
                                "volume on it. Host = '%s'. This is "
                                "unsupported") %
                            (lun.Wwn, mount.esx_host_name))

                    for vol in lun.VmfsVolumeUuidDict.values():
                        vc['SnapshotDatastoreName'] = operator.iconcat(
                            str(vc['SnapshotDatastoreName']), vol + " ")

                        ds_info = rmv_utils.first_or_default(
                            host_info.DatastoreDict.values(),
                            lambda i: i.Name == vol)
                        if not ds_info:
                            raise exception.DatastoreNotFound()

                        mount.virtual_copy_datastore_moref = \
                            ds_info.DatastoreMoref
                        mount.virtual_copy_datastore_name = ds_info.Name

                        if ds_info.VmList and ds_info.VmList.__len__() != 0:
                            for vm in ds_info.VmList:
                                vm_info = host_info.VMDict.get(vm.Moref)
                                if not vm_info:
                                    continue

                                if not vm_info.VirtualCopyPairList or \
                                        vm_info.VirtualCopyPairList.__len__(
                                        ) == 0:
                                    continue

                                vm_v_copy = rmv_utils.first_or_default(
                                    vm_info.VirtualCopyPairList,
                                    lambda
                                        i: vc['MountInfo'].rw_volume_wwn in i.InServBaseVolumeWwn
                                )
                                if not vm_v_copy or not \
                                        vm_v_copy.RestorableItemsList or \
                                        vm_v_copy.RestorableItemsList.__len__() \
                                        == 0:
                                    continue

                                vmdk_list = []
                                for vmdk in vc['RestorableItemsList']:
                                    if not vmdk['FileName']:
                                        continue

                                    name = vmdk['FileName']
                                    if name.__contains__(
                                            "[") and name.__contains__("]"):
                                        sa = name.split("]")
                                        if not sa or sa.__len__() != 2:
                                            continue
                                        name = sa[1].strip()

                                    vm_vmdk = rmv_utils.first_or_default(
                                        vm_v_copy.RestorableItemsList,
                                        lambda i: i.FileName.__contains__(
                                            name))

                                    if vm_vmdk:
                                        vmdk['IsMountedOnVm'] = True
                                        vmdk['MountedOnVmMoref'] = vm_info.VmMoref
                                        vmdk['MountedOnVmName'] = vm_info.Name
                                        vmdk['MountedOnVmdkPathName'] = vm_vmdk.FileName

                                    vmdk_list.append(vmdk)

                                vc['RestorableItemsList'] = vmdk_list
                                break
                        break
                vc_list.append(vc)

            snap_info['VirtualCopyList'] = vc_list
        LOG.info("get_mount_list : exit")
        return snap_info

    def get_mount_info_for_backup(self, backup_info, backups,
                                  attach_status,
                                  esx_hosts):
        """
        get_mount_info_for_backup

        This function will populate backup appMetadata with mounted backup info (mounted on which ESX,
        mounted datastore name, VM name to which vmdk is attached) for backup object

        :param backup_info: The appMetaData info containing metadata info for backup object returned from GET backupId
        RMC REST call
        :param backups: The backups info containing attach info returned from GET RMC REST call
        :param attach_status: attach status of backup object
        :param vm_vv_map_cache: vmware cache - Cache is removed from RMC-V 4.0
        :param esx_hosts: ESX Host info with VM and DS list
        :return: The appMetaData with mount details populated (mounted ESXi info, mounted datastore name etc)
        """

        LOG.info("get_mount_info_for_backup : enter")
        vc_list = []
        esx_host_moref_dict = {}
        host_info = None

        try:
            if attach_status == "attached" or attach_status == "attached_partial" \
                    or attach_status == "volume_not_available":
                for vc in backup_info['VirtualCopyList']:
                    # Get corresponding backup object to populate the VirtualCopyList Mount Information
                    # From 6.0 'InServROVolume' field is removed from clientdata. So now matching with WWN
                    # backup = rmv_utils.first_or_default(backups, lambda i: i['snapName'] in vc['InServROVolume'])
                    backup = rmv_utils.first_or_default(backups,
                                                        lambda i: i['copyOfVolumeWwn'] in vc['InServBaseVolumeWwn'])
                    if not backup:
                        # Try with updated id field which should be part of newely created backup appmetadata
                        backup = rmv_utils.first_or_default(backups, lambda i: i['id'] == vc['id'])
                        if not backup:
                            LOG.error("Unable to find backup details from backups list returned from RMC")
                            vc_list.append(vc)
                            continue

                    # Get mounted esx host name using iscsi initiator name returned from RMC attach info
                    if not backup.has_key('attach'):
                        LOG.error("Unable to get mounted hosts details from GET call returned from RMC")
                        vc_list.append(vc)
                        continue

                    vc['IsMounted'] = True
                    mnt_info = vi_objects.vm_snapshot_volume_mount_info()
                    vc['MountInfo'] = mnt_info

                    # Get mounted esx host name using iscsi initiator name returned from RMC attach info
                    if not backup['attach'].has_key('hosts'):
                        LOG.error("Unable to get mounted hosts details from GET call returned from RMC")
                        vc_list.append(vc)
                        continue

                    iscsi_initiator_name = backup['attach']['hosts'][0]['iSCSIInitiatorName']
                    LOG.debug("iSCSIInitiatorName from backup mounted info: %s", iscsi_initiator_name)
                    esx_host = self.get_esx_host_name_from_iqn(iscsi_initiator_name, esx_hosts)
                    if not esx_host:
                        LOG.error("Unable to find ESXi from iSCSIInitiatorName returned from RMC")
                        vc_list.append(vc)
                        continue

                    host_exists = False
                    if esx_host.esx_host_moref in esx_host_moref_dict:
                        host_exists = True
                        host_info = esx_host_moref_dict[esx_host.esx_host_moref]
                    else:
                        host_exists = False

                    # Get complete host system information
                    if not host_info or not host_exists:
                        host_info = \
                            self.vi_helper.get_host_system_complete_info(
                                esx_host.esx_host_moref)
                        esx_host_moref_dict[esx_host.esx_host_moref] = host_info
                    mnt_info.is_esx_host_mount = True
                    mnt_info.esx_host_name = esx_host.esx_host_name
                    mnt_info.esx_host_moref = esx_host.esx_host_moref
                    vc['IsMountedOnEsxHost'] = True
                    iscsi_target_name = backup['attach']['iSCSITargetName']
                    if not iscsi_target_name:
                        LOG.error("Unable to find iSCSITargetName from GET call returned from RMC")
                        vc_list.append(vc)
                        continue

                    # get mounted datastoreinfo using the iscsi target name of the attached backup object
                    ds_info = self.get_mounted_datastore_for_backup(host_info, iscsi_target_name, mnt_info)
                    if not ds_info and vc['LunUsedAs'] == 0:
                        LOG.debug("Unable to find ESXi host Datastore from attached iscsi target")
                        vc_list.append(vc)
                        continue

                    # If not RDM populate mounted datastore name
                    if vc['LunUsedAs'] == 0:
                        mnt_info.virtual_copy_datastore_moref = ds_info.DatastoreMoref
                        mnt_info.virtual_copy_datastore_name = ds_info.Name
                        vc['SnapshotDatastoreName'] = ds_info.Name

                    vc['MountInfo'] = mnt_info

                    if ds_info and ds_info.VmList and ds_info.VmList.__len__() != 0:
                        for vm in ds_info.VmList:
                            vm_info = host_info.VMDict.get(vm.Moref)
                            if not vm_info:
                                continue

                            vm_vmdk_file_paths = self.vi_helper.get_vm_vmdk_file_paths(vm.Moref)
                            vmdk_list = []
                            for vmdk in vc['RestorableItemsList']:
                                if not vmdk['FileName']:
                                    continue

                                name = vmdk['FileName']
                                if name.__contains__("[") and name.__contains__("]"):
                                    sa = name.split("]")
                                    if not sa or sa.__len__() != 2:
                                        continue
                                    name = sa[1].strip()

                                attached_vmdk_name = "[" + ds_info.Name + "] " + name
                                vm_vmdk_file_name = rmv_utils.first_or_default(
                                    vm_vmdk_file_paths, lambda i: i.__contains__(attached_vmdk_name))
                                LOG.debug("attached_vmdk_name: %s", attached_vmdk_name)
                                LOG.debug("vm_vmdk_file_name: %s", vm_vmdk_file_name)
                                if vm_vmdk_file_name:
                                    vmdk['IsMountedOnVm'] = True
                                    vmdk['MountedOnVmMoref'] = vm_info.VmMoref
                                    vmdk['MountedOnVmName'] = vm_info.Name
                                    vmdk['MountedOnVmdkPathName'] = vm_vmdk_file_name
                                vmdk_list.append(vmdk)

                                vc['RestorableItemsList'] = vmdk_list
                    vc_list.append(vc)

                backup_info['VirtualCopyList'] = vc_list
        except Exception as e:
            LOG.exception("Exception got while getting mount info for express backup object:%s", e)
        LOG.info("get_mount_info_for_backup : exit")
        return backup_info

    def get_restorable_list_from_backup(self, backup_info, esx_hosts):
        """
        get_restorable_list_from_backup
        This function will populate backup appMetadata with mounted backup info (VM name to which vmdk is attached) for backup object
        :param backup_info: The appMetaData info containing metadata info for backup
        :param vm_vv_map_cache: vmware cache - Cache is removed from RMC-V 4.0
        :param esx_hosts: ESX Host info with VM and DS list
        """

        LOG.info("get_restorable_list_from_backup : enter")
        restorableVMSlist = []
        vc_list = []
        try:

            for vc in backup_info['VirtualCopyList']:
                mnt_info = vc['MountInfo']
                if vc['IsMounted']:
                    if backup_info['VmWareObjectType'] == "VirtualMachine":
                        datastoreLevel = False
                        restorableVMSlist = self.get_restorable_vms_list(mnt_info.virtual_copy_datastore_moref,
                                                                         mnt_info.virtual_copy_datastore_name,
                                                                         backup_info, esx_hosts, datastoreLevel)
                        restorableVMSlist = rmv_utils.convert_object_to_dict_recursively(restorableVMSlist)
                        vc['RestorableVMList'] = restorableVMSlist
                        vc_list.append(vc)
                    elif backup_info['VmWareObjectType'] == "Datastore":
                        datastoreLevel = True
                        restorableVMSlist = self.get_restorable_vms_list(mnt_info.virtual_copy_datastore_moref,
                                                                         mnt_info.virtual_copy_datastore_name,
                                                                         backup_info, esx_hosts, datastoreLevel)
                        restorableVMSlist = rmv_utils.convert_object_to_dict_recursively(restorableVMSlist)
                        vc['RestorableVMList'] = restorableVMSlist
                        vc_list.append(vc)
                else:
                    vc['RestorableVMList'] = None
            if vc_list:
                backup_info['VirtualCopyList'] = vc_list

        except Exception as e:
            LOG.exception("Exception got while get restorable list from backup:%s", e)

        LOG.info("get_restorable_list_from_backup : exit")
        return backup_info

    def get_mounted_datastore_for_backup(self, host_info, iscsi_target_name, mnt_info):
        """
        get_mounted_datastore_for_backup

        This function will get the backup volume uuid/wwn from StoreOnce returned iscsiTargetName and using that get
        the mounted datastore info from datastore dict. This is a workaround as current VMware LUN uuid's varies with
        our  backup object unique ID in the first nibble. For VMware the first nibble will be always '6'.
        Thereby changing the first nibble to match ESXi host lun uuid for comparing

        :param host_info: host info with datstore info dictionary
        :param iscsi_target_name: iscsi target name of the mounted/attached express protect backup object
        :param mnt_info: information regarding mounted datastore
        :return: The attached/mounted datastore info for the backup object
        """
        LOG.info("get_mounted_datastore_for_backup : enter")
        ds_info = None
        try:
            backup_vol_uuid = iscsi_target_name.rsplit('.', 1)[1]
            backup_vol_uuid = backup_vol_uuid.replace("-", "")
            backup_vol_wwn = rmv_utils.ESX_LUN_UUID_FIRST_NIBBLE + backup_vol_uuid[1:]
            mnt_info.rw_volume_wwn = backup_vol_wwn
            LOG.debug("rw_volume_wwn got from iSCSITargetName in backup info: %s", backup_vol_wwn)
            LOG.debug("DatastoreDict : %s", host_info.DatastoreDict)

            # Get the mounted datastore info using the wwn got from iscsitargetname
            for datastore_info in host_info.DatastoreDict.values():
                if datastore_info.DatstoreType == json_helper.TpdVmHostFileSystemType.Vmfs:
                    datastore_extent = rmv_utils.first_or_default(
                        datastore_info.VmfsExtent,
                        lambda i: i.diskName.strip().__contains__(backup_vol_wwn.lower().strip()))

                    if datastore_extent:
                        ds_info = datastore_info

            if not ds_info:
                LOG.debug("Unable to get datastore info for iscsi_target_name : %s", iscsi_target_name)
        except Exception as e:
            LOG.exception("UUnable to get datastore info for iscsi_target_name:%s", e)
            return ds_info

        LOG.info("get_mounted_datastore_for_backup : exit")
        return ds_info

    def get_esx_host_name_from_iqn(self, iqn, esx_hosts):
        """
        get_esx_host_name_from_iqn

        Function to get a ESXi host using the associated iscsi initiator name
        :param iqn: iscsi initiator associated with esx host
        :param vm_vv_map_cache:
        :return:ESXi host associated with given iqn
        """
        LOG.debug("get_esx_host_name_from_iqn : enter")

        ret_value = None
        if not iqn:
            return ret_value
        try:
            ret = {}
            for esx_host in esx_hosts.values():
                for hba in esx_host.Hbas:
                    if hba.hba_type == \
                            json_helper.vm_scsi_transport_type.ISCSI \
                            and hasattr(hba, 'friendly_name1') \
                            and hba.friendly_name1 \
                            and hba.friendly_name1.lower() not in ret:
                        ret[hba.friendly_name1.lower()] = esx_host

            esx_h = None
            esx_h = ret.get(iqn.lower().strip())

            if esx_h:
                LOG.debug("Got ESXi in  get_esx_host_name_from_iqn")
                mountable_esx_host = vi_objects.vm_snapshot_mountable_host()
                mountable_esx_host.esx_host_name = esx_h.HostName
                mountable_esx_host.esx_host_moref = esx_h.HostSystemMoref
                mountable_esx_host.esx_host_storage_system_moref = esx_h.HostStorageSystemMoref
                mountable_esx_host.is_esx_host = True
                mountable_esx_host.array_host_name = "N/A"
                ret_value = mountable_esx_host

        except Exception as e:
            LOG.exception("Unable to get esx host name from iqn:%s", e)
            return ret_value

        LOG.debug("get_esx_host_name_from_iqn : exit")
        return ret_value

    def get_all_esx_host_names(self, esx_hosts):
        """
        get_all_esx_host_names

        Function to get all ESXi host info from vm cache

        :param vm_vv_map_cache:  vmware cache information
        :return: Get all esx names available from vn cache
        """
        LOG.info("get_all_esx_host_names : enter")
        ret_value = []
        try:
            for esx_host in esx_hosts.values():
                mountable_esx_host = vi_objects.vm_snapshot_mountable_host()
                mountable_esx_host.esx_host_name = esx_host.HostName
                mountable_esx_host.esx_host_moref = esx_host.HostSystemMoref
                mountable_esx_host.esx_host_storage_system_moref = esx_host.HostStorageSystemMoref
                mountable_esx_host.array_host_name = "N/A"
                mountable_esx_host.is_esx_host = True
                ret_value.append(mountable_esx_host)

        except Exception as e:
            LOG.exception("Unable to get all esx host names for vm cache : %s", e)
            return ret_value

        LOG.info("get_all_esx_host_names : exit")
        return ret_value

    def get_snapshot_metadata(self, rmc_wrapper_service, v_lun):
        # TO get metadata of specific snapshot
        snapshot_metadata = rmc_wrapper_service.get_snapshot_metadata(
            v_lun['id'])
        return snapshot_metadata['metadata']

    def get_backup_details(self,
                           context,
                           backup_id,
                           x_auth_token):
        """
        Call RMC REST API to get backup object details via the manager layer call.

        :param context: context
        :param backup_id: backup-id
        :param x_auth_token: auth-token
        :return backup_detail: backupSet dictionary from response body
        """

        LOG.info("Enter: get_backup_details")
        try:
            backup_detail = self.get_backup_for_backupId(context,
                                                         backup_id,
                                                         x_auth_token,
                                                         False)
            if not backup_detail:
                msg = "Express Protect Object ('%s') Not Found" % backup_id
                LOG.error("Get Backup details returned None : %s", msg)
                raise exception.BackupNotFound(backup_id=backup_id)
        except Exception as e:
            LOG.exception("Exception occurred fetching backup object [%s] details: %s", backup_id, e)
            msg = "Unable to fetch Express Protect Object ('%s') details" % backup_id
            raise exception.BackupNotFound(msg)

        LOG.info("Exit: get_backup_details")
        return backup_detail['backupSet']

    def is_backup_attached(self,
                           backup_details):
        """
        Validate backup object status and return attach status.

        :param backup_details: backup object details
        :return: boolean attach status
        """

        LOG.info("Enter: is_backup_attached")
        try:
            backup_state = backup_details.get('status', None)
            if backup_state not in ['available']:
                LOG.error("Invalid Express Protect Object [%s] Status : %s", backup_details['id'], backup_state)
                raise exception.BackupNotAvailable(backup_id=backup_details.get('id', "NA"))
            else:
                attach_status = backup_details.get('attachStatus', None)
                LOG.debug("Backup Object [%s] Attach Status : %s ", backup_details.get('name', "NA"), attach_status)
                if attach_status == 'attached':
                    LOG.debug("Express Protect Object is mounted on ESXi host")
                    LOG.info("Exit: is_backup_attached")
                    return True
                elif attach_status == 'error_attaching' or attach_status == 'attached_partial' \
                        or attach_status == 'volume_not_available':
                    msg = "Express Protect Object ('%s') attach status ('%s') is invalid. " \
                          "Unable to continue current operation. Please try after sometime." \
                          % (backup_details.get('name', backup_details.get('id', "NA")), attach_status)
                    raise exception.BackupVolumeAttachFailure(msg)
                else:
                    if attach_status is None:
                        LOG.error("Unable to fetch backup object [%s] attachStatus: None",
                                  backup_details.get('name'), "NA")
                        msg = "Unable to fetch Express Protect Object ('%s') details" \
                              % backup_details.get('name', backup_details.get('id', "NA"))
                        raise exception.BackupNotAvailable(msg)

                    LOG.info("Exit: is_backup_attached")
                    return False
        except Exception as e:
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Unable to fetch Express Protect Object ('%s') details" \
                      % backup_details.get('name', backup_details.get('id', "NA"))
            LOG.exception("Exception occurred fetching backup object : %s", e)
            raise exception.BackupNotAvailable(msg)

    def get_num_vmfs_volumes(self, objectType, moref):
        """
        Function to get the number of VMFS volumes from the backup set

        :return: number of VMFS volumes in backup set
        """
        LOG.debug("Enter: get_num_vmfs_volumes")
        vmdk_list = []
        datastore_ids = []
        objectId = None
        ctx = context.get_admin_context()
        try:
            if objectType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                row = self.db.get_rmcv_datastore_by_moref(context, moref)
                objectId = row.id
                vmdk_list = self.db.get_vmdk_by_ds_id(ctx, objectId)
            elif objectType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                row = self.db.get_rmcv_virtual_machines_by_moref(context, moref)
                objectId = row.id
                vmdk_list = self.db.get_vmdk_by_vm_id(ctx, objectId)
        except Exception as e:
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal error"
            LOG.exception("Error while querying db :%s", e)
        num_vmfs_volumes = 0
        for vmdk in vmdk_list:
            if vmdk.type == "datastore":
                datastore_ids.append(vmdk.datastore_id)
        num_vmfs_volumes = len(set(datastore_ids))
        LOG.debug("Exit: get_num_vmfs_volumes")
        return num_vmfs_volumes

    def get_all_datastores_in_vcenter(self,
                                      vm_vv_map_cache):
        """
        This method returns all the datastores for all hosts in the VCenter
        from the VCenter cache

        :param vm_vv_map_cache: VCenter Cache
        :return: vmware_object datastore object list
        """
        LOG.info("Enter: get_all_datastores_in_vcenter")
        vcenter_datastore_list = []
        try:
            if vm_vv_map_cache:
                for datastore in vm_vv_map_cache.datastores:
                    # if not datastore.IsUnusable:
                    datastore_obj = json_helper.vmware_object("Datastore",
                                                              datastore.DatastoreMoref,
                                                              datastore.Name,
                                                              None,
                                                              None)
                    vcenter_datastore_list.append(datastore_obj)
            else:
                LOG.error("VCenter Cache is NULL. Unable to fetch all datastores in VCenter")

        except Exception as e:
            LOG.exception("Exception occurred fetching all datastores from VCenter: %s", e)

        LOG.info("Exit: get_all_datastores_in_vcenter")
        return vcenter_datastore_list

    def copy_file(self,
                  source_file_path,
                  target_file_path,
                  source_datacenter_moref,
                  target_datacenter_moref,
                  overwrite_file):
        """
        Copy a file from Source to Target destination

        :param source_file_path: Source File Datastore Path
        :param target_file_path: Target File Datastore Path
        :param source_datacenter_moref: Datacenter Moref Object of source
        :param target_datacenter_moref: Datacenter Moref Object of target
        :param overwrite_file: boolean overwrite file param
        :return: None
        """
        LOG.info("Enter: copy_file")
        try:
            task_info = self.vi_helper.copy_vmdk_file(source_file_path,
                                                      target_file_path,
                                                      source_datacenter_moref,
                                                      target_datacenter_moref,
                                                      overwrite_file)

            if task_info.state == rmv_utils.OPERATION_STATE_SUCCESS:
                LOG.debug("Successfully completed file [%s] copy to target destination [%s]", source_file_path,
                          target_file_path)
            else:
                error_info = str(task_info.error.localizedMessage)
                LOG.error("Error copying VMDK metadata file : %s", error_info)
                raise rmv_exception.CopyVMDKFileException(error_info)
        except Exception as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Unknown error occurred"
            LOG.error("Exception occurred copying file from [%s] to [%s] : %s", source_file_path, target_file_path, msg)
            raise rmv_exception.CopyVMDKFileException(msg)

        LOG.info("Exit: copy_file")

    def get_datacenter_moref(self,
                             backup_app_metadata):
        """
        Get Datacenter Moref object using Datastore Moref object.
        :param app_metadata: Backu Object Metadata
        :return datacenter_moref: Datacenter Moref Object
        """

        LOG.info("Enter: get_datacenter_moref")
        datastore_moref = None
        try:
            # Obtain Datastore Moref Object using the VirtualCopy List data. Need only one reference Datastore Object
            if backup_app_metadata['VirtualCopyList']:
                virtual_copy_list = backup_app_metadata['VirtualCopyList']
                for virtual_copy_data in virtual_copy_list:
                    if virtual_copy_data['MountInfo']:
                        mount_info = virtual_copy_data['MountInfo']
                        if mount_info['virtual_copy_datastore_moref']:
                            datastore_moref = mount_info['virtual_copy_datastore_moref']
                            LOG.debug("Found a Datastore Moref to obtain Datacenter object: %s", datastore_moref)
                            break
            if not datastore_moref:
                msg = ("Unable to fetch Datastore Information")
                LOG.error("Datastore Moref is not available as part of the Virtual Copy List")
                raise rmv_exception.CopyVMDKFileException(msg)

            # Use Datastore Moref object to get Datacenter Moref.
            datacenter_moref = self.vi_helper.get_parent_chain_upto_datacenter(datastore_moref)

            if not datacenter_moref:
                LOG.error("Unable to obtain Datacenter Moref Object")
                msg = "Unable to get Datacenter Information"
                raise rmv_exception.CopyVMDKFileException(msg)

            LOG.info("Exit: get_datacenter_moref")
            return datacenter_moref
        except Exception as e:
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal error"
                LOG.exception("Exception occurred fetching Datacenter Moref Object : %s, %s", msg, e)
            raise rmv_exception.CopyVMDKFileException(msg)

    def backup_copy_vmdk(self,
                         context,
                         clone_id,
                         x_auth_token,
                         copy_vmdk_input_params,
                         task_id):
        """
        Validate backup object attach status, acquire operation lock on backup object and
        initiate Copy VMDK Operation from Source to Target datastore

        :param context: context
        :param backup_id: backup object ID
        :param x_auth_token: auth token
        :param copy_vmdk_input_params: Input params including source and target datastore file paths
        :param task_id: RMC Operation Task ID
        :return: None
        """

        LOG.info("Enter: backup_copy_vmdk")
        copy_vmdk_task_state = rmv_utils.OPERATION_STATE_FAILURE
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        backup_operation_lock = None

        object_type = rmv_utils.TASK_OBJECT_TYPE
        mo_ref = rmv_utils.TASK_MO_REF
        msg = 'Begin Express Protect VMDK Copy Operation'
        vm_task_helper = VmTaskHelper(self.vi_helper)

        try:

            self.vi_helper.LogEvent(mo_ref, object_type, msg)
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 "VMDKCopyTask",
                                                 "VMDKCopyFailedFault")
            # Update Task Details
            task_desc_string = 'Begin VMDK Copy Operation'
            task_percentage = 10
            task_state = 'Running'
            task_status = "Initiated"
            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            clone_db_details = self.db.get_rmcv_clone_by_id(context, clone_id)
            copy_id = clone_db_details.parent_copy_id

            copy_details = self.db.get_rmcv_copy_by_id(context, copy_id)
            has_vmfs_snapshots = copy_details.has_vmfs_snapshots

            if has_vmfs_snapshots:
                copy_vmdk_task_state = rmv_utils.OPERATION_STATE_FAILURE
                LOG.error("Copy VMDK operation failed because of presence of one or more VMFS snapshots")
                msg = "VMDK is part of one or more VMFS snapshots. This is not a supported configuration " \
                      "for Express Protect VMDK Copy Operation."
                raise rmv_exception.CopyVMDKFileException(msg)

            # If there is a '//' in input for source file, this may result in intermitent issue.
            vmdk_path = copy_vmdk_input_params.get('vmdkPath').replace('//', '/')

            source_ds_name = copy_vmdk_input_params.get("sourceDSName")
            source_vmdk_path = "[" + source_ds_name + "] " + vmdk_path
            LOG.debug("VMDK Source Datastore Name: %s", source_ds_name)

            target_ds_name = copy_vmdk_input_params.get("targetDSName")
            target_vmdk_path = "[" + target_ds_name + "] " + vmdk_path
            LOG.debug("VMDK Copy Target Datastore Name: %s", target_ds_name)

            source_ds_ref = copy_vmdk_input_params.get("sourceDSId")
            source_ds_moref = vim.get_moref(source_ds_ref, "Datastore")

            target_ds_ref = copy_vmdk_input_params.get("targetDSId")
            target_ds_moref = vim.get_moref(target_ds_ref, "Datastore")

            self.validate_target_ds_size_for_copy(target_ds_ref,
                                                  target_ds_name,
                                                  source_ds_ref,
                                                  source_ds_name,
                                                  source_vmdk_path)
            if source_ds_moref:
                source_datacenter_moref = self.vi_helper.get_parent_datacenter(source_ds_moref)
                if not source_datacenter_moref:
                    LOG.error("Unable to obtain Datacenter Moref from Source datastore moref [%s]", source_ds_moref)
                    msg = "Unable to get Datacenter Information from VCenter"
                    raise rmv_exception.CopyVMDKFileException(msg)
            else:
                LOG.error("Unable to get Source Datastore Object from Source Datastore [%s]. "
                          "Source VMDK Path given is %s", source_ds_name, source_vmdk_path)
                msg = "Unable to fetch Source Datastore Information from ESXi host"
                raise rmv_exception.CopyVMDKFileException(msg)

            if target_ds_moref:
                target_datacenter_moref = self.vi_helper.get_parent_datacenter(target_ds_moref)
                if not target_datacenter_moref:
                    LOG.error("Unable to obtain Datacenter Moref from Target datastore moref [%s]", target_ds_moref)
                    msg = "Unable to get Datacenter Information from VCenter"
                    raise rmv_exception.CopyVMDKFileException(msg)
            else:
                LOG.error("Unable to get Target Datastore Object from Target Datastore [%s]. "
                          "Target VMDK Path given is %s", target_ds_moref, target_vmdk_path)
                msg = "Unable to fetch Target Datastore Information from ESXi host"
                raise rmv_exception.CopyVMDKFileException(msg)

            backup_operation_lock = False
            with rmv_locks.backup_op_lock:
                # Acquire operation lock on backup object
                self.acquire_backup_operation_lock(clone_id, "copy_vmdk")
                backup_operation_lock = True
            LOG.debug("Locked Backup Object for Copy VMDK operation: '%s'" % clone_id)

            # Create target folder at the destination Datastore
            target_folder_name = rmv_utils.get_target_folder_name(target_vmdk_path)
            LOG.debug("Create Target folder: %s", target_folder_name)

            self.validate_vmdk_before_copy(copy_vmdk_input_params, target_vmdk_path, source_ds_name, target_ds_name,
                                           target_folder_name)

            # Update Task Details
            task_desc_string = 'Creating target folder for VMDK copy...'
            task_percentage = 20
            task_state = 'Running'
            task_status = "Initiated"
            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            if target_folder_name:
                self.vi_helper.make_folder(target_folder_name,
                                           target_datacenter_moref)
            else:
                LOG.debug("No target folder specified. Copying VMDK file into the root directory")

            # Initiate VMDK metadata file copy
            self.copy_file(source_vmdk_path,
                           target_vmdk_path,
                           source_datacenter_moref,
                           target_datacenter_moref,
                           copy_vmdk_input_params[rmv_utils.REQUEST_BODY_OVERWRITE_TARGET_FILE])

            # Update Task Details
            task_desc_string = 'VMDK Copy Operation in progress...'
            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            task_percentage = 60
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Extract VMDK data file (flat file) names
            srcfile_without_vmdk_extension = source_vmdk_path.replace(rmv_utils.VMDK_FILE_EXTENSION, "")
            tgtfile_without_vmdk_extension = target_vmdk_path.replace(rmv_utils.VMDK_FILE_EXTENSION, "")

            source_flat_file = srcfile_without_vmdk_extension + rmv_utils.VMDK_FLAT_FILE_EXTENSION
            target_flat_file = tgtfile_without_vmdk_extension + rmv_utils.VMDK_FLAT_FILE_EXTENSION

            # Initiate VMDK data file (-flat.vmdk) copy
            self.copy_file(source_flat_file,
                           target_flat_file,
                           source_datacenter_moref,
                           target_datacenter_moref,
                           copy_vmdk_input_params[rmv_utils.REQUEST_BODY_OVERWRITE_TARGET_FILE])

            copy_vmdk_task_state = rmv_utils.OPERATION_STATE_SUCCESS

        except Exception as e:
            copy_vmdk_task_state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal Error"
            LOG.exception(e)

        finally:
            if backup_operation_lock:
                with rmv_locks.backup_op_lock:
                    # Release operation lock on backup object
                    self.release_backup_operation_lock(clone_id)
            else:
                # If unable to acquire lock on backup object,
                # update VCenter and RMC task with error
                if backup_operation_lock is False:
                    task_desc_string = "Express Protect Object is currently in use. " \
                                       "Please retry operation after sometime."
                    task_percentage = 100
                    task_state = 'Failed'
                    task_status = "Error"

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    # Commenting below LogEvent call, as the same event is logged using PostEvent
                    # self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)
                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            # End VCenter and RMC with corresponding operation completion state
            if copy_vmdk_task_state == rmv_utils.OPERATION_STATE_SUCCESS:
                # Update Task Details
                task_desc_string = 'Express Protect VMDK Copy Operation completed successfully'
                task_percentage = 100
                task_state = 'Completed'
                task_status = "Ok"
                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                LOG.debug("%s", task_desc_string)
            if copy_vmdk_task_state == rmv_utils.OPERATION_STATE_FAILURE:
                # Update Task Details
                task_desc_string = "Express Protect VMDK Copy Operation Failed: %s" % msg
                task_percentage = 100
                task_state = 'Failed'
                task_status = "Error"

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                # Commenting below LogEvent call, as the same event is logged using PostEvent
                # self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                LOG.error("%s", task_desc_string)

        LOG.info("Exit: backup_copy_vmdk")
        return

    def validate_target_ds_size_for_copy(self,
                                         target_ds_ref,
                                         target_ds_name,
                                         source_ds_ref,
                                         source_ds_name,
                                         vmdk_source_file_path):
        """
        Function to validate if the target datastore has enough space to copy the VMDK into.
        :param target_ds_ref: Target datastore reference
        :param target_ds_name: Target datastore name
        :param source_ds_ref: Source datastore reference
        :param source_ds_name: Source datastore name
        :param vmdk_source_file_path: VMDK source file datastore path
        :return: boolean
        """
        LOG.info("Enter: validate_target_ds_size_for_copy")
        try:
            target_ds_size_info = self.vi_helper.get_datastore_size_info(target_ds_ref, target_ds_name)
            if not target_ds_size_info:
                msg = "Unable to fetch target datastore [%s] size. Size Info returned None" % target_ds_size_info
                LOG.error(msg)
                raise rmv_exception.CopyVMDKFileException(msg)
            target_ds_free_space = target_ds_size_info["vmfsFreeSize"]
            LOG.debug("Target Datastore [%s] free space: %s bytes", target_ds_name, target_ds_free_space)

            vmdk_file_name = vmdk_source_file_path.split("/")[1]
            ds_virtual_disk_list = self.vi_helper.get_all_virtual_disks_in_datastore(source_ds_ref,
                                                                                     source_ds_name,
                                                                                     vmdk_file_name)
            if not ds_virtual_disk_list:
                msg = "Unable to fetch virtual disk file [%s] information from source datastore [%s]" % (vmdk_file_name,
                                                                                                         source_ds_name)
                LOG.error(msg)
                raise rmv_exception.CopyVMDKFileException(msg)
            source_vmdk_size = None
            for virtual_disk in ds_virtual_disk_list:
                if not rmv_utils.has_attribute(virtual_disk, 'file'):
                    continue
                for file in virtual_disk.file:
                    if file:
                        if file.path in vmdk_source_file_path:
                            source_vmdk_size = file.capacityKb * 1024
                            LOG.debug("Source VMDK [%s] File Size (Thick): %s bytes", vmdk_source_file_path,
                                      source_vmdk_size)
                            break
                    else:
                        msg = "Unable to fetch virtual disk file [%s] information from source datastore [%s]" % \
                              (vmdk_file_name, source_ds_name)
                        LOG.error(msg)
                        raise rmv_exception.CopyVMDKFileException(msg)

            if not source_vmdk_size:
                msg = "Unable to fetch virtual disk file [%s] size from source datastore [%s]" % (vmdk_file_name,
                                                                                                  source_ds_name)
                LOG.error(msg)
                raise rmv_exception.CopyVMDKFileException(msg)
            if source_vmdk_size <= target_ds_free_space:
                LOG.debug("Target datastore does has enough space [%s] to copy the VMDK file [size = %s]",
                          target_ds_free_space, source_vmdk_size)
                LOG.info("Exit: validate_target_ds_size_for_copy")
                return
            else:
                source_vmdk_size_GB = source_vmdk_size / (1024 * 1024 * 1024)
                target_ds_free_space_GB = target_ds_free_space / (1024 * 1024 * 1024)
                LOG.error("Target datastore does not enough space [%s GB] to copy the VMDK file [size = %s GB]",
                          target_ds_free_space_GB, source_vmdk_size_GB)

        except Exception as e:
            LOG.exception("Exception occurred validating target datastore size for VMDK copy: %s", e)
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal Error: Unable to fetch VMDK Source File [%s] Information from vCenter" % \
                      vmdk_source_file_path
            raise rmv_exception.CopyVMDKFileException(msg)
        msg = "Target Datastore [%s] does not have enough space to copy VMDK file." \
              "Available Free Space on Datastore = %s GB. VMDK (thick provisioned) File Size = %s GB" \
              % (target_ds_name, target_ds_free_space_GB, source_vmdk_size_GB)
        LOG.info("Exit: validate_target_ds_size_for_copy")
        raise rmv_exception.CopyVMDKFileException(msg)

    def build_vmx_path(self, part_vmx_path, ds_filepath_dict):
        """
        This function which builds the vmx path
        :param part_vmx_path: in the format "vmname/vmname.vmdk"
        :param ds_filepath_dict: Dictionary whose key is the path of vmdk and value is the ds where the vmdk is present
        :param vm_vv_map_cache: cache object
        :return: vmx_path, snp_ds, ds_ref_obj
        """
        try:
            LOG.info("build_vmx_path : Enter")
            vmx_path = []

            # Get Ds name and its moref mapping dict of all the DS present in vCenter.
            ds_name_to_moref_dict = self.vi_helper.get_ds_names_to_moref_dict()

            for dstr in ds_name_to_moref_dict:
                dataStoreName = dstr
                if dataStoreName.startswith('snap-') and len(dataStoreName) >= 14:
                    dsName = dataStoreName[rmv_utils.PRIMARY_DS_INDEX:]
                    for dkeys_1 in ds_filepath_dict:
                        if dkeys_1 == dsName:
                            ds_Moref = self.get_datastore_ref_from_name(dsName, ds_name_to_moref_dict)
                            vmx_list = self.vi_helper.get_all_vmx_in_datastore(ds_Moref, dkeys_1)
                            if vmx_list:
                                vmx_path = "[" + dkeys_1 + "] " + part_vmx_path
                                if vmx_path in vmx_list:
                                    snp_ds = dataStoreName
                                    ds_ref_obj = vim.get_moref(ds_Moref, "Datastore")
                                    return (vmx_path, snp_ds, ds_ref_obj)
            LOG.info("build_vmx_path : Exit")
        except Exception as e:
            LOG.exception("caught exception in build vmx path:%s", e)
            msg = "Exception in copyvmdk:%s" % e
            raise exception.CopyVMDKFileException(msg)

    def pre_copyvmdk_checks(self, context, clone_id, target_vmdk, copyvmdk_input, task_id):
        """
        This function basically registers the VM in the mounted DS and consolidates the disk to
        perform the copy vmdk
        :param snapshot_id: Snapshot that is mounted
        :param x_auth_token: auth token
        :param copyvmdk_input: input parameter of copy_vmdk
        :param task_id: rmc task tracker id
        :return:
        """
        LOG.info("pre_copyvmdk_checks : Enter")
        is_vm_registered = False
        vm_moref = None
        try:
            tar_path = None
            tar_vmx_path = None

            clone_db_details = self.db.get_rmcv_clone_by_id(context, clone_id)
            copy_id = clone_db_details.parent_copy_id

            copy_details = self.db.get_rmcv_copy_by_id(context, copy_id)
            has_vmfs_snapshots = copy_details.has_vmfs_snapshots

            if not has_vmfs_snapshots:
                return tar_path
            else:
                LOG.info("The VM has VMFS snapshots..!!!!")
                # format of target vmdk path will be "[data store name] //New_test_VM1.vmdk"
                # datastore name can have the space in between so split the string with "] "
                tar_vmdk = target_vmdk
                src_list = tar_vmdk.split("] ", 1)
                if src_list:
                    src_list[0] = src_list[0] + ']'
                temp_det = src_list[rmv_utils.VM_NAME_VMDK_INDEX].split("/")
                if not temp_det[rmv_utils.SOURCE_DATASTORE_VMDK_INDEX] and not temp_det[rmv_utils.VM_NAME_VMDK_INDEX]:
                    LOG.info("Copy VMDK Operation on the VMDK present on Datastore")
                    return tar_path
                tmp = temp_det[rmv_utils.PART_VMDK_PATH_INDEX].split(temp_det[0])
                if len(tmp[rmv_utils.VM_NAME_VMDK_INDEX]) == rmv_utils.PRIMARY_BASE_DISK_MIN_LEN:
                    tar_path = tar_vmdk
                    tar_vmx_path = tar_path.replace('vmdk', 'vmx')
                elif rmv_utils.PRIMARY_BASE_DISK_MIN_LEN < len(
                        tmp[rmv_utils.VM_NAME_VMDK_INDEX]) <= rmv_utils.SECONDARY_BASE_DISK_MAX_LEN:
                    tar_path = tar_vmdk
                    tar_vmx_path = tar_vmdk.replace(tmp[rmv_utils.VM_NAME_VMDK_INDEX], '.vmx')
                elif len(tmp[rmv_utils.VM_NAME_VMDK_INDEX]) >= rmv_utils.DELTA_DISK_MAX_LEN:
                    # Case where the path chosen is the detla disk
                    indx = tmp[rmv_utils.VM_NAME_VMDK_INDEX].find('_')
                    if indx == 0:
                        str_tmp = tmp[rmv_utils.VM_NAME_VMDK_INDEX][2:]
                    elif indx == -1:
                        str_tmp = tmp[rmv_utils.VM_NAME_VMDK_INDEX]
                    str_split = str_tmp.split('.vmdk')
                    tar_path = tar_vmdk.split(str_split[0])
                    tar_path = tar_path[0] + tar_path[1]
                    tar_vmx_path = src_list[0] + " " + temp_det[0] + '/' + temp_det[0] + '.vmx'

                LOG.info("Target vmx path is : %s" % tar_vmx_path)
                LOG.info("Target vmdk path is : %s" % tar_path)

                fileName_list = []
                assoc_ds_list = []
                ori_vmdk_path = []
                snap_ref_list_to_del = []

                # Build the vmx path
                vmdk_list = tar_vmx_path.split("] ", 1)
                part_vmx_path = vmdk_list[1]
                part_vmx_path = part_vmx_path.replace('//', '/')
                LOG.info("Part vmx path : %s" % part_vmx_path)
                """
                Using this path, extract and build the path to new mounted DS
                Retieve the details of the mounted DS
                """

                src_vmx_path = None
                vmx_ds_moref = None

                clone_details = clone_db_details.clone_details
                cloned_ds_details = clone_details.get("cloned_ds_details")
                for cloned_ds in cloned_ds_details:
                    cloned_ds_mo_ref = cloned_ds.get('moref')
                    cloned_ds_name = cloned_ds.get('name')

                    vmx_list = self.vi_helper.get_all_vmx_in_datastore(cloned_ds_mo_ref, cloned_ds_name)
                    if vmx_list:
                        vmx_path = "[" + cloned_ds_name + "] " + part_vmx_path
                        if vmx_path in vmx_list:
                            src_vmx_path = vmx_path
                            vmx_ds_moref = cloned_ds_mo_ref

                            break

                LOG.info("src_vmx_path : %s" % src_vmx_path)
                LOG.info("vmx_ds_moref : %s" % vmx_ds_moref)

                if not src_vmx_path:
                    LOG.error("Source Datastore VMX Path could not be found from the details available in Clones table")
                    # TODO:6.0 decide whether to through exception here
                    return tar_path

                ds_ref_obj = pyvmomi_util.get_moref(vmx_ds_moref, "Datastore")
                ds_oc = self.vi_helper.get_object_properties(ds_ref_obj, "host")
                ds_prop = pyvmomi_util.extract_properties(ds_oc[0])
                ds_host_mount = ds_prop.get('host')
                host_mo_ref = ds_host_mount[0].key

                vm_resPool_ref = self.get_respool_from_host(host_mo_ref._moId)

                LOG.debug("Resource Pool for registering the VM : %s" % vm_resPool_ref)
                LOG.info("Getting the parent datacenter managed reference object")
                dc_mo_id = self.vi_helper.get_parent_datacenter_moref(ds_ref_obj)

                inventory_moref = None
                inventory_type = None
                if dc_mo_id:
                    inventory_moref = dc_mo_id
                    inventory_type = "Datacenter"

                vm_name = src_vmx_path.split(" ")[1].split("/")[0] + "_registered_VM_" + rmv_utils.get_curr_date_time()
                LOG.info("VM name for adding to inventory : %s" % vm_name)

                register_task_details = None
                try:
                    register_task_details = self.vi_helper.register_vm(src_vmx_path, inventory_moref, inventory_type,
                                                                       vm_name, False, vm_resPool_ref,
                                                                       host_mo_ref._moId)
                    is_vm_registered = True
                    LOG.info("Completed register VM task")
                except Exception as e:
                    LOG.exception(e)
                    if hasattr(e, "msg"):
                        LOG.error(('%s'), e.msg)
                        LOG.exception("Exception: %s", str(e.msg))
                        msg = "Exception in Register VM Task : ", e
                        raise exception.RegisterVmException(msg)

                # Now get all the snapshots in the vm, remove the RMCV_INTERNAL_SNAPSHOT by keeping consolidate false
                # Now remove all snaphots and consolidate to the parent disk
                # to get all the snapshots , use mob and rootSnapshot property
                # After consolidate , unregister the VM

                registered_vm_moref = None
                if register_task_details:
                    task_result = register_task_details.result
                    registered_vm_moref = task_result.value

                vm_moref = vim.get_moref(registered_vm_moref, "VirtualMachine")
                snap_prop = self.vi_helper.GetObjectProperties(vm_moref, "snapshot")
                if snap_prop and hasattr(snap_prop.objects[0], "propSet"):
                    snap_conf_obj_list = vim_util.extract_properties(snap_prop.objects[0])
                    snapTree = snap_conf_obj_list['snapshot'].rootSnapshotList[0]
                    snap_to_delete = self.vi_helper.traverse_and_get_rmcv_internal_snap(snapTree,
                                                                                        vi_objects.VmfsSnapshotName)
                    snap_ref_list_to_del.append(snap_to_delete)
                    if snap_ref_list_to_del:
                        LOG.info("Deleting the __RMC_V_INTERNAL_SNAP__ snapshot")
                        del_task = self.vi_helper.DeleteVmfsSnapshot(snap_ref_list_to_del, False, False)

                    # remove all snapshots and consolidate the disks
                    LOG.info("Remove all the VMWare vmfs snapshots and consolidate")
                    rem_task = self.vi_helper.DeleteAllVmfsSnapshot_consolidate(vm_moref, True)

                # Unregister the VM
                LOG.info("Unregister the VM from inventory")
                try:
                    delVM_task = self.vi_helper.unregister_vm(vm_moref)
                    is_vm_registered = False
                except Exception as e:
                    LOG.exception("Exception: %s", e)
                    if hasattr(e, "msg"):
                        LOG.error(('%s'), e.msg)
                        msg = "Exception in Unregister VM Task : ", e
                        raise exception.UnregisterVMException(msg)

                LOG.info("pre_copyvmdk_checks : Exit")
                return tar_path

        except Exception as e:
            LOG.exception("caught exception in pre Copy vmdk : %s" % e)
            msg = "Exception in copyvmdk:'%s'" % e
            # un register the vm if its registered previously and got exception in b/w
            if is_vm_registered and vm_moref:
                self.vi_helper.unregister_vm(vm_moref)
            raise exception.CopyVMDKFileException(msg)

    def validate_vmdk_before_copy(self, copyvmdk_input, target_vmdk_path, source_ds_name,
                                  target_ds_name, folderName):

        vm_power_state = None
        if copyvmdk_input['overwriteTargetFile']:
            if source_ds_name.startswith('snap-') and len(source_ds_name) >= 14:
                parentDSName = source_ds_name[rmv_utils.PRIMARY_DS_INDEX:]
                if parentDSName == target_ds_name:
                    if folderName.rfind('/') == -1:
                        vm_name = folderName[folderName.find(']') + 1:].lstrip()
                    else:
                        vm_name = folderName[folderName.find(']') + 1: folderName.rfind('/')].lstrip()
                    # TODO:6.0 Check if GUI can send the VM moref also. May not reqire to do this i think. Check.
                    moref = self.vi_helper.get_vm_ref_from_name(vm_name)
                    vm_power_state, vm_name = self.vi_helper.get_vm_power_state(moref)

        if vm_power_state == 'poweredOn':
            LOG.error(
                "The virtual disk '%s' to be overwritten is currently in use with the VM '%s' which is powered on. "
                "Power off the VM and retry the operation" % (target_vmdk_path, vm_name))
            msg = "The virtual disk '" + target_vmdk_path + "' to be overwritten is currently in use with the VM '" + vm_name + "' which is powered on. " \
                                                                                                                                "Power off the VM and retry the copy operation"
            raise rmv_exception.CopyVMDKFileException(msg)

    def copyvmdk_snapshot(self, context, clone_id, x_auth_token, copyvmdk_input, task_id):
        LOG.info("copyvmdk_snapshot : enter")

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        exception_lock_copyvmdk = False

        object_type = rmv_utils.TASK_OBJECT_TYPE
        mo_ref = rmv_utils.TASK_MO_REF
        vm_task_helper = VmTaskHelper(self.vi_helper)

        try:
            msg = 'Begin Snapshot VMDK Copy Operation'
            self.vi_helper.LogEvent(mo_ref, object_type, msg)
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 "SnapshotVMDKCopyTask",
                                                 "SnapshotVMDKCopyFailedFault")

            LOG.info("Locking Snapshot : '%s'" % clone_id)
            self._update_task('Waiting for snapshot lock', 5, 'Running',
                              task_id, rmc_wrapper_service,
                              vm_task_helper)

            # TODO:6.0 Lock logic needs to changed. And same should be used in all clone operations.
            lock_response = rmv_utils.acquire_snapshot_operation_lock(self.snapshot_id_dict, clone_id,
                                                                      self.vi_helper.validated_username)
            if lock_response:
                exception_lock_copyvmdk = True
                LOG.error("Could not acquire snapshot lock.")
                raise rmv_exception.SnapshotLockException(error=lock_response)

            LOG.info("Locked Snapshot : '%s'" % clone_id)
            LOG.info("Calling pre_copyvmdk_checks from copyvmdk_snapshot")

            # If there is a '//' in input for source file, this may result in intermitent issue.
            vmdk_path = copyvmdk_input.get('vmdkPath').replace('//', '/')

            source_vmdk_path = "[" + copyvmdk_input.get('sourceDSName') + "] " + vmdk_path
            target_vmdk_path = "[" + copyvmdk_input.get('targetDSName') + "] " + vmdk_path

            target_path = self.pre_copyvmdk_checks(context, clone_id, target_vmdk_path, copyvmdk_input, task_id)

            # Build the vmdk path to the consolidated path
            if target_path:
                target_vmdk_path = target_path
                tar_vmdk = target_path.split("] ", 1)
                src_file = source_vmdk_path
                indx = src_file.find(']')
                ds = src_file[:indx + 1]
                flat_src_path = ds + " " + tar_vmdk[1]
                source_vmdk_path = flat_src_path

            # source_vmdk_path = source_vmdk_path.replace('//','/')

            source_ds_name = copyvmdk_input.get("sourceDSName")
            LOG.debug("VMDK Source Datastore Name: %s", source_ds_name)

            target_ds_name = copyvmdk_input.get("targetDSName")
            LOG.debug("VMDK Copy Target Datastore Name: %s", target_ds_name)

            source_ds_ref = copyvmdk_input.get("sourceDSId")
            source_ds_moref = vim.get_moref(source_ds_ref, "Datastore")

            target_ds_ref = copyvmdk_input.get("targetDSId")
            target_ds_moref = vim.get_moref(target_ds_ref, "Datastore")

            self.validate_target_ds_size_for_copy(target_ds_ref,
                                                  target_ds_name,
                                                  source_ds_ref,
                                                  source_ds_name,
                                                  source_vmdk_path)

            LOG.info("Fetch the datacenters corresponding to the source and target datastores")

            if source_ds_moref:
                source_datacenter_moref = self.vi_helper.get_parent_datacenter(source_ds_moref)
                if not source_datacenter_moref:
                    LOG.error("Unable to obtain Datacenter Moref from Source datastore moref [%s]", source_ds_moref)
                    msg = "Unable to get Datacenter Information from VCenter"
                    raise rmv_exception.CopyVMDKFileException(msg)
            else:
                LOG.error("Unable to get Source Datastore Object from Source Datastore [%s]. "
                          "Source VMDK Path given is %s", source_ds_name, source_vmdk_path)
                msg = "Unable to fetch Source Datastore Information from ESXi host"
                raise rmv_exception.CopyVMDKFileException(msg)

            if target_ds_moref:
                target_datacenter_moref = self.vi_helper.get_parent_datacenter(target_ds_moref)
                if not target_datacenter_moref:
                    LOG.error("Unable to obtain Datacenter Moref from Target datastore moref [%s]", target_ds_moref)
                    msg = "Unable to get Datacenter Information from VCenter"
                    raise rmv_exception.CopyVMDKFileException(msg)
            else:
                LOG.error("Unable to get Target Datastore Object from Target Datastore [%s]. "
                          "Target VMDK Path given is %s", target_ds_moref, target_vmdk_path)
                msg = "Unable to fetch Target Datastore Information from ESXi host"
                raise rmv_exception.CopyVMDKFileException(msg)

            # Progress status
            task_status = "Ok"
            self._update_task('Copy vmdk task started', 10, 'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # craete folder if not available
            folder_name = rmv_utils.get_target_folder_name(target_vmdk_path)

            self.validate_vmdk_before_copy(copyvmdk_input, target_vmdk_path, source_ds_name,
                                           target_ds_name, folder_name)

            LOG.info("Trying to create folder '%s'", folder_name)
            # Now create the target directory
            if folder_name:
                self.vi_helper.make_folder(folder_name, target_datacenter_moref)
            else:
                # We are copying to the root folder, no need to create target directory
                LOG.info("We are copying to the root folder, no need to create target directory")

            self._update_task('Target folder is created', 20, 'Running',
                              task_id, rmc_wrapper_service,
                              vm_task_helper, task_status="Initiated")  # vm_task_helper)

            # strip source and target file so we can use it to copy
            # -flat.vmdk file too.
            srcfile_without_extension = source_vmdk_path.replace(".vmdk", "")
            tgtfile_without_extension = target_vmdk_path.replace(".vmdk", "")
            LOG.info("Trying to acquire snapshot lock")

            # First copy the vmdk metadata file
            LOG.info("Started copying vmdk metadata file.")
            self._update_task('Started copying vmdk metadata file. Please check '
                              'Vcenter task manager for detailed task status.',
                              20, 'Running', task_id, rmc_wrapper_service,
                              vm_task_helper, task_status="Initiated")

            task_info = self.vi_helper.copy_vmdk_file(source_vmdk_path,
                                                      target_vmdk_path,
                                                      source_datacenter_moref,
                                                      target_datacenter_moref,
                                                      copyvmdk_input['overwriteTargetFile'])
            if task_info.state == 'success':
                LOG.info("Finished copying vmdk metadata file")
                self._update_task('Finished copying vmdk metadata file',
                                  25, 'Running', task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status="Initiated")
            else:
                task_status = "Error"
                error_info = str(task_info.error.localizedMessage)
                self._update_task(error_info,
                                  100,
                                  'Error',
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper,
                                  task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(error_info)

                vm_task_helper.CustomVMwareTaskEnd("error", error_info)
                LOG.error("Error copying vmdk metadata file : '%s'", error_info)

                return

            # Now copy the data file
            LOG.info("Started copying vmdk data file.")
            task_status = "Initiated"
            self._update_task('Started copying vmdk data file. Please check Vcenter '
                              'task manager for detailed task status.',
                              40,
                              'Running', task_id, rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            task_info = self.vi_helper.copy_vmdk_file(srcfile_without_extension + "-flat.vmdk",
                                                      tgtfile_without_extension + "-flat.vmdk",
                                                      source_datacenter_moref,
                                                      target_datacenter_moref,
                                                      copyvmdk_input['overwriteTargetFile'])

            if task_info.state == 'success':
                LOG.info("Finished copying vmdk data file")
                self._update_task('Finished copying vmdk data file',
                                  40,
                                  'Running', task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
            else:
                error_info = str(task_info.error.localizedMessage)
                task_status = "Error"
                self._update_task(error_info,
                                  100,
                                  'Error',
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper,
                                  task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(error_info)

                vm_task_helper.CustomVMwareTaskEnd("error", error_info)
                LOG.error("Error copying vmdk data file : '%s'",
                          error_info)
                return
            LOG.info("copy vmdk files completed successfully for snapshot: '%s'", clone_id)
            self._update_task('copy vmdk files completed successfully',
                              100, 'Completed', task_id,
                              rmc_wrapper_service, vm_task_helper, task_status="Ok")

            vm_task_helper.CustomVMwareTaskEnd("success", 'VMDK File Copy completed successfully')

        except Exception as e:
            LOG.exception("caught exception in Copy vmdk: %s", e)
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal Error"
            task_status = "Error"
            self._update_task(
                msg,
                100, 'Error', task_id, rmc_wrapper_service,
                vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(msg)

            vm_task_helper.CustomVMwareTaskEnd("error", msg)

        finally:

            if not exception_lock_copyvmdk:
                # Release the aquired snapshot lock
                rmv_utils.release_snapshot_operation_lock(self.snapshot_id_dict, clone_id)
                LOG.info(("Released Lock for snapshot '%s'") % clone_id)

        LOG.info("manager copyvmdk_snapshot :Exit")
        return

    def get_vmware_object_name_from_vc(self, context, type, moref):
        try:
            ref = pyvmomi_util.get_moref(moref, type)
            res = self.vi_helper.get_object_properties(ref, 'name')
            prop_dict = pyvmomi_util.extract_properties(res[0])
            name = prop_dict.get('name')
        except Exception:
            LOG.exception("Couldn't find any value")
            name = None

        return name

    def delete_snapshot(self, context, snapshot_id, vmware_object_type, object_ref_id, x_authtoken, task_id):
        LOG.info("delete_snapshot - Enter")
        response_data = None
        vmware_object_name = None
        volume_type = None
        rmv_vmware_object = None
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_authtoken)
            object_type = 'Folder'
            mo_ref = "group-d1"
            vm_task_helper = VmTaskHelper(self.vi_helper)

            # with self.lock:
            exception_lock_delete = False
            notification_kwargs = {}
            try:
                self.snapshot_op_in_progress = True
                if not snapshot_id in self.snaps_in_operation_dict:
                    self.snaps_in_operation_dict[snapshot_id] = "busy"

                LOG.info("Locking Snapshot : '%s'" % snapshot_id)

                rmv_snapshot_resp = self.db.get_rmcv_copy_by_id(context, snapshot_id)
                rmc_snapshotset_id = rmv_snapshot_resp.rmc_copyset_id
                copy_type = rmv_snapshot_resp.type
                snapstatus = rmv_snapshot_resp.status
                vvol_vm_snap = rmv_snapshot_resp.vmfs_snap_moref
                if vmware_object_type == rmv_utils.OBJECT_TYPE_RC or vmware_object_type == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                    vmware_object_type = rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP

                    rmv_vmware_object = self.db_utils.get_vmware_object_by_object_type_and_moref(context,
                                                                                                 vmware_object_type,
                                                                                                 object_ref_id,
                                                                                                 copy_id=snapshot_id)
                else:
                    rmv_vmware_object = self.db_utils.get_vmware_object_by_object_type_and_moref(context,
                                                                                                 vmware_object_type,
                                                                                                 object_ref_id)
                if rmv_vmware_object:
                    vmware_object_name = rmv_vmware_object.name
                    volume_type = None if (
                                vmware_object_type == rmv_utils.OBJECT_TYPE_RC or vmware_object_type == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP) else rmv_vmware_object.volume_type

                if vmware_object_type and (vmware_object_type.strip() ==
                                           "VirtualMachine" or
                                           vmware_object_type.strip() == "Datastore"):

                    try:
                        moref_obj = pyvmomi_util.get_moref(object_ref_id, vmware_object_type)

                        obj_content = self.vi_helper.get_object_properties(
                            moref_obj, "name")
                        if obj_content:
                            object_type = vmware_object_type
                            mo_ref = object_ref_id
                    except Exception as e:
                        LOG.exception(e)

                vm_task_helper.CustomVMwareTaskBegin(
                    object_type,
                    mo_ref,
                    "DeleteVirtualCopyTask",
                    "DeleteVirtualCopyFailedFault")

                if volume_type is None:
                    volume_type = rmv_utils.VMFS_DISK_TYPE

                lock_response = rmv_utils.acquire_snapshot_operation_lock(self.snapshot_id_dict, snapshot_id,
                                                                          self.vi_helper.validated_username)
                if lock_response:
                    exception_lock_delete = True
                    LOG.error("Could not acquire snapshot lock.")

                    LOG.info("Snapshot operation is in progress:%s",
                             self.snaps_in_operation_dict[snapshot_id])
                    task_state = 'Failed'
                    task_desc_string = "Other snapshot operation is in progress"
                    task_status = "Error"
                    task_percentage = 100

                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error",
                                                       task_desc_string)

                    raise rmv_exception.SnapshotLockException(error=lock_response)

                LOG.info("Locked Snapshot : '%s'" % snapshot_id)

                try:
                    response_data = rmc_wrapper_service.array_refresh(context, rmc_snapshotset_id, "snapshot-sets",
                                                                      task_id)
                    if response_data:
                        rmc_wrapper_service.rmc_low_level.wait_on_task(response_data)
                except Exception as exc:
                    if hasattr(exc, "message"):
                        LOG.error(('%s'), exc.message)
                    else:
                        LOG.error("Caught Exception in snapshot refresh - %s", exc)

                # snapstatus = snapshotsets_resp['snapshotSet']['status']  # need to check will get it from rmcv db

                if (volume_type == rmv_utils.VVOL_DISK_TYPE):
                    if ((snapstatus == 'available') or (snapstatus == 'error') or
                            (snapstatus == 'error_restoring') or (snapstatus == 'error_extending')):
                        snap_id_to_del = rmv_snapshot_resp.vmfs_snap_moref
                        snap = []
                        # delete vmfs snapshot now
                        LOG.debug(_("Deleting vmware internal snapshot"))
                        # Check if the snapshot exists in vCenter.
                        snap_obj_exists = self.vi_helper.check_if_managed_object_exists(str(snap_id_to_del),
                                                                                        "VirtualMachineSnapshot")
                        if snap_obj_exists:
                            obj_ref = pyvmomi_util.get_moref(str(snap_id_to_del), "VirtualMachineSnapshot")
                            Object_content = self.vi_helper.get_object_properties(
                                obj_ref, "config.hardware")
                            snapshot_object = Object_content[0].obj
                            snap.append(snapshot_object)
                            self.vi_helper.Delete_vmfs_snapshot(snap, False)
                        else:
                            LOG.info(
                                "VVOL VMware internal snapshot has already been deleted. Marking the snapshot in the db as deleted")
                    else:
                        msg = (_("Snapshot in "'"%s"'" state cannot be deleted") % snapstatus)
                        raise rmv_exception.TaskError(error=msg)
                # Validating if snapshot is mounted anyway delete will
                # fail from RMC. error message will get as snapshot is
                # attached
                if rmc_snapshotset_id:
                    snapshotsets_resp = rmc_wrapper_service.get_snapshot(rmc_snapshotset_id)
                    snapshotSet = snapshotsets_resp.get('snapshotSet', None)
                    # Bug 129069: in case of vvol vm snap no need to check snapshot attach status in core
                    if snapshotSet and not vvol_vm_snap:
                        attachStatus = snapshotSet.get('attachStatus', None)
                        if attachStatus == "attached" and snapstatus != 'error':
                            msg = "Snapshot is mounted. Please unmount it before " \
                                  "deleting."
                            raise rmv_exception.TaskError(error=msg)

                    response_data = rmc_wrapper_service.delete_snapshot(rmc_snapshotset_id, task_id=task_id)
                # delete snapshot from rmcv db
                self.db.delete_rmcv_copy_by_id(context, snapshot_id)
                # checking for remote appliances registered if registered delete the snapshot from remote appliance as well
                if (vmware_object_type == rmv_utils.OBJECT_TYPE_RC or rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP) \
                        and copy_type == rmv_utils.copy_type.REMOTE_SNAPSHOT:
                    try:
                        remote_appliance_configured = False
                        remote_appliane_resp = rmc_wrapper_service.get_all_appliance_details()
                        remoteAppliances = remote_appliane_resp.get("remoteAppliances")
                        for remote_appliance in remoteAppliances:
                            if remote_appliance['remoteEnabled'] is True:
                                remote_appliance_configured = True
                                break
                        if remote_appliance_configured:
                            rmc_wrapper_service.delete_copies_from_remote_appliance_db_using_rmc(task_id,
                                                                                                 rmc_snapshotset_id)

                    except Exception as e:
                        LOG.exception(e)

                LOG.info("delete snapshot response in manager %s", response_data)

            except (Exception, rmv_exception.RMCAPIError, rmv_exception.TaskError) as e:
                LOG.exception(e)
                task_percentage = 100
                task_state = 'Failed'
                # task_desc_string = "".join(e) if e else None
                if hasattr(e, "msg"):
                    task_desc_string = e.msg
                else:
                    task_desc_string = "Unknown error"
                task_status = "Error"
                self._update_task(
                    task_desc_string,
                    task_percentage,
                    task_state,
                    task_id,
                    rmc_wrapper_service,
                    vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                # if snapshot_id in self.snaps_in_operation_dict:
                #     if self.snaps_in_operation_dict[snapshot_id] == "delete":
                #         del self.snaps_in_operation_dict[snapshot_id]
                return

            finally:
                if not exception_lock_delete:
                    if snapshot_id in self.snaps_in_operation_dict:
                        LOG.info(("Deleting snapshot_id : '%s' from snaps_in_operation_dict") % snapshot_id)
                        del self.snaps_in_operation_dict[snapshot_id]

                    self.snapshot_op_in_progress = False

                    # Release the aquired snapshot lock
                    rmv_utils.release_snapshot_operation_lock(self.snapshot_id_dict, snapshot_id)
                    LOG.info(("Released Lock for snapshot '%s'") % snapshot_id)

            # task_status = response_data['task']['taskState']
            if rmc_snapshotset_id and not response_data:
                # error_detail = response_data['task']['taskErrors']['errorDetails']
                task_desc_string = 'Error deleting snapshot.'
                task_status = "Error"
                task_percentage = 100
                task_state = 'Failed'
                self._update_task(
                    task_desc_string,
                    task_percentage,
                    task_state,
                    task_id,
                    rmc_wrapper_service,
                    vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                return

            # task_status = response_data['task']['taskState']
            if response_data and response_data['task']['taskState'] == "Error":
                # error_detail = response_data['task']['taskErrors']['errorDetails']
                errors = response_data['task']['taskErrors']
                error = errors[0]
                task_desc_string = error['errorDetails']
                task_status = "Error"
                task_percentage = 100
                task_state = 'Failed'
                self._update_task(
                    task_desc_string,
                    task_percentage,
                    task_state,
                    task_id,
                    rmc_wrapper_service,
                    vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

                # Update Tasks (Task Tracker and VMware Task)
            task_desc_string = 'Snapshot deleted successfully.'
            task_status = "Ok"
            task_percentage = 100
            task_state = 'Completed'
            self._update_task(
                task_desc_string,
                task_percentage,
                task_state,
                task_id,
                rmc_wrapper_service,
                vm_task_helper, task_status=task_status)
            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

            LOG.info("delete_snapshot - Exit")
            return

        finally:
            nu.SnapshotNotification(context, task_id, rmc_wrapper_service, rmv_vmware_object,
                                    rmv_snapshot_resp.id, vmware_object_type, "deleteSnapshot").start()
            return

    def promote_rmv_snapshot(self, context, copy_id, x_auth_token, task_id, force_restore, objectType, moref,
                             volume_type, recovery_set_id, ds_moref_list_to_restore):
        """
        Decides to create whether VMFS of VVOL snapshot

        :param snapshot_id: Rmv snapshot guid
        :param x_auth_token: Authentication token
        :param task_id: RMC task id

        """
        LOG.debug(_("promote_rmv_snapshot : Enter"))
        rmc_wrapper_service = None
        vm_task_helper = None
        task_percentage = 5
        notification_kwargs = {}
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            vm_task_helper = VmTaskHelper(self.vi_helper)
            # # Check if MoRef got changed during SRM Failover/Failback. If yes then update its ClientData.
            # changed_client_data = self.check_and_update_moref_in_snap_cd(context,
            #                                        x_auth_token=x_auth_token,
            #                                        dict_client_data=snapshot_client_data,
            #                                        snap_gui_id=snapshot_id)
            # if changed_client_data:
            #     snapshot_client_data = changed_client_data

            task_state = 'Running'
            task_desc_string = "Initiating restore from snapshot operation."
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            copy_info = None
            try:
                rmcv_copy_info = self.db_base.db.get_rmcv_copy_by_id(context, copy_id)
                snapshot_id = rmcv_copy_info.rmc_copyset_id
                # update copy status to restoring
                rmcv_copy_info.status = rmv_utils.copy_states.RESTORING
                self.db.update_rmcv_copy(context, copy_id, rmcv_copy_info)

            except Exception as e:
                msg = "Unable to retrieve copy details"
                raise Exception(msg)

            if volume_type == 'vvol':
                self.promote_vvol_snapshot(context,
                                           snapshot_id,
                                           x_auth_token,
                                           task_id,
                                           vm_task_helper,
                                           rmcv_copy_info, objectType, moref, recovery_set_id)
            else:
                copy_info = self.db.get_rmcv_ds_with_base_wwn_by_copy_id(context, copy_id)
                self.promote_snapshot(context, snapshot_id, x_auth_token, task_id, force_restore, copy_info,
                                      objectType, moref, copy_id, ds_moref_list_to_restore)
        except Exception as e:
            LOG.exception("Exception while restoring from snapshot:%s", e)
            msg = (_("Exception while restoring from snapshot"))
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            if hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                msg = e.message
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(msg,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(msg)

            vm_task_helper.CustomVMwareTaskEnd("error", msg)
            self.vi_helper.LogEvent(moref, objectType, msg)
            return

        finally:
            self.update_copy_status(context, x_auth_token, copy_id)
            rmv_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, objectType, moref)
            if rmv_obj:
                nu.SnapshotNotification(context, task_id, rmc_wrapper_service, rmv_obj,
                                        rmcv_copy_info.id, objectType, "restoreSnapshot").start()
            else:
                LOG.error('RMV object not found, Email notification aborted.')

        LOG.debug(_("promote_rmv_snapshot : Exit"))
        return

    def promote_vvol_snapshot(self, context, snapshot_id, x_auth_token, task_id, vm_task_helper, rmcv_copy_info,
                              objectType, moref, recovery_set_id):
        """
        Promoting the snapshot of the VVOL type VM

        :param snapshot_id: rmv snapshot guid
        :param x_auth_token: Authentication token
        :param task_id: RMC task id
        :param vm_task_helper: vmware task object
        :param snapshot_client_data: client data of rmv snapshot
        """

        LOG.debug(_("promote_vvol_snapshot : Enter"))

        rmc_wrapper_service = None
        task_percentage = 40
        obj_type = objectType
        mo_ref = moref
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            LOG.debug(_("Restoring the VM from the snapshot."))
            snap_id_to_promote = rmcv_copy_info.vmfs_snap_moref
            snap_obj = []
            # obj_ref = vim.get_moref(str(snap_id_to_promote[0][1]),str(snap_id_to_promote[1][1]))
            snapshot_type = "VirtualMachineSnapshot"
            obj_ref = vim.get_moref(snap_id_to_promote, snapshot_type)
            snap_obj.append(obj_ref)

            obj_exists = self.check_if_object_exists(mo_ref, obj_type)
            if obj_exists:
                type_for_vcenter_logevent = obj_type
                type_for_vcenter_log = obj_type
                mo_ref_for_vcenter_logevent = mo_ref
            else:
                LOG.info("The parent object has either been removed or deleted, so proceeding with folder level task")
                # These 2 values are used for vCenter Events and Tasks logging
                type_for_vcenter_logevent = "Folder"
                type_for_vcenter_log = "Folder"
                mo_ref_for_vcenter_logevent = "group-d1"

            # Create a VMware Task
            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_logevent,
                                                 mo_ref_for_vcenter_logevent,
                                                 "RestoreDatastoreVvTask",
                                                 "RestoreDatastoreVvFailedFault")

            task_desc_string = "Restoring the VM from the snapshot."
            task_status = "Initiated"
            task_state = 'Running'
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            # error out if VM is power on
            vm_power_state, vm_name = self.vi_helper.get_vm_power_state(moref)
            if vm_power_state == "poweredOn":
                task_state = 'Failed'
                task_desc_string = "Please power off the VM and then try again"
                task_status = "Error"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

                # Commenting below LogEvent call, as the same event is logged using PostEvent
                # self.vi_helper.LogEvent(mo_ref, obj_type, task_desc_string)
                msg = (_("Restore cannot be performed on a powered on VM, power off the VM and try again."))
                raise Exception(msg)
            response_data = rmc_wrapper_service.array_refresh(context, snapshot_id, "snapshot-sets", task_id)
            if response_data:
                response_data = \
                    rmc_wrapper_service.rmc_low_level.wait_on_task(response_data)
            # putting recoverysets and snap in restoring-snapshot status
            res = rmc_wrapper_service.update_recovery_set_status(recovery_set_id, updateStatus=True,
                                                                 state='restoring', status='restoring-snapshot')
            LOG.debug("response in func" + str(res))

            rmc_wrapper_service.update_snapshot_status(snapshot_id, updateStatus=True,
                                                       state='restoring', status='restoring-snapshot')

            # Calling the VM API to restore
            vc_response = self.vi_helper.RevertSnapshot(snap_obj)

            # Tracking the vCenter task to complete
            completed_task_status = self.vi_helper.WaitForvCenterTaskComplete(vc_response)
            if completed_task_status.state != "success":
                msg = (_("Error in getting vCenter task update"))
                raise Exception(msg)
            elif completed_task_status.state == "success":
                task_state = 'Completed'
                task_desc_string = "Snapshot restored successfully"
                task_status = "Ok"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

            msg = "Restore from snapshot '%s' completed" % vm_name
            LOG.info(msg)
            vm_task_helper.CustomVMwareTaskEnd("success", msg)
            self.vi_helper.LogEvent(mo_ref, obj_type, msg)

        except Exception as e:
            msg = (_("Exception while restoring the VM from snapshot"))
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            elif hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                msg = e.message
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(msg,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            LOG.error(_(msg))

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(msg)

            vm_task_helper.CustomVMwareTaskEnd("error", msg)

            # Commenting below LogEvent call, as the same event is logged using PostEvent
            # self.vi_helper.LogEvent(mo_ref, obj_type, msg)
        finally:
            if recovery_set_id:
                # putting recoverysets and snap back in available status
                res = rmc_wrapper_service.update_recovery_set_status(recovery_set_id, updateStatus=True,
                                                                     state='available', status='available')
                LOG.debug("response in finally" + str(res))
            rmc_wrapper_service.update_snapshot_status(snapshot_id, updateStatus=True,
                                                       state='available', status='available')

        LOG.debug(_("promote_vvol_snapshot : Exit"))
        return

    def promote_snapshot(self, context, snapshot_id, x_auth_token, task_id, force_restore, copy_info, obj_type, mo_ref,
                         copy_id, ds_moref_list_to_restore):
        """Method to restore Snapshot"""
        LOG.info("Enter restore_snapshot")
        LOG.info(("snapshot_id: %s"), snapshot_id)

        try:
            '''
            Step # 1 : Initializing, Constructing required objects
            '''
            ds_info = None
            task_state = None
            task_status = None
            task_desc_string = None
            vcenter_task_result = None
            msg_event = None
            base_volume_list = list()
            ro_volume_list = list()
            ds_moref_list = list()
            exception_lock_promote = False
            exception_object_lock_promote = False
            # These 2 values are used for vCenter Events and Tasks logging
            type_for_vcenter_log = "Folder"
            mo_ref_for_vcenter_log = "group-d1"
            locked_ds_moref_list = list()
            snap_recovery_set_id = ""
            register_vm_failed_count = 0
            unregister_vm_failed_count = 0

            # Create an instance of RMC Wrapper, to make any RMC or TaskTracker calls
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            # Create an instance of VMware Task Helper to populate vCenter Tasks
            vm_task_helper = VmTaskHelper(self.vi_helper)
            restoreOutput = {}
            attachOutput = {}
            ds_moref_wwn_dict = {}
            response_data = rmc_wrapper_service.get_snapshot(snapshot_id)
            snapshot_details = response_data['snapshotSet']
            # snapshot_client_data = jsonutils.loads(snapshot_details['clientData'])
            try:

                '''Step # 2 : get snapshot from rmc and create vCenter task '''

                if copy_info:
                    for copy_row in copy_info:
                        # restore to parent on copy level
                        if not ds_moref_list_to_restore:
                            if copy_row.moref not in ds_moref_list:
                                ds_moref_list.append(copy_row.moref)

                                wwn_details_list = jsonutils.loads(copy_row.wwn_details)
                                ds_moref_wwn_dict[copy_row.moref] = rmv_utils.extract_wwn_list(wwn_details_list)
                        # restore to parent on ds level
                        else:
                            if copy_row.moref not in ds_moref_list and copy_row.moref in ds_moref_list_to_restore:
                                ds_moref_list.append(copy_row.moref)
                                wwn_details_list = jsonutils.loads(copy_row.wwn_details)
                                ds_moref_wwn_dict[copy_row.moref] = rmv_utils.extract_wwn_list(wwn_details_list)
                # Get snapshot clientdata

                # for VirtualCopy in snapshot_client_data['VirtualCopyList']:
                #     base_volume_list.append(VirtualCopy.get("InServBaseVolume"))
                #     ro_volume_list.append(VirtualCopy.get("InServROVolume"))
                if obj_type == rmv_utils.VMWARE_OBJECT_TYPE_REMOTECOPY or obj_type == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                    vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log, mo_ref_for_vcenter_log,
                                                         "RestoreDatastoreVvTask", "RestoreDatastoreVvFailedFault")
                    # Identify belonging datastores in remote copy group  from client data
                    # obj_type = snapshot_client_data['VmWareObjectType']
                    # vvPairList = snapshot_client_data['vvPairList']
                    # ds_moref_list = rmv_utils.extract_datastores_moref_from_client_data(vvPairList)
                # Full restore triggered from VM, which is part of Protection Group
                elif obj_type == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                    if self.check_if_managed_object_exists(context, mo_ref, obj_type):
                        vm_task_helper.CustomVMwareTaskBegin(obj_type, mo_ref, "RestoreDatastoreVvTask",
                                                             "RestoreDatastoreVvFailedFault")
                    else:
                        vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log, mo_ref_for_vcenter_log,
                                                             "RestoreDatastoreVvTask", "RestoreDatastoreVvFailedFault")

                else:
                    ds_access_state = self.check_datastore_accessible_state(mo_ref, obj_type)
                    # Create a VMware Task
                    if ds_access_state:
                        vm_task_helper.CustomVMwareTaskBegin(obj_type, mo_ref, "RestoreDatastoreVvTask",
                                                             "RestoreDatastoreVvFailedFault")
                        # ds_moref_list.append(mo_ref)
                    else:
                        vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log, mo_ref_for_vcenter_log,
                                                             "RestoreDatastoreVvTask", "RestoreDatastoreVvFailedFault")
                # ds_moref_wwn_dict = {}
                # ds_moref_wwn_dict[mo_ref] = copy_info.base_vol_wwn_list
                if mo_ref in self.promote_ds_moref_dict:
                    msg = "Restore operation on datastore '" + str(
                        mo_ref) + "' is already in progess as part of remotecopy group restore."
                    LOG.info(msg)
                    raise rmv_exception.RestoreAlreadyInProgess(msg)

                ds_moref_list = list(set(ds_moref_list))

                for moref in ds_moref_list:
                    lock_response = rmv_utils.acquire_object_operation_lock(self.promote_ds_moref_dict, moref,
                                                                            self.vi_helper.validated_username)
                    if lock_response:
                        LOG.error("Could not acquire object lock.")
                        exception_object_lock_promote = True
                        raise rmv_exception.SnapshotLockException(error=lock_response)
                    else:
                        locked_ds_moref_list.append(moref)

                '''
                Step # 3 : Let's refresh and get Snapshot Record
                (using RMC APIs)
                '''

                resource = "snapshot-sets"
                self.refresh_snapshot_or_recovery_set(context, rmc_wrapper_service, snapshot_id, resource, task_id)
                # If snapshot id is not present then an exception is raise and will be caught in exception of try except.
                response_data = rmc_wrapper_service.get_snapshot(snapshot_id)
                snapshotSet = response_data.get("snapshotSet", None)
                if snapshotSet and snapshotSet.get("status") != "available":
                    raise rmv_exception.SnapshotInbadState()

                snap_recovery_set_id = snapshotSet.get("recoverySetId", "")
                LOG.info("Locking Snapshot : '%s'" % snapshot_id)
                lock_response = rmv_utils.acquire_snapshot_operation_lock(self.snapshot_id_dict, snapshot_id,
                                                                          self.vi_helper.validated_username)
                if lock_response:
                    LOG.error("Could not acquire snapshot lock.")
                    exception_lock_promote = True
                    raise rmv_exception.SnapshotLockException(error=lock_response)

                self.snapshot_op_in_progress = True

                if not snapshot_id in self.snaps_in_operation_dict:
                    self.snaps_in_operation_dict[snapshot_id] = "Busy"

                LOG.info("Locked Snapshot : '%s'" % snapshot_id)

                # Fetch volume information from snapshot-set
                # TODO:6.0 Test remove commented code after testing
                # for VirtualCopy in snapshot_client_data['VirtualCopyList']:
                #     base_volume_list.append(VirtualCopy.get("InServBaseVolume"))
                #     ro_volume_list.append(VirtualCopy.get("InServROVolume"))
                snap_volumes = snapshot_details.get('volumes')
                for vol in snap_volumes:
                    ro_volume_list.append(vol.get('name'))
                    base_volume_list.append(vol.get('copyOfVolumeName'))

                # Log an event in vCenter
                LOG.info("Restorevv " + str(base_volume_list) + " " + str(ro_volume_list) + ". Begins")
                msg = "Restoring snapshot(s) onto base volume(s) begins"
                self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)

                # validate requested copy recovery set wwn's with requested object wwn's
                obj_recovery_set_wwn = list()
                snap_recovery_set_wwn = None
                snap_recovery_set = rmc_wrapper_service.get_recovery_set(snap_recovery_set_id)
                recovery_set = snap_recovery_set.get("recoverySet", {})
                snap_recovery_set_wwn = recovery_set.get("wwnlist", None)

                for moref in ds_moref_list:
                    scsi_luns = []
                    ds_info = self.vi_helper.get_datastore_details(moref, scsi_luns)
                    for lun in scsi_luns:
                        obj_recovery_set_wwn.append(lun.Wwn)

                # if obj_type == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                #     if ds_moref_list_to_restore:
                #         for moref in ds_moref_list_to_restore:
                #             scsi_luns = []
                #             ds_info = self.vi_helper.get_datastore_details(moref, scsi_luns)
                #             obj_recovery_set_wwn = list()
                #             for lun in scsi_luns:
                #                 obj_recovery_set_wwn.append(lun.Wwn)
                #     elif mo_ref:
                #         scsi_luns = []
                #         ds_info = self.vi_helper.get_datastore_details(mo_ref, scsi_luns)
                #         obj_recovery_set_wwn = list()
                #         for lun in scsi_luns:
                #             obj_recovery_set_wwn.append(lun.Wwn)
                if snap_recovery_set_wwn and obj_recovery_set_wwn:
                    if ((set(snap_recovery_set_wwn) != set(obj_recovery_set_wwn) and not ds_moref_list_to_restore) or
                            not set(snap_recovery_set_wwn).issuperset(set(obj_recovery_set_wwn))):
                        msg = "Could not perform restore. Mismatch detected in volume(s) between the copy and the " \
                              "Datastore. This could be because 1) New volumes have been added or existing volumes " \
                              "have been removed from the Datastore 2) The snapshot was performed at a different " \
                              "resource or a resource group (Folder or Datastore or  VM). Restore is not allowed in " \
                              "these cases, however, the Datastore or VMs can be recovered by performing Mount/Clone."
                        raise rmv_exception.RestoreNotallowed(msg=msg)

                # get vm assoc with vm details by copy id
                vm_assoc_details = self.db.get_vm_assoc_with_vm_and_ds_details_by_copy_id(context, copy_id)
                db_ds_to_vm_dict = rmv_utils.extract_ds_to_vm_mapping(context, vm_assoc_details)
                if ds_moref_list_to_restore:
                    ds_to_vm_dict = {}
                    for ds_moref in ds_moref_list_to_restore:
                        ds_to_vm_dict[ds_moref] = db_ds_to_vm_dict.get(ds_moref)

                    db_ds_to_vm_dict = ds_to_vm_dict
                # preparing for restore
                mounted_host_list, ds_uuid_to_moref_dict = \
                    self.pre_restore(context, ds_moref_list, mo_ref, snap_recovery_set_id, rmc_wrapper_service,
                                     vm_task_helper, ds_info, task_id, ds_moref_wwn_dict, db_ds_to_vm_dict)
                try:
                    wwn_list = []
                    msg = "Initiating restore from snapshot Storage System operation"
                    LOG.info(msg)
                    if ds_moref_list_to_restore:
                        for ds_moref in ds_moref_list_to_restore:
                            wwn_list.extend(ds_moref_wwn_dict.get(ds_moref))
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                    # Use RMC to restore snapshot. Catch exception in case of error during restore snapshot operation
                    response = rmc_wrapper_service.restore_snapshot(snapshot_id, force_restore, task_id, wwn_list)
                    msg = "Restore from snapshot operation completed"
                    LOG.info(msg)
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                except rmv_exception.TaskError as e:
                    LOG.exception(e)
                    # "TaskError" exception would contain the failure reason, populated by RMC
                    if ro_volume_list and base_volume_list:
                        msg = "Restore snapshot <" + str(ro_volume_list) + "> to <" + str(
                            base_volume_list) + "> failed. Error: " + str(e)
                    else:
                        msg = "Restore snapshot failed. Error:"
                    LOG.error(msg)
                    # we should not triger event on datastore as the base volume is already unexported for restore purpose
                    # so vcenter will throw an error object not found
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                    restoreOutput['status'] = 'Error'
                    restoreOutput['msg'] = e.msg
                except rmv_exception.Warning as e:
                    LOG.exception(e)
                    restoreOutput['status'] = 'Warning'
                    restoreOutput['msg'] = e.msg
                except Exception as e:
                    if ro_volume_list and base_volume_list:
                        msg = "Restore snapshot <" + str(ro_volume_list) + "> to <" + str(
                            base_volume_list) + "> failed. Error: " + str(e)
                    else:
                        msg = "Restore snapshot failed. Error:"
                    LOG.exception(msg)
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                    restoreOutput['status'] = 'Error'
                    restoreOutput['msg'] = e.msg
                try:
                    self.post_restore(context, snap_recovery_set_id, mounted_host_list, ds_uuid_to_moref_dict, task_id,
                                      rmc_wrapper_service, vm_task_helper, base_volume_list, ds_moref_list)
                    msg = "Restore snapshot: " + str(base_volume_list) + ". Base volume attached back"
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                    register_vm_failed_count, unregister_vm_failed_count = self.post_restore_verify_and_register_unregistered_vms(
                        context, x_auth_token,
                        task_id, rmc_wrapper_service, vm_task_helper, copy_id, ds_moref_list)
                except Exception as e:
                    msg = "Failure while attaching back the volumes to the host: '%s'" % e
                    LOG.exception(msg)
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)

                    task_desc_string = "HPE Array snapshot restore failed: " + msg
                    task_state = 'Failed'
                    vcenter_task_result = 'error'
                    msg_event = "Restore snapshot: " + str(base_volume_list) + " " + str(ro_volume_list) + ". Failed"
                    attachOutput['status'] = 'Error'
                    attachOutput['msg'] = msg

                else:
                    task_desc_string = "HPE Array snapshot restore Completed successfully"
                    attachOutput['status'] = 'Completed'
                    attachOutput['msg'] = task_desc_string
                    task_state = 'Completed'
                    vcenter_task_result = 'success'
                    msg_event = "Restore snapshot: " + str(base_volume_list) + " " + str(ro_volume_list) + ". Success"
            except (rmv_exception.VirtualCopySystemBusy,
                    rmv_exception.SnapshotNotFound,
                    rmv_exception.VIMPropertyNotFoundError,
                    rmv_exception.VMNotPoweredOffError,
                    rmv_exception.UnknownVMwareObjectError,
                    rmv_exception.DatastoreUnusableError,
                    rmv_exception.DatastoreUnsupportedTypeError,
                    rmv_exception.DatastoreSpannedError,
                    rmv_exception.DatastoreNon3parError,
                    rmv_exception.DatastoreMoreThanOneIn3parVolumeError,
                    rmv_exception.RMCAPIError,
                    rmv_exception.RMCAPIUnknownError,
                    rmv_exception.vCenterMoRefError,
                    rmv_exception.SnapshotLockException,
                    rmv_exception.PyVmomiException,
                    rmv_exception.SnapshotInbadState,
                    rmv_exception.OneOrMoreVMSNotPoweredOffError,
                    rmv_exception.RestoreAlreadyInProgess,
                    rmv_exception.DatastoresWwnMissmatch,
                    rmv_exception.RestoreNotallowed,
                    rmv_exception.VmMovedToDifferentDatastore
                    ) as e:
                LOG.exception(("Exception in HPE Array snapshot restore : '%s'"), e)
                task_desc_string = "HPE Array snapshot restore failed: "
                if hasattr(e, "msg"):
                    task_desc_string = task_desc_string + str(e.msg)
                task_state = 'Failed'
                vcenter_task_result = 'error'
                msg_event = "Restorevv " + str(base_volume_list) + " " + str(ro_volume_list) + ". Failed. " + e.msg
                restoreOutput['status'] = task_state
                restoreOutput['msg'] = task_desc_string

            except Exception as e:
                LOG.exception(("Exception: '%s'"), e)
                task_desc_string = "HPE Array snapshot restore failed: Internal Error"
                task_state = 'Failed'
                vcenter_task_result = 'error'
                msg_event = "Restorevv " + str(base_volume_list) + " " + str(ro_volume_list) + ". Failed"
                restoreOutput['status'] = task_state
                restoreOutput['msg'] = task_desc_string

            finally:
                self.update_copy_status(context, x_auth_token, copy_id)
                if not exception_lock_promote:
                    if snapshot_id in self.snaps_in_operation_dict:
                        LOG.info(("Deleting snapshot_id : '%s' from snaps_in_operation_dict") % snapshot_id)
                        del self.snaps_in_operation_dict[snapshot_id]

                    self.snapshot_op_in_progress = False

                    # Release the aquired snapshot lock
                    rmv_utils.release_snapshot_operation_lock(self.snapshot_id_dict, snapshot_id)
                    LOG.info(("Released Lock for snapshot '%s'") % snapshot_id)

                if locked_ds_moref_list:
                    # Release the acquired object level lock
                    for moref in locked_ds_moref_list:
                        rmv_utils.release_object_operation_lock(self.promote_ds_moref_dict, moref)
                        LOG.info(("Released Lock for ds_obj '%s'") % moref)

                task_state = restoreOutput.get('status', 'Completed')
                attach_status = attachOutput.get('status', 'Completed')
                LOG.info("restoreOutput: " + str(restoreOutput) + " and attach data: " + str(attachOutput))
                task_status = "Ok"
                if task_state == 'Error' or task_state == 'Failed':
                    task_desc_string = restoreOutput.get('msg', 'Unknown RMC error')
                    vcenter_task_result = 'error'
                    msg_event = task_desc_string
                    task_status = 'Error'
                elif task_state == 'Completed' and attach_status == 'Error':
                    vcenter_task_result = 'success'
                    task_desc_string = 'Snapshot restore completed successfully but it fails attaching ' \
                                       'snapshot back'
                    msg_event = task_desc_string
                    task_status = "Ok"
                elif task_state == 'Warning' and attach_status == 'Error':
                    vcenter_task_result = 'success'
                    task_desc_string = 'Snapshot restore completed successfully but could not start remotecopy group ' \
                                       'and it fails attaching snapshot back. Try starting the remotecopy group manually.'
                    msg_event = task_desc_string
                    task_status = "Ok"
                elif task_state == 'Warning':
                    vcenter_task_result = 'success'
                    task_desc_string = 'Snapshot restore completed successfully but could not start remotecopy group. ' \
                                       'Try starting the remotecopy group manually.'
                    msg_event = task_desc_string
                    task_status = "Ok"
                # updating the task_desc_string if register/unregister got failed
                if register_vm_failed_count > 0:
                    task_desc_string = task_desc_string + "Unable to Register vm(s) on restored Datastore. " \
                                                          "However you can register the vm(s) by login to vCenter."
                if unregister_vm_failed_count > 0:
                    task_desc_string = task_desc_string + "Unable to remove the inaccessible vm(s) from restored datastore. " \
                                                          "However you can unregister the vm(s) from inventory by login to vCenter."

                task_percentage = 100
                LOG.info(('%s'), task_desc_string)

                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd(vcenter_task_result, task_desc_string)

                # Commenting below LogEvent call, as the same event is logged using PostEvent
                # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg_event)


        except Exception as excep:
            LOG.exception("Unknown exception during restore_snapshot '%s'", excep)
        finally:
            pass

        LOG.info("Exit restore_snapshot")

    def post_restore_verify_and_register_unregistered_vms(self, context, x_auth_token, task_id, rmc_wrapper_service,
                                                          vm_task_helper, copy_id, ds_moref_list):
        """
            This function will clean up the datastore after restore
            1. Will remove inaccessible vms from the datastore after restore (The vms which are not available in copy and part of datastore)
            2. Will register the vms on datastore after restore (the vms which are part of copy and not available in datastore)
        """
        LOG.debug("post_restore_verify_and_register_unregistered_vms::Enter")

        vm_moref_list_from_copy = []
        vm_moref_list_from_ds = []
        ds_moref_to_name_dict = {}
        vm_register_failed_count = 0
        vm_unregister_failed_count = 0
        post_protection_filtered_multi_ds_vms = None
        try:
            # Below code gets vm moref list using vm_assoc entry. Keeping this code as is if needed
            # # get the recoverable items from rmcv copy
            # recoverable_items = self.get_vms_from_rmcv_copy_id(context, copy_id)
            # # iterate thru each recoverable item and get the vm morefs, if vm belongs to ds which is part of ds_moref_list
            # for item in recoverable_items:
            #     if item.get('objectRefID') in ds_moref_list:
            #         vmdks = item.get('vmdks')
            #         for vmdk in vmdks:
            #             vm_moref_list_from_copy.append(vmdk.get('vm_moref'))

            vm_moref_list_from_copy = self.get_vms_in_ds_assoc_using_rmcv_copy_id(context, copy_id)

            # get all the vms which are available from list of  datastores(ds_moref_list)
            for ds_moref in ds_moref_list:
                name = self.vi_helper.get_vmware_name('Datastore', ds_moref)
                ds_moref_to_name_dict[ds_moref] = name
                vm_list_in_ds = self.vi_helper.get_virtual_machine_in_datastore(ds_moref, name)
                for vm_obj in vm_list_in_ds:
                    vm_moref_list_from_ds.append(vm_obj.Moref)

            # find the vms which are part of this copy and not available in the datastore
            deleted_vms = list(set(vm_moref_list_from_copy) - set(vm_moref_list_from_ds))
            LOG.info("Deleted vms from the datastore after protecting thru RMC-V :%s" % deleted_vms)

            vms_inaccessible_list = self.get_inaccesible_vms_from_moref_list(vm_moref_list_from_copy)
            LOG.debug('vms_inaccessible_list - {0}'.format(vms_inaccessible_list))

            existing_vm_moref_details_dict = {}
            for vm_moref in vms_inaccessible_list:
                vm_mo = pyvmomi_util.get_moref(vm_moref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
                props = ["name", "config.uuid", "config.createDate"]
                try:
                    vm_properties = self.vi_helper.get_object_properties(vm_mo, props)
                    property_dict = pyvmomi_util.extract_properties(vm_properties[0])
                    vm_uuid = property_dict.get("config.uuid")
                    LOG.debug('vm uuid of current vm - {0}'.format(vm_uuid))
                    vm_create_date = property_dict.get("config.createDate")
                    existing_vm_moref_details_dict[vm_moref] = {'uuid': vm_uuid, 'create_date': vm_create_date}
                except Exception as e:
                    LOG.exception(e)

            # if deleted_vms is not None, then need to register those vms back after restore to parent
            if deleted_vms or vms_inaccessible_list:
                LOG.info(
                    "few vm's has been deleted from the datastore after protecting thru RMC, we will register back those vms")
                task_desc_string = 'Registering restored vm(s) on the datastore'
                task_status = "Initiated"
                task_percentage = 95
                task_state = 'Running'
                self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vmx_path_to_host_dict_from_ds = {}
                ESXi_to_dc_dict = {}
                ds_mo_list = []
                host_info = {}
                host_name = None

                # get the vmx files and hostname from datastore
                for ds_moref in ds_moref_to_name_dict:
                    ds_mo = pyvmomi_util.get_moref(ds_moref, "Datastore")
                    ds_mo_list.append(ds_mo)
                props = ["browser", "name", "host"]
                oc_list = self.vi_helper.get_object_properties(ds_mo_list, props)

                for oc_datastore in oc_list:
                    property_dict = pyvmomi_util.extract_properties(oc_datastore)
                    search_spec = vim_util.get_host_datastore_VMX_search_spec(self.vi_helper.client_factory)
                    mo_obj_browser = property_dict.get("browser")
                    mo_obj_browser = vim.get_moref(mo_obj_browser._moId, mo_obj_browser._wsdlName)
                    DatastoreName = "[" + property_dict.get('name') + "] "
                    host_moref = property_dict.get('host')[0].key if property_dict.get("host") else ""
                    if host_moref in host_info:
                        host_name = host_info.get(host_moref)
                    else:
                        host_prop_list = ["name"]
                        host_oc_list = self.vi_helper.get_object_properties(host_moref, host_prop_list)
                        host_name = pyvmomi_util.extract_properties(host_oc_list[0]).get('name')
                        host_info[host_moref] = host_name
                        dc_mo_id = self.vi_helper.get_parent_datacenter_moref(host_moref)
                        ESXi_to_dc_dict[host_name] = dc_mo_id

                    res = self.vi_helper.vmops_obj.search_datastore_sub_folders_task(mo_obj_browser, DatastoreName,
                                                                                     search_spec)
                    search_res_list = res.HostDatastoreBrowserSearchResults
                    for search_res in search_res_list:
                        if not rmv_utils.has_attribute(search_res, 'file'):
                            continue
                        for file in search_res.file:
                            vmx_path = search_res.folderPath + file.path
                            vmx_path_to_host_dict_from_ds[vmx_path] = host_name
                # get vmx path using vm_moref_list_from_ds
                vm_mo_obj_list = []
                vmx_path_list_from_vm = []
                vm_oc_list = []
                for vm_moref in vm_moref_list_from_ds:
                    vm_mo = pyvmomi_util.get_moref(vm_moref, "VirtualMachine")
                    vm_mo_obj_list.append(vm_mo)
                prop_list = ["config"]
                if vm_mo_obj_list:
                    vm_oc_list = self.vi_helper.get_object_properties(vm_mo_obj_list, prop_list)
                if vm_oc_list:
                    for vm_oc in vm_oc_list:
                        try:
                            prop_dict = pyvmomi_util.extract_properties(vm_oc)
                            vmx_path = prop_dict.get('config').files.vmPathName if prop_dict.get("config") else ""
                            if vmx_path:
                                vmx_path_list_from_vm.append(vmx_path)
                        except Exception as e:
                            LOG.exception(e)

                removed_vms_vmx_list = list(
                    set(list(vmx_path_to_host_dict_from_ds.keys())) - set(vmx_path_list_from_vm))
                LOG.debug('removed_vms_vmx_list - {0}'.format(removed_vms_vmx_list))
                LOG.debug('vmx_path_to_host_dict_from_ds - {0}'.format(vmx_path_to_host_dict_from_ds))
                LOG.debug('vmx_path_list_from_vm - {0}'.format(vmx_path_list_from_vm))
                LOG.debug('vm_moref_list_from_ds - {0}'.format(vm_moref_list_from_ds))

                orig_to_cloned_vm_moref_dict = {}
                vm_db_id_to_moref_dict = {}
                orig_vm_name_moref_dict = {}

                # Unregister the vms which are inaccessible. We will register vm with same name again
                for vm in vms_inaccessible_list:
                    try:
                        inaccessible_vm_details = self.db_utils.get_vmware_object_by_object_type_and_moref(context,
                                                                                                           rmv_utils.VMWARE_OBJECT_TYPE_VM,
                                                                                                           vm)
                        vm_db_id_to_moref_dict[inaccessible_vm_details.id] = inaccessible_vm_details.moref
                        orig_vm_name_moref_dict[inaccessible_vm_details.name] = inaccessible_vm_details.moref
                        vm_obj = vim.get_moref(vm, rmv_utils.VMWARE_OBJECT_TYPE_VM)
                        self.vi_helper.unregister_vm(vm_obj)
                    except Exception as e:
                        vm_unregister_failed_count += 1
                        LOG.exception(e)

                vm_name_vmx_for_db_update_dict = self.get_recent_vmx_path_from_datastore(removed_vms_vmx_list)

                LOG.debug('vm_name_vmx_for_db_update_dict - {0}'.format(vm_name_vmx_for_db_update_dict))
                LOG.debug('orig_vm_name_moref_dict - {0}'.format(vm_name_vmx_for_db_update_dict))
                # need to register all the vmx in removed_vms_vmx_list
                for vmx in removed_vms_vmx_list:
                    registervm_obj = json_helper.register_vm()
                    registervm_obj.esxHostName = vmx_path_to_host_dict_from_ds.get(vmx)
                    registervm_obj.sourceDatastoreName = vmx.split('] ')[0].replace('[', '')
                    registervm_obj.inventoryMoref = ESXi_to_dc_dict.get(vmx_path_to_host_dict_from_ds.get(vmx))
                    registervm_obj.resourcePoolMoref = None
                    registervm_obj.vmxFilePath = vmx.split("] ")[1]
                    registervm_obj.objectId = None
                    registervm_obj.redirectIODatastoreName = None
                    registervm_obj.asTemplate = False
                    registervm_obj.inventoryType = "Datacenter"
                    registervm_obj.powerOnVM = True
                    timestamp_in_local_time = rmv_utils.get_current_date_time()

                    vm_name = vmx.split("/")[-1].split('.')[0]
                    vm_name = rmv_utils.get_vm_name_from_cloned_vm_name(vm_name)
                    # if the vm name exists in the existing registered vm and if it is inaccessible then assign vm name for registering
                    if vm_name in orig_vm_name_moref_dict.keys() and orig_vm_name_moref_dict[
                        vm_name] in vms_inaccessible_list:
                        cloned_vm_name = vm_name
                    else:
                        cloned_vm_name = vm_name + "_" + timestamp_in_local_time

                    registervm_obj.vmName = cloned_vm_name

                    register_vm_task = self._create_task_recover(rmc_wrapper_service, 'Register', vm_name, task_id,
                                                                 'Registering the VM on the Datastore', copy_id,
                                                                 cloned_vm_name, "VirtualMachine")

                    try:
                        registered_vm_details = self.register_vm_operations(context, copy_id, x_auth_token,
                                                                            registervm_obj.__dict__, register_vm_task,
                                                                            None)
                        if registered_vm_details:
                            task_state = 'Running'
                            task_status = "Initiated"
                            task_desc_string = "VM -" + vm_name + "successfully registered."

                            # Get the uuid of the registered VM and then compare with the existing vm. If UUID are same,
                            # the moref of the registered VM is used for updating our database
                            vm_mo = pyvmomi_util.get_moref(registered_vm_details['vm_moref'],
                                                           rmv_utils.VMWARE_OBJECT_TYPE_VM)
                            props = ["config.uuid"]
                            vm_moref_orig_vm = None
                            try:
                                vm_properties = self.vi_helper.get_object_properties(vm_mo, props)
                                property_dict = pyvmomi_util.extract_properties(vm_properties[0])
                                vm_uuid_after_register = property_dict.get("config.uuid")
                                LOG.debug('vm uuid of the registered vm - {0}'.format(vm_uuid_after_register))
                                for vm_moref, vm_details in existing_vm_moref_details_dict.items():
                                    if vm_details['uuid'] == vm_uuid_after_register:
                                        vm_moref_orig_vm = vm_moref
                                        break
                            except Exception as e:
                                LOG.exception(e)

                            if vm_moref_orig_vm and registervm_obj.vmxFilePath == vm_name_vmx_for_db_update_dict[
                                vm_name]:
                                LOG.debug('vm moref of the inaccessible virtual machine - {0}'.format(vm_moref_orig_vm))
                                orig_to_cloned_vm_moref_dict[orig_vm_name_moref_dict.get(vm_name)] = \
                                registered_vm_details['vm_moref']

                    except Exception as e:
                        vm_register_failed_count += 1
                        LOG.exception(e)
                        task_state = 'Running'
                        task_status = "Initiated"
                        task_desc_string = "Registering the VM" + vm_name + " was unsuccessful"

                    task_percentage = 95
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      None, task_status=task_status)
                # Update new registered vm moref in our database
                for vm_db_id, orig_moref in vm_db_id_to_moref_dict.items():
                    updated_moref = {'moref': orig_to_cloned_vm_moref_dict[orig_moref]}
                    self.db.update_rmcv_virtual_machines(context, vm_db_id, updated_moref, read_deleted="no")
                self.update_resource_id_in_workflow_by_moref(rmc_wrapper_service, orig_to_cloned_vm_moref_dict)

            else:
                LOG.info("No deleted vm's found after restore to parent volume on copy '%s'" % copy_id)

            try:
                post_protection_added_vms = list(set(vm_moref_list_from_ds) - set(vm_moref_list_from_copy))
                LOG.info(
                    "Newly registered vms on the Datastore after protecting thru RMC-V:%s" % post_protection_added_vms)
                if post_protection_added_vms:
                    vms_with_multi_ds = []
                    for ds_moref in ds_moref_list:
                        vms_with_multi_ds_specific_ds_moref = self.get_multi_ds_vms_in_specified_ds(ds_moref)
                        vms_with_multi_ds.extend(vms_with_multi_ds_specific_ds_moref)
                    LOG.info("vms with multiple datastores :%s" % vms_with_multi_ds)
                    post_protection_filtered_multi_ds_vms = list(
                        set(post_protection_added_vms) - set(vms_with_multi_ds))
                    LOG.info(
                        "post protection vms after filtered mulit ds vms :%s" % post_protection_filtered_multi_ds_vms)

                if post_protection_filtered_multi_ds_vms:
                    inacessible_vm_list = self.get_inaccesible_vms_from_moref_list(
                        post_protection_filtered_multi_ds_vms)
                    LOG.info("Inaccessible vm list which will be unregistered is :%s" % inacessible_vm_list)
                    for vm in inacessible_vm_list:
                        try:
                            # self.vi_helper.delete_vm(vm)
                            vm_obj = vim.get_moref(vm, rmv_utils.VMWARE_OBJECT_TYPE_VM)
                            self.vi_helper.unregister_vm(vm_obj)
                        except Exception as e:
                            vm_unregister_failed_count += 1
                            LOG.exception(e)
            except Exception as e:
                LOG.exception(e)

        except Exception as e:
            LOG.exception(e)
        LOG.debug("post_restore_verify_and_register_unregistered_vms::Exit")
        return vm_register_failed_count, vm_unregister_failed_count

    def get_recent_vmx_path_from_datastore(self, vmx_list):
        """
        Get vmx file with highest timestamp. vm moref that vmx will be used for updating our database
        :param vmx_list - list of vmx files

        """
        LOG.debug('get_recent_vmx_path_from_datastore: Enter')
        vm_name_vmx_for_db_update_dict = {}
        for vmx in vmx_list:
            vmx_vm_name = vmx.split("/")[-1].split('.')[0]
            orig_vm_name = rmv_utils.get_vm_name_from_cloned_vm_name(vmx_vm_name)

            if vmx_vm_name == orig_vm_name:
                vm_name_vmx_for_db_update_dict[orig_vm_name] = vmx.split("] ")[1]
            elif vmx_vm_name.startswith("clone_") or vmx_vm_name.startswith("Clone_Of_"):
                vmx_time_stamp = int(vmx_vm_name.split("_")[-1])
                if orig_vm_name in vm_name_vmx_for_db_update_dict:
                    vm_name_as_in_dict = vm_name_vmx_for_db_update_dict[orig_vm_name].split("/")[-1].split('.')[0]
                    if vm_name_as_in_dict != orig_vm_name and "_" in vm_name_as_in_dict:
                        vmx_time_stamp_in_dict = int(vmx_vm_name.split("_")[-1])
                        # 14 here represents the length of timestamp returned by RMVUtils.get_current_date_time()
                        if len(str(vmx_time_stamp_in_dict)) != 14 and vmx_time_stamp > vmx_time_stamp_in_dict:
                            vm_name_vmx_for_db_update_dict[orig_vm_name] = vmx.split("] ")[1]
                else:
                    vm_name_vmx_for_db_update_dict[orig_vm_name] = vmx.split("] ")[1]
        LOG.debug('get_recent_vmx_path_from_datastore: Exit')
        return vm_name_vmx_for_db_update_dict

    def get_inaccesible_vms_from_moref_list(self, vm_moref_list):
        """

        :param vm_moref_list:
        :return:
        """
        LOG.debug('get_inaccesible_vms_from_moref_list: Enter')
        vms_inaccessbile_list = []
        if vm_moref_list and len(vm_moref_list) > 0:
            vm_moref_obj_list = []
            prop_list = ["name", "runtime"]
            for vm_moref in vm_moref_list:
                if self.check_if_object_exists_by_moref(vm_moref, rmv_utils.VMWARE_OBJECT_TYPE_VM) is True:
                    vm_moref_obj = pyvmomi_util.get_moref(vm_moref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
                    vm_moref_obj_list.append(vm_moref_obj)
            vm_oc_list = self.vi_helper.get_object_properties(vm_moref_obj_list, prop_list)
            if vm_oc_list:
                for vm_oc in vm_oc_list:
                    prop_dict = pyvmomi_util.extract_properties(vm_oc)
                    vm_moref_id = vm_oc.obj._moId
                    # TODO: relook if needed to check for any other state
                    if prop_dict['runtime'].connectionState.lower() != 'connected':
                        vms_inaccessbile_list.append(vm_moref_id)
        LOG.debug('get_inaccesible_vms_from_moref_list: Exit')
        return vms_inaccessbile_list

    def check_if_object_exists_by_moref(self, moref, obj_type):
        LOG.debug('check_if_vm_exists_by_moref: Enter')
        is_object_exists = False
        moref_obj = pyvmomi_util.get_moref(moref, obj_type)
        try:
            obj_content = self.vi_helper.get_object_properties(moref_obj, "name")
            if obj_content:
                is_object_exists = True
        except Exception as exc:
            LOG.exception(self.extract_msg_from_exception(exc))
            is_object_exists = False
        LOG.debug('check_if_vm_exists_by_moref: Exit')
        return is_object_exists

    def get_multi_ds_vms_in_specified_ds(self, ds_moref):
        """

        :param ds_moref:
        :return:
        """
        LOG.debug('get_multi_ds_vms_in_specified_ds: Enter')
        vm_in_ds_list = []
        ds_oc_list = None
        if ds_moref:
            prop_list = ["name", "vm"]
            ds_moref_obj = pyvmomi_util.get_moref(ds_moref, rmv_utils.VMWARE_OBJECT_TYPE_DS)
            ds_oc_list = self.vi_helper.get_object_properties([ds_moref_obj], prop_list)
        if ds_oc_list:
            for ds_oc in ds_oc_list:
                prop_dict = pyvmomi_util.extract_properties(ds_oc)
                ds_moref_id = ds_oc.obj._moId
                vm_in_ds_list.extend(prop_dict['vm'])

        vms_multiple_datatore = []
        if vm_in_ds_list and len(vm_in_ds_list) > 0:
            prop_list = ["name", "datastore"]
            vm_oc_list = self.vi_helper.get_object_properties(vm_in_ds_list, prop_list)
            if vm_oc_list:
                for vm_oc in vm_oc_list:
                    prop_dict = pyvmomi_util.extract_properties(vm_oc)
                    vm_moref_id = vm_oc.obj._moId
                    vm_name = prop_dict['name']
                    vm_ds_list = prop_dict['datastore']
                    if len(vm_ds_list) > 1:
                        vms_multiple_datatore.append(vm_moref_id)

        LOG.debug('get_multi_ds_vms_in_specified_ds: Exit')
        return vms_multiple_datatore

    def get_vms_from_rmcv_copy_id(self, context, copy_id):
        """This method will return the recoverable items from the RMC-V copy"""

        LOG.debug("get_vms_from_rmcv_copy_id::Enter")

        datastores_from_db = self.db.get_datastores_by_copy_id(context, copy_id)
        vms_from_db = self.db.get_vms_by_copy_id(context, copy_id)

        vm_id_obj_map = {}
        for row in vms_from_db:
            vm_id_obj_map[row.vm_id] = row

        datastores_list = []
        if datastores_from_db:
            for row in datastores_from_db:
                datastore_ret = self.transform_datastore_props(row)

                if row.vmdks:
                    vmdk_list = []
                    vmdks = json.loads(row.vmdks)
                    if vmdks:
                        for vmdk in vmdks:
                            vmdk_from_db = None
                            try:
                                vmdk_from_db = self.db.get_vmdk_by_id(context, vmdk['vmdk_id'])
                            except Exception as e:
                                msg = ("Failed to get rmcv VMDK from DB by ID:" + vmdk['vmdk_id'])
                                LOG.error(msg)
                                LOG.exception(e)

                            if vmdk_from_db:
                                # We should not list the RDM Disks in GUI
                                if vmdk_from_db.type != "rdm":
                                    vmdk_response = {'type': vmdk_from_db.type, 'fileName': vmdk_from_db.path,
                                                     'rdmType': vmdk_from_db.rdm_type, 'id': vmdk_from_db.id}

                                    if vmdk['vm_id'] and vm_id_obj_map.get(vmdk['vm_id']):
                                        vmdk_response['vm_id'] = vm_id_obj_map[vmdk['vm_id']].vm_id
                                        vmdk_response['vm_name'] = vm_id_obj_map[vmdk['vm_id']].vm_name
                                        vmdk_response['vm_moref'] = vm_id_obj_map[vmdk['vm_id']].moref
                                    vmdk_list.append(vmdk_response)

                        datastore_ret['vmdks'] = vmdk_list
                datastores_list.append(datastore_ret)
        LOG.debug("get_vms_from_rmcv_copy_id::Exit")

        return datastores_list

    def get_vms_in_ds_assoc_using_rmcv_copy_id(self, context, copy_id):
        """This method will return the recoverable items from the RMC-V copy"""
        LOG.debug("get_vms_in_ds_assoc_using_rmcv_copy_id::Enter")
        vms_from_db = self.db.get_vms_id_in_ds_assoc_using_copy_id(context, copy_id)

        vm_moref_list_in_datastore_copy = []
        for row in vms_from_db:
            vm_id = row.vm_id.strip('"')
            vm_details = self.db.get_vm_by_vm_id(context, vm_id)
            if vm_details:
                vm_moref_list_in_datastore_copy.append(vm_details.moref)
        LOG.debug("get_vms_in_ds_assoc_using_rmcv_copy_id::Exit")
        return vm_moref_list_in_datastore_copy

    def get_attach_status_of_recovery_set(self, rmc_wrapper_service, recovery_set_id):
        """This method fetches the attach status of the given recovery set"""
        response = rmc_wrapper_service.get_recovery_set(recovery_set_id)
        list_volumes = response['recoverySet']['volumes']
        map_wwn_hostlist = dict()
        for volume in list_volumes:
            wwn = volume['wwn']
            hostlist = volume['attach']['hosts']
            status = volume['attach']['status']
            vol_name = volume['name']
            map_wwn_hostlist[wwn] = {'attached_hosts': hostlist,
                                     'attach_status': status,
                                     'volume_name': vol_name
                                     }
        return map_wwn_hostlist

    def validate_virtualmachines_for_promote(self, ds_mo_ref):
        vm_morefs = self.vi_helper.get_vm_morefs_used_by_datastore(ds_mo_ref)
        for vm_moref in vm_morefs:
            vm_power_state, vm_name = self.vi_helper.get_vm_power_state(vm_moref)
            if vm_power_state.lower() != "poweredOff".lower():
                raise rmv_exception.VMNotPoweredOffError(vm_name=vm_name)

    def get_recovery_set_based_on_mo_ref(self, context, mo_ref):
        """This method fetches the corresponding recovery-set-id of the given vmware mo-ref"""
        # Get the database record object based on mo_ref
        snapshot_db = self.db.get_record_based_on_mo_ref(context, mo_ref)
        # Read the recovery-set-id
        recovery_set_id = snapshot_db['recoverysetid']
        LOG.info(("recovery_set_id: %s"), recovery_set_id)
        return recovery_set_id

    def getArrayList_WC(self, context, client_id, x_auth_token):
        LOG.info("Enter getArrayList_WC  in manager layer %s", client_id)
        LOG.info(
            "BackupJobManager.web_client_cache.web_client_rmv_sessions_dict"
            "=%s",
            BackupJobManager.web_client_cache.web_client_rmv_sessions_dict)
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        ret = {}

        if BackupJobManager.web_client_cache.web_client_rmv_sessions_dict \
                .keys():
            LOG.info("web client session Found in dict :%s client_id:%s",
                     BackupJobManager.web_client_cache
                     .web_client_rmv_sessions_dict.keys(), client_id)
        else:
            LOG.info("web client  session Not Found in dict ")
            ret[
                'StatusCode'] = \
                json_helper.TpdVmPluginWebOperationStatusCode.UnexpectedFailure
            ret['StatusDescription'] = "The web client session " + \
                                       client_id + " was not found"
            return ret
        ret['StatusCode'] = json_helper.TpdVmPluginWebOperationStatusCode.Ready
        # TODO Dictionary<int, string> dictCabIdtoRMVServerPort =
        # Adapter.PrepareRMVHostDict(this.MyRmRepo)
        # passing dummy value now for remote copy object
        # myrmrepo={}
        # dictCabIdtoRMVServerPort = adapter.prepareRMVHostDict(myrmrepo)
        dictCabIdtoRMVServerPort = {}
        web_sess = \
            BackupJobManager.web_client_cache.web_client_rmv_sessions_dict \
                .values()[0]

        return_list = {}
        LOG.info("BackupJobManager.web_client_cache"
                 ".web_client_rmv_sessions_dict.keys()[0]:%s",
                 BackupJobManager.web_client_cache.web_client_rmv_sessions_dict \
                 .keys()[0])
        LOG.info("web_sess.web_service_dict=%s", web_sess.web_service_dict)

        if not web_sess:
            return {'webclient': {'return code': "0", 'description':
                " The web client session" + client_id +
                "was not found"}}

        serverInfoList = web_sess.user_session['userSession']['serverInfoList']
        vCenterId = None
        vCenterName = None
        for s in serverInfoList:
            vCenterId = s['ServerGuid']
            vCenterName = s['Name']

        ret['List'] = []
        ret['vCenterIdDictionary'] = []
        for ws in web_sess.web_service_dict:
            LOG.info("ws=%s", ws)
            # resList = self.getarraylist()  # Get Inserv details from cache
            rmc_storeservlist = \
                rmc_wrapper_service.get_storage_system_details()
            storserv_list = rmc_storeservlist['storageSystems']
            for storserv in storserv_list:
                if storserv['status'] == "error":
                    storage_system_id = storserv['id']
                    try:
                        resp = rmc_wrapper_service.refresh_storage_system(storserv[
                                                                              'id'])

                        registered_storage_pools = rmc_wrapper_service.get_storage_pools(storserv[
                                                                                             'id'])
                        pool_type = ['FC', 'ISCSI']
                        for protocol in pool_type:
                            pool_name = "RMC-V" + str(protocol) + str(storage_system_id)
                            LOG.info("pool_name:%s", pool_name)
                            try:
                                rmc_wrapper_service.create_storage_pool(
                                    pool_name, storage_system_id, protocol)
                            except Exception as e:
                                LOG.info("Got exception while creating storage pool")
                    except Exception as e:
                        LOG.error("storage system id is in error state:%s", storage_system_id)
                        LOG.error("Got Exception while refreshing "
                                  "storeserv:%s", str(e))

            rmc_storeservlist = \
                rmc_wrapper_service.get_storage_system_details()
            storserv_list = rmc_storeservlist['storageSystems']

            plugin_details_list = []
            lstStoreServs = storserv_list
            # LOG.info("Array list from cache:%s", resList.values())
            # We will retrieve all the Arrays which are registered in RMC
            # for s in resList.values():
            #     is_found = False
            #     for ss in storserv_list:
            #         LOG.info("from cache:%s from rmc:%s", s, ss)
            #         if s == ss["serialNumber"]:
            #             is_found = True
            #             lstStoreServs.append(ss)
            #     if not is_found:
            #         lstStoreServs.append({"serialNumber": s})
            for storserv in lstStoreServs:
                if storserv['status'] != "error":
                    copy = json_helper.VmPluginArrayWC(storserv)
                    bFound = False
                    for curr in ret['List']:
                        if curr['serialNumber'] == copy.serialNumber:
                            bFound = True
                            if not self.isNullOrEmpty(vCenterId):
                                if vCenterId in curr['vCenterIdDictionary']:
                                    curr['vCenterIdDictionary'].update(
                                        {vCenterId: vCenterName})
                                break
                    if not bFound:
                        # if dictCabIdtoRMVServerPort.has_key(
                        # adapter.convertHexCabIdToInt(copy.InServCabId)):
                        # rmvTargetHostAndPort = rmv_utils.get_value_from_dict(
                        # adapter.convertHexCabIdToInt(copy.InServCabId),
                        # dictCabIdtoRMVServerPort)
                        # if rmvTargetHostAndPort:
                        # copy.rmvTargetHostAndPort = rmvTargetHostAndPort
                        # copy.is_logged_in = True

                        if not self.isNullOrEmpty(vCenterId):
                            # copy['vCenterIdDictionary'][vCenterId] = vCenterName
                            copy.vCenterIdDictionary.update(
                                {vCenterId: vCenterName})
                            LOG.info("need to check")
                    copy = self.add_target_server_to_response(context, copy)
                    plugin_details_list.append(copy.__dict__)
                    ret['List'] = plugin_details_list

        # ret['List'] = plugin_details_list
        # ret['StatusCode'] =""

        return ret

    def isNullOrEmpty(self, value):
        if value is None or not value:
            return True

    # def getarraylist(self):
    #     LOG.info("Inside getarraylist")
    #     ret = self.getarraylistprivate(False)
    #     return ret

    # def getarraylistprivate(self, bIgnoreState):
    #     LOG.info("inside getarrayistprivate")
    #     CabIdParam = []
    #     lst = ""
    #     if not CabIdParam:
    #         for v in CabIdParam:
    #             operator.iconcat(lst, v + " ")
    #     cabId = None
    #     if CabIdParam is not None and len(CabIdParam) >= 1:
    #         cabId = CabIdParam[0].strip()
    #         LOG.info("CabId looking for is " + lst)
    #     else:
    #         LOG.info("No CabId given. All StoreServs will be returned")
    #     ret = {}  # var ret = new TpdVmPluginGetInServResult();
    #     array = {}
    #
    #     # if MyState != json_helper.TpdVmPluginWebServiceState.Ready:
    #     #    self.ProcessNotReadyState(ret)
    #     # TODO Mystate is not available now. change this once available
    #     MyState = True
    #     if not MyState:
    #         LOG.info("change tis condition later on")
    #     else:
    #         LOG.info("Waiting to acquire lock ...")
    #         with self.lock:
    #             LOG.info("Got the lock ...")
    #             ret[
    #                 "StatusCode"] = \
    #                 json_helper.TpdVmPluginWebOperationStatusCode.Ready
    #             ret["StatusDescription"] = ""
    #             LOG.info(
    #                 "BackupJobManager.web_client_cache.cached_vm_centers=%s",
    #                 BackupJobManager.web_client_cache.cached_vm_centers)
    #
    #             vcenter_obj = \
    #                 BackupJobManager.web_client_cache.cached_vm_centers
    #             if len(BackupJobManager.web_client_cache.cached_vm_centers.keys()) < 1:
    #                 raise rmv_exception.WebclientInialization()
    #             vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
    #             vmcenter_cache_instance = vcenter_obj.get(vcenter_ip)
    #             vm_vv_map = vmcenter_cache_instance.vm_vv_map
    #             LOG.info(
    #                 "cache.array_cab_id_list= %s",
    #                 vm_vv_map.array_cab_id_list)
    #
    #             if self.isNullOrEmpty(cabId):
    #                 if vm_vv_map is None or vm_vv_map.array_cab_id_list is \
    #                         None:
    #                     # if
    #                     # BackupJobManager.web_client_cache.cached_vm_centers.vm_vv_map
    #                     # == None or
    #                     # BackupJobManager.web_client_cache.cached_vm_centers.vm_vv_map.array_cab_id_list
    #                     # == None:
    #                     ret[
    #                         "StatusCode"] = \
    #                         json_helper.TpdVmPluginWebOperationStatusCode \
    #                         .VCConnectionFailure
    #                     msg = "No VvMap is available"
    #                     ret["StatusDescription"] = msg
    #                     return ret
    #                 else:
    #                     array_list = vm_vv_map.array_cab_id_list
    #                     return array_list
    """
                        i=0
                        for insEntity in  vm_vv_map.array_cab_id_list:
                            LOG.info("ListPrivate - key:%s , value",
                            insEntity ,insEntity)
                            LOG.info("Allocated new VmPluginInServ, checking
                            for containing key now.")
                            if CabIdToInServDict.has_key(insEntity.Key):
                                LOG.info("Adding logged in user to
                                structure...")
                                array["LoggedOnAs"] = CabIdToInServDict[
                                insEntity.Key].User
                                LOG.info("populate")
                                PopulateTpdVmPluginInServFromCache(array[i],
                                insEntity.Key)
                            else:
                                LOG.info("Enter " + insEntity + " is not
                                found. Returning NotLoggedToInServ")
                                array["LoggedOnAs"] = False
                                array[
                                "InServCacheState"]=json_helper.TpdVmPluginInServCacheState.NotLoggedToInServ
                            i=i+1
                            ret["array"]=array
                else:
                    if not CabIdToInServDict.has_key(cabId):
                        LOG.info("CabId " + cabId + " is not found in the
                        cache")
                        ret["StatusCode"] =
                        json_helper.TpdVmPluginWebOperationStatusCode
                        .ObjectNotFound
                        ret["StatusDescription"]="CabId " + cabId + " is not
                        found in the cache"
                    else:
                        array["LoggedOnAs"]=CabIdToInServDict[cabId].User
                        PopulateTpdVmPluginInServFromCache(ret.Array[0], cabId)
            LOG.info("Returning " + ret["StatusCode"] + "; " + ret[
            "StatusDescription"])
            return ret
    """
    """
    def create_backup(self, context, snapshot_id, x_auth_token, task_id, request_body):

        #:param snapshot_id: id of the snapshot for backup
        #:param x_auth_token: autho token required to communicate to RMC service
        #:param task_id: task id which needs to be updated
        #:param request_body: backup params
        #:return: taskid
        try:
            LOG.info(('In create_backup of manager '))
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            backup_policy_id =  request_body['backupPolicyId']
            response_data = rmc_wrapper_service.create_backup(snapshot_id, backup_policy_id)
            LOG.info(_("Create_backup_manager: The response_data is %s")%response_data)
            return response_data
        except (rmv_exception.RMCBackupPolicyError,
                    Exception
                    ) as e:
                if hasattr(e,"msg"):
                    LOG.info(('%s'), e.msg)
                    msg = e.msg
                else:
                    LOG.info(('%s'), e)
                    msg = "Internal error while creating backup"
    """

    def process_config_object(self, prop_dict):

        try:
            LOG.info("process_config_object : Enter")
            conf_dict = dict(prop_dict.values()[0])
            snap_config_dict = {}

            for ckeys in conf_dict:
                if ckeys == 'alternateGuestName' or ckeys == 'annotation' or ckeys == 'changeVersion' \
                        or ckeys == 'cpuHotAddEnabled' or ckeys == 'cpuHotRemoveEnabled' or ckeys == 'guestId' \
                        or ckeys == 'vAssertsEnabled' or ckeys == 'npivTemporaryDisabled' or ckeys == 'version' \
                        or ckeys == 'guestFullName' or ckeys == 'locationId' or ckeys == 'name' or ckeys == 'npivNodeWorldWideName' \
                        or ckeys == 'npivPortWorldWideName' or ckeys == 'npivWorldWideNameType' or ckeys == 'swapPlacement' \
                        or ckeys == 'template' or ckeys == 'uuid':
                    snap_config_dict[ckeys] = conf_dict[ckeys]

                elif ckeys == 'bootOptions' or ckeys == 'consolePreferences' or ckeys == 'cpuAffinity' \
                        or ckeys == 'cpuAllocation' or ckeys == 'defaultPowerOps' \
                        or ckeys == 'files' or ckeys == 'flags' or ckeys == 'memoryAffinity' \
                        or ckeys == 'memoryAllocation' or ckeys == 'tools':
                    snap_config_dict[ckeys] = vim_util.recursive_asdict(conf_dict[ckeys])

                elif ckeys == 'extraConfig':
                    exConf_list = []
                    exConf_dict = {}
                    exConf_list_dict = []
                    exConf_list = conf_dict[ckeys]
                    for ex in range(len(exConf_list)):
                        exConf_dict = vim_util.recursive_asdict(exConf_list[ex])
                        if ('ctkEnabled' in exConf_dict.get('key')):
                            LOG.info("Skipping config: " + str(exConf_dict))
                            continue
                        exConf_list_dict.append(exConf_dict)
                    snap_config_dict[ckeys] = exConf_list_dict

                elif ckeys == 'hardware':
                    h_dict = dict(conf_dict[ckeys])
                    for hkey in h_dict:
                        if hkey == 'memoryMB' or hkey == 'numCPU' or hkey == 'numCoresPerSocket' \
                                or hkey == 'virtualICH7MPresent' or hkey == 'virtualSMCPresent':
                            snap_config_dict[hkey] = h_dict[hkey]

            if 'hardware' in conf_dict:
                hw = conf_dict['hardware']['device']
                snap_config_dict['hardware'] = []
                device_dict = {}
                for dev in range(len(hw)):
                    device_dict = {}
                    device_dict[hw[dev].__class__.__name__] = vim_util.recursive_asdict(hw[dev])
                    snap_config_dict['hardware'].append(device_dict)

            LOG.info("process_config_object : Exit")
            return snap_config_dict

        except Exception as e:
            LOG.exception("Error while processing the config object:%s", e)
            msg = "Error while processing the config object"
            raise e(msg=msg)

    def get_snapshot_configuration_info(self, snapshotSetID, x_auth_token, task_id, vm_task_helper):

        #:param snapshotSetID: Snapshot set id for retrieving the client data from rmc db
        #:param x_auth_token: autho token required to communicate to RMC service
        #:param task_id: task id to keep track of the config infor fetch
        #:return: configuration information of the VM at the given instant. It ll retrieved via snapshot moref

        LOG.info(('get_snapshot_configuration_info: Enter'))

        snap_config_obj = None

        try:

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            LOG.debug(_('Retrieving details from RMC for snapshot : %s') % snapshotSetID)
            snapshot_details = rmc_wrapper_service.get_snapshot(snapshotSetID)

            if not snapshot_details:
                LOG.error(_('Could not get the snapshot information'))
                raise rmv_exception.InvalidSnapshot

            snapshot_clientData = snapshot_details['snapshotSet']['clientData']
            dict_client_data = jsonutils.loads(snapshot_clientData)
            LOG.debug(_('Fetching the moref from the snapshot client data'))
            snapshot_moref = dict_client_data['SnapshotMoref']

            # Extract the moref value and type from the snapshot_moref_list
            # snap = [str(snapshot_moref_list.pop(i).pop()) if i == 0 else
            # str(snapshot_moref_list.pop().pop()) for i in range(len(snapshot_moref_list))]
            # the list snap contains the value in snap[0] and type in snap[1] which is passed as params to get_moref()
            snap_moref_obj = vim.get_moref(snapshot_moref, "VirtualMachineSnapshot")
            LOG.debug(_('Retrieving the configuration information for the snapshot'))
            snap_config_info = self.vi_helper.GetObjectProperties(snap_moref_obj, "config")
            conf_prop_dict = vim_util.extract_properties(snap_config_info.objects[0])
            snap_config_obj = self.process_config_object(conf_prop_dict)

        except Exception as e:
            LOG.exception("Exception while retrieving snapshot details for backup: %s", e)

        LOG.info(('get_snapshot_configuration_info: Exit'))
        return snap_config_obj

    def get_vmfs_snapshot_config_info(self, ctxt, copy_set_id):

        LOG.debug("get_vmfs_snapshot_config_info : enter")

        snap_config_obj = None

        try:
            copy_obj = self.db.get_rmcv_copy_by_rmc_copyset_id(ctxt, copy_set_id)
            vmfs_snap_moref = copy_obj.vmfs_snap_moref

            if not vmfs_snap_moref:
                msg = "Unable to find the VMFS Snapshot reference ID for copy_set_id : '%s'" % copy_set_id
                LOG.error(msg)
                raise rmv_exception.VMFSSnapshotException(msg)

            LOG.info("Retrieving the config information for the snapshot : '%s'" % vmfs_snap_moref)
            snap_moref_obj = vim.get_moref(vmfs_snap_moref, "VirtualMachineSnapshot")
            snap_config_info = self.vi_helper.GetObjectProperties(snap_moref_obj, "config")
            conf_prop_dict = vim_util.extract_properties(snap_config_info.objects[0])
            snap_config_obj = self.process_config_object(conf_prop_dict)

        except Exception as e:
            LOG.exception(("Unable to retrieve VMFS Snapshot config details for "
                           "copy_set_id: %s. %s") % (copy_set_id, e))
            raise e

        LOG.debug("get_vmfs_snapshot_config_info : exit")
        return snap_config_obj

    def create_backup_new(self, context, snapshot_id, x_auth_token, task_id, request_body):

        #:param snapshot: snapshot for backup in rmv db
        #:param x_auth_token: autho token required to communicate to RMC service
        #:param task_id: task id to keep track of the entire backup tasks
        #:param request_body: backup params request_body
        #:return: taskid
        LOG.debug(_("create_backup_new snapshot_id: '%s'") % snapshot_id)
        LOG.debug(_("create_backup_new snapshot_id: '%s'") % request_body)
        # TODO: Need to revisit this on auth token validation.
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        task_percentage = 0
        notification_kwargs = {}
        backjob_response = None
        completed_percentage = 0
        task_progress_share = 0
        backup_policy_id = None
        vmLevelBackupFlag = False
        mountVolFlag = False
        vm_cbt_flag = False
        attachFlag = False
        hostAccessSpecifier = {}
        files = []
        pre_backup_dict = {}
        transportMode = None

        notification_kwargs['backupName'] = request_body.get('backupName', 'No Name')
        notification_kwargs['rmcvTaskId'] = task_id
        protectionPolicyId = request_body.get("protectionPolicyId", None)

        # Support for scheduler.
        # It does not come through web client session initialization.
        try:
            if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                LOG.info("vCenter not initialized. Let's do it")
                with self.lock:
                    self.vi_helper = ViHelper()

                    # DB could be empty
                    if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                        msg = "Please make sure vCenter is registered with RMC-V"
                        LOG.error(msg)
                        task_desc_string = "HPE RMC Express Backup creation failed: %s" % msg
                        task_status = "Error"
                        task_state = 'Failed'
                        task_percentage = 0

                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service, task_status=task_status)
                        return

        except Exception as e:
            LOG.exception("Exception: %s", e)
            msg = "vCenter session could not be initialized. Please make sure" \
                  " vCenter is registered with RMC-V and accessible"
            LOG.error(msg)
            task_desc_string = "HPE RMC Express Backup creation failed: %s" % msg
            task_state = 'Failed'
            task_status = "Error"
            task_percentage = 0

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service, task_status=task_status)
            return

        # Step1: Call the routine to create snapshot, with the task_id
        try:
            # Create the VMware task helper and populate vCenter Tasks
            vm_task_helper = VmTaskHelper(self.vi_helper)

            # Log an event in vCenter
            mo_ref = request_body['vmWareMoref']
            object_type = request_body['vmWareObjectType']
            backup_name = request_body['backupName']

            # Create a VMware Task
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 "CreateVMBackupTask",
                                                 "CreateVMBackupFailedFault")

            try:
                isBackupCreation = True
                # Based on the snap_ret_info we ll decide whether the backup is for the traditional VMFS or the VVol VM
                # snap_ret_info contains snapshot_set_id and vm type for VVol. In case of VMFS snapshot_set_id will be null
                snap_ret_info = self.create_rmv_snapshot(context, snapshot_id, x_auth_token, task_id, request_body,
                                                         isBackupCreation)
            except (rmv_exception.TaskError
            ) as e:
                err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
                task_desc_string = err_args_msg
                task_percentage = 10
                task_state = 'Failed'
                task_status = "Error"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                return

            except exception as e:
                # No need to update task here, as it already happened in create_snapshot method itself.
                LOG.exception(e)
                err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
                LOG.exception("Exception: %s", err_args_msg)
                task_desc_string = err_args_msg
                task_percentage = 10
                task_state = 'Failed'
                task_status = "Error"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                return

            snapshot_response = None
            # Get the snapshot creation status and if created extract the snapshot_id if not raise exception

            if snap_ret_info.get('nonVolume') is True:
                dummy_recovery_set_id = snap_ret_info['recoverySetId']
                recoverySetId = snap_ret_info['recoverySetId']
                LOG.info(_('dummy_recovery_set_id: %s') % dummy_recovery_set_id)
                snapshot_response = jsonutils.loads(snap_ret_info['snapInfo'])
                vmType = snapshot_response.get('VmType')
                if vmType in rmv_utils.DISK_TYPE.keys():
                    snapshot_response['VmType'] = rmv_utils.DISK_TYPE.get(vmType)
                    LOG.info("vm type was numeric, converted value: " + snapshot_response['VmType'])

            elif snap_ret_info['_type'] == json_helper.TpdVmHostFileSystemType.Vmfs or snap_ret_info[
                '_type'] == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                task_response = rmc_wrapper_service.get_snapshot_id(task_id)
                snapshot_config_obj = None
                snapshot_id_in_rmc = snap_ret_info['snapshotSetId']
                LOG.info(_('The snapshot id is %s') % snapshot_id_in_rmc)

                if (task_response['task']['taskState'] == 'Completed'):
                    # With the latest trcker changes, we dont need to assign parent task id now
                    # snapshot_id_in_rmc = task_response['task']['parentTaskId']
                    LOG.debug(_('create_backup_new: snapshot id is %s') % snapshot_id_in_rmc)
                    LOG.debug(_("create_backup_new: '%s'") % snapshot_id_in_rmc)
                elif (task_response['task']['taskState'] == 'Error' or task_response['task']['taskState'] == 'Failed'):
                    LOG.error(_('Could not create the snapshot for backup.'))
                    ### ERROR ERROR ERROR, We should not be coming here
                    # Update vcenter task status otherwise it will be in running state forever

                    task_desc_string = 'The snapshot creation is failed for backup.'
                    task_percentage = 20
                    task_status = "Error"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      "Error",
                                      task_id,
                                      None,
                                      vm_task_helper, task_status=task_status)
                    raise rmv_exception.RMCAPIError(rmc_api_error=task_desc_string)
            elif snap_ret_info['_type'] == json_helper.TpdVmHostFileSystemType.VVol:
                # update the snapshot_Set_id from snap_ret_info to the snapshot_id_in_rmc and fetch the config info
                if snap_ret_info['snapshotSetId']:
                    LOG.info(_('Get the configuration information of snapshot for backup of VVol VM'))
                    snapshot_id_in_rmc = snap_ret_info['snapshotSetId']
                    snapshot_config_obj = self.get_snapshot_configuration_info(snapshot_id_in_rmc, x_auth_token,
                                                                               task_id, vm_task_helper)
                    LOG.debug(_('Snapshot config obj retrieved is : %s') % snapshot_config_obj)
                else:
                    task_desc_string = 'The snapshot creation is failed for backup.'
                    task_status = "Ok"
                    task_percentage = 20
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      "Error",
                                      task_id,
                                      None,
                                      vm_task_helper, task_status=task_status)
                    raise rmv_exception.RMCAPIError(rmc_api_error=task_desc_string)

            LOG.info(("Object Type: %s"), object_type)
            LOG.info(("mo ref: %s"), mo_ref)
            LOG.info(("Backup name: %s"), backup_name)

            # Update Tasks (Task Tracker and VMware Task)
            task_desc_string = 'Snapshot Creation Complete, Preparing to initiate Backup'
            task_status = "Initiated"
            task_percentage = 20
            task_state = 'Running'
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            msg = 'BackupJob begins for snapshot '
            self.vi_helper.LogEvent(mo_ref, object_type, msg)

            # Call to initiate the backup at the RMC
            # backup-name
            if (request_body.has_key('backupName')):
                backup_name = request_body['backupName']
                if backup_name is None or len(backup_name) < 1:
                    backup_name = rmv_utils.get_object_name_by_time()
            else:
                backup_name = str(snapshot_id)

            # backup_policy_id
            if (request_body.has_key('backupPolicyId')):
                backup_policy_id = request_body['backupPolicyId']
            else:
                # backupPolicyId is an optional keyword if protectionPolicyId is given then no need to pass backupPolicyId
                if not protectionPolicyId:
                    raise exception.RMCBackupPolicyError()

            # backup_description
            if (request_body.has_key('backupDescription')):
                backup_description = request_body['backupDescription']
            else:
                backup_description = "backup of snapshot " + snapshot_id

            # Update Tasks (Task Tracker and VMware Task)
            task_desc_string = 'Initiating Backup'
            task_status = "Initiated"
            task_percentage = 20
            task_state = 'Running'
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            if snap_ret_info['nonVolume'] is False:
                # Do a get on the snapshot created and collect the client-data and pass it
                # as the app_metadata to RMC backup.
                # for 3PAR volume
                snap_response = rmc_wrapper_service.get_rmc_snapshot(snapshot_id_in_rmc, x_auth_token)
                # snap_response = response_data = rmc_wrapper_service.get_snapshot(snapshot_id)

                LOG.info(_('The snapshot response is %s') % snap_response)
                snapshot_response = jsonutils.loads(snap_response['snapshotSet']['clientData'])
                LOG.info(_('The snapshot created time is %s') % snap_response['snapshotSet']['createdAt'])
                recoverySetId = snap_response['snapshotSet']['recoverySetId']
                notification_kwargs['recoverySetId'] = recoverySetId
                if not backup_name:
                    timestamp_in_utc_time = snap_response['snapshotSet']['createdAt']
                    LOG.info("Snapshot timestamp: '%s'" % timestamp_in_utc_time)
                    timestamp_in_local_time = rmv_utils.convert_utc_to_local_format(timestamp_in_utc_time)
                    LOG.info("Snapshot timestamp converted to local time: '%s'" % timestamp_in_local_time)
                    backup_name = timestamp_in_local_time

            # Copy required metadata from snapshot to backup app_metadata
            # if 'clientData' in snap_response.keys():

            LOG.info(_('The snapshot_response -- 1 %s') % snapshot_response)
            app_metadata = {}
            temp = {}
            app_metadata['DatastoreMountPathDict'] = snapshot_response.get("DatastoreMountPathDict", {})
            app_metadata['CreatedVcUserName'] = snapshot_response['CreatedVcUserName']
            app_metadata['VirtualCenterInstanceId'] = snapshot_response['VirtualCenterInstanceId']
            app_metadata['VirtualCenterUrl'] = snapshot_response['VirtualCenterUrl']
            app_metadata['ObjectUUID'] = snapshot_response['ObjectUUID']
            app_metadata['ObjectRefID'] = snapshot_response['ObjectRefID']
            app_metadata['VmWareObjectType'] = snapshot_response['VmWareObjectType']
            app_metadata['VmWareObjectName'] = snapshot_response['VmWareObjectName']
            app_metadata['MoUuid'] = snapshot_response.get('MoUuid')
            app_metadata['IsAppConsistent'] = snapshot_response['IsAppConsistent']
            app_metadata['VirtualCopyList'] = snapshot_response['VirtualCopyList']
            app_metadata['Version'] = rmv_utils.RMCV_VERSION
            if snap_ret_info['nonVolume'] is False:
                app_metadata['snapshot_timestamp'] = snap_response['snapshotSet']['createdAt']
                notification_kwargs['vmwObjName'] = snap_response.get('VmWareObjectName')
                for VirtualCopyList in snapshot_response['VirtualCopyList']:
                    if VirtualCopyList:
                        app_metadata['Vendor'] = VirtualCopyList.get('Vendor',
                                                                     None)
                        break
            notification_kwargs['vmwObjType'] = snapshot_response.get('VmWareObjectType')
            # notification_kwargs['vmwObjName']=snap_response.get('VmWareObjectName', "")

            if snapshot_response.has_key('VmType'):
                LOG.info(_("Snapshot response has vmType with value : %s ") % (snapshot_response['VmType']))
                if snapshot_response['VmType'] == rmv_utils.VMFS_DISK_TYPE and snap_ret_info['nonVolume'] is False:
                    LOG.info(_("Updating the Vmtype"))
                    app_metadata['VmType'] = snapshot_response['VmType']
                    app_metadata['EsxHostToVmListDict'] = snapshot_response['EsxHostToVmListDict']
                    app_metadata['EsxHostToDatastoreListDict'] = snapshot_response['EsxHostToDatastoreListDict']
                    app_metadata['ArraySerialNum'] = snapshot_response['ArraySerialNum']
                    app_metadata['MountableEsxHostList'] = snapshot_response['MountableEsxHostList']
                    app_metadata['isERTEnabled'] = True
                    app_metadata['HasVmfsSnapshots'] = snapshot_response.get("HasVmfsSnapshots", False)

                elif snapshot_response['VmType'] == rmv_utils.VVOL_DISK_TYPE:
                    app_metadata['VmType'] = snapshot_response['VmType']

                else:
                    app_metadata['EsxHostToVmListDict'] = snapshot_response['EsxHostToVmListDict']
                    app_metadata['EsxHostToDatastoreListDict'] = snapshot_response['EsxHostToDatastoreListDict']
                    app_metadata['ArraySerialNum'] = snapshot_response['ArraySerialNum']
                    app_metadata['MountableEsxHostList'] = snapshot_response['MountableEsxHostList']
                    app_metadata['isERTEnabled'] = True
                    app_metadata['HasVmfsSnapshots'] = snapshot_response.get("HasVmfsSnapshots", False)

            elif snap_ret_info['_type'] == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                app_metadata['EsxHostToVmListDict'] = snapshot_response['EsxHostToVmListDict']
                app_metadata['EsxHostToDatastoreListDict'] = snapshot_response['EsxHostToDatastoreListDict']
                app_metadata['ArraySerialNum'] = snapshot_response['ArraySerialNum']
                app_metadata['MountableEsxHostList'] = snapshot_response['MountableEsxHostList']
                app_metadata['isERTEnabled'] = True
                app_metadata['HasVmfsSnapshots'] = snapshot_response.get("HasVmfsSnapshots", False)

            else:
                app_metadata['VmType'] = rmv_utils.VMFS_DISK_TYPE

            """
            Update app metadata for granular VM backup
            """
            vmLevelBackupFlag = snapshot_response.get('vmLevelBackup', False)
            if isBackupCreation and object_type == 'VirtualMachine' and snap_ret_info['_type'] is not \
                    json_helper.TpdVmHostFileSystemType.VVol:
                # Changes to get the changeID in case of the CBT enabled disk on VM
                """
                    1. Get the config object of snapshot update the app Metadata appropriately
                """
                snapshot_config_obj = snap_ret_info.get('snapConfigObj', None)
                LOG.info("*********** VM LEVEL BACKUP ************")
                LOG.debug("Config info of snap is : %s" % snapshot_config_obj)
                app_metadata['changeIdPerDisk'] = snapshot_response.get('changeIdPerDisk', None)
                app_metadata['vmdkPathList'] = snapshot_response.get('vmdkPathList', None)
                app_metadata['vmdkMapList'] = snapshot_response.get('vmdkMapList', None)
            app_metadata['vmLevelBackup'] = snapshot_response.get('vmLevelBackup', None)
            app_metadata['VmType'] = str(snapshot_response.get('VmType', None))
            transportMode = snapshot_response.get('transportMode', None)

            LOG.info(_('The app_metadata is %s ') % app_metadata)
            increment = False
            optimized = False
            if vmLevelBackupFlag:
                vmdkOperations = vmdkOps.VmdkOperations(context, x_auth_token, self.vi_helper, self)

                protectionPolicy_det = rmc_wrapper_service.get_protection_policy(protectionPolicyId)
                LOG.info("******* Protection Policy Details ******* : %s" % protectionPolicy_det)
                current_backup_policy_id = protectionPolicy_det['protectionPolicy']['backupPolicy']['backupPolicyId']
                backup_exists, pre_backup_details = self.check_if_vm_backup_exists(x_auth_token, recoverySetId)
                if pre_backup_details and len(pre_backup_details) > 0:
                    vmdkBackupTypeList = vmdkOperations.assign_backup_type_to_vDisk(pre_backup_details,
                                                                                    current_backup_policy_id)

                    app_metadata['vmdkBackupTypeMap'] = vmdkBackupTypeList

                # attach the backup, form the request body and then call backup.. Detach once backup is done
                if transportMode == "san:nbd":

                    if backup_policy_id:
                        bkp_policy_det = rmc_wrapper_service.get_backupId_from_policyId(context, backup_policy_id,
                                                                                        x_auth_token)
                    else:
                        if protectionPolicyId:
                            bkp_policy_det = rmc_wrapper_service.get_backupId_from_policyId(context,
                                                                                            current_backup_policy_id,
                                                                                            x_auth_token)

                    storageAccessProtocol = bkp_policy_det['backupPolicy'].get('transportType', None)

                    attach_response = rmc_wrapper_service.attachSnapshot_and_discovery(snapshot_id_in_rmc,
                                                                                       storageAccessProtocol,
                                                                                       task_id)
                    if attach_response == "Completed":
                        pre_backup_dict = vmdkOperations.build_fileBackupSet_request(mo_ref,
                                                                                     snapshot_response[
                                                                                         'SnapshotMoref'],
                                                                                     transportMode,
                                                                                     snapshot_response['vmUuid'],
                                                                                     app_metadata)

                    else:
                        task_desc_string = 'The snapshot attach failed for vm level backup.'
                        task_percentage = 25
                        task_status = "Error"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          "Error",
                                          task_id,
                                          None,
                                          vm_task_helper, task_status=task_status)
                        raise rmv_exception.RMCAPIError(rmc_api_error=task_desc_string)

                elif snap_ret_info['nonVolume'] is True:
                    pre_backup_dict = vmdkOperations.build_fileBackupSet_request(mo_ref,
                                                                                 snapshot_response['SnapshotMoref'],
                                                                                 transportMode,
                                                                                 snapshot_response['vmUuid'],
                                                                                 app_metadata)

                app_metadata['hostAccessSpecifier'] = pre_backup_dict.get('hostAccessSpecifier')
                app_metadata['files'] = pre_backup_dict.get('files')

                increment = pre_backup_dict.get('incremental', False)
                LOG.info("The incremental Flag..... : %s" % increment)
                optimized = pre_backup_dict.get('optimized', False)
                LOG.info("The optimized Flag..... : %s" % optimized)

                response_data = rmc_wrapper_service.create_vDisk_backup(recoverySetId, backup_policy_id,
                                                                        backup_description, backup_name,
                                                                        pre_backup_dict.get('hostAccessSpecifier'),
                                                                        pre_backup_dict.get('files'),
                                                                        app_metadata, increment,
                                                                        snapshot_config_obj, optimized,
                                                                        pre_backup_dict.get('parentBackupSetId'),
                                                                        protectionPolicyId=protectionPolicyId,
                                                                        task_id=task_id)
            else:
                """
                From RMC we support only two modes of backup,
                1. Auto mode performs a backup as efficiently as possible, optimising reads from array source and using previous backups as sources.
                2. Full backup mode performs a full backup by reading all the data from the source array with no optimisation or use of prior backups
                """
                LOG.info("Checking whether the backup is auto mode or full mode")

                if ('incremental' in request_body):
                    if request_body['incremental'] is False:
                        LOG.info("Full backup initiated")
                        increment = False
                        optimized = False
                    # If incremental is False then increment and optimized should be set to None
                    # so that incrimental backup is taken.
                    else:
                        LOG.info("incremental is True. Auto Backup Initiated")
                        increment = None
                        optimized = None
                else:
                    LOG.info("Auto Backup Initiated")
                    increment = None
                    optimized = None

                # Now call RMC to do the actual backup
                # app_metadata_text = dict(app_metadata)
                # LOG.info(_('The app_metadata_text is %s') % app_metadata_text)
                LOG.debug(_("create_backup_new snapshot_id_in_rmc  '%s'") % snapshot_id_in_rmc)
                response_data = rmc_wrapper_service.create_backup(snapshot_id_in_rmc, backup_policy_id,
                                                                  backup_description, backup_name, app_metadata,
                                                                  increment,
                                                                  snapshot_config_obj, optimized,
                                                                  protectionPolicyId=protectionPolicyId,
                                                                  task_id=task_id)

            LOG.info(_("create_backup_new response_data: '%s' ") % response_data)
            LOG.info(_('Backup Task Id in RMC is %s') % response_data['taskUri'])
            notification_kwargs['backupName'] = backup_name
            notification_kwargs['rmc_wrapper_service'] = rmc_wrapper_service
            task_desc_string = 'Backup In Progress'
            task_status = "Initiated"
            task_percentage = 20
            task_state = 'Running'
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Read the response from RMC task-id and update to backup-task-id in RMV.
            # Looping inside this function, returns only after backup job is completed successfully/errored out.
            # extract the task if from the response_data
            rmc_backup_taskid = response_data['taskUri'].split('/')[-1]
            notification_kwargs['rmcTaskId'] = rmc_backup_taskid
            starting_rate = 20
            catalyst_copy_set = request_body.get('catalystCopySet', None)
            if catalyst_copy_set:
                task_progress_share = 40
            backjob_response = self.update_backup_task(rmc_wrapper_service, False, task_id, vm_task_helper,
                                                       rmc_backup_taskid,
                                                       task_id, starting_rate, mo_ref, object_type, task_progress_share)
            LOG.info(_('The backup job response is %s') % backjob_response)

            # now update the task to backup tasks and also VMware Tasks
            task_state = backjob_response['task']['taskState']
            completed_percentage = backjob_response['task']['completedPercentage']
            if task_state == 'Aborted':
                task_desc_string = "This task has been aborted by user."
                task_status = "Error"
                task_desc_string = task_desc_string + self.getLatestProgressMsg(backjob_response.get('task'))
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            elif task_state == 'Error' or task_state == 'Failed':
                task_desc_string = "HPE Express Protect backup failed. Reason "
                task_desc_string = self.get_error_details(backjob_response, task_desc_string)
                # # Get detailed error detail from task-tree GET output of backup job.
                # response_error_datas = rmc_wrapper_service.get_backup_task_tree_status(rmc_backup_taskid)
                # tasks = response_error_datas['task']['subTasks']['tasks']
                # for response_error_data in  tasks:
                #     temp_msg = response_error_data['taskStatus']
                #     childTaskState = response_error_data['taskState']
                #     #Removing the repeated messages getting appended to task description
                #     if temp_msg not in task_desc_string and childTaskState == 'Error' or childTaskState == 'Aborted' or childTaskState == 'Failed':
                #         task_desc_string = task_desc_string + self.getLatestProgressMsg(response_error_datas.get('task'))
                task_status = "Error"
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            else:
                task_desc_string = "HPE Express Protect backup completed successfully. "
                task_desc_string = task_desc_string + str(self.getLatestProgressMsg(backjob_response.get('task')))
                task_state = 'Completed'
                task_status = "Ok"

                # Update the appmetadata vitualcopylist field with corresponding backup object id
                self.update_appmetadata(backjob_response, app_metadata, rmc_wrapper_service, x_auth_token)

                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                LOG.debug(_("create_backup_new response_data") % response_data)
                catalyst_copy_set = request_body.get('catalystCopySet', None)
                copyPolicy = None
                if protectionPolicyId:
                    # get portection policy from rmc and check catalyst copy
                    response_data = rmc_wrapper_service.get_protection_policy(protectionPolicyId)
                    protectionPolicy = response_data.get("protectionPolicy", None)
                    if protectionPolicy:
                        copyPolicy = protectionPolicy.get("copyPolicy", None)
                if catalyst_copy_set or copyPolicy:
                    LOG.debug(_("creating catalyst copy for one click"))
                    backup_id = (backjob_response['task']['associatedResource']['resourceUri']).split('/')[-1]
                    LOG.debug(_('create_backup_new The backup_id is %s') % backup_id)
                    copy_name = None
                    copy_description = None
                    copy_policy_id = None
                    if catalyst_copy_set:
                        copy_name = catalyst_copy_set.get('copyName', None)
                        copy_description = catalyst_copy_set.get('copyDescription', None)
                        copy_policy_id = catalyst_copy_set.get('copyPolicyId', None)
                    if not copy_name:
                        backup_details = self.get_backup_details(context,
                                                                 backup_id,
                                                                 x_auth_token)
                        LOG.debug("create_backup_new BackupSet backup_details: '%s'" % backup_details)
                        timestamp_in_utc_time = backup_details.get('createdAt', None)
                        LOG.debug("create_backup_new BackupSet timestamp: '%s'" % timestamp_in_utc_time)
                        timestamp_in_local_time = rmv_utils.convert_utc_to_local_format(timestamp_in_utc_time)
                        LOG.info(
                            "create_backup_new BackupSet timestamp converted to local time: '%s'" % timestamp_in_local_time)
                        copy_name = timestamp_in_local_time

                    if protectionPolicyId:
                        LOG.info("creating catalyst copy using protection policy id ")
                    else:
                        # if protectionPolicyId is empty then validate the copy_policy_id
                        if not copy_policy_id:
                            msg = (_("exception in getting copyPolicyId "))
                            LOG.error(_(msg))
                            LOG.exception("Exception: %s", msg)
                            raise exception.RMCCopyPolicyError()

                    # Create the vmware task
                    vm_task_helper = VmTaskHelper(self.vi_helper)
                    vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                         mo_ref,
                                                         "CreateVMCopyTask",
                                                         "CreateVMCopyFailedFault")

                    task_desc_string = 'Catalyst Copy In Progress'
                    task_status = "Initiated"
                    task_state = 'Running'
                    task_percentage = completed_percentage - 60  # Since 60% is allocated for Snapshot and backup so remaining 40% for Catalyst Copy
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    LOG.debug(("create_copy_from_backup calling from create_backup_new"))
                    starting_rate = completed_percentage
                    self.create_copy_from_backup(context, backup_id, copy_name, copy_description, copy_policy_id,
                                                 x_auth_token, task_id, mo_ref, vm_task_helper, object_type,
                                                 protectionPolicyId=protectionPolicyId)
                    LOG.debug(("create_copy_from_backup calling from create_backup_new returned"))
        except (rmv_exception.TaskError,
                rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.RMCFieldNotFoundException,
                rmv_exception.RMCCopyPolicyError,
                Exception
                ) as e:
            err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            LOG.exception(e)
            LOG.error(_('create_backup_new exception: %s') % (err_args_msg))

            task_desc_string = err_args_msg
            task_status = "Error"
            task_state = 'Failed'
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

        except Exception as e:
            err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            LOG.exception(_('create_backup_new exception: %s') % err_args_msg)

            task_desc_string = err_args_msg
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
        finally:
            if vmLevelBackupFlag:
                if pre_backup_dict and transportMode == "san:nbd":
                    if snapshot_id_in_rmc is not None:
                        detach_response = rmc_wrapper_service.cleanup_snapshot(snapshot_id_in_rmc, task_id)
                        del_response_data = rmc_wrapper_service.delete_snapshot(snapshot_id_in_rmc, task_id=task_id)
                if snap_ret_info.get('snap_moref_list', None) is not None:
                    self.vi_helper.Delete_vmfs_snapshot(snap_ret_info.get('snap_moref_list'), False)
            notification_kwargs['eventType'] = 'createExpressProtect'
            if backjob_response is not None:
                backupSetId = (backjob_response['task']['associatedResource']['resourceUri']).split('/')[-1]
                bs = rmc_wrapper_service.get_backup_for_backupId(context, backupSetId).get('backupSet')
                notification_kwargs['vmwObjName'] = bs.get('appMetadata').get('VmWareObjectName')

        return

    def backup_delete(self, context, copy_id, x_auth_token, task_id, vm_objType=None, moref=None):
        LOG.info("Enter - backup_delete")
        response_data = None
        vmware_object_name = None
        rmc_backup_set_id = None

        try:
            # instantiate rmc_wrapper class
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            object_type = 'Folder'
            mo_ref = "group-d1"
            vm_task_helper = VmTaskHelper(self.vi_helper)

            rmv_backup_id_details = self.db.get_rmcv_copy_by_id(context, copy_id)

            if rmv_backup_id_details:
                rmc_backup_set_id = rmv_backup_id_details.rmc_copyset_id
                # backup_id_details = self.get_backup_for_backupId(context, rmc_backup_set_id, x_auth_token)
                # backup_id_details = backup_id_details['backupSet']
                rmv_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, vm_objType, moref)
                notification = nu.BackupNotification(rmv_backup_id_details, rmv_obj, task_id, 'deleteExpressProtect',
                                                     rmc_wrapper_service)
            else:
                LOG.info(_("Could not fetch the backup details"))
                msg = ("Failed to get details for backup id " + copy_id)
                raise Exception(msg)

            if vm_objType and (vm_objType.strip() ==
                               "VirtualMachine" or
                               vm_objType.strip() == "Datastore"):

                try:
                    moref_obj = pyvmomi_util.get_moref(moref, vm_objType)

                    obj_content = self.vi_helper.get_object_properties(
                        moref_obj, "name")
                    if obj_content:
                        object_type = vm_objType
                        mo_ref = moref
                except Exception as e:
                    LOG.exception(e)

            vm_task_helper = VmTaskHelper(self.vi_helper)
            # Log an event in vCenter
            vm_task_helper.CustomVMwareTaskBegin(
                object_type,
                mo_ref,
                "DeleteBackupTask",
                "DeleteBackupFailedFault")
            LOG.info("RMC copyset id to delete is: ", rmc_backup_set_id, "and RMCV copy id to delete is:", copy_id)
            if rmc_backup_set_id:
                response_data = rmc_wrapper_service.backup_delete(backup_id=rmc_backup_set_id, task_id=task_id)
            # delete backup from rmcv db
            self.db.delete_rmcv_copy_by_id(context, copy_id)

        except (rmv_exception.RMCAPIError,
                rmv_exception.TaskError) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            task_desc_string = e.msg
            task_percentage = 100
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper,
                              task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            return

        # Update Tasks (Task Tracker and VMware Task)
        if rmc_backup_set_id and not response_data:
            task_desc_string = 'Error deleting backup job.'
            task_status = "Error"
            task_percentage = 100
            task_state = 'Failed'
            self._update_task(
                task_desc_string,
                task_percentage,
                task_state,
                task_id,
                rmc_wrapper_service,
                vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            return

        # task_status = response_data['task']['taskState']

        if response_data and response_data['task']['taskState'] == "Error":
            # error_detail = response_data['task']['taskErrors']['errorDetails']
            errors = response_data['task']['taskErrors']
            error = errors[0]
            task_desc_string = error['errorDetails']
            task_status = "Error"
            task_percentage = 100
            task_state = 'Failed'
            self._update_task(
                task_desc_string,
                task_percentage,
                task_state,
                task_id,
                rmc_wrapper_service,
                vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            return

        # update successful completion of the backup job
        task_desc_string = 'backup job deleted successfully.'
        task_percentage = 100
        task_state = 'Completed'
        task_status = "Ok"
        self._update_task(
            task_desc_string,
            task_percentage,
            task_state,
            task_id,
            rmc_wrapper_service,
            vm_task_helper, task_status=task_status)
        vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
        # after all initiating thread to send notification
        notification.start()

        LOG.info("Exit - backup_delete")

    def get_backup_notification2(self, context, **kwargs):
        try:
            """
            creates Notification object including Email msg for rmcv backup

            :param kwargs: list of args as dict
            :return: notifaction obj
            """
            notification_obj = {}

            eventType = kwargs.get('eventType', None)
            eventState = kwargs.get('taskState', 'info')
            rmc_wrapper_service = kwargs.get('rmc_wrapper_service')
            errorMsg = kwargs.get('errorMsg')
            backupSet = kwargs['backupSet']
            backupName = backupSet.get('name')
            rsId = backupSet.get('recoverySetId')
            backupId = backupSet.get('id')
            appData = backupSet.get('appMetadata', [])
            vmwObjName = appData.get('VmWareObjectName', 'unknown')
            vmwObjType = appData.get('VmWareObjectType', 'VirtualMachine')
            policyId = backupSet['backupPolicy']['id']
            storeName = backupSet['backupPolicy']['storeName']
            snapName = backupSet['backups']['snapName']
            notificationId = ''

            bacSysIP = ''

            oprtState = 'success'
            event_name = 'Unknown operation'
            try:
                bacSys = self.get_backup_system_from_backupPolicyId(context,
                                                                    policyId,
                                                                    rmc_wrapper_service.get_default_headers())
                bacSysIP = bacSys['backupSystem']['ipHostname']

                RS = rmc_wrapper_service.get_recovery_set(rsId)
                notificationId = RS['recoverySet']['notificationPolicyId']

            except Exception as e:
                pass

            if eventState is not None and eventState.lower() == 'error':
                oprtState = 'failed'

            if eventType is None:
                return None
            if eventType == 'deleteExpressProtect':
                event_name = 'Delete express protect'
            elif eventType == 'createExpressProtect':
                event_name = 'Create express protect'
            elif eventType == 'restoreExpressProtect':
                event_name = 'Restore express protect'
            else:
                event_name = eventType

            subject = ("RMCV Email Notification of - %(vmwObjType)s - %("
                       "vmwObjName)s %(eventName)s %(backupName)s %(oprtState)s"
                       % {"vmwObjType": vmwObjType,
                          "vmwObjName": vmwObjName,
                          "eventName": event_name,
                          "backupName": backupName,
                          "oprtState": oprtState})

            if eventState.lower() is 'error':
                message = ("Operation %(event_name)s %(oprtState)s"
                           "\n\n %(vmwObjType)s name %(vmwObjName)"
                           "\n\n by using store %(storeName)s on BackupSystem %("
                           "bacSysIP)"
                           "\n\n Snapshot Name : %(snap_name)s "
                           "\n\n recoverySetId : %(rsId)"
                           "\n\n error : %(errorMsg) "
                           % {'event_name': event_name,
                              'oprtState': oprtState,
                              'vmwObjType': vmwObjType,
                              'vmObjName': vmwObjName,
                              'storeName': storeName,
                              'bacSysIP': bacSysIP,
                              'snap_name': snapName,
                              'rsId': rsId,
                              'errorMsg': errorMsg
                              }

                           )
            else:
                message = ("Operation %(event_name)s %(oprtState)s"
                           "\n\n %(vmwObjType)s name %(vmwObjName)"
                           "\n\n by using store %(storeName)s on BackupSystem %("
                           "bacSysIP)"
                           "\n\n Snapshot Name : %(snap_name)s "
                           "\n\n recoverySetId : %(rsId)"
                           % {'event_name': event_name,
                              'oprtState': oprtState,
                              'vmwObjType': vmwObjType,
                              'vmObjName': vmwObjName,
                              'storeName': storeName,
                              'bacSysIP': bacSysIP,
                              'snap_name': snapName,
                              'rsId': rsId, }
                           )
                notification_obj = {
                    "notificationPolicyId": notificationId,
                    "subject": subject,
                    "messageBody": message
                }
        except Exception as e:
            LOG.exception("error while sending notifiaction mail :%s", e)
        return notification_obj

    def get_backup_notification(self, context, rmc_wrapper_service,
                                notification_kwargs):

        """
        creates Notification object including Email msg for rmcv backup

        :param kwargs: list of args as dict
        :return: notifaction obj
        """
        eventType = notification_kwargs.get('eventType', None)
        vmwObjType = notification_kwargs.get('vmwObjType', None)
        vmwObjName = notification_kwargs.get('vmwObjName', None)
        rmcTaskId = notification_kwargs.get('rmcTaskId', None)
        rmcvTaskId = notification_kwargs.get('rmcvTaskId', None)
        backupName = notification_kwargs.get('backupName', '').strip()

        # LOG.info("Entire notification kwargs: "+str(notification_kwargs))

        if backupName is None or backupName == '':
            backupName = 'No Name'
        recoverySetId = notification_kwargs.get('recoverySetId', None)
        notificationType = None

        notification_body = None
        if not recoverySetId:
            LOG.error('No recovery-set found, returning...')
            return None
        msg_dict = {}
        if eventType is None:
            LOG.info('eventType is None, returning...')
            return None
        eventType = eventType.strip()
        if eventType == 'deleteExpressProtect':
            event_name = 'Delete Express Protect'
        elif eventType == 'createExpressProtect':
            event_name = 'Create Express Protect'
        elif eventType == 'restoreExpressProtect':
            event_name = 'Restore from Express Protect'
        elif eventType == 'createExpressProtectCatalystCopy':
            event_name = 'Create Catalyst Copy'
        elif eventType == 'deleteExpressProtectCatalystCopy':
            event_name = 'Delete Catalyst Copy'
        elif eventType == 'restoreExpressProtectCatalystCopy':
            event_name = 'Restore from Catalyst Copy'
        else:
            event_name = eventType
        subject = str(event_name)
        LOG.info("notification for objType: " + str(vmwObjType) + " Name: " + str(vmwObjName))
        if vmwObjType and vmwObjName:
            vmwObjName = vmwObjName.strip()
            vmwObjType = vmwObjType.strip()
            subject = subject + " for " + str(vmwObjType) + " " + str(vmwObjName)
            if vmwObjType == 'Datastore':
                msg_dict['Datastore Name'] = vmwObjName
            elif vmwObjType == 'VirtualMachine':
                msg_dict['Virtual machine name'] = vmwObjName
            else:
                msg_dict[vmwObjType] = vmwObjName

        try:
            if rmcvTaskId:
                rmcvTaskResponse = \
                    rmc_wrapper_service.get_copy_task_status(rmcvTaskId)[
                        'task']
                LOG.info('rmcvTaskResponse: ' + str(rmcvTaskResponse))
                # msg_dict['Task state'] = rmcvTaskResponse.get('taskState')
                # msg_dict['Task name'] = rmcvTaskResponse.get('name')
                # msg_dict['description'] = 'Notification from RMC-V'
                if rmcvTaskResponse.get('taskState').lower() == 'error':
                    msg_dict['Error'] = nu.getLatestProgressMsg(rmcvTaskResponse)
                else:
                    msg_dict['Status'] = nu.getLatestProgressMsg(rmcvTaskResponse)
                # msg_dict['Percentage completed'] = rmcvTaskResponse.get('completedPercentage')
            if rmcTaskId:
                rmcTaskResponse = rmc_wrapper_service.get_backup_task_tree_status(
                    rmcTaskId)['task']
                LOG.debug('rmcTaskResponse: ' + str(rmcTaskResponse))

                # Commenting code to fix later
                # associatedData  = rmcTaskResponse.get('associatedData')
                # if associatedData:
                # msg_dict['storeName'] = associatedData.get('storeName', 'NA')
                # msg_dict['storageSystemName'] = associatedData.get('storageSystemName', 'NA')
                # msg_dict['backupSystemName'] = associatedData.get('backupDeviceName', 'NA')

            taskState = rmcvTaskResponse.get('taskState', 'completed').lower()

            msg_dict['Backup Name'] = backupName

            rs_body = rmc_wrapper_service.get_recovery_set(
                recoverySetId)['recoverySet']

            notificationId = rs_body.get('notificationPolicyId', None)
            if taskState == 'error':
                notificationType = 'error'
                subject = "RMCV task [failed]: " + subject.lower()
            else:
                notificationType = 'info'
                subject = "RMCV task [" + str(taskState).lower() + "] " + subject
            notification_body = {
                "notificationPolicyId": notificationId,
                "subject": subject,
                "messageBody": self.get_notification_msg_by_dict(
                    msg_dict),
                'notificationType': notificationType,
                'rmcvTaskBody': rmcvTaskResponse
            }
        except Exception as e:
            LOG.exception(e)
        return notification_body

    def get_notification_msg_by_dict(self, msg_dict):

        msg = msg_dict.pop('description', "") + "\n" + "\n"

        for key in msg_dict.keys():
            msg = msg + " " + str(key) + ": " + str(msg_dict.get(key, 'NA')) + "\n" + "\n"
        return msg

    def delete_all_vmfs_snapshot_vm(self, vm_info, mo_ref):
        """
        delete all vmfs snapshot for a vm. we need this functionality for vmdk backup
        """
        LOG.debug("delete_all_vmfs_snapshot_vm: Enter")
        snap_id_list = []
        vm = vm_info
        if vm.VmMoref != mo_ref:
            raise rmv_exception.VmMorefMissmatch(("Could not map VM: '%s' "
                                                  "VMobjectID "
                                                  "mismatch.") % (mo_ref))

        hasVmfsSnap = self.check_vmfs_snapshot_present(mo_ref)
        vm.HasVmfsSnapshots = hasVmfsSnap

        if vm.HasVmfsSnapshots:
            vm_ref_obj = pyvmomi_util.get_moref(mo_ref, 'VirtualMachine')
            snap_prop = self.vi_helper.get_object_properties(vm_ref_obj, "snapshot")

            if not snap_prop:
                LOG.debug("No snapshot properties found, delete_all_vmfs_snapshot_vm: Exit")
                return
            snap_conf_obj_list = vim_util.extract_properties(snap_prop[0])
            snapTree = snap_conf_obj_list['snapshot'].rootSnapshotList[0]

            self.vi_helper.Delete_vmfs_snapshot([snapTree.snapshot], True)
        LOG.debug("delete_all_vmfs_snapshot_vm: Exit")

    # TODO: this is available in vmware_checks.py and can be removed
    def check_and_delete_vmfs_sapshots_vm(self, is_app_consistent,
                                          vm_info,
                                          object_type,
                                          mo_ref):
        """
        To delete the VMFS snapshot of a VirtualMachine
        """
        LOG.debug("check_and_delete_vmfs_sapshots_vm : enter")
        snap_id_list = []
        vm = vm_info
        if vm.VmMoref != mo_ref:
            raise rmv_exception.VmMorefMissmatch(("Could not map VM: '%s' "
                                                  "VMobjectID "
                                                  "mismatch.") % (mo_ref))

        #        if vm.IsUnusable:
        #            raise rmv_exception.VmUnusableError(("Could not map VM: '%s' Fatal errors "
        #                             "during vv mapping.") % (mo_ref))

        if vm.HasVmfsSnapshots and is_app_consistent:
            # if len(vm.VmfsSnapshots) > 1:
            #    raise rmv_exception.VMFSsnapshotExistsException(vm_name=vm.Name)
            vm_ref_obj = pyvmomi_util.get_moref(mo_ref, 'VirtualMachine')
            snap_prop = self.vi_helper.get_object_properties(vm_ref_obj, "snapshot")
            LOG.info("No of snapshots: " + str(len(vm.VmfsSnapshots)))
            if snap_prop:
                snap_conf_obj_list = vim_util.extract_properties(snap_prop[0])
                snapTree = snap_conf_obj_list['snapshot'].rootSnapshotList[0]
                LOG.info("SnapTree is ..... %s" % snapTree)
                vmfs_snap_ref = \
                    self.vi_helper.traverse_and_get_rmcv_internal_snap_pyv(
                        snapTree, vi_objects.VmfsSnapshotName)
                if vmfs_snap_ref:
                    LOG.info("Delete the snap : %s" % vmfs_snap_ref)
                    snap_id_list.append(vmfs_snap_ref)
                    LOG.debug("Deleting Left over VMFS snapshot")
                    self.vi_helper.Delete_vmfs_snapshot(snap_id_list, False)
                else:
                    LOG.info("VMFS Snapshots Exists")
                # raise rmv_exception.VMFSsnapshotExistsException(vm_name=vm.Name)

        LOG.debug("check_and_delete_vmfs_sapshots_vm : exit")

    # TODO: this is available in vmware_checks.py and can be removed
    def setup_restorable_items(self, mo_ref, vmObject_name, virtual_copy_info, ds_assoc_vm_list):
        """
        Retrives restorable_items_list for a datastore
        """
        LOG.info("setup_restorable_items : enter")
        try:
            virtual_disk_list = self.vi_helper.get_all_flat_virtual_disks_in_datastore(
                mo_ref,
                vmObject_name)

            for virtual_disk in virtual_disk_list:
                vm_obj = json_helper.virtual_machine_item()
                vm_obj.FileName = virtual_disk
                # vm_obj.DatastoreName = vmObject_name
                # vm_obj.TpdLunWwn = virtual_copy_info.InServBaseVolumeWwn

                vm_detail_info = None

                for vm in ds_assoc_vm_list:
                    for vm_info in vm.vmInfo.VirtualCopyPairList:
                        for ret_item in vm_info.RestorableItemsList:
                            if ret_item.FileName == vm_obj.FileName:
                                vm_detail_info = vm
                    if vm_detail_info:
                        break

                if vm_detail_info:
                    vm_obj.OriginalVMName = vm_detail_info.vmInfo.Name
                    vm_obj.vm_moref = vm_detail_info.vmInfo.VmMoref
                    if vm_detail_info.bIsSelected:
                        vm_obj.IsAppConsistent = True
                    else:
                        vm_obj.IsAppConsistent = False
                else:
                    vm_obj.IsAppConsistent = False

                virtual_copy_info.RestorableItemsList.append(vm_obj)
        except rmv_exception.VirtualDiskNotFoundException() as e:
            LOG.exception(e)

        LOG.info("setup_restorable_items : exit")
        return virtual_copy_info

    def validate_vm_vmdks_size_datastore_size(self, source_vm_moref_list, target_ds_ref, target_ds_name):
        LOG.debug("Enter: validate_vm_vmdks_size_datastore_size")
        try:
            target_ds_size_info = self.vi_helper.get_datastore_size_info(target_ds_ref, target_ds_name)
            if not target_ds_size_info:
                msg = "Unable to fetch target datastore [%s] size. Size Info returned None" % target_ds_size_info
                LOG.error(msg)
                raise rmv_exception.RestoreVirtualMachineException(msg)
            target_ds_free_space = target_ds_size_info["vmfsFreeSize"]
            LOG.info("Target Datastore [%s] free space: %s bytes", target_ds_name, target_ds_free_space)

            # TODO: for now assuming we need total space of all the vms in datastore, else throw
            # Check if can it be partially successful, so that maximum size of VM can be validated

            total_size_of_all_vm = 0
            for source_vm_moref in source_vm_moref_list:
                source_vmdk_size = self.vi_helper.get_vm_vmdk_total_size(source_vm_moref)
                total_size_of_all_vm += source_vmdk_size

                if not source_vmdk_size:
                    msg = "Unable to fetch VM virtual disk file [%s] size" % (source_vm_moref)
                    LOG.error(msg)
                    raise rmv_exception.RestoreVirtualMachineException(msg)

            if total_size_of_all_vm <= target_ds_free_space:
                LOG.debug("Target datastore does has enough space [%s] to copy the VMDK file [size = %s]",
                          target_ds_free_space, total_size_of_all_vm)
                LOG.info("Exit: validate_target_ds_size_for_copy")
                return
            else:
                source_vmdk_size_GB = total_size_of_all_vm / (1024 * 1024 * 1024)
                target_ds_free_space_GB = target_ds_free_space / (1024 * 1024 * 1024)
                LOG.error("Target datastore does not enough space [%s GB] to copy the VMDK file [size = %s GB]",
                          target_ds_free_space_GB, source_vmdk_size_GB)

        except Exception as e:
            LOG.exception("Exception occurred validating target datastore size for VMDK copy: %s", e)
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal Error: Unable to fetch total VMDK size for [%s] Information from vCenter" % \
                      "".join(source_vm_moref_list)
            raise rmv_exception.RestoreVirtualMachineException(msg)

        msg = "Target Datastore [%s] does not have enough space to copy VMDK file." \
              "Available Free Space on Datastore = %s GB. VMDK (thick provisioned) File Size = %s GB" \
              % (target_ds_name, target_ds_free_space_GB, source_vmdk_size_GB)
        LOG.debug("Exit: validate_target_ds_size_for_copy")
        raise rmv_exception.RestoreVirtualMachineException(msg)

    def restore_vms_to_original_state(self, vm_state_dict):
        LOG.debug("restore_vms_to_original_state: Enter")
        for vm_moref, vm_states in vm_state_dict.items():
            self.renameVm(vm_moref, vm_states['original_name'])
            if 'powerState' in vm_states and vm_states['powerState'] == 'poweredOn':
                self.power_on_vm(vm_moref)
        LOG.debug("restore_vms_to_original_state: Exit")

    def delete_relocated_vms(self, vms_list):
        LOG.debug("restore_vms_to_original_state: Enter")
        for vm_moref in vms_list:
            self.delete_vm(vm_moref)
        LOG.debug("restore_vms_to_original_state: Exit")

    def restore_virtual_machines_using_snapshot_or_backup(self, context, x_auth_token, task_id, copy_id, object,
                                                          params):
        """
        Attach snapshot to given ESX, than rescan and register vm, and move to given datastore.
        """
        LOG.debug("restore_virtual_machines_using_snapshot_or_backup: Enter")
        restore_to_other = params.get("restoreToOther")
        restore_to_parent = params.get("restoreToParent")
        virtual_machines_to_restore = params['virtualMachineList']
        power_on = params.get('powerOn', False)
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        is_task_failed = False
        # Create dict to maintain current state of VM, if any error we can revert it
        vm_current_state = {}
        clone_details_resp = None
        recovery_set_id = None
        delete_failed_vms = {}
        relocatedVms = []
        is_recover_task_successful = False
        is_ert_already_unmounted = False
        copy_info = None
        restored_vm_moref_list = None
        is_relocated_success = None
        rdm_snapshot_set_id = None
        is_rdm_snap_creation = False
        is_rdm_restore_to_orig_failed = False
        rdm_wwn_list = []
        rdm_volume_name_host_dict = {}
        orig_vm_rdm_full_details_list = []

        try:
            if virtual_machines_to_restore is None or len(virtual_machines_to_restore) == 0:
                msg = "No virtual machine specified for restore"
                raise Exception(msg)
            parse = object.split(':')
            if len(parse) < 1:
                msg = "Invalid object being passed"
                raise Exception(msg)
            objectType = parse[0]
            moref = parse[1]
            rmv_vmware_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, objectType, moref)
            parentResourceName = rmv_vmware_obj.name
            # validate if the copy_id has the requested vms when it was backed up
            vm_details_list_in_copy = self.db.get_rmcv_vm_assoc_with_vm_details(context, copy_id)
            ds_details_list_in_copy = self.db.get_rmcv_ds_assoc_with_ds_details(context, copy_id)

            for vm_details in vm_details_list_in_copy:
                datacenter_moref = vm_details['datacenter_id']
                break

            vm_details_list_in_copy = self.db.get_rmcv_vm_assoc_with_vm_details(context, copy_id)
            vm_moref_list_in_copy = [vm_details['moref'] for vm_details in vm_details_list_in_copy]
            ds_moref_list_in_copy = [ds_details['moref'] for ds_details in ds_details_list_in_copy]

            copy_info = self.db.get_rmcv_copy_by_id(context, copy_id)

            if ((set(virtual_machines_to_restore) <= set(vm_moref_list_in_copy)) is False):
                msg = "Request VMs does not exist in requested copy"
                raise Exception(msg)

            # Updating name of virtual machine in our database before restore operation
            vm_obj_list = []
            for mo_ref in virtual_machines_to_restore:
                vm_ref = pyvmomi_util.get_moref(mo_ref, "VirtualMachine")
                vm_obj_list.append(vm_ref)

            deleted_vm_moref = []
            for vm_mo_ref in virtual_machines_to_restore:
                result = self.db.get_virtual_machine_by_moref(context, vm_mo_ref)
                if result is None or result.status == 'deleted':
                    deleted_vm_moref.append(vm_mo_ref)

            if len(deleted_vm_moref) == 0:
                self.update_rmcv_virtual_machines(context, vm_obj_list)

            # Assuming only one vm to restore
            is_vm_deleted_from_vsphere = True if virtual_machines_to_restore[0] in deleted_vm_moref else False

            target_datastore_moref = None
            target_datastore_name = None
            if restore_to_parent is True:
                # restore to parent
                rmv_vm = self.db_utils.get_vmware_object_by_object_type_and_moref(context,
                                                                                  rmv_utils.VMWARE_OBJECT_TYPE_VM,
                                                                                  virtual_machines_to_restore[0])

                if is_vm_deleted_from_vsphere is False:
                    datastore_name = self.get_datastore_of_vm_using_vmx(vm_obj_list[0])
                    target_datastore_moref = self.get_datastore_moref_using_name(datastore_name)
                    target_datastore_name = datastore_name

                if is_vm_deleted_from_vsphere is False:
                    vm_obj = vim.get_moref(virtual_machines_to_restore[0], "VirtualMachine")
                    folder_obj = self.vi_helper.get_parent_moref(vm_obj)
                    folder_moref = str(folder_obj.value)
                else:
                    # if VM is deleted, then then the parent vm folder using datacenter id
                    datacenter_ref = pyvmomi_util.get_moref(datacenter_moref, "Datacenter")
                    vmFolder = self.vi_helper.get_object_properties(datacenter_ref, "vmFolder")
                    prop_dict = pyvmomi_util.extract_properties(vmFolder[0])
                    folder_obj = prop_dict['vmFolder']
                    folder_moref = str(folder_obj._moId)

                host_name = rmv_vm.get('host_name')

            elif restore_to_other:
                folder_moref = restore_to_other.get('folderIdentifier', None)
                if folder_moref is None:
                    msg = "No folderIdentifier specified for restore"
                    raise Exception(msg)
                datastore_moref = restore_to_other.get('datastoreIdentifier', None)
                if datastore_moref is None:
                    msg = "No datastoreIdentifier specified for restore"
                    raise Exception(msg)
                ds_info = self.vi_helper.get_datastore_details(datastore_moref, [])
                if ds_info is None:
                    msg = "Datastore details not found with specified datastoreIdentifier"
                    raise Exception(msg)

                target_datastore_moref = ds_info.DatastoreMoref
                target_datastore_name = ds_info.Name
                host_name = ds_info.host_name

            vm_dict = {}
            vm_db_id_to_moref_dict = {}
            for vm_moref in virtual_machines_to_restore:
                vm = self.db_utils.get_vmware_object_by_object_type_and_moref(context, rmv_utils.VMWARE_OBJECT_TYPE_VM,
                                                                              vm_moref)
                vm_dict[vm.name] = vm.moref
                vm_db_id_to_moref_dict[vm.id] = vm.moref

            ds_mount_path_dir = copy_info.ds_mount_path_dir
            rmc_copyset_id = copy_info.rmc_copyset_id

            try:
                lun_details_list = self.db_utils.get_vmdk_wwn_details_by_copy_id_and_vm_moref(context, copy_id, moref)
            except Exception as ex:
                LOG.exception(ex)
                raise ex
            rdm_wwn_list = []
            for lun in lun_details_list:
                if lun.get('lun_used_as') == 'rdm':
                    rdm_wwn_list.append(lun.get('wwn'))

            self._update_task(task_desc_string='Initiated virtual machine restore',
                              task_percentage=10,
                              task_state='Running',
                              task_id=task_id,
                              rmc_wrapper_service=rmc_wrapper_service,
                              task_status='Initiated')

            recovery_set_id_from_copy = self.db_utils.get_recovery_set_id_by_copy_id(context, copy_id)
            LOG.debug('recovery_set_id_from_copy - {0}'.format(recovery_set_id_from_copy))

            is_rdm_snap_creation = False
            if is_vm_deleted_from_vsphere is False:
                if len(rdm_wwn_list) > 0:
                    try:
                        timestr = datetime.now().strftime("%Y%m%d%H%M%S%f")
                        rdm_snapshot_set_name = "rdm_snapshot_set_" + timestr
                        rdm_snapshot_inner_data = rmc_wrapper_service.create_rmc_snapshot_inner(rdm_snapshot_set_name,
                                                                                                None,
                                                                                                recovery_set_id_from_copy,
                                                                                                None, None,
                                                                                                task_id=task_id)
                        rdm_snapshot_set_id = rdm_snapshot_inner_data['id']
                        rdm_snapshot_set_name = rdm_snapshot_inner_data['name']
                    except Exception as exc:
                        LOG.exception(exc)
                        msg = "Unable to create snapshot for the rdm volumes"
                        raise Exception(msg)
                    finally:
                        is_rdm_snap_creation = True
            else:
                if len(rdm_wwn_list) > 0:
                    msg = "Restoring VM from deleted resources with RDM associated is not supported"
                    LOG.error(msg)
                    raise Exception(msg)

            if copy_info.type == rmv_utils.copy_type.SNAPSHOT:
                mount_task = self._create_task_recover(rmc_wrapper_service, 'Mount', "Snapshot", task_id,
                                                       "Mounting snapshot to ESXi Host.", copy_id,
                                                       copy_info.get('name'), 'Snapshot')
                clone_details, recovery_set_id = self.mount_snapshot_esx(context, rmc_copyset_id, x_auth_token,
                                                                         host_name,
                                                                         'esxHostIP', mount_task, None,
                                                                         rmv_vmware_obj.id,
                                                                         objectType, copy_id, None, None, None, None,
                                                                         None, None,
                                                                         is_vm_relocate_task=True)

                self._update_task(task_desc_string='Snapshot mounted',
                                  task_percentage=20,
                                  task_state='Running',
                                  task_id=task_id,
                                  rmc_wrapper_service=rmc_wrapper_service,
                                  task_status='Initiated')

                clone_info = self.db.get_rmcv_clone_by_recovery_set_id(context, recovery_set_id)
                hostname_ref = self.get_hostref_from_name(host_name)
                resource_pool_moref = self.get_respool_from_host(hostname_ref)
                clone_details_resp = self.register_vm_from_restored_ds(context, x_auth_token, rmc_wrapper_service,
                                                                       host_name,
                                                                       vm_dict, folder_moref, copy_id, object,
                                                                       resource_pool_moref,
                                                                       clone_info, task_id, None, power_on_vm=False,
                                                                       is_vm_relocate_task=True)

                if len(clone_details_resp.get('clone_details').get('cloned_virtual_machines')) == 0:
                    msg = "This could be because VM has been renamed and relocated. " \
                          + "The VM can be recovered by mounting the copy and registering the VM (manually) from the newly mounted datastore."
                    LOG.exception(msg)
                    raise Exception(msg)

                self._update_task(task_desc_string='Virutal Machines registered',
                                  task_percentage=40,
                                  task_state='Running',
                                  task_id=task_id,
                                  rmc_wrapper_service=rmc_wrapper_service,
                                  task_status='Initiated')

            elif copy_info.type == rmv_utils.copy_type.EXPRESS_PROTECT or \
                    copy_info.type == rmv_utils.copy_type.CATALYST_COPY:
                is_recover_task_successful = False
                mount_task = self._create_task_recover(rmc_wrapper_service, 'Mount', parentResourceName, task_id,
                                                       "Express protect backup object mount operation", copy_id,
                                                       copy_info.get('name'), 'Express Protect')

                is_recover_task_successful, clone_details_resp = self.recover_vm(context, copy_id, x_auth_token,
                                                                                 objectType, moref, host_name, None,
                                                                                 None, folder_moref,
                                                                                 False, True, vm_dict, mount_task, None,
                                                                                 None, is_vm_relocate_task=True)

                if is_recover_task_successful is False:
                    msg = "Mounting backup failed"
                    LOG.exception(msg)
                    raise Exception(msg)

            elif copy_info.type == rmv_utils.copy_type.CLOUD_COPY:
                msg = "Restoring a virtual machine from cloud copy is not supported"
                LOG.error(msg)
                raise Exception(msg)

            # Get vm_moref of cloned corresponding received vm_moref list
            cloned_vm_details = clone_details_resp.get('clone_details').get('cloned_virtual_machines')

            if len(cloned_vm_details) == 0:
                msg = "Mounting backup failed"
                LOG.error(msg)
                raise Exception(msg)

            orig_to_cloned_vm_moref_dict = {}
            cloned_vms_moref_to_restore = {}
            for vm in cloned_vm_details:
                cloned_vms_moref_to_restore[vm.get('moref')] = {
                    'cloned_vm_name': vm.get('name'),
                    'parent_vm_name': vm.get('parent_vm_name'),
                    'parent_vm_moref': vm.get('parent_vm_moref')
                }

                orig_to_cloned_vm_moref_dict[vm.get('parent_vm_moref')] = vm.get('moref')

            # cloned_vm_list = list(cloned_vms_moref_to_restore.keys())
            # self.validate_vm_vmdks_size_datastore_size(cloned_vm_list, target_datastore_moref, target_datastore_name)

            if is_vm_deleted_from_vsphere is False:
                relocate_disk_spec_list = self.get_disk_relocate_spec(context,
                                                                      cloned_vms_moref_to_restore,
                                                                      virtual_machines_to_restore,
                                                                      copy_id)
            else:
                relocate_disk_spec_list = self.get_disk_relocate_spec(context,
                                                                      cloned_vms_moref_to_restore,
                                                                      None,
                                                                      copy_id)

            # Detach the rdm from cloned vm before relocating
            cloned_vm_list = list(cloned_vms_moref_to_restore.keys())
            cloned_vm_rdm_full_details_list = []
            for vm_moref in cloned_vm_list:
                vm_host = self.get_vm_rdm_config_details(vm_moref, cloned_vm_rdm_full_details_list)
                vm_moref_obj = vim.get_moref(vm_moref, "VirtualMachine")
                self.detach_rdm_from_cloned_vm(context, "detach", clone_details_resp, vm_moref_obj, task_id,
                                               copy_id=copy_id)

            if is_vm_deleted_from_vsphere is False:
                vm_host = self.get_vm_rdm_config_details(moref, orig_vm_rdm_full_details_list)

                # validate if rdm wwn in catalog and from vmware if same. Else throw error
                matched_wwn_list = self.get_matching_rdm_wwn_from_copy(orig_vm_rdm_full_details_list, rdm_wwn_list)
                wwn_mismatch_list = list(set(rdm_wwn_list) - set(matched_wwn_list))
                if wwn_mismatch_list:
                    msg = "The VM does not have some RDM disks that were available when creating the Copy"
                    LOG.error(msg)
                    raise Exception(msg)

            # Integrating CheckRelocate_Task for dry running relocation
            for cloned_vm_moref, cloned_vm_details in cloned_vms_moref_to_restore.items():
                # Relocate cloned vm
                try:
                    if is_vm_deleted_from_vsphere is False:
                        try:
                            self.checkRelocateVm(cloned_vm_moref, target_datastore_moref, folder_moref,
                                                 relocate_disk_spec_list)
                        except Exception as exp:
                            msg = self.extract_msg_from_exception(exp)
                            LOG.error(msg)
                            raise Exception(msg)
                    else:
                        for ds_moref in ds_moref_list_in_copy:
                            ds_ref = vim.get_moref(ds_moref, "Datastore")
                            ds_name = self.vi_helper.get_managed_object_ref_name(ds_ref)
                            target_datastore_moref = ds_moref
                            target_datastore_name = ds_name
                            try:
                                self.checkRelocateVm(cloned_vm_moref, target_datastore_moref, folder_moref,
                                                     relocate_disk_spec_list)
                                is_relocated_success = True
                                break
                            except Exception as exp:
                                is_relocated_success = False
                                msg = self.extract_msg_from_exception(exp)
                                LOG.exception(msg)

                        if is_relocated_success is False:
                            msg = self.extract_msg_from_exception(exp)
                            LOG.error(msg)
                            raise Exception(msg)

                    relocatedVms.append(cloned_vm_moref)
                except Exception as exp:
                    msg = "Validate relocation of VM " + cloned_vm_details[
                        'parent_vm_name'] + " failed: " + self.extract_msg_from_exception(exp)
                    LOG.exception(msg)
                    raise Exception(msg)

            for cloned_vm_moref, cloned_vm_details in cloned_vms_moref_to_restore.items():
                # check relocation of cloned vm
                try:
                    self.relocateVm(cloned_vm_moref, target_datastore_moref, folder_moref, relocate_disk_spec_list)
                except Exception as exp:
                    msg = self.extract_msg_from_exception(exp)
                    LOG.exception(msg)
                    raise Exception(msg)

            if cloned_vms_moref_to_restore:
                restored_vm_moref_list = cloned_vms_moref_to_restore.keys() if cloned_vms_moref_to_restore else None
            if copy_info.type == rmv_utils.copy_type.EXPRESS_PROTECT or \
                    copy_info.type == rmv_utils.copy_type.CATALYST_COPY:
                try:
                    if is_relocated_success is False:
                        restored_vm_moref_list = None
                    self.unmount_backup_esx(context,
                                            copy_id,
                                            x_auth_token,
                                            host_name,
                                            rmv_utils.REQUEST_BODY_PARAM_ESX_HOST_IP,
                                            task_id,
                                            True,
                                            rmc_copyset_id,
                                            ds_mount_path_dir, clone_details_resp.get('id'),
                                            unregister_skip_vm_moref_list=restored_vm_moref_list)
                    is_ert_already_unmounted = True
                except Exception as exp:
                    msg = self.extract_msg_from_exception(exp)
                    LOG.exception(msg)
                    raise Exception(msg)

            if is_vm_deleted_from_vsphere is False:
                # Rename the currently  running VM
                try:
                    for vm_name, vm_moref in vm_dict.items():
                        timestr = datetime.now().strftime("%Y%m%d%H%M%S%f")
                        new_vm_name = "orig_" + vm_name + "_" + timestr
                        vm_current_state[vm_moref] = {'original_name': vm_name,
                                                      'new_name': new_vm_name}
                        self.renameVm(vm_moref, new_vm_name)
                except Exception as exp:
                    msg = "Could not rename the VM:" + self.extract_msg_from_exception(exp)
                    LOG.exception(msg)
                    raise rmv_exception.RenameVmException(msg)

                # TODO: Poweroff all the vms before restore by taking confirmation by api
                # refer comment in "https://cgit1-pro.austin.hpecorp.net/gerrit/#/c/36480/1/rmv/virt/pyvmomi/pyvmomi_wrapper.py"

                # Power off the original vm
                try:
                    for vm_name, vm_moref in vm_dict.items():
                        self.power_off_vm(vm_moref, vm_current_state)
                except Exception as exp:
                    msg = "Exception while powering off original VM"
                    LOG.error(msg)
                    LOG.exception(exp)
                    raise Exception(msg)

                self._update_task(task_desc_string='Original virutal machine is renamed and powered off',
                                  task_percentage=40,
                                  task_state='Running',
                                  task_id=task_id,
                                  rmc_wrapper_service=rmc_wrapper_service,
                                  task_status='Initiated')

                # Detach rdm from the original vm
                if is_vm_deleted_from_vsphere is False:
                    # vm_host = self.get_vm_rdm_config_details(moref, orig_vm_rdm_full_details_list)
                    self.detach_rdm_from_vm_native_vm(moref, orig_vm_rdm_full_details_list)

            for cloned_vm_moref, cloned_vm_details in cloned_vms_moref_to_restore.items():
                # if relocate vm is successful, then rename the cloned vm to current name of vm
                try:
                    if is_vm_deleted_from_vsphere is False:
                        self.renameVm(cloned_vm_moref,
                                      vm_current_state[cloned_vm_details['parent_vm_moref']]['original_name'])
                    else:
                        self.renameVm(cloned_vm_moref, cloned_vm_details['parent_vm_name'])
                except Exception as exp:
                    try:
                        msg = "Renaming VM " + cloned_vms_moref_to_restore[cloned_vm_moref][
                            'cloned_vm_name'] + " failed"
                    except Exception:
                        msg = "Renaming VM " + cloned_vm_moref + " failed"
                    msg = msg + self.extract_msg_from_exception(exp)
                    LOG.exception(exp)
                    raise Exception(msg)

                if len(rdm_wwn_list) >= 1:
                    try:
                        map_wwn_hostlist = self.get_attach_status_of_recovery_set(rmc_wrapper_service,
                                                                                  recovery_set_id_from_copy)
                        LOG.info(("map_wwn_hostlist: '%s'"), map_wwn_hostlist)

                        for wwn in rdm_wwn_list:
                            if not map_wwn_hostlist[wwn]['volume_name'] in rdm_volume_name_host_dict:
                                rdm_volume_name_host_dict[map_wwn_hostlist[wwn]['volume_name']] = []
                            for host in map_wwn_hostlist[wwn]['attached_hosts']:
                                rdm_volume_name_host_dict[map_wwn_hostlist[wwn]['volume_name']].append(host['hostname'])

                        try:
                            response = rmc_wrapper_service.detach_recoveryset(recovery_set_id_from_copy,
                                                                              retainAttachInfo=False,
                                                                              task_id=task_id,
                                                                              volumelist=rdm_volume_name_host_dict.keys())
                        except Exception as exp:
                            msg = str(exp)
                            LOG.error(msg)
                            raise Exception(msg)

                        if copy_info.type == rmv_utils.copy_type.SNAPSHOT:
                            try:
                                response = rmc_wrapper_service.restore_snapshot(rmc_copyset_id, False, task_id,
                                                                                rdm_wwn_list)
                            except Exception as exp:
                                msg = str(exp)
                                LOG.error(msg)
                                raise Exception(msg)
                            finally:
                                for rdm_vol_name, attached_hosts in rdm_volume_name_host_dict.items():
                                    for hostname in attached_hosts:
                                        LOG.debug('hostname to attach to %s', hostname)
                                        response = rmc_wrapper_service.attach_recoveryset(recovery_set_id_from_copy,
                                                                                          hostname, False,
                                                                                          task_id=task_id,
                                                                                          volumelist=[rdm_vol_name])
                        elif copy_info.type == rmv_utils.copy_type.EXPRESS_PROTECT or \
                                copy_info.type == rmv_utils.copy_type.CATALYST_COPY:
                            try:
                                response = rmc_wrapper_service.restore_to_parent_vol(backup_id=rmc_copyset_id,
                                                                                     task_id=task_id,
                                                                                     wwn_list=rdm_wwn_list,
                                                                                     is_sync=False)
                            except Exception as exp:
                                msg = str(exp)
                                LOG.error(msg)
                                raise Exception(msg)
                            finally:
                                for rdm_vol_name, attached_hosts in rdm_volume_name_host_dict.items():
                                    for hostname in attached_hosts:
                                        LOG.debug('hostname to attach to %s', hostname)
                                        response = rmc_wrapper_service.attach_recoveryset(recovery_set_id_from_copy,
                                                                                          hostname, False,
                                                                                          task_id=task_id,
                                                                                          volumelist=[rdm_vol_name])

                    except Exception as exp:
                        LOG.exception(exp)
                        msg = str(exp) + ": Restoring rdm disk(s) with wwn " + str(rdm_wwn_list) + " failed"
                        LOG.error(msg)
                        raise Exception(msg)

                # rescan the host hbas
                self.rescan_host_hba(host_name)

                if is_vm_deleted_from_vsphere is False:
                    vm_name_to_attach_rdm = cloned_vm_details['cloned_vm_name']
                else:
                    vm_name_to_attach_rdm = cloned_vm_details['parent_vm_name']

                self.attach_rdms_to_vm(cloned_vm_moref, vm_host, cloned_vm_rdm_full_details_list,
                                       vm_name_to_attach_rdm, '[' + target_datastore_name + ']')

                # then power on the cloned vm
                try:
                    if power_on is True:
                        self.power_on_vm(cloned_vm_moref)
                except Exception as exp:
                    try:
                        msg = "Powering on VM " + cloned_vms_moref_to_restore[cloned_vm_moref][
                            'parent_vm_name'] + " failed after successful restore."
                    except Exception:
                        msg = "Powering on VM " + cloned_vm_moref + " failed after successful restore."
                    LOG.error(msg)
                    raise Exception(msg)

                if is_vm_deleted_from_vsphere is False:
                    # if power on is also successful, then delete the original vm
                    try:
                        self.delete_vm(cloned_vm_details['parent_vm_moref'])
                    except Exception as exp:
                        msg = "Deleting VM " + cloned_vm_details['parent_vm_moref'] + " failed"
                        LOG.error(msg)
                        delete_failed_vms[cloned_vm_details['parent_vm_moref']] = \
                        vm_current_state[cloned_vm_details['parent_vm_moref']]['new_name']

                self._update_task(task_desc_string='Relocated virutal machine to datastore:' + target_datastore_name,
                                  task_percentage=90,
                                  task_state='Running',
                                  task_id=task_id,
                                  rmc_wrapper_service=rmc_wrapper_service,
                                  task_status='Initiated')

        except Exception as e:
            is_task_failed = True
            error_reason = str(e)
            LOG.exception("error: " + error_reason)

            if len(relocatedVms) > 0:
                self.delete_relocated_vms(relocatedVms)

            # if restoring of the vm is failed, then restore the rdm of original vm to existing state
            if is_rdm_snap_creation is True and len(rdm_wwn_list) >= 1 and \
                    rdm_snapshot_set_id is not None and len(rdm_volume_name_host_dict) > 0:
                try:
                    self.restore_from_recovery_set_using_wwn_list(recovery_set_id_from_copy, rdm_snapshot_set_id,
                                                                  rdm_volume_name_host_dict, rdm_wwn_list,
                                                                  rmc_wrapper_service, task_id)
                except Exception as exc:
                    LOG.exception(exc)
                    is_rdm_restore_to_orig_failed = True

            # rescan the host hbas
            self.rescan_host_hba(host_name)

            # reattach the original vm datastore
            if is_vm_deleted_from_vsphere is False and vm_current_state:
                vm_name_to_attach_rdm = vm_current_state[cloned_vm_details['parent_vm_moref']]['original_name']
                if orig_vm_rdm_full_details_list:
                    self.attach_rdms_to_vm(moref, vm_host, orig_vm_rdm_full_details_list,
                                           vm_name_to_attach_rdm, '[' + target_datastore_name + ']')
            if len(vm_current_state) > 0:
                self.restore_vms_to_original_state(vm_current_state)

        finally:
            if is_rdm_snap_creation is True and rdm_snapshot_set_id is not None:
                if is_rdm_restore_to_orig_failed is False:
                    try:
                        rmc_wrapper_service.delete_snapshot(rdm_snapshot_set_id, task_id=task_id)
                    except Exception as exc:
                        LOG.exception(exc)
                else:
                    task_state = 'Warning'
                    task_status = 'Warning'
                    tasc_desc = 'Failed to restore rdm snapshots to initial state. Use snapshot: \'' + rdm_snapshot_set_name + \
                                '\' in volume set: \'' + rmv_vmware_obj.recovery_set_name + '\' to restore respective rdm volumes to original state'

                    self._update_task(task_desc_string=tasc_desc,
                                      task_percentage=100,
                                      task_state=task_state,
                                      task_id=task_id,
                                      rmc_wrapper_service=rmc_wrapper_service,
                                      task_status=task_status)

            # if task is failed, then unregister the cloned vm, hence setting restored_vm_moref_list to None
            if is_task_failed is True:
                restored_vm_moref_list = None

            is_unmount_failed = False
            # If requested vms are cloned and mounted, then unmount the snapshot
            if copy_info and copy_info.type == rmv_utils.copy_type.SNAPSHOT:
                # TODO(jayadevk): check if we need to add retry logic here
                try:
                    if clone_details_resp is not None:
                        self.unmount_snapshot_esx(context, clone_details_resp.get('recovery_set_id'), x_auth_token,
                                                  host_name, None,
                                                  task_id, True, copy_id, clone_details_resp.get('id'), True,
                                                  unregister_skip_vm_moref_list=restored_vm_moref_list)
                    elif recovery_set_id:
                        self.unmount_snapshot_esx(context, recovery_set_id, x_auth_token, host_name, None,
                                                  task_id, True, copy_id, None, True,
                                                  unregister_skip_vm_moref_list=restored_vm_moref_list)
                except Exception as ex:
                    is_unmount_failed = True
                    LOG.exception(ex)
                    msg = self.extract_msg_from_exception(ex)
                    self._update_task(task_desc_string=msg,
                                      task_percentage=90,
                                      task_state='Warning',
                                      task_id=task_id,
                                      rmc_wrapper_service=rmc_wrapper_service,
                                      task_status='Warning')

            elif copy_info and (
                    copy_info.type == rmv_utils.copy_type.EXPRESS_PROTECT or copy_info.type == rmv_utils.copy_type.CATALYST_COPY) \
                    and is_recover_task_successful is True and is_ert_already_unmounted is False:
                try:
                    self.unmount_backup_esx(context,
                                            copy_id,
                                            x_auth_token,
                                            host_name,
                                            rmv_utils.REQUEST_BODY_PARAM_ESX_HOST_IP,
                                            task_id,
                                            True,
                                            rmc_copyset_id,
                                            ds_mount_path_dir, clone_details_resp.get('id'),
                                            unregister_skip_vm_moref_list=restored_vm_moref_list)
                except Exception as ex:
                    is_unmount_failed = True
                    LOG.exception(ex)
                    msg = self.extract_msg_from_exception(ex)
                    self._update_task(task_desc_string=msg,
                                      task_percentage=90,
                                      task_state='Warning',
                                      task_id=task_id,
                                      rmc_wrapper_service=rmc_wrapper_service,
                                      task_status='Warning')
            elif copy_info and copy_info.type == rmv_utils.copy_type.CLOUD_COPY:
                task_state = 'Failed'
                task_status = 'Error'
                tasc_desc = 'Could not restore VM \'' + ",".join(vm_dict.keys()) + '\' to datastore: \'' \
                            + target_datastore_name + '\'. Reason: ' + error_reason

                self._update_task(task_desc_string=tasc_desc,
                                  task_percentage=100,
                                  task_state=task_state,
                                  task_id=task_id,
                                  rmc_wrapper_service=rmc_wrapper_service,
                                  task_status=task_status)
                return

            if len(delete_failed_vms) > 0:
                delete_failed_vm_names = delete_failed_vms.values()
                self._update_task(
                    task_desc_string='Unable to delete virtual machines:' + "".join(delete_failed_vm_names),
                    task_percentage=100,
                    task_state='Warning',
                    task_id=task_id,
                    rmc_wrapper_service=rmc_wrapper_service,
                    task_status='Warning')

            # Update moref of newly relocated VM in rmcv_virtual_machines database and workflow
            if is_task_failed is False:
                for vm_db_id, orig_moref in vm_db_id_to_moref_dict.items():
                    updated_moref = {'moref': orig_to_cloned_vm_moref_dict[orig_moref]}
                    self.db.update_rmcv_virtual_machines(context, vm_db_id, updated_moref, read_deleted="no")
                self.update_resource_id_in_workflow_by_moref(rmc_wrapper_service, orig_to_cloned_vm_moref_dict)

                # If vm was deleted and then restored from deleted resources, we need to set status is available
                if is_vm_deleted_from_vsphere is True:
                    values = {}
                    for vm_db_id, orig_moref in vm_db_id_to_moref_dict.items():
                        values['status'] = 'available'
                        vm_moref = orig_to_cloned_vm_moref_dict[orig_moref]
                        self.db.update_rmcv_virtual_machine_by_moref(context, vm_moref, values)

            if is_task_failed is True:
                task_state = 'Failed'
                task_status = 'Error'
                if target_datastore_name:
                    tasc_desc = 'Could not restore VM \'' + ",".join(vm_dict.keys()) + '\' to datastore: \'' \
                                + target_datastore_name + '\'. Reason: ' + error_reason + '.' \
                                + ' Use the Clone operation to recover the VM.'
                else:
                    tasc_desc = 'Could not restore VM \'' + ",".join(vm_dict.keys()) \
                                + '\'. Reason: ' + error_reason + '.' \
                                + ' Use the Clone operation to recover the VM.'
            else:
                if is_rdm_restore_to_orig_failed is False and is_unmount_failed is False:
                    task_state = 'Completed'
                    task_status = 'Ok'
                else:
                    task_state = 'Warning'
                    task_status = 'Warning'
                tasc_desc = 'Restoring VM \'' + ",".join(
                    vm_dict.keys()) + '\' to datastore: \'' + target_datastore_name + '\' is successful'

            self._update_task(task_desc_string=tasc_desc,
                              task_percentage=100,
                              task_state=task_state,
                              task_id=task_id,
                              rmc_wrapper_service=rmc_wrapper_service,
                              task_status=task_status)

            LOG.debug("restore_virtual_machines_using_snapshot_or_backup: Exit")

    def get_disk_relocate_spec(self, context, cloned_vms_moref_to_restore, virtual_machines_to_restore, copy_id):
        LOG.info("get_disk_relocate_spec : enter")

        disk_uuid_to_virtual_disk_mapping = {}

        cloned_vm_moref = cloned_vms_moref_to_restore.keys()[0]
        cloned_vm_moref = pyvmomi_util.get_moref(cloned_vm_moref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
        cloned_vm_oc = self.vi_helper.get_object_properties(cloned_vm_moref, "config.hardware.device")
        vm_prop = pyvmomi_util.extract_properties(cloned_vm_oc[0])
        cloned_vm_device_list = vm_prop.get("config.hardware.device")
        for vm_device in cloned_vm_device_list:
            if vm_device._wsdlName == "VirtualDisk":
                # We should not consider RDM disks during VM relocate. So ignoring RDM disks.
                if vm_device.backing._wsdlName == "VirtualDiskFlatVer2BackingInfo":
                    disk_uuid = vm_device.backing.uuid
                    disk_uuid_to_virtual_disk_mapping[disk_uuid] = vm_device

        current_disk_uuid_to_virtual_disk_mapping = {}
        current_vm_oc = None

        if virtual_machines_to_restore is not None:
            current_mo_ref = virtual_machines_to_restore[0]
            current_mo_ref = pyvmomi_util.get_moref(current_mo_ref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
            try:
                current_vm_oc = self.vi_helper.get_object_properties(current_mo_ref,
                                                                     ["datastore", "config.hardware.device"])
            except exception as e:
                pass

        if current_vm_oc:
            current_vm_prop = pyvmomi_util.extract_properties(current_vm_oc[0])
            current_vm_device_list = current_vm_prop.get("config.hardware.device")
            for vm_device in current_vm_device_list:
                if vm_device._wsdlName == "VirtualDisk":
                    # We should not consider RDM disks during VM relocate. So ignoring RDM disks.
                    if vm_device.backing._wsdlName == "VirtualDiskFlatVer2BackingInfo":
                        disk_uuid = vm_device.backing.uuid
                        current_file_name = vm_device.backing.fileName
                        current_ds_name = current_file_name.split("] ")[0].replace("[", "")

                        temp_dict = {}
                        temp_dict['ds_name'] = current_ds_name
                        temp_dict['ds_moref'] = vm_device.backing.datastore
                        current_disk_uuid_to_virtual_disk_mapping[disk_uuid] = temp_dict
        else:
            vm_assoc_details = self.db.get_rmcv_vm_copy_assoc_by_copy_id(context, copy_id)
            vmdks = vm_assoc_details.vmdks
            for vmdk in vmdks:
                vmdk_id = vmdk.get("vmdk_id")
                ds_id = vmdk.get("datastore_id")

                ds_details = self.db.get_datastore_by_id(context, ds_id)
                ds_name = ds_details.name
                ds_moref = pyvmomi_util.get_moref(ds_details.moref, rmv_utils.VMWARE_OBJECT_TYPE_DS)

                vmdk_details = self.db.get_vmdk_by_id(context, vmdk_id)
                vmdk_uuid = vmdk_details.uuid
                # vmdk_filename = vmdk_details.filename
                temp_dict = {}
                temp_dict['ds_name'] = ds_name
                temp_dict['ds_moref'] = ds_moref
                current_disk_uuid_to_virtual_disk_mapping[vmdk_uuid] = temp_dict

        is_disk_level_restore_supported = True

        relocate_disk_spec_list = []
        vm_device_list = disk_uuid_to_virtual_disk_mapping.values()
        for vm_device in vm_device_list:

            disk_uuid = vm_device.backing.uuid
            cloned_file_name = vm_device.backing.fileName
            cloned_ds_name = cloned_file_name.split("] ")[0].replace("[", "").split("-")[2]

            current_vm_device = current_disk_uuid_to_virtual_disk_mapping.get(disk_uuid)
            if current_vm_device:

                current_ds_name = current_vm_device.get('ds_name')
                dest_ds_moref = current_vm_device.get('ds_moref')

                LOG.info("current_ds_name : %s " % current_ds_name)
                LOG.info("cloned_ds_name : %s " % cloned_ds_name)
                if current_ds_name == cloned_ds_name:
                    backing_info = vm_device.backing
                    disk_id = int(vm_device.key)

                    relocate_disk_spec = pyvmomi_util.get_vm_RelocateSpecDiskLocator(backing_info, disk_id,
                                                                                     dest_ds_moref)
                    relocate_disk_spec_list.append(relocate_disk_spec)

                else:
                    is_disk_level_restore_supported = False
                    LOG.info("Virtual Disk is moved to a different datastore.")

                    break
            else:
                is_disk_level_restore_supported = False
                LOG.info("Virtual Disk got deleted")

                break

        if not is_disk_level_restore_supported:
            relocate_disk_spec_list = None

        LOG.info("get_disk_relocate_spec : exit")
        return relocate_disk_spec_list

    def get_matching_rdm_wwn_from_copy(self, orig_vm_rdm_full_details_list, rdm_wwn_list):
        LOG.debug('get_matching_rdm_wwn_from_copy: Enter')
        matched_wwn_list = []
        vm_lun_wwn_list = map(lambda x: x['lun_wwn'], orig_vm_rdm_full_details_list)
        # TODO(jayadevk): Check if can be written in lambda
        for rdm_wwn_catalog in rdm_wwn_list:
            for lun_wwn_current in vm_lun_wwn_list:
                if rdm_wwn_catalog.lower() == lun_wwn_current.lower():
                    matched_wwn_list.append(rdm_wwn_catalog)
        LOG.debug('get_matching_rdm_wwn_from_copy: Exit')
        return matched_wwn_list

    def attach_rdms_to_vm(self, cloned_vm_moref, host, rdm_details_list, vm_name_to_attach_rdm,
                          vmdk_file_path):
        LOG.debug('attach_rdms_to_vm: Enter')
        try:
            scsi_luns = host.config.storageDevice.scsiLun
            rdm_count = 0
            cloned_vm_moref_obj = pyvmomi_util.get_moref(cloned_vm_moref, "VirtualMachine")
            controller_key_unit_dict = {}
            # Get unit and device key details based on controller
            for rdm_details in rdm_details_list:
                ctrl_key = rdm_details.get('controller_key')
                device_key = rdm_details.get('device_key')
                unit_num = rdm_details.get('unit_number')
                if not ctrl_key in controller_key_unit_dict:
                    controller_key_unit_dict[ctrl_key] = []
                controller_key_unit_dict[ctrl_key].append({'unit_number': unit_num, 'device_key': device_key})

            for rdm_details in rdm_details_list:
                rdm_lun_uuid = rdm_details.get('lun_uuid')
                rdm_lun_wwn = rdm_details.get('lun_wwn')
                lun_uuid = None
                device_name = None
                for scsi_lun in scsi_luns:
                    if len(scsi_lun.canonicalName.split("naa.")) > 1:
                        lun_wwn = scsi_lun.canonicalName.split("naa.")[1] if scsi_lun.canonicalName else None
                    elif len(scsi_lun.canonicalName.split("eui.")) > 1:
                        lun_wwn = scsi_lun.canonicalName.split("eui.")[1] if scsi_lun.canonicalName else None

                    if lun_wwn == rdm_lun_wwn:
                        device_name = scsi_lun.deviceName
                        lun_uuid = scsi_lun.uuid
                        break
                if lun_uuid:
                    disk_mode = rdm_details.get('disk_mode')
                    sharing_mode = rdm_details.get('sharing_mode')
                    disk_compatibility_mode = rdm_details.get('compatibility_mode')
                    ctrl_key = rdm_details.get('controller_key')
                    device_details = controller_key_unit_dict[ctrl_key].pop()
                    device_key = int(device_details.get('device_key'))
                    unit_num = int(device_details.get('unit_number'))
                    # If you add a SCSI controller, you can reassign an existing or new hard disk or device to that controller.
                    # For example, you can assign the device to (1:z ), where 1 is SCSI controller 1 and z is a
                    # virtual device node from 0 to 15. For SCSI controllers, z cannot be 7. By default, the virtual SCSI
                    # controller is assigned to virtual device node (z:7), so that device node is unavailable for hard disks or other devices.
                    if unit_num == 7:
                        unit_num = unit_num + 1
                    # TODO(karthik): Relook for all the device types
                    # if unit_num > 15:
                    #     msg = "Maximum allowed unit number for controller is 15"
                    #     LOG.error(msg)
                    #     raise Exception(msg)

                    rdm_count += 1
                    # vm_name = props.get('name')
                    vm_name = vm_name_to_attach_rdm
                    vmdk_name = vm_name + "_rdm_" + str(rdm_count) + ".vmdk"
                    new_file_name = vmdk_file_path.split("/")[0] + "/" + vm_name + "/" + vmdk_name
                    LOG.debug("new_file_name - %s", new_file_name)
                    LOG.info("Adding new RDM Disk : '%s' " % new_file_name)
                    LOG.debug('device_name - %s', device_name)
                    LOG.debug('controller key - %s', str(ctrl_key))
                    LOG.debug('unit number - %s', str(unit_num))
                    LOG.debug('device key - %s', str(device_key))
                    add_spec = pyvmomi_util.get_vm_virtual_disk_device_config_spec(new_file_name,
                                                                                   device_name,
                                                                                   ctrl_key,
                                                                                   unit_num,
                                                                                   device_key,
                                                                                   "add",
                                                                                   file_operation="create",
                                                                                   backing_type="VirtualDiskRawDiskMappingVer1BackingInfo",
                                                                                   disk_mode=disk_mode,
                                                                                   disk_compatibility_mode=disk_compatibility_mode,
                                                                                   sharing_mode=sharing_mode)
                    try:
                        self.vi_helper.reconfig_vm_task(cloned_vm_moref_obj, add_spec)
                    except Exception as exp:
                        LOG.exception(exp)
                        controller_key_unit_dict[ctrl_key].append({'unit_number': unit_num, 'device_key': device_key})
                        raise Exception(exp)
                else:
                    msg = "Unable to find the scsi device for rdm device with lunUuid " + rdm_lun_uuid
                    LOG.error(msg)
                    raise Exception(msg)
            LOG.debug('attach_rdms_to_vm: Exit')
        except Exception as exc:
            LOG.exception(exc)
            raise Exception(exc)

    def detach_rdm_from_vm_native_vm(self, moref, orig_vm_rdm_full_details_list):
        LOG.debug('detach_rdm_from_vm_native_vm: Enter')
        try:
            vm_moref = pyvmomi_util.get_moref(moref, "VirtualMachine")
            for orig_vm_details in orig_vm_rdm_full_details_list:
                orig_vm_file_path = orig_vm_details['vmdk_filename']
                orig_controller_key = orig_vm_details['controller_key']
                orig_unit_number = orig_vm_details['unit_number']
                orig_device_key = orig_vm_details['device_key']
                delete_spec = pyvmomi_util.get_vm_virtual_disk_device_config_spec(orig_vm_file_path,
                                                                                  None,
                                                                                  orig_controller_key,
                                                                                  orig_unit_number,
                                                                                  orig_device_key,
                                                                                  "remove",
                                                                                  file_operation="destroy",
                                                                                  backing_type="VirtualDiskRawDiskMappingVer1BackingInfo")
                self.vi_helper.reconfig_vm_task(vm_moref, delete_spec)
        except Exception as ex:
            LOG.exception(ex)
            raise Exception(ex)
        LOG.debug('detach_rdm_from_vm_native_vm: Exit')

    def get_vm_rdm_config_details(self, moref, vm_rdm_full_details_list):
        LOG.debug('get_vm_rdm_config_details: Enter')
        try:
            vmdk_file_path = None
            vm_moref = pyvmomi_util.get_moref(moref, "VirtualMachine")
            vm_hardware_device_oc = self.vi_helper.get_object_properties(vm_moref, ["name",
                                                                                    "config.hardware.device",
                                                                                    "runtime.host"])
            props = pyvmomi_util.extract_properties(vm_hardware_device_oc[0])
            host = props.get('runtime.host')
            vm_hardware_device_list = props.get("config.hardware.device")
            scsi_luns = host.config.storageDevice.scsiLun
            for vm_hardware_device in vm_hardware_device_list:
                if vm_hardware_device._wsdlName == "VirtualDisk":
                    tempDict = {}
                    virtual_disk = vm_hardware_device.backing
                    vmdk_file_path = virtual_disk.fileName
                    # In case of mounting snapshot/backup to same ESXi then RDM disk type = RawDisk
                    # In case of mounting snapshot/backup to other ESXi, then RDM disk type = FlatDisk
                    if virtual_disk._wsdlName == "VirtualDiskRawDiskMappingVer1BackingInfo":
                        tempDict['vmdk_filename'] = virtual_disk.fileName
                        tempDict['controller_key'] = vm_hardware_device.controllerKey
                        tempDict['compatibility_mode'] = virtual_disk.compatibilityMode
                        tempDict['sharing_mode'] = virtual_disk.sharing
                        tempDict['disk_mode'] = virtual_disk.diskMode
                        tempDict['unit_number'] = vm_hardware_device.unitNumber
                        tempDict['device_key'] = vm_hardware_device.key
                        tempDict['lun_uuid'] = virtual_disk.lunUuid
                        tempDict['device_name'] = virtual_disk.deviceName
                        tempDict['lun_wwn'] = None
                        matching_scsi_lun = list(filter(lambda x: x.uuid == virtual_disk.lunUuid, scsi_luns))
                        if len(matching_scsi_lun) > 0:
                            if len(matching_scsi_lun[0].canonicalName.split("naa.")) > 1:
                                lun_wwn = matching_scsi_lun[0].canonicalName.split("naa.")[1] if matching_scsi_lun[
                                    0].canonicalName else None
                            elif len(matching_scsi_lun[0].canonicalName.split("eui.")) > 1:
                                lun_wwn = matching_scsi_lun[0].canonicalName.split("eui.")[1] if matching_scsi_lun[
                                    0].canonicalName else None
                            tempDict['lun_wwn'] = lun_wwn

                        # break
                        vm_rdm_full_details_list.append(tempDict)

            if not vmdk_file_path:
                msg = "File path of vmdk for original VM could not be found."
                raise Exception(msg)
        except Exception as ex:
            LOG.exception(ex)
            raise Exception(ex)
        LOG.debug('get_vm_rdm_config_details: Exit')
        return host

    def get_vm_rdm_details(self, moref, vm_moref_rdm_details_dict):
        LOG.debug('get_vm_rdm_details: Enter')
        vmInfo, hostInfo = self.get_virtual_machine_details(moref)
        VmType = vmInfo.VmType
        scsi_lun_values = vmInfo.VirtualCopyPairList
        LOG.debug(scsi_lun_values)
        for scsi_lun in scsi_lun_values:
            if scsi_lun.LunUsedAs == json_helper.virtual_copy_item_type.RDMLun:
                temp_rdm_details_dict = {}
                for restorable_item in scsi_lun.RestorableItemsList:
                    temp_rdm_details_dict['wwn'] = scsi_lun.InServBaseVolumeWwn
                    temp_rdm_details_dict['disk_mode'] = restorable_item.disk_mode
                    temp_rdm_details_dict['sharing_mode'] = restorable_item.sharing_mode
                    if restorable_item.Properties[
                        0] == json_helper.TpdVmVirtualMachineItemProperty.VirtualDiskRDMIsInVirtualCompatableMode:
                        temp_rdm_details_dict['disk_compatibility_mode'] = "virtualMode"
                    elif restorable_item.Properties[0] == \
                            json_helper.TpdVmVirtualMachineItemProperty.VirtualDiskRDMIsInPhysicalCompatableMode:
                        temp_rdm_details_dict['disk_compatibility_mode'] = "physicalMode"
                vm_moref_rdm_details_dict.append(temp_rdm_details_dict)
        LOG.debug('get_vm_rdm_details: Exit')

    def restore_from_recovery_set_using_wwn_list(self, current_recovery_set_id, rdm_snapshot_set_id,
                                                 rdm_volume_name_host_dict, rdm_wwn_list, rmc_wrapper_service, task_id):
        LOG.debug('restore_from_recovery_set_using_wwn_list: Enter')
        try:
            response = rmc_wrapper_service.detach_recoveryset(current_recovery_set_id, retainAttachInfo=False,
                                                              task_id=task_id,
                                                              volumelist=rdm_volume_name_host_dict.keys())
        except Exception as exp:
            msg = str(exp)
            LOG.exception(exp)
            raise Exception(msg)
        try:
            response = rmc_wrapper_service.restore_snapshot(rdm_snapshot_set_id, False, task_id, rdm_wwn_list)
        except Exception as exp:
            msg = str(exp)
            LOG.exception(exp)
            raise Exception(msg)
        finally:
            for rdm_vol_name, attached_hosts in rdm_volume_name_host_dict.items():
                for hostname in attached_hosts:
                    LOG.debug('hostname to attach to %s', hostname)
                    response = rmc_wrapper_service.attach_recoveryset(current_recovery_set_id,
                                                                      hostname, False, task_id=task_id,
                                                                      volumelist=[rdm_vol_name])
            # after attaching the wwn to hosts rescan the hba
            for hostname in rdm_volume_name_host_dict.values():
                self.rescan_host_hba(hostname)
        LOG.debug('restore_from_recovery_set_using_wwn_list: Exit')

    def get_datastore_of_vm_using_vmx(self, vm_ref_obj):
        LOG.debug('get_datastore_of_vm_using_vmx: Enter')
        vmPathName = self.vi_helper.get_object_properties(vm_ref_obj, "config.files.vmPathName")
        prop_dict = pyvmomi_util.extract_properties(vmPathName[0])
        vmx_path = prop_dict['config.files.vmPathName']
        datastore_name = vmx_path[vmx_path.find('[') + 1:vmx_path.find(']')]
        LOG.debug('get_datastore_of_vm_using_vmx: Exit')
        return datastore_name

    def get_datastore_moref_using_name(self, datastore_name):
        LOG.debug('get_datastore_moref_using_name: Enter')
        ds_name_moref_dict = self.vi_helper.pyvmomi_wrapper_obj.build_ds_name_to_moref_mapping_dict()
        datastore_moref = ds_name_moref_dict[datastore_name]
        LOG.debug('get_datastore_moref_using_name: Exit')
        return datastore_moref

    def update_resource_id_in_workflow_by_moref(self, rmc_wrapper_service,
                                                orig_to_cloned_vm_moref_dict):

        LOG.info("update_resource_id_in_workflow_by_moref : enter")

        for orig_moref, changed_moref in orig_to_cloned_vm_moref_dict.items():
            try:
                resource_type = "VirtualMachine"
                workflow_details = rmc_wrapper_service.get_work_flow_by_app_resource_id(orig_moref)

                # Always there will be only one workflow per app_resource_id. So taking 1st entry by default
                workflows = workflow_details.get('workflows')
                if workflows:
                    workflow = workflow_details.get('workflows')[0]
                    workflow_id = workflow.get('id')
                    protection_resource = workflow.get('protectionResource')
                    protection_resource['appResourceId'] = changed_moref

                    rmc_wrapper_service.update_workflow(workflow_id, protection_resource)

            except Exception as e:
                LOG.exception("Unable to get the update appResourceId. Ignore and continue. '%s' " % e)
                continue

        LOG.info("update_resource_id_in_workflow_by_moref : exit")

    def attachvmdk_snapshot(self,
                            context,
                            clone_id,
                            x_auth_token,
                            attachvmdk_input,
                            task_id):
        LOG.info("manager attachvmdk_snapshot :Enter")
        LOG.info("attachvmdk_input=%s", attachvmdk_input)

        object_type = rmv_utils.TASK_OBJECT_TYPE
        mo_ref = rmv_utils.TASK_MO_REF
        msg = 'Begin Snapshot VMDK Attach Operation'
        vm_task_helper = VmTaskHelper(self.vi_helper)

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        exception_lock_attach = False
        task_status = "Initiated"
        operation_task_state = rmv_utils.OPERATION_STATE_FAILURE

        vm_task_helper.CustomVMwareTaskBegin(object_type,
                                             mo_ref,
                                             "SnapshotVMDKAttachTask",
                                             "SnapshotVMDKAttachFailedFault")

        self._update_task('Waiting for snapshot lock',
                          5,
                          'Running',
                          task_id,
                          rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)  # vm_task_helper)
        LOG.debug("Trying to acquire snapshot lock")
        LOG.debug("Locking Snapshot : '%s'" % clone_id)
        try:
            lock_response = rmv_utils.acquire_snapshot_operation_lock(self.snapshot_id_dict, clone_id,
                                                                      self.vi_helper.validated_username)
            if lock_response:
                exception_lock_attach = True
                LOG.error("Could not acquire snapshot lock.")
                raise rmv_exception.SnapshotLockException(error=lock_response)

            LOG.info("Locked Snapshot : '%s'" % clone_id)

            self._update_task('Acquired snapshot lock',
                              10,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)  # vm_task_helper)

            clone = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_status = clone.status
            clone_info = clone.clone_details
            cloned_ds_info = clone_info.get('cloned_ds_details')
            attached_vmdks = clone_info.get('attached_vmdks_details', list())

            sourceDatastoreName = attachvmdk_input[rmv_utils.SOURCE_DATASTORE_NAME]
            parentDatastoreName = attachvmdk_input[rmv_utils.PARENT_DATASTORE_NAME]
            vmdk_path = attachvmdk_input[rmv_utils.VMDK_SOURCE_FILE]
            source_vmdk_path = "[" + sourceDatastoreName + "] " + vmdk_path
            parent_vmdk_path = "[" + parentDatastoreName + "] " + vmdk_path

            LOG.info('vmdk file to be attached: %s' % source_vmdk_path)
            vm_moref = attachvmdk_input['virtualMachineMoref']
            vm_moref_obj = vim.get_moref(vm_moref, "VirtualMachine")
            vm_name = self.vi_helper.get_managed_object_ref_name(vm_moref_obj)
            vmdkId = attachvmdk_input.get(rmv_utils.VMDK_ID)
            vmdk_info = self.db.get_vmdk_with_vm_info(context, vmdkId)
            # vmdkType = attachvmdk_input['vmdkType']

            vmTsk = self.vi_helper.attachVmdkToVMVer2(vm_moref,
                                                      source_vmdk_path)
            # Updating Attached vmdk details into DB
            clone_status_json = json_helper.clone_status
            vmdk_details = json_helper.attached_vmdks_detail_json()
            vmdk_details.source_vmdk_path = source_vmdk_path
            vmdk_details.parent_vmdk_path = parent_vmdk_path
            vmdk_details.target_vm_moref = vm_moref
            vmdk_details.target_vm_name = vm_name
            if vmdk_info:
                vmdk_details.parent_vm_name = vmdk_info.vm_name
                vmdk_details.parent_vm_moref = vmdk_info.moref
            attached_vmdks.append(vmdk_details.__dict__)
            clone_info['attached_vmdks_details'] = attached_vmdks
            if clone_status == clone_status_json.mounted:
                clone_status = clone_status_json.vmdk_attached
            elif clone_status == clone_status_json.cloned:
                clone_status = clone_status_json.cloned_attached
            values = {'status': clone_status, 'clone_details': clone_info}
            self.db.update_rmcv_clone_by_clone_id(context, clone_id, values)
            operation_task_state = rmv_utils.OPERATION_STATE_SUCCESS

        except Exception as e:
            LOG.exception(("attachvmdk failed: : '%s'") % e)
            operation_task_state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            elif hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                msg = e.message
            else:
                LOG.error(('%s'), e)
                msg = "Internal error"

        finally:
            if not exception_lock_attach:
                # Release the aquired snapshot lock
                rmv_utils.release_snapshot_operation_lock(self.snapshot_id_dict, clone_id)
                LOG.info(("Released Lock for snapshot '%s'") % clone_id)

            if operation_task_state == rmv_utils.OPERATION_STATE_FAILURE:
                task_desc_string = ("attach vmdk operation failed: '%s'" % msg)
                LOG.error(task_desc_string)
                task_status = "Error"
                task_state = 'Failed'
                task_percentage = 100
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            if operation_task_state == rmv_utils.OPERATION_STATE_SUCCESS:
                task_desc_string = "attach vmdk operation completed succesfully:"
                task_status = "Ok"
                task_state = 'Completed'
                task_percentage = 100
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

        LOG.info("manager attachvmdk_snapshot :Exit")
        return

    def detachvmdk_snapshot(self,
                            context,
                            clone_id,
                            x_auth_token,
                            detachvmdk_input,
                            task_id):
        LOG.info("manager detachvmdk_snapshot :Enter")
        LOG.debug("detachvmdk_input=%s", detachvmdk_input)

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        exception_lock_detach = False
        operation_task_state = rmv_utils.OPERATION_STATE_FAILURE

        object_type = rmv_utils.TASK_OBJECT_TYPE
        mo_ref = rmv_utils.TASK_MO_REF
        msg = 'Begin Snapshot VMDK Detach Operation'
        vm_task_helper = VmTaskHelper(self.vi_helper)

        vm_task_helper.CustomVMwareTaskBegin(object_type,
                                             mo_ref,
                                             "SnapshotVMDKDetachTask",
                                             "SnapshotDetachFailedFault")

        task_status = "Initiated"
        self._update_task('Waiting for snapshot lock',
                          5,
                          'Running',
                          task_id,
                          rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)  # vm_task_helper)
        LOG.debug("Trying to acquire snapshot lock")
        # with self.lock:
        LOG.debug("Locking Snapshot : '%s'" % clone_id)
        try:
            lock_response = rmv_utils.acquire_snapshot_operation_lock(self.snapshot_id_dict, clone_id,
                                                                      self.vi_helper.validated_username)
            if lock_response:
                exception_lock_detach = True
                LOG.error("Could not acquire snapshot lock.")
                raise rmv_exception.SnapshotLockException(error=lock_response)

            LOG.info("Locked Snapshot : '%s'" % clone_id)

            LOG.info("Acquired snapshot lock")
            self._update_task('Acquired snapshot lock',
                              10,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)  # vm_task_helper)

            clone = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_status = clone.status
            clone_info = clone.clone_details
            cloned_ds_info = clone_info.get('cloned_ds_details')
            attached_vmdks = clone_info.get('attached_vmdks_details', list())
            vmdk = detachvmdk_input[rmv_utils.VMDK_SOURCE_FILE]
            vm_moref = None

            for attached_vmdk in attached_vmdks:
                if attached_vmdk['source_vmdk_path'] == detachvmdk_input[rmv_utils.VMDK_SOURCE_FILE]:
                    vm_moref = attached_vmdk.get('target_vm_moref')
                    break
            LOG.info('vm moref from db clones: %s' % vm_moref)

            vmTsk = self.vi_helper.detachVmdkToVMVer2(vm_moref,
                                                      vmdk)
            # Updating detached vmdk details into DB
            self.update_rmcv_clones_detach_vmdk_details(context, clone_id, clone, vmdk)
            operation_task_state = rmv_utils.OPERATION_STATE_SUCCESS
        except rmv_exception.VMDKNotFound as e:
            LOG.exception(("detachvmdk failed: : '%s'") % e)
            operation_task_state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            elif hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                msg = e.message
            else:
                LOG.error(('%s'), e)
                msg = "Internal error"
            # Updating vmdk details in DB if the vmdk detached manually without using RMC-V
            self.update_rmcv_clones_detach_vmdk_details(context, clone_id, clone, vmdk)

            LOG.error(('%s'), msg)

        except Exception as e:
            LOG.exception(("detachvmdk failed: : '%s'") % e)
            operation_task_state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            elif hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                msg = e.message
            else:
                LOG.error(('%s'), e)
                msg = "Internal error"

            LOG.error(('%s'), msg)
        finally:
            if not exception_lock_detach:
                # Release the aquired snapshot lock
                rmv_utils.release_snapshot_operation_lock(self.snapshot_id_dict, clone_id)
                LOG.info(("Released Lock for snapshot '%s'") % clone_id)
            if operation_task_state == rmv_utils.OPERATION_STATE_FAILURE:
                task_desc_string = ("detach vmdk operation failed: '%s'" % msg)
                LOG.error(task_desc_string)
                task_state = 'Failed'
                task_status = "Error"
                task_percentage = 100
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            if operation_task_state == rmv_utils.OPERATION_STATE_SUCCESS:
                task_desc_string = "detach vmdk operation completed successfully"
                LOG.debug(task_desc_string)
                task_state = 'Completed'
                task_percentage = 100
                task_status = "Ok"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

        LOG.info("manager detachvmdk_snapshot :Exit")
        return

    def update_rmcv_clones_detach_vmdk_details(self, context, clone_id, clone, detach_vmdk_path):
        LOG.debug("update rmcv clones detach vmdk details::Enter")
        LOG.info("detached VMDK path %s" % detach_vmdk_path)
        try:
            clone_status = clone.status
            clone_info = clone.clone_details
            clone_status_json = json_helper.clone_status
            temp_vmdk_info = []
            attached_vmdks = clone_info.get('attached_vmdks_details', list())

            for vmdk_dict in attached_vmdks:
                if vmdk_dict['source_vmdk_path'] != detach_vmdk_path:
                    temp_vmdk_info.append(vmdk_dict)
            clone_info['attached_vmdks_details'] = temp_vmdk_info
            if clone_status == clone_status_json.vmdk_attached and len(temp_vmdk_info) == 0:
                clone_status = clone_status_json.mounted
            elif clone_status == clone_status_json.cloned_attached and len(temp_vmdk_info) == 0:
                clone_status = clone_status_json.cloned

            values = {'status': clone_status, 'clone_details': clone_info}
            self.db.update_rmcv_clone_by_clone_id(context, clone_id, values)

        except Exception as e:
            LOG.exception("Unable to update the clone details after performing detach vmdk operation %s", e)
        LOG.debug("update rmcv clones detach vmdk details::Exit")

    # def get_ref_from_vmname(self,backup_vmname):
    #     """
    #     This method returns the back up vm moref on the basis of vmname
    #     :param backup_vmname: back up vm name
    #     :return :backup vm moref
    #     """
    #     vm_vv_map_cache = None
    #     redirectIO_DS_Name_ref = None
    #     cache = BackupJobManager.web_client_cache.cached_vm_centers
    #     vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()
    #     for ip in range(len(vcenter_ip)):
    #         vcenter_obj = cache.get(vcenter_ip[ip])
    #         vm_vv_map_cache = vcenter_obj.vm_vv_map
    #     for dstr in range(len(vm_vv_map_cache.datastores)):
    #         vm_list = vm_vv_map_cache.find_all_vms_in_datastore(dstr)
    #         for item in vm_list :
    #             for vmname, vmmoref in item.iteritems():
    #                 if vmname == backup_vmname:
    #                     backup_vmref = vmmoref
    #                     return backup_vmref

    def register_vm_from_backup_clone(self, context, clone_id, x_auth_token, operation_input, task_id):
        LOG.debug("Register VM from backup clone :: Enter")

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        task_state = 'Running'
        task_status = "Initiated"
        task_desc_string = "Initiate Register virtual machine.."
        task_percentage = 10
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service, None,
                          task_status=task_status)

        try:
            clone_status = json_helper.clone_status
            clone_info = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_details = clone_info.get('clone_details', dict())
            pre_operation_registered_vms_count = len(clone_details.get('cloned_virtual_machines', list()))
            esx_host_name = clone_info.esxi_host_name
            copy_id = clone_info.parent_copy_id
            inventoryMoref = operation_input.get("inventoryMoref")
            newVmName = operation_input.get("newVmName")
            powerOnVM = operation_input.get("powerOnVM")
            redirectIODatastoreName = operation_input.get("redirectIODatastoreName")
            vm_list = operation_input.get("vm_list")
            object = operation_input.get("objectId")
            vm_dict = {}
            for vm in vm_list:
                parent_vm_id = vm['parent_vm_id']
                vm_info = self.db.get_virtual_machine_by_id(context, parent_vm_id)
                recover_vm = vm_info.name
                vm_dict[recover_vm] = vm_info.moref
            response = self.register_vm_from_restored_ds(context, x_auth_token,
                                                         rmc_wrapper_service, esx_host_name,
                                                         vm_dict, inventoryMoref, copy_id, object,
                                                         None, clone_info, task_id, newVmName, powerOnVM,
                                                         redirectIODatastoreName)

            if response.get('status') == clone_status.mounted:
                response['status'] = clone_status.cloned
            elif response.get('status') == clone_status.vmdk_attached:
                response['status'] = clone_status.cloned_attached
            self.db.update_rmcv_clone_by_clone_id(context, clone_id, response)
            post_operation_clone_details = response.get('clone_details', dict())
            post_operation_registered_vms_count = len(
                post_operation_clone_details.get('cloned_virtual_machines', list()))
            if post_operation_registered_vms_count == pre_operation_registered_vms_count:
                task_desc_string = "Registering VMs operation was unsuccessful"
                task_state = 'Failed'
                task_status = "Error"
                task_percentage = 100
            elif post_operation_registered_vms_count == pre_operation_registered_vms_count + len(vm_list):
                task_desc_string = "Registering VMs operation completed succesfully"
                task_state = 'Completed'
                task_status = "Ok"
                task_percentage = 100
            else:
                task_desc_string = "Registering VMs operation partialy completed. Check sub tasks for more information"
                task_state = 'Completed'
                task_status = "Warning"
                task_percentage = 100

        except Exception as e:
            task_state = 'Failed'
            task_status = "Error"
            task_desc_string = "registering Vms was unsuccessful"
            task_percentage = 100

        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service, None,
                          task_status=task_status)

        LOG.debug("Register VM from backup clone :: Exit")

    def register_vm_operations(self,
                               context,
                               copy_id,
                               x_auth_token,
                               operation_input,
                               task_id,
                               clone_details,
                               is_vm_relocate_task=False):
        """
        This method calls the Register operation on VM from Express Protect Object on to
        a Virtual Machine
        Creates folder with vm name given by user on target datastore.
        Creates snapshot for the virtual machine on target datastore.
        :param context: context
        :param copy_id: copy_id
        :param x_auth_token: auth_token
        :param opertion_input: input values for the register operation
        :param operation_type: registervm fot the register operation
        :param task_id: RMC Operation Task ID
        :return: None
        """
        LOG.info("Enter: backup_register_vm_operations")
        register_task = None
        reconfig_task = None
        isDatastore = False
        isVMLevel = False
        redirect_io_ds_name_ref = None

        object_type = rmv_utils.TASK_OBJECT_TYPE
        mo_ref = rmv_utils.TASK_MO_REF
        rmc_wrapper_service = None

        state = rmv_utils.OPERATION_STATE_FAILURE
        msg = "Begin Instant Virtual Machine Recovery from Express Protect Object"
        vm_task_helper = VmTaskHelper(self.vi_helper)
        target_snapshot_folder = None
        backup_operation_lock = None
        datacenter_moref = None
        registered_vm_moref = None
        powerOn = "False"
        registered_details = {}

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            self.vi_helper.LogEvent(mo_ref, object_type, msg)
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 "VirtualMachineInstantRecoveryTask",
                                                 "VirtualMachineInstantRecoveryFailedFault")

            task_desc_string = 'Initiate Virtual Machine Instant Recovery...'
            task_percentage = 10
            task_state = 'Running'
            task_status = "Initiated"

            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            LOG.debug("Acquiring lock on backup object")
            backup_operation_lock = False
            with rmv_locks.backup_op_lock:
                # Acquire operation lock on backup object
                self.acquire_backup_operation_lock(copy_id, "register_vm_operation")
                backup_operation_lock = True

            # Prepare input for registration operation on vm
            source_datastore_name = operation_input[rmv_utils.VM_DATASTORENAME]
            vmx_sourcefilepath = "[" + operation_input['sourceDatastoreName'] + "] " + \
                                 operation_input['vmxFilePath']
            vm_hostname = operation_input[rmv_utils.HOST_SYSTEM]
            vm_respool = operation_input[rmv_utils.RESOURCE_POOL]
            redirect_io_ds_name = operation_input[rmv_utils.VM_REDIRECTIODSNAME]
            vm_astemplate = operation_input[rmv_utils.TEMPLATE]
            inventoryMoref = operation_input[rmv_utils.INVENTORYMOREF]
            inventorytype = operation_input[rmv_utils.INVENTORYTYPE]
            vm_name = operation_input[rmv_utils.VM_VMNAME]
            powerOn = operation_input[rmv_utils.VM_POWERON]
            objectId = operation_input.get(rmv_utils.VMWARE_OBJECT, None)
            virtual_machine_id = operation_input.get("vm_id", None)

            if not virtual_machine_id and objectId:
                vmware_object_type = objectId.split(':')[0]
                object_ref_id = objectId.split(':')[1]
                vmware_object = self.db_utils.get_vmware_object_by_object_type_and_moref(context, vmware_object_type,
                                                                                         object_ref_id)
                if not vmware_object:
                    msg = "Unable to fetch the VirtulaMachine [%s] details from backup object" % objectId
                    LOG.error(msg)
                else:
                    virtual_machine_id = vmware_object.id

            if not vm_name:
                name = operation_input['vmxFilePath'].split("/")[1].split(".")[0]
                vm_name = name + "_" + operation_input['sourceDatastoreName']

            # Get Ds name and its moref mapping dict of all the DS present in vCenter.
            ds_name_to_moref_dict = self.vi_helper.get_ds_names_to_moref_dict()

            if redirect_io_ds_name:
                redirect_io_ds_name_ref = self.get_datastore_ref_from_name(redirect_io_ds_name, ds_name_to_moref_dict)
                if not redirect_io_ds_name_ref:
                    msg = "Unable to fetch re-direct IO datastore [%s] information from ESXi host" % redirect_io_ds_name
                    raise exception.RegisterVmException(msg)

            source_datastore_moref = self.get_datastore_ref_from_name(source_datastore_name, ds_name_to_moref_dict)
            if not source_datastore_moref:
                msg = "Unable to fetch datastore [%s] information from ESXi host" % source_datastore_name
                raise exception.RegisterVmException(msg)

            vm_hostname_ref = self.get_hostref_from_name(vm_hostname)
            if not vm_hostname_ref:
                msg = "Unable to fetch ESXi host [%s] information" % vm_hostname
                raise exception.RegisterVmException(msg)

            if vm_respool:
                vm_respool_ref = vm_respool
            else:
                vm_respool_ref = self.get_respool_from_host(vm_hostname_ref)
                if not vm_respool_ref:
                    msg = "Unable to fetch Resource Pool information from ESXi host [%s]" % vm_hostname
                    raise exception.RegisterVmException(msg)

            task_desc_string = 'Registering Virtual Machine [%s] with ESXi host [%s]...' % (vm_name, vm_hostname)
            task_percentage = 30
            task_state = 'Running'
            task_status = "Initiated"

            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            register_task = self.vi_helper.register_vm(vmx_sourcefilepath,
                                                       inventoryMoref,
                                                       inventorytype,
                                                       vm_name,
                                                       vm_astemplate,
                                                       vm_respool_ref,
                                                       vm_hostname_ref)
            if not register_task:
                msg = "Error registering Virtual Machine [%s] with ESXi host [%s] " % (vm_name, vm_hostname)
                raise exception.RegisterVmException(msg)

            registered_vm_moref = register_task.result
            if not registered_vm_moref:
                msg = "Unable to fetch Virtual Machine details. Error registering Virtual Machine " \
                      "[%s] with ESXi host [%s] " % (vm_name, vm_hostname)
                raise exception.RegisterVmException(msg)

            # backup_response = self.get_backup_for_backupId(context, backup_id, x_auth_token,True)
            # response_backup = backup_response['backupSet']
            # backup_appmetadata = response_backup['appMetadata']

            # if backup_appmetadata['VmWareObjectType'] == 'Datastore':
            #    isDatastore = True
            # elif backup_appmetadata['VmWareObjectType'] == 'VirtualMachine':
            #    isVMLevel = True

            task_desc_string = 'Consolidate Virtual Machine...'
            task_percentage = 50
            task_state = 'Running'
            task_status = "Initiated"

            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # IsAppConsistent = backup_appmetadata['IsAppConsistent']
            backup_response = self.db_utils.get_vm_assoc_by_vm_id_and_copy_id(context, copy_id, virtual_machine_id)
            # currently vm assc is not being inserted in DB, so bydefault marking IsAppConsistent as false
            if backup_response:
                IsAppConsistent = backup_response.is_app_consistent
            else:
                IsAppConsistent = False
            try:
                if IsAppConsistent:
                    vm_snapshot_list = []
                    registered_vm_snapshot_prop = self.vi_helper.GetObjectProperties(registered_vm_moref, "snapshot")
                    if registered_vm_snapshot_prop:
                        registered_vm_snapshot = vim_util.extract_properties(
                            registered_vm_snapshot_prop.objects[0])
                        if registered_vm_snapshot:
                            registered_vm_root_snapshot_list = registered_vm_snapshot['snapshot'].rootSnapshotList[0]
                            LOG.debug("Virtual Machine [%s] Snapshot List: %s", vm_name,
                                      registered_vm_root_snapshot_list)
                            rmcv_internal_snapshot_ref = self.vi_helper.traverse_and_get_rmcv_internal_snap(
                                registered_vm_root_snapshot_list,
                                vi_objects.VmfsSnapshotName)
                            if rmcv_internal_snapshot_ref:
                                LOG.debug("RMC-V Internal Snapshot detected : %s", rmcv_internal_snapshot_ref)
                                vm_snapshot_list.append(rmcv_internal_snapshot_ref)
                                LOG.debug("Deleting RMC-V Internal Snapshot on Virtual Machine [%s]...", vm_name)
                                self.vi_helper.DeleteVmfsSnapshot(vm_snapshot_list, True)
                            else:
                                LOG.error("Virtual Machine [%s] does not contain any Internal RMC-V Snapshot", vm_name)
                        else:
                            LOG.error("Unable to fetch Virtual Machine [%s] Snapshot Information. "
                                      "Snapshot property value returned is NULL", vm_name)
                            # no need to raise the exception here, after registering the vm we are trying to delete any vm snapshots on it
                            # raise
                    else:
                        LOG.error("Unable to fetch Virtual Machine [%s] Snapshot Information. Snapshot property value "
                                  "returned is NULL", vm_name)
                        raise
                else:
                    LOG.error("Virtual Machine is not App Consistent.. Continue recovery operation...")
            except Exception as e:
                LOG.exception("Exception occurred removing Virtual Machine [%s] Internal RMC-V Snapshot. : %s", vm_name,
                              e)
                if redirect_io_ds_name_ref:
                    LOG.error("Redirect-IO is enabled for the Virtual Machine [%s]. "
                              "Unable to consolidate Virtual Machine Internal RMC-V Snapshot. "
                              "Failing VM Recovery Task", vm_name)
                    msg = "Error consolidating Virtual Machine [%s] Snapshot" % vm_name
                    raise exception.RegisterVmException(msg)

            copy_details = self.db.get_rmcv_copy_by_id(context, copy_id)
            if copy_details.version == "5.0.0":
                if not self.db.get_all_rmcv_vm_copy_assoc_by_copy_id(context, copy_id):
                    if self.db.get_all_rmcv_ds_copy_assoc_by_copy_id(context, copy_id):
                        isDatastore = True

            if isDatastore:
                copy_type = copy_details.type
                source_ds_name = "[" + source_datastore_name + "]"
                vm_mo_ref = pyvmomi_util.get_moref(registered_vm_moref.value, rmv_utils.VMWARE_OBJECT_TYPE_VM)
                vm_devices_oc = self.vi_helper.get_object_properties(vm_mo_ref, "config.hardware.device")
                vm_devices_prop = pyvmomi_util.extract_properties(vm_devices_oc[0])
                vm_devices = vm_devices_prop.get("config.hardware.device")
                if vm_devices:
                    for virtual_device in vm_devices:
                        if virtual_device and virtual_device._wsdlName == "VirtualDisk":
                            virtual_disk = virtual_device.backing
                            if virtual_disk:
                                if virtual_disk._wsdlName == "VirtualDiskFlatVer2BackingInfo":
                                    vmdk_path = virtual_disk.fileName
                                    if not vmdk_path.startswith(source_ds_name):
                                        if copy_type == rmv_utils.copy_type.SNAPSHOT:
                                            msg = "Recovered Virtual Machine [%s] contains one or more VMDK disks " \
                                                  "which are not part of the mounted datastore Snapshot" % vm_name
                                        else:
                                            msg = "Recovered Virtual Machine [%s] contains one or more VMDK disks " \
                                                  "which are not part of the mounted Express Protect Object datastore" % vm_name
                                        raise exception.RegisterVmException(msg)

                                elif virtual_disk._wsdlName == "VirtualDiskRawDiskMappingVer1BackingInfo":
                                    msg = "Recovered Virtual Machine [%s] contains one or more RDM disks. " \
                                          "This configuration is not supported for 5.x migrated Snapshots" % vm_name

                                    raise exception.RegisterVmException(msg)

                # file_layout_exlist = self.vi_helper.get_vm_vmdk_file_paths(registered_vm_moref.value)
                # if not file_layout_exlist:
                #     msg = "Unable to fetch Virtual Machine [%s] information from ESXi host [%s]" \
                #           % (vm_name, vm_hostname)
                #     raise exception.RegisterVmException(msg)
                # for path in file_layout_exlist:
                #     if path.endswith(".vmdk"):
                #         if not path.startswith(source_ds_name):
                #             if copy_type == rmv_utils.copy_type.SNAPSHOT:
                #                 msg = "Recovered Virtual Machine [%s] contains one or more VMDK disks " \
                #                       "which are not part of the mounted datastore Snapshot" % vm_name
                #             else:
                #                 msg = "Recovered Virtual Machine [%s] contains one or more VMDK disks " \
                #                       "which are not part of the mounted Express Protect Object datastore" % vm_name
                #             raise exception.RegisterVmException(msg)

            if redirect_io_ds_name_ref:
                target_snapshot_folder = "[" + redirect_io_ds_name + "] " + vm_name
                self.vi_helper.create_target_folder(target_snapshot_folder, redirect_io_ds_name_ref)

                datastore_moref = vim.get_moref(redirect_io_ds_name_ref, "Datastore")
                datacenter_moref = self.vi_helper.get_parent_datacenter(datastore_moref)
                if not datacenter_moref:
                    LOG.error("Unable to fetch datacenter from datastore moref [%s]", datastore_moref)
                    raise exception.RegisterVmException("Unable to fetch datacenter information. "
                                                        "Create target folder operation failed")

                task_desc_string = 'Reconfigure Virtual Machine ...'
                task_percentage = 60
                task_state = 'Running'
                task_status = "Initiated"

                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                reconfig_task = self.vi_helper.reconfigure_for_snapshotcreation(target_snapshot_folder,
                                                                                register_task)
                if not reconfig_task:
                    msg = "Unable to reconfigure Virtual Machine [%s] for IO re-direction" % vm_name
                    raise exception.RegisterVmException(msg)

                task_desc_string = 'Re-direct Virtual Machine [%s] IO to [%s] datastore...' % (vm_name,
                                                                                               redirect_io_ds_name)
                task_percentage = 70
                task_state = 'Running'
                task_status = "Initiated"

                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                snapshot_task = self.vi_helper.create_target_snapshot(register_task, vm_name)
                if not snapshot_task:
                    msg = "Virtual Machine [%s] Snapshot creation Failed" % vm_name
                    raise exception.RegisterVmException(msg)
            else:

                if isVMLevel and redirect_io_ds_name:
                    msg = "Given redirectIO Datastore is either invalid or not found"
                    raise exception.RegisterVmException(msg)

            if register_task:

                # If Base VM has RDM disks attached then registered VM also points to the base VM RDM luns.
                # So updating the RW snapshots RDM luns to registered VM.
                try:
                    if clone_details and is_vm_relocate_task is False:
                        self.update_rdm_disk_lun_info(context, clone_details, registered_vm_moref, task_id,
                                                      copy_id=copy_id)
                except Exception as e:
                    LOG.exception("Unable to update RDM disks with new RW Lun. %s" % e)

                if powerOn:
                    task_desc_string = 'Powering On Virtual Machine [%s]...' % vm_name
                    task_percentage = 80
                    task_state = 'Running'
                    task_status = "Initiated"

                    self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # self.vi_helper.powerOn_VM(registered_vm_moref)

                    self.vi_helper.power_on_vm(registered_vm_moref.value, is_register_vm_task=True)

            # updating cache with newly registered virtual machine TODO Remove below once complete cache is removed
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map
            # self.vi_helper.update_vcenter_cache_with_vm_info(vm_vv_map_cache,register_task.result.value)

            state = rmv_utils.OPERATION_STATE_SUCCESS

        except Exception as e:
            LOG.exception("Exception occurred during Register Virtual Machine Operation: %s", e)
            state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal error"

            if register_task:
                self.vi_helper.unregister_vm(registered_vm_moref)

                task_desc_string = "Instant Virtual Machine Recovery Task Failed : Initiate clean-up. " \
                                   "Remove Virtual Machine from ESXi host..."
                task_percentage = 80
                task_state = 'Running'
                task_status = "Initiated"
                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

            if redirect_io_ds_name_ref:
                if reconfig_task:
                    self.vi_helper.delete_datastore_file(target_snapshot_folder, datacenter_moref)

                    task_desc_string = "Instant Virtual Machine Recovery Task Failed : " \
                                       "Clean-up Virtual Machine Folders..."
                    task_percentage = 90
                    task_state = 'Running'
                    task_status = "Initiated"
                    self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

        finally:
            if backup_operation_lock:
                # Release the aquired backup lock
                with rmv_locks.backup_op_lock:
                    self.release_backup_operation_lock(copy_id)
                LOG.debug("Released Lock for Express Protect: %s", copy_id)
            else:
                if backup_operation_lock is False:
                    msg = "HPE Express Protect Backup Object is currently in use. Please retry after sometime."

            if state == rmv_utils.OPERATION_STATE_FAILURE:
                task_desc_string = "Instant Virtual Machine Recovery Task Failed: '%s'" % msg
                task_percentage = 100
                task_state = 'Failed'
                task_status = "Error"

                # Commenting below LogEvent call, as the same event is logged using PostEvent
                # self.vi_helper.LogEvent(mo_ref, object_type,task_desc_string)

                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                LOG.error("%s", task_desc_string)

            else:
                task_desc_string = "Instant Virtual Machine Recovery Task Completed Successfully"
                task_state = 'Completed'
                task_percentage = 100
                task_status = "Ok"

                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                LOG.debug("%s", task_desc_string)

        if state == rmv_utils.OPERATION_STATE_SUCCESS:
            registered_details['vm_moref'] = registered_vm_moref.value
            registered_details['vm_name'] = vm_name
        LOG.debug("register_vm_operations: Exit")

        return registered_details

    def update_rdm_disk_lun_info(self, context, clone_details, registered_vm_moref, task_id, copy_id=None):
        LOG.info("update_rdm_disk_lun_info : enter")
        LOG.info("Clone details : %s " % clone_details)

        vmdk_to_wwn_mapping_dict = self.get_vmdk_to_wwn_mapping_dict(context, clone_details, task_id, copy_id)

        if vmdk_to_wwn_mapping_dict:
            vm_moref = pyvmomi_util.get_moref(registered_vm_moref.value, registered_vm_moref._type)
            vm_hardware_device_oc = self.vi_helper.get_object_properties(vm_moref, ["name",
                                                                                    "config.hardware.device",
                                                                                    "runtime.host"])
            props = pyvmomi_util.extract_properties(vm_hardware_device_oc[0])

            host = props.get('runtime.host')
            scsi_luns = host.config.storageDevice.scsiLun

            vm_hardware_device_list = props.get("config.hardware.device")
            rdm_count = 0
            for vm_hardware_device in vm_hardware_device_list:
                rw_snap_wwn = disk_mode = sharing_mode = disk_compatibility_mode = None

                if vm_hardware_device._wsdlName == "VirtualDisk":

                    virtual_disk = vm_hardware_device.backing
                    # In case of mounting snapshot/backup to same ESXi then RDM disk type = RawDisk
                    # In case of mounting snapshot/backup to other ESXi, then RDM disk type = FlatDisk
                    if virtual_disk._wsdlName == "VirtualDiskRawDiskMappingVer1BackingInfo" or \
                            virtual_disk._wsdlName == "VirtualDiskFlatVer2BackingInfo":

                        vmdk_file_path = virtual_disk.fileName
                        LOG.debug('vmdk_file_path - %s', vmdk_file_path)
                        if len(vmdk_file_path.split("] ")) > 0:
                            vmdk_file_path_split = vmdk_file_path.split("] ")[1]
                            vmdk_info = vmdk_to_wwn_mapping_dict.get(vmdk_file_path_split)

                            if not vmdk_info:
                                continue

                            rw_snap_wwn = vmdk_info.get('rw_snap_wwn')
                            disk_mode = vmdk_info.get('disk_mode')
                            sharing_mode = vmdk_info.get('sharing_mode')
                            disk_compatibility_mode = vmdk_info.get('disk_compatibility_mode')

                        lun_uuid = None
                        device_name = None
                        for scsi_lun in scsi_luns:
                            if scsi_lun.canonicalName:
                                lun_wwn = None
                                if len(scsi_lun.canonicalName.split("naa.")) > 1:
                                    lun_wwn = scsi_lun.canonicalName.split("naa.")[
                                        1] if scsi_lun.canonicalName else None
                                elif len(scsi_lun.canonicalName.split("eui.")) > 1:
                                    lun_wwn = scsi_lun.canonicalName.split("eui.")[
                                        1] if scsi_lun.canonicalName else None

                                if lun_wwn and rw_snap_wwn and lun_wwn.lower() == rw_snap_wwn.lower():
                                    device_name = scsi_lun.deviceName
                                    lun_uuid = scsi_lun.uuid
                                    LOG.debug('lun_uuid to be updated - {0}'.format(lun_uuid))
                                    break
                        if lun_uuid:
                            # If disk type = Raw Disk then making the old raw disk point to new RW snapshot/backup
                            if virtual_disk._wsdlName == "VirtualDiskRawDiskMappingVer1BackingInfo":
                                rdm_count += 1

                                if lun_uuid == virtual_disk.lunUuid:
                                    LOG.info("LunUUID is already up to date. So no need to update")
                                    pass
                                else:
                                    vm_name = props.get('name')
                                    vmdk_name = vm_name + "_rdm_" + str(rdm_count) + ".vmdk"
                                    new_file_name = vmdk_file_path.split("/")[0] + "/" + vmdk_name
                                    LOG.debug('new_file_name - %s', new_file_name)
                                    virtual_disk.fileName = new_file_name

                                    virtual_disk.deviceName = device_name
                                    virtual_disk.lunUuid = lun_uuid

                                    LOG.info("LunUUID mismatch. Replacing with new disk : '%s'" % new_file_name)
                                    spec = pyvmomi_util.get_vm_config_spec_to_change_rdm_lunUuid(vm_hardware_device)
                                    self.vi_helper.reconfig_vm_task(vm_moref, spec)

                                    datacenter_mo = self.vi_helper.get_parent_datacenter_moref(host)
                                    datacenter_mo = pyvmomi_util.get_moref(datacenter_mo, "Datacenter")
                                    self.vi_helper.delete_vmdk(vmdk_file_path, datacenter_mo)

                            # If the disk type = Flat disk then delete the old one and create new disk with new RW Lun
                            elif virtual_disk._wsdlName == "VirtualDiskFlatVer2BackingInfo":

                                rdm_count += 1

                                vm_name = props.get('name')
                                vmdk_name = vm_name + "_rdm_" + str(rdm_count) + ".vmdk"
                                new_file_name = vmdk_file_path.split("/")[0] + "/" + vmdk_name

                                LOG.info("Deleting the Virtual Disk : '%s' " % vmdk_file_path)
                                delete_spec = pyvmomi_util.get_vm_virtual_disk_device_config_spec(vmdk_file_path,
                                                                                                  None,
                                                                                                  vm_hardware_device.controllerKey,
                                                                                                  vm_hardware_device.unitNumber,
                                                                                                  vm_hardware_device.key,
                                                                                                  "remove",
                                                                                                  file_operation="destroy",
                                                                                                  backing_type="VirtualDiskFlatVer2BackingInfo")
                                self.vi_helper.reconfig_vm_task(vm_moref, delete_spec)

                                LOG.info("Adding new Virtual Disk : '%s' " % new_file_name)
                                add_spec = pyvmomi_util.get_vm_virtual_disk_device_config_spec(new_file_name,
                                                                                               device_name,
                                                                                               vm_hardware_device.controllerKey,
                                                                                               vm_hardware_device.unitNumber,
                                                                                               vm_hardware_device.key,
                                                                                               "add",
                                                                                               file_operation="create",
                                                                                               backing_type="VirtualDiskRawDiskMappingVer1BackingInfo",
                                                                                               disk_mode=disk_mode,
                                                                                               disk_compatibility_mode=disk_compatibility_mode,
                                                                                               sharing_mode=sharing_mode)
                                self.vi_helper.reconfig_vm_task(vm_moref, add_spec)

        LOG.info("update_rdm_disk_lun_info : exit")

    def detach_rdm_from_cloned_vm(self, context, operation, clone_details, registered_vm_moref, task_id, copy_id):
        LOG.debug('detach_rdm_from_cloned_vm: Enter')
        try:
            vmdk_to_wwn_mapping_dict = self.get_vmdk_to_wwn_mapping_dict(context, clone_details, task_id, copy_id)
            if vmdk_to_wwn_mapping_dict:
                vm_moref = pyvmomi_util.get_moref(registered_vm_moref.value, registered_vm_moref._type)
                vm_hardware_device_oc = self.vi_helper.get_object_properties(vm_moref, ["name",
                                                                                        "config.hardware.device",
                                                                                        "runtime.host"])
                props = pyvmomi_util.extract_properties(vm_hardware_device_oc[0])

                host = props.get('runtime.host')
                scsi_luns = host.config.storageDevice.scsiLun

                vm_hardware_device_list = props.get("config.hardware.device")
                rdm_count = 0
                for vm_hardware_device in vm_hardware_device_list:
                    rw_snap_wwn = disk_mode = sharing_mode = disk_compatibility_mode = None

                    if vm_hardware_device._wsdlName == "VirtualDisk":

                        virtual_disk = vm_hardware_device.backing
                        # In case of mounting snapshot/backup to same ESXi then RDM disk type = RawDisk
                        # In case of mounting snapshot/backup to other ESXi, then RDM disk type = FlatDisk
                        if virtual_disk._wsdlName == "VirtualDiskRawDiskMappingVer1BackingInfo" or \
                                virtual_disk._wsdlName == "VirtualDiskFlatVer2BackingInfo":

                            vmdk_file_path = virtual_disk.fileName
                            if len(vmdk_file_path.split("] ")) > 0:
                                vmdk_file_path_split = vmdk_file_path.split("] ")[1]
                                vmdk_info = vmdk_to_wwn_mapping_dict.get(vmdk_file_path_split)

                                if not vmdk_info:
                                    continue

                                rw_snap_wwn = vmdk_info.get('rw_snap_wwn')
                                disk_mode = vmdk_info.get('disk_mode')
                                sharing_mode = vmdk_info.get('sharing_mode')
                                disk_compatibility_mode = vmdk_info.get('disk_compatibility_mode')

                            lun_uuid = None
                            device_name = None
                            for scsi_lun in scsi_luns:
                                if scsi_lun.canonicalName:
                                    lun_wwn = None
                                    if len(scsi_lun.canonicalName.split("naa.")) > 1:
                                        lun_wwn = scsi_lun.canonicalName.split("naa.")[
                                            1] if scsi_lun.canonicalName else None
                                    elif len(scsi_lun.canonicalName.split("eui.")) > 1:
                                        lun_wwn = scsi_lun.canonicalName.split("eui.")[
                                            1] if scsi_lun.canonicalName else None

                                    if lun_wwn and rw_snap_wwn and lun_wwn.lower() == rw_snap_wwn.lower():
                                        device_name = scsi_lun.deviceName
                                        lun_uuid = scsi_lun.uuid
                                        LOG.debug('lun_uuid being detached - {0}'.format(lun_uuid))
                                        break

                            if lun_uuid:
                                if virtual_disk._wsdlName == "VirtualDiskRawDiskMappingVer1BackingInfo":
                                    rdm_count += 1

                                    if operation == "detach":
                                        LOG.info("Deleting the RDM Virtual Disk : '%s' " % vmdk_file_path)

                                        delete_spec = pyvmomi_util.get_vm_virtual_disk_device_config_spec(
                                            vmdk_file_path,
                                            None,
                                            vm_hardware_device.controllerKey,
                                            vm_hardware_device.unitNumber,
                                            vm_hardware_device.key,
                                            "remove",
                                            file_operation="destroy",
                                            backing_type="VirtualDiskRawDiskMappingVer1BackingInfo")
                                        self.vi_helper.reconfig_vm_task(vm_moref, delete_spec)
        except Exception as ex:
            LOG.exception(ex)
            raise Exception(ex)
        LOG.debug('detach_rdm_from_cloned_vm: Exit')

    def get_vmdk_to_wwn_mapping_dict(self, context, clone_details, task_id, copy_id):
        LOG.debug('get_vmdk_to_wwn_mapping_dict: Enter')
        try:
            mount = Mount()
            backups = []
            volumes = []
            backup_volume_mapping_dict = {}
            cloned_bck_id_wwn_dict = {}

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(None)
            clone_type = clone_details.get('type')

            if clone_type == "physical_clone":
                copy_id = copy_id
            else:
                copy_id = clone_details.get('parent_copy_id')

            if clone_type == rmv_utils.CLONE_TYPE_ERT:
                backup_copy_details = self.db.get_rmcv_copy_by_id(context, copy_id)
                rmc_copyset_id = backup_copy_details.rmc_copyset_id
                backup = rmc_wrapper_service.get_backup_for_backupId(context, rmc_copyset_id, None)
                backup_copy_details = backup.get("backupSet")
                backups = backup_copy_details.get("backups")

            elif clone_type == "physical_clone":
                """
                TODO:
                In case of physical_clone there is no direct mapping between Base RDM wwn and its cloned RDM wwn,
                so this association is read from the Task. This logic will be changed in 6.1.
                """
                register_task_details = rmc_wrapper_service.get_copy_task_status(task_id)
                restore_task_id = register_task_details.get('task').get('parentTaskId')
                restore_task_details = rmc_wrapper_service.get_copy_task_status(restore_task_id)
                sub_tasks = restore_task_details.get('task').get('subTasks').get('tasks')
                for sub_task in sub_tasks:
                    LOG.debug("sub_task : %s " % sub_task)
                    if sub_task.get('action') == 'Restore Express Protect' or sub_task.get(
                            'action') == 'Restore Catalyst Copy':
                        associated_data_list = sub_task.get('associatedData')
                        for associated_data in associated_data_list:
                            resource_name = associated_data.get('resourceName')
                            if resource_name:
                                resource_name_split = resource_name.split(':')
                                # resource_name_split[0] = Base Volume Backup volume ID
                                # resource_name_split[1] = Cloned Volume Backup volume ID
                                backup_volume_mapping_dict[resource_name_split[0]] = resource_name_split[1]

                cloned_recovery_set = clone_details.get('recovery_set_id')
                response = rmc_wrapper_service.get_recoery_set(cloned_recovery_set, None)
                recovery_set_details = response.get('recoverySet')
                volumes = recovery_set_details.get('volumes')

                for volume in volumes:
                    cloned_bck_id_wwn_dict[volume.get('id')] = volume.get('wwn')

                backup_copy_details = self.db.get_rmcv_copy_by_id(context, copy_id)
                rmc_copyset_id = backup_copy_details.rmc_copyset_id
                backup = rmc_wrapper_service.get_backup_for_backupId(context, rmc_copyset_id, None)
                backup_copy_details = backup.get("backupSet")
                backups = backup_copy_details.get("backups")

            else:
                cloned_recovery_set = clone_details.get('recovery_set_id')
                response = rmc_wrapper_service.get_recoery_set(cloned_recovery_set, None)
                recovery_set_details = response.get('recoverySet')
                volumes = recovery_set_details.get('volumes')

            # RDM details got updated in Assoc table while creating snapshot.
            ds_assoc_info_list = self.db.get_all_rmcv_ds_copy_assoc_by_copy_id(context, copy_id)

            vmdk_to_wwn_mapping_dict = {}

            for ds_assoc_info in ds_assoc_info_list:
                wwn_details_list = ds_assoc_info.wwn_details
                if wwn_details_list:
                    for wwn_detail in wwn_details_list:
                        if wwn_detail.get('lun_used_as') == "rdm":
                            base_vol_wwn = wwn_detail.get('wwn')

                            rw_snap_wwn = None
                            if clone_type == rmv_utils.CLONE_TYPE_ERT:
                                for backup in backups:
                                    if backup.get("copyOfVolumeWwn") == base_vol_wwn:
                                        backup_vol_iqn_list = mount.get_backup_rw_volume_iqn([backup])
                                        backup_vol_lun_uuid = mount.get_backup_vol_lun_uuid(backup_vol_iqn_list)
                                        rw_snap_wwn = backup_vol_lun_uuid[0] if backup_vol_lun_uuid else None
                                        LOG.debug("rw_snap_wwn : %s " % rw_snap_wwn)
                                        break

                            elif clone_type == "physical_clone":
                                for backup in backups:
                                    if backup.get("copyOfVolumeWwn") == base_vol_wwn:
                                        # Based on RDM base volume ID get its cloned backup volume ID
                                        cloned_bck_id = backup_volume_mapping_dict.get(backup.get('id'))
                                        # Then by cloned backup ID get its cloned WWN
                                        rw_snap_wwn = cloned_bck_id_wwn_dict.get(cloned_bck_id)

                                        break

                            else:
                                for volume in volumes:
                                    if volume.get('baseVolumeWWN') == base_vol_wwn:
                                        rw_snap_wwn = volume.get('wwn')

                                        break

                            vmdks = self.db.get_vmdk_by_id(context, wwn_detail.get('vmdk_id'))
                            vmdk_path = vmdks.path.split("] ")[1] if vmdks.path else None

                            vmdk_info = {}
                            if not vmdks.disk_mode and not vmdks.sharing_mode:
                                if vmdks.rdm_type == "virtualMode":
                                    vmdk_info['disk_mode'] = "persistent"
                                elif vmdks.rdm_type == "physicalMode":
                                    vmdk_info['disk_mode'] = "independent_persistent"

                                vmdk_info['sharing_mode'] = "sharingNone"
                            else:
                                vmdk_info['disk_mode'] = vmdks.disk_mode
                                vmdk_info['sharing_mode'] = vmdks.sharing_mode

                            vmdk_info['rw_snap_wwn'] = rw_snap_wwn
                            vmdk_info['disk_compatibility_mode'] = vmdks.rdm_type

                            vmdk_to_wwn_mapping_dict[vmdk_path] = vmdk_info
        except Exception as ex:
            LOG.exception(ex)
            raise Exception(ex)
        LOG.debug('get_vmdk_to_wwn_mapping_dict: Exit')
        return vmdk_to_wwn_mapping_dict

    def get_datastore_ref_from_name(self, datastore_name, ds_name_to_moref_dict):
        """
        gets datastore reference gor the datastorename given
        :param datastorename:
        :return:datastore reference
        """
        LOG.info("get_datastore_ref_from_name:ENTER")
        datastore_ref = None
        try:
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()
            # for ip in range(len(vcenter_ip)):
            #     vcenter_obj = cache.get(vcenter_ip[ip])
            #     vm_vv_map_cache = vcenter_obj.vm_vv_map
            # for dstr in range(len(vm_vv_map_cache.datastores)):
            #     if datastore_name:
            #         if vm_vv_map_cache.datastores[dstr].Name == datastore_name:
            #             datastore_ref = vm_vv_map_cache.datastores[dstr].DatastoreMoref

            datastore_ref = ds_name_to_moref_dict.get(datastore_name)

        except Exception as e:
            LOG.exception("Exception occurred fetching datastore moref object from VCenter cache: %s", e)
        LOG.info("get_datastore_ref_from_name : EXIT")
        return datastore_ref

    def get_hostref_from_name(self, host_name):
        """
        This function gets host reference from host ip
        :param host_name: ip of the esx host
        :return:host reference
        """
        LOG.info("get_hostref_from_name : ENTER")
        host_moref = None
        try:
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()
            # for ip in range(len(vcenter_ip)):
            #     vcenter_obj = cache.get(vcenter_ip[ip])
            #     vm_vv_map_cache = vcenter_obj.vm_vv_map

            mo_type = "HostSystem"
            host_moref_list = self.vi_helper.get_all_mo_moref_in_vcenter(
                mo_type)  # TODO test it with more than 100 host moref

            prop_list = ["name"]
            host_oc_list = self.vi_helper.get_object_properties(host_moref_list, prop_list)
            hostnr_dict = {}

            # for hkey in vm_vv_map_cache.esx_hosts:
            for host_oc in host_oc_list:
                prop_dict = pyvmomi_util.extract_properties(host_oc)
                hostNam = prop_dict.get("name")
                hostRef = host_oc.obj._moId
                hostnr_dict[hostNam] = hostRef
                if host_name == hostNam:
                    host_moref = hostRef
        except Exception as e:
            LOG.exception("Exception occurred fetching ESXi host moref object from VCenter cache: %s", e)
        LOG.info("get_hostref_from_name : EXIT")
        return host_moref

    def _create_vm_unregister_task(self, rmc_wrapper_service, action, parentResourceName, parent_task_id, desc,
                                   clone_id, vmName):
        kwargs = {}
        kwargs['name'] = desc
        kwargs['owner'] = 'RMC-V User'
        kwargs['task_state'] = 'New'
        kwargs['task_type'] = 'User'
        kwargs['resource_name'] = vmName
        kwargs['resource_category'] = 'Clone'
        kwargs['association_type'] = 'IS_A'
        kwargs['resource_id'] = clone_id
        kwargs['action'] = action
        kwargs['resourceType'] = 'Virtual Machine'
        kwargs['total_steps'] = rmv_utils.TOTAL_TASK_TRACKER_STEPS
        kwargs['parentTaskId'] = parent_task_id
        kwargs['parentResourceName'] = parentResourceName if parentResourceName else "VMWare"
        created_task_id = ''
        try:
            response_data = rmc_wrapper_service.create_task(kwargs)
            created_task_id = response_data['id']
        except:
            msg = ("Failed to create sub task. Please check if TaskTracker service is running")
            raise Exception(msg)
        return created_task_id

    def unregister_vm_from_clone(self, context, clone_id, x_auth_token, operation_input, task_id):
        LOG.debug("Unregister VM from clone :: Enter")

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        failured_unregistered_vms = set()
        try:
            clone_status = json_helper.clone_status
            clone_info = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_details = clone_info.get("clone_details")
            registered_vm_info = clone_details.get('cloned_virtual_machines', list())
            attached_vmdks_details = clone_details.get('attached_vmdks_details', list())
            vm_moref_dict_list = operation_input.get('vmMorefList')
            temp_vm = copy.deepcopy(registered_vm_info)
            vm_moref_list = []
            for moref in vm_moref_dict_list:
                vm_moref_list.append(moref.get('vmMoref'))

            for vmMoref in vm_moref_list:
                for registeredVm in registered_vm_info:
                    vmName = registeredVm['name']
                    parent_id = registeredVm['parent_id']
                    if registeredVm['moref'] == vmMoref:
                        try:
                            # Check registered vm is exists in vcenter inventoryor not. If it is not exist clean RMCV DB.
                            obj_exists = self.check_if_object_exists(vmMoref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
                            if not obj_exists:
                                LOG.info("Virtual Machine '%s' is not exists in vCenter" % vmMoref)
                                temp_vm.remove(registeredVm)
                            vm_info = self.db.get_virtual_machine_by_id(context, parent_id)
                            parentVmName = vm_info.name
                            unregister_vm_task = self._create_vm_unregister_task(rmc_wrapper_service, "Delete",
                                                                                 parentVmName, task_id,
                                                                                 "Unregistering VM from cloned object",
                                                                                 clone_id, vmName)
                            unregister_vm_state = self.unregister_vm_operations(context, clone_id, x_auth_token,
                                                                                vmMoref, unregister_vm_task)
                            if unregister_vm_state == rmv_utils.OPERATION_STATE_SUCCESS:
                                task_desc_string = "VM - " + vmName + " unregistered operation completed successfully"
                                LOG.info(task_desc_string)
                                temp_vm.remove(registeredVm)
                            else:
                                task_desc_string = "VM - " + vmName + " unregistered operation failed"
                                LOG.info(task_desc_string)
                                if obj_exists:
                                    failured_unregistered_vms.add(vmName)
                        except Exception as e:
                            task_desc_string = "VM -" + vmName + " unregister was unsuccessful"
                            LOG.Exception(task_desc_string, e)
                            failured_unregistered_vms.add(vmName)
            clone_details['cloned_virtual_machines'] = temp_vm
            clone_info['clone_details'] = clone_details
            # updating the clone status on DB
            if len(temp_vm) == 0 and len(attached_vmdks_details) == 0:
                clone_info['status'] = clone_status.mounted
            elif len(temp_vm) == 0 and len(attached_vmdks_details) > 0:
                clone_info['status'] = clone_status.vmdk_attached

            self.db.update_rmcv_clone_by_clone_id(context, clone_id, clone_info)
            if len(failured_unregistered_vms) == len(vm_moref_dict_list):
                task_desc_string = "Unregistering VMs operation was unsuccessful"
                task_state = 'Failed'
                task_percentage = 100
                task_status = "Error"
            elif len(failured_unregistered_vms) > 0:
                vm_msg = ', '.join('\'{0}\''.format(vm) for vm in failured_unregistered_vms)
                task_desc_string = "Unregistering VMs operation was Completed. Unable to un register the VMs %s" % vm_msg
                task_state = 'Completed'
                task_percentage = 100
                task_status = "Warning"
            else:
                task_desc_string = "Unregistering VMs operation successfully completed."
                task_state = 'Completed'
                task_percentage = 100
                task_status = "Ok"

        except Exception as e:
            task_state = 'Failed'
            task_status = "Error"
            task_desc_string = "Unregistering VMs was unsuccessful"
            task_percentage = 100
            LOG.exception(("Unregistering Virtual machines operation failed. ", e))

        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          task_id,
                          rmc_wrapper_service, None,
                          task_status=task_status)

        LOG.debug("Unregister VM from clone :: Exit")

    def unregister_vm_operations(self,
                                 context,
                                 clone_id,
                                 x_auth_token,
                                 vm_mo_ref,
                                 task_id):
        """
        :param context:
        :param clone_id:
        :param x_auth_token:
        :param operation_input:
        :param operation_type:
        :param task_id:
        :return:
        """
        LOG.info("unregister_vm_operations:Enter")
        object_type = rmv_utils.TASK_OBJECT_TYPE
        mo_ref = rmv_utils.TASK_MO_REF
        rmc_wrapper_service = None
        msg = "Begin Virtual Machine Un-register Operation"
        vm_task_helper = VmTaskHelper(self.vi_helper)
        backup_operation_lock = None
        is_redirect_io_ds_present = False
        redirect_io_ds_name = None
        state = rmv_utils.OPERATION_STATE_FAILURE
        is_vm_moved = False
        vm_name = ""
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            self.vi_helper.LogEvent(mo_ref, object_type, msg)
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 "UnregisterVirtualMachineTask",
                                                 "UnregisterVirtualMachineFailedFault")

            vm_moref_obj = pyvmomi_util.get_moref(vm_mo_ref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
            vm_oc = self.vi_helper.get_object_properties(vm_moref_obj, ["name", "datastore"])
            prop_dict = pyvmomi_util.extract_properties(vm_oc[0])
            vc_ds_list = prop_dict.get('datastore')
            vm_name = prop_dict.get('name')
            vc_ds_moref_list = []
            for ds in vc_ds_list:
                vc_ds_moref_list.append(ds._moId)

            clone_info = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_details = clone_info.get("clone_details")
            cloned_ds_details = clone_details.get('cloned_ds_details', list())
            cloned_ds_moref_list = []
            for ds in cloned_ds_details:
                cloned_ds_moref_list.append(ds.get("moref"))
            # will compare vcente ds moref list with RMCV DB mounted ds moref list(at the time of mount)
            # if any one of the mounted ds is in use we will trigger unregister
            # If the VM is completely moved to another ds(vmotion) then skip unregister operation
            ds_moref_list = [ds_moref for ds_moref in vc_ds_moref_list if ds_moref in cloned_ds_moref_list]

            if len(ds_moref_list) == 0:
                # Cloned VM has beeen moved to another datastore and vm is not
                # reffering to any of the cloned datastore. So no need to unregister this
                state = rmv_utils.OPERATION_STATE_SUCCESS
                is_vm_moved = True
                return state

            task_desc_string = 'Initiate Virtual Machine Un-register Operation...'
            task_percentage = 20
            task_state = 'Running'
            task_status = "Initiated"

            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            backup_operation_lock = False
            with rmv_locks.backup_op_lock:
                # Acquire operation lock on backup object
                self.acquire_backup_operation_lock(clone_id, "unregister_vm_operation")
                backup_operation_lock = True
            LOG.debug("Locked Backup Object for Mount operation: '%s'" % clone_id)

            # vm_mo_ref = operation_input[rmv_utils.VM_MOREF]
            vm_mo_ref_obj = vim.get_moref(vm_mo_ref, "VirtualMachine")
            if not vm_mo_ref_obj:
                msg = "Unable to fetch Virtual Machine [%s] Information from ESXi host" % vm_mo_ref
                raise exception.UnregisterVMException(msg)
            vm_name = self.vi_helper.get_managed_object_ref_name(vm_mo_ref_obj)
            if not vm_name:
                msg = "Unable to fetch Virtual Machine [%s] Information from ESXi host" % vm_mo_ref
                raise exception.UnregisterVMException(msg)

            vm_power_state = self.vi_helper.get_vm_power_state(vm_mo_ref)[0]
            LOG.debug("Virtual Machie [%s] power status: '%s'", vm_power_state)
            if vm_power_state == 'poweredOn':
                vm_poweroff = self.vi_helper.powerOff_VM(vm_mo_ref_obj)
                LOG.debug("Virtual Machine [%s] Power-Off Task State: %s", vm_name, vm_poweroff)
                if not vm_poweroff:
                    LOG.error("Virtual Machine [%s] Power-Off Failed. Task State returned Null", vm_name,
                              vm_poweroff)
                    msg = "Power-Off Virtual Machine [%s] Task Failed" % vm_name
                    raise exception.UnregisterVMException(msg)

            vm_file_layoutEx_list = self.vi_helper.get_vm_vmdk_file_paths(vm_mo_ref)
            if not vm_file_layoutEx_list:
                msg = "Unable to fetch Virtual Machine [%s] Disk Layout Information from ESXi host" % vm_name
                raise exception.UnregisterVMException(msg)
            for path in vm_file_layoutEx_list:
                if path.endswith(".vmdk"):
                    if not path.startswith("[snap-"):
                        redirect_io_ds_name = path.split("]")[0].split("[")[1]
                        LOG.debug("Virtual Machine [%s] re-direct IO datastore: %s", vm_name, redirect_io_ds_name)
                        is_redirect_io_ds_present = True
                        break
                else:
                    msg = "Unable to fetch Virtual Machine [%s] File Path Information from ESXi host" % vm_name
                    raise exception.UnregisterVMException(msg)

            if is_redirect_io_ds_present:
                task_desc_string = 'Remove Virtual Machine Snapshot...'
                task_percentage = 40
                task_state = 'Running'
                task_status = "Initiated"

                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                target_snapshot_folder = "[" + redirect_io_ds_name + "] " + vm_name
                delete_snap_res = self.vi_helper.DeleteAllSnap_Task(vm_mo_ref_obj, False)
                if delete_snap_res.state != "success":
                    msg = "Unable to delete Virtual Machine [%s] snapshot" % vm_name
                    raise exception.UnregisterVMException(msg)

                # Get Ds name and its moref mapping dict of all the DS present in vCenter.
                ds_name_to_moref_dict = self.vi_helper.get_ds_names_to_moref_dict()

                redirect_io_ds_mo_ref = self.get_datastore_ref_from_name(redirect_io_ds_name, ds_name_to_moref_dict)
                if not redirect_io_ds_mo_ref:
                    msg = "Unable to fetch Datastore [%s] Information from ESXi host" % redirect_io_ds_name
                    raise exception.UnregisterVMException(msg)
                redirect_io_ds_mo_ref_obj = vim.get_moref(redirect_io_ds_mo_ref, "Datastore")
                redirect_io_dc_mo_ref = self.vi_helper.get_parent_datacenter(redirect_io_ds_mo_ref_obj)
                if not redirect_io_dc_mo_ref:
                    msg = "Unable to fetch Datacenter details for ESXi host datastore [%s]" % redirect_io_ds_name
                    raise exception.UnregisterVMException(msg)

                task_desc_string = 'Remove Virtual Machine Datastore Contents...'
                task_percentage = 60
                task_state = 'Running'
                task_status = "Initiated"

                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                self.vi_helper.delete_datastore_file(target_snapshot_folder, redirect_io_dc_mo_ref)

            task_desc_string = 'Un-register Virtual Machine [%s] from ESXi host...' % vm_name
            task_percentage = 80
            task_state = 'Running'
            task_status = "Initiated"

            self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            self.vi_helper.unregister_vm(vm_mo_ref_obj)
            # Updating cache with removed Virtual machine
            # cache = BackupJobManager.web_client_cache.cached_vm_centers #TODO remove this once complete cache is removed
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            # vcenter_obj = cache.get(vcenter_ip)
            # vm_vv_map_cache = vcenter_obj.vm_vv_map
            # self.vi_helper.update_vcenter_cache_with_removed_vm_info(vm_vv_map_cache,vm_mo_ref)

            state = rmv_utils.OPERATION_STATE_SUCCESS

        except Exception as e:
            LOG.exception(e)
            state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = "Internal error"
            LOG.error("Exception occurred during Un-register Virtual Machine Operation: %s", e)

        finally:
            if backup_operation_lock:
                # Release the aquired backup lock
                with rmv_locks.backup_op_lock:
                    self.release_backup_operation_lock(clone_id)
                LOG.debug("Released Lock for Express Protect: %s", clone_id)
            else:
                if backup_operation_lock is False:
                    msg = "HPE Express Protect Backup Object is currently in use. Please retry after sometime."

            if state == rmv_utils.OPERATION_STATE_FAILURE:
                task_desc_string = "Virtual Machine Un-register Operation Failed: '%s'" % msg
                task_percentage = 100
                task_state = 'Failed'
                task_status = "Error"

                # Commenting below LogEvent call, as the same event is logged using PostEvent
                # self.vi_helper.LogEvent(mo_ref, object_type,task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            else:
                state = rmv_utils.OPERATION_STATE_SUCCESS
                if is_vm_moved:
                    task_desc_string = "Virtual Machine '%s' not found in the mounted datastore. Skipping Unregister of the Virtual Machine." % vm_name
                else:
                    task_desc_string = "Virtual Machine Un-register Operation completed successfully"
                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                task_state = 'Completed'
                task_percentage = 100
                task_status = "Ok"
                self.vi_helper.LogEvent(mo_ref, object_type, task_desc_string)
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
        LOG.info("unregister vm operations:Exit")
        return state

    def backup_attach_detach_vmdk_operations(self,
                                             context,
                                             clone_id,
                                             x_auth_token,
                                             operation_input,
                                             operation_type,
                                             task_id):
        """
        This method calls the Attach or Detach operation on VMDK from Express Protect Object on to
        a Virtual Machine

        :param context: context
        :param clone_id: clone-id
        :param x_auth_token: auth-token
        :param operation_type: attachvmdk for attach operation and detachvmdk for detach operation
        :param operation_input: input values for attach or detach vmdk operation
        :param task_id: RMC Operation Task ID
        :return: None
        """
        LOG.info("Enter: backup_attach_detach_vmdk_operations ")
        LOG.debug("operation_input=%s", operation_input)

        backup_operation_lock = None

        object_type = rmv_utils.TASK_OBJECT_TYPE
        mo_ref = rmv_utils.TASK_MO_REF
        msg = 'Begin Express Protect VMDK Attach Operation'
        vm_task_helper = VmTaskHelper(self.vi_helper)
        rmc_wrapper_service = None
        operation_name = "Attach VMDK"
        operation_task_state = rmv_utils.OPERATION_STATE_FAILURE

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            custom_task_id = "ExpressProtectVMDKAttachTask"
            custom_task_fault_id = "ExpressProtectVMDKAttachFailedFault"

            if operation_type == rmv_utils.ACTION_ATTACH_VMDK_TO_VM:
                LOG.debug("Acquiring backup lock for Attach VMDK operation")
            elif operation_type == rmv_utils.ACTION_DETACH_VMDK_TO_VM:
                LOG.debug("Acquiring backup lock for Detach VMDK operation")
                custom_task_id = "ExpressProtectVMDKDetachTask"
                custom_task_fault_id = "ExpressProtectVMDKDetachFailedFault"
                operation_name = "Detach VMDK"
                msg = 'Begin Express Protect VMDK Detach Operation'

            self.vi_helper.LogEvent(mo_ref, object_type, msg)
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 custom_task_id,
                                                 custom_task_fault_id)

            task_status = "Initiated"

            self._update_task('Acquiring Express Protect operation lock',
                              20,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)  # vm_task_helper)

            # Prepare input for attach or detach operation on vmdk
            clone = self.db.get_rmcv_clone_by_id(context, clone_id)
            clone_status = clone.status
            clone_info = clone.clone_details
            cloned_ds_info = clone_info.get('cloned_ds_details')
            attached_vmdks = clone_info.get('attached_vmdks_details', list())

            if operation_type == rmv_utils.ACTION_ATTACH_VMDK_TO_VM:
                sourceDatastoreName = operation_input[rmv_utils.SOURCE_DATASTORE_NAME]
                parentDatastoreName = operation_input[rmv_utils.PARENT_DATASTORE_NAME]
                vmdk_path = operation_input[rmv_utils.VMDK_SOURCE_FILE]
                source_vmdk_path = "[" + sourceDatastoreName + "] " + vmdk_path
                parent_vmdk_path = "[" + parentDatastoreName + "] " + vmdk_path
                vm_moref = operation_input[rmv_utils.VIRTUAL_MACHINE_MOREF]
                LOG.info('vmdk file path to be attached: %s' % source_vmdk_path)
            if operation_type == rmv_utils.ACTION_DETACH_VMDK_TO_VM:
                source_vmdk_path = operation_input[rmv_utils.VMDK_SOURCE_FILE]
                sourceDatastoreName = source_vmdk_path.split('] ')[0].replace('[', '')
                LOG.info('vmdk file path to perform detach: %s' % source_vmdk_path)
                for attached_vmdk in attached_vmdks:
                    if attached_vmdk['source_vmdk_path'] == operation_input[rmv_utils.VMDK_SOURCE_FILE]:
                        vm_moref = attached_vmdk.get('target_vm_moref')
                        break

            vm_moref_obj = vim.get_moref(vm_moref, "VirtualMachine")
            vm_name = self.vi_helper.get_managed_object_ref_name(vm_moref_obj)
            if not vm_name:
                LOG.error("Unable to fetch Virtual Machine Name from VM MoRef [%s]", vm_moref_obj)
                msg = "Unable to fetch Virtual Machine Information from vCenter"
                raise rmv_exception.AttachDetachVMDKFileException(msg)

            # vmdkSourceFile": "Dummy-test_VM/Dummy-test_VM_1.vmdk
            vm_folder_name = operation_input[rmv_utils.VMDK_SOURCE_FILE].rsplit('/', 1)[0]
            reg_vm_name_postfix = '_' + sourceDatastoreName
            name = vm_name.rsplit(reg_vm_name_postfix, 1)[0]
            LOG.debug("vm_name [%s], vm_folder_name [%s], reg_vm_name_postfix [%s], orig_vm_name[%s]",
                      vm_name, vm_folder_name, reg_vm_name_postfix, name)
            if not name == vm_name:
                LOG.debug("Virtual Machine [%s] is registered from Express Protect Datastore", vm_name)
                if name == vm_folder_name:
                    LOG.error("The VMDK disk [%s] belongs to a registered Virtual Machine [%s]. "
                              "Source File Path [%s] contains original VM Name [%s] in the Folder Path.",
                              operation_input[rmv_utils.VMDK_SOURCE_FILE], vm_name, source_vmdk_path, name)
                    msg = "The VMDK disk [%s] belongs to a registered Virtual Machine [%s]. " \
                          "Cannot perform VMDK Detach Operation." % (operation_input[rmv_utils.VMDK_SOURCE_FILE],
                                                                     vm_name)
                    raise rmv_exception.AttachDetachVMDKFileException(msg)
            backup_operation_lock = False
            with rmv_locks.backup_op_lock:
                # Acquire operation lock on backup object
                self.acquire_backup_operation_lock(clone_id,
                                                   operation_type)
                backup_operation_lock = True
            LOG.debug("Locked Backup Object for Copy VMDK operation: '%s'" % clone_id)

            task_status = "Initiated"

            self._update_task(('Initiate Express Protect %s Operation' % operation_name),
                              40,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            if operation_type == rmv_utils.ACTION_ATTACH_VMDK_TO_VM:
                LOG.debug("Beginning Attach VMDK operation")
                vmTsk = self.vi_helper.attachVmdkToVMVer2(vm_moref,
                                                          source_vmdk_path)
                vmdkId = operation_input.get(rmv_utils.VMDK_ID)
                vmdk_info = self.db.get_vmdk_with_vm_info(context, vmdkId)
                # Updating Attached vmdk details into DB
                clone_status_json = json_helper.clone_status
                vmdk_details = json_helper.attached_vmdks_detail_json()
                vmdk_details.source_vmdk_path = source_vmdk_path
                vmdk_details.parent_vmdk_path = parent_vmdk_path
                vmdk_details.target_vm_moref = vm_moref
                vmdk_details.target_vm_name = vm_name
                if vmdk_info:
                    vmdk_details.parent_vm_name = vmdk_info.vm_name
                    vmdk_details.parent_vm_moref = vmdk_info.moref
                attached_vmdks.append(vmdk_details.__dict__)
                clone_info['attached_vmdks_details'] = attached_vmdks
                if clone_status == clone_status_json.mounted:
                    clone_status = clone_status_json.vmdk_attached
                elif clone_status == clone_status_json.cloned:
                    clone_status = clone_status_json.cloned_attached
                values = {'status': clone_status, 'clone_details': clone_info}
                self.db.update_rmcv_clone_by_clone_id(context, clone_id, values)

            elif operation_type == rmv_utils.ACTION_DETACH_VMDK_TO_VM:
                LOG.debug("Beginning Detach VMDK operation")
                vmTsk = self.vi_helper.detachVmdkToVMVer2(vm_moref,
                                                          source_vmdk_path)
                # Updating detached vmdk details into DB
                self.update_rmcv_clones_detach_vmdk_details(context, clone_id, clone, source_vmdk_path)

            operation_task_state = rmv_utils.OPERATION_STATE_SUCCESS

        except rmv_exception.VMDKNotFound as e:
            LOG.exception(("Exception occurred during VMDK Attach/Detach Operation: '%s'") % e)
            operation_task_state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            elif hasattr(e, "message"):
                LOG.error(('%s'), e.message)
                msg = e.message
            else:
                LOG.error(('%s'), e)
                msg = "Internal error"
            if operation_type == rmv_utils.ACTION_DETACH_VMDK_TO_VM:
                # Updating vmdk details in DB if the vmdk detached manually without using RMC-V
                self.update_rmcv_clones_detach_vmdk_details(context, clone_id, clone, source_vmdk_path)

            LOG.error(('%s'), msg)
        except Exception as e:
            LOG.exception("Exception occurred during VMDK Attach/Detach Operation: %s", e)
            operation_task_state = rmv_utils.OPERATION_STATE_FAILURE
            if hasattr(e, "msg"):
                msg = e.msg
            elif hasattr(e, "message"):
                msg = e.message
            else:
                msg = "Internal error"

        finally:

            if backup_operation_lock:
                with rmv_locks.backup_op_lock:
                    # Release operation lock on backup object
                    self.release_backup_operation_lock(clone_id)
            else:
                # If unable to acquire lock on backup object,
                # update VCenter and RMC task with error
                if backup_operation_lock is False:
                    msg = "Express Protect Object is currently in use. Please retry operation after sometime."

            if operation_task_state == rmv_utils.OPERATION_STATE_FAILURE:
                task_desc_string = "Express Protect %s Operation failed: '%s'" % (operation_name, msg)
                LOG.error(task_desc_string)
                task_state = 'Failed'
                task_status = "Error"
                task_percentage = 100
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            if operation_task_state == rmv_utils.OPERATION_STATE_SUCCESS:
                task_desc_string = "Express Protect %s Operation is successful" % operation_name
                LOG.debug(task_desc_string)
                task_state = 'Completed'
                task_percentage = 100
                task_status = "Ok"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

        LOG.info("manager backup_attach_detach_vmdk_operations :Exit")
        return

    def get_vmware_server_details(self,
                                  context,
                                  x_auth_token,
                                  id=None,
                                  vmbios_uuid=None):
        """
        Method to get registered ESXi/vCenter Server details.

        :param context: context
        :param x_auth_token: auth-token
        :param id: server id
        :param vmbiod_uuid: If virtual machine BIOS UUID is provided, then the Server on which the VM running will be
        returned
        :return: server detail dictionary
        """
        LOG.info("Enter: get_vmware_server_details ")
        LOG.debug("operation_input=%s %s", id, vmbios_uuid)
        server_operations_return = {}

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            rmv_server_manager = RmvServerManager()
            server_operations_return = rmv_server_manager.get_server_details(context, id, vmbios_uuid)

        except Exception as e:
            LOG.exception("Exception occurred: %s", e)
        finally:
            LOG.info("Exit: get_vmware_server_details")
            server_operations_return = rmv_utils.convert_object_to_dict_recursively(server_operations_return)
            return server_operations_return

    def get_vmware_vm_details(self,
                              context,
                              x_auth_token,
                              id=None,
                              vm_identifier=None,
                              detail=False):
        """
        Method to get Virtual Machine details.

        :param context: context
        :param x_auth_token: auth-token
        :param id: server id
        :param vm_identifier: VM BIOS UUID/ VM Moref
        :param detail: if set to TRUE will return virtual disk details along with VM details
        :return: vm detail dictionary
        """
        LOG.info("Enter: get_vmware_vm_details ")
        LOG.info("operation_input=%s %s", id, vm_identifier)
        server_operations_return = {}

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            rmv_server_manager = RmvServerManager()
            server_operations_return['vm'] = rmv_server_manager.get_vm_details(context, id, vm_identifier, detail)

            LOG.info("Exit: get_vmware_vm_details")
            return server_operations_return
        except Exception as e:
            LOG.exception(e)
            raise e

    def get_virtualdisk_details(self,
                                context,
                                x_auth_token,
                                id=None,
                                vm_identifier=None,
                                vdisk_identifier=None,
                                lunVendor=None):
        """
        Method to get Virtual Disk details

        :param context: context
        :param x_auth_token: auth-token
        :param id: server id
        :param vm_identifier: VM BIOS UUID/ VM Moref
        :param vdisk_identifier: virtual disk UUID
        :return: lunVendor: either 3par or Nimble
        """
        LOG.info("Enter: get_virtualdisk_details ")
        LOG.info("operation_input=%s %s", id, vm_identifier)
        server_operations_return = {}

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            rmv_server_manager = RmvServerManager()

            server_operations_return = \
                rmv_server_manager.get_virtualdisk_details(context, id, vm_identifier, vdisk_identifier, lunVendor)

            LOG.info("Exit: get_virtualdisk_details")
            return server_operations_return
        except Exception as e:
            LOG.exception(e)
            raise e

    def get_vmware_host_details(self,
                                context,
                                x_auth_token,
                                id=None,
                                host_identifier=None):
        """
        Method to get ESXi Server details.

        :param context: context
        :param x_auth_token: auth-token
        :param id: server id
        :param vm_identifier: HOST UUID/ HOST Moref
        :return: vm detail dictionary
        """
        LOG.info("Enter: get_vmware_host_details ")
        LOG.info("operation_input=%s %s", id, host_identifier)
        server_operations_return = {}

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            rmv_server_manager = RmvServerManager()
            server_operations_return['host'] = rmv_server_manager.get_host_details(context, id, host_identifier)

            LOG.info("Exit: get_vmware_host_details")
            return server_operations_return
        except Exception as e:
            LOG.exception(e)
            raise e

    def vmware_server_operations(self,
                                 context,
                                 x_auth_token,
                                 operation_input,
                                 operation_type):
        """
        This method takes all the calls related hypervisor server(ESXi/vCenter) and pass
        it to rmv server manager for performing each operation. (e.g regiser server)

        :param context: context
        :param x_auth_token: auth-token
        :param operation_type: register, un-register,update server
        :param operation_input: input values for various operations related to hypervisor server
        :return: None
        """
        LOG.info("Enter: vmware_server_operations ")
        LOG.debug("operation_input=%s", operation_input)
        server_operations_return = {}

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            rmv_server_manager = RmvServerManager()
            server_operations_return = rmv_server_manager.execute_server_operations(context, operation_input,
                                                                                    operation_type)
            if server_operations_return:
                server_operations_return = rmv_utils.convert_object_to_dict_recursively(server_operations_return)

            LOG.info("Exit: vmware_server_operations")
            return server_operations_return
        except Exception as e:
            LOG.exception(e)
            raise e

    def create_snapshot_policy(self, context, createSnapshotpolicy_input, x_auth_token):
        LOG.info("manager update_snapshot_policy :Enter")

        recoveryset_id = None
        array_serial_number = None
        virtual_copy_luns = []
        scsi_luns = []
        vmInfo = None
        ds_info = None
        db_create = False
        wwn_list = None
        VmType = None
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vmObjId = createSnapshotpolicy_input['VmObjId']
        vmObjType = createSnapshotpolicy_input['VmObjType']
        snap_count = createSnapshotpolicy_input['NumMaxSnapshots']
        numeric_policy = createSnapshotpolicy_input['NumericPolicy']

        mo_ref = vmObjId
        policy_info = rmv_structures.Policy()
        policy_info.ExpiryTime = createSnapshotpolicy_input['ExpiryTime']
        policy_info.RetentionTime = createSnapshotpolicy_input['RetentionTime']
        policy_info.NumMaxSnapshots = createSnapshotpolicy_input['NumMaxSnapshots']
        policy_info.IsRetention = createSnapshotpolicy_input['IsRetention']
        policy_info.SnapRetention = createSnapshotpolicy_input['SnapRetention']
        policy_info.SnapExpiry = createSnapshotpolicy_input['SnapExpiry']
        policy_info.AppConsistent = createSnapshotpolicy_input['AppConsistent']
        policy_info.RemoveOldestSnap = createSnapshotpolicy_input['RemoveOldestSnap']
        policy_info.StartsAsExpirable = createSnapshotpolicy_input['StartsAsExpirable']
        policy_info.MakeVmConsistent = createSnapshotpolicy_input['MakeVmConsistent']
        policy_info.NumericPolicy = createSnapshotpolicy_input['NumericPolicy']
        policy_info.NonExpirablePolicyHandling = createSnapshotpolicy_input['NonExpirablePolicyHandling']
        policy_info.Active = createSnapshotpolicy_input.get('Active', True)
        policy_info.VmMorefList = createSnapshotpolicy_input.get('VmMorefList', None)
        notification_policy_id = createSnapshotpolicy_input.get('notificationPolicyId', None)

        try:
            # TODO move below code to pyvmomi
            # Checking whether the datastore is in accessible state or not. If not then raise an exception
            is_ds_active = self.vi_helper.isDatastoreActive(vmObjType, mo_ref)
            if not is_ds_active:
                raise rmv_exception.DatastoreUnusableError(
                    error="Selected datastore or virtual machine is inaccessible. Please verify and retry.")

            json_policy_info = jsonutils.dumps(policy_info.__dict__)
            policy_info_dict = policy_info.__dict__
            LOG.debug("json_policy_info=%s", json_policy_info)

            try:
                recoveryset_row = self.db.get_record_based_on_mo_ref(context, vmObjId)
            except exception.DBRecordNotFound as e:
                LOG.error("Record not found in DB so creating new record")
                db_create = True

            ds_moref = None
            scsi_lun_values = []
            # If type is VirtualMachine, then 1st get the datastore moref and then check for ScsiLun information.
            if vmObjType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                vmInfo, hostInfo = self.get_virtual_machine_details(mo_ref)
                VmType = vmInfo.VmType
                scsi_lun_values = vmInfo.VirtualCopyPairList
                policy_name = rmv_utils.get_recoveryset_name(vmInfo.Name, vmObjType)
                # Update DB with mo_uuid. Which is used to uniquely identify the ManagedObjects
                # In case of DS, VmfsUuid will be uqinue field
                createSnapshotpolicy_input['mo_uuid'] = vmInfo.InstanceUUID
            elif vmObjType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                ds_moref = vmObjId
                LOG.info("Retrieving properties of Datastore : '%s' and its Lun information..." % ds_moref)
                ds_info = self.vi_helper.get_datastore_details(ds_moref, scsi_lun_values)
                # ds_info = self.pyvmomi_wrapper_obj.get_datastore_complete_info(ds_moref, scsi_lun_dict)
                VmType = ds_info.DatstoreType
                policy_name = rmv_utils.get_recoveryset_name(ds_info.Name, vmObjType)
                # Update DB with mo_uuid. Which is used to uniquely identify the ManagedObjects
                # In case of DS, VmfsUuid will be uqinue field
                createSnapshotpolicy_input['mo_uuid'] = ds_info.VmfsUuid
                if scsi_lun_values and hasattr(scsi_lun_values[0], "Wwn"):
                    createSnapshotpolicy_input['lun_wwn'] = scsi_lun_values[0].Wwn

            LOG.info("Policy name : %s" % policy_name)

            if vmObjType == "VirtualMachine":
                datastore_mref = None
                array_serial_number = None
                virtual_copy_luns = []
                if VmType == json_helper.TpdVmHostFileSystemType.Vmfs:
                    ScsiLun = scsi_lun_values

                    if vmInfo.InservSerialNumbers:
                        array_serial_number = vmInfo.InservSerialNumbers[0]
                    virtual_copy_info = json_helper.plugin_virtual_copy_info()
                    virtual_copy_info.Is3ParLun = ScsiLun[0].Is3ParLun
                    virtual_copy_info.ItemName = vmInfo.Name
                    virtual_copy_info.LunUsedAs = json_helper.virtual_copy_item_type.Datastore
                    virtual_copy_info.InServBaseVolumeWwn = vmInfo.VirtualCopyPairList[0].InServBaseVolumeWwn
                    virtual_copy_luns.append(virtual_copy_info)
                    VmType = rmv_utils.VMFS_DISK_TYPE

                elif VmType == json_helper.TpdVmHostFileSystemType.VVol:
                    vm_prop_dict = self.vi_helper.get_object_prop_dict(mo_ref, vmObjType, "config.hardware")

                    # Extract WWN list of the base Datadisk of the VM.
                    wwn_list = self.get_object_wwn_list(vm_prop_dict, "config.hardware")

                    array_name = vmInfo.ArrayName
                    VmType = rmv_utils.VVOL_DISK_TYPE

                    # Get the details of the registered array using array name.
                    storage_system_details = self.get_rmc_registered_array_list(x_auth_token, array_name)

                    # Extract the array information.
                    array_serial_number = storage_system_details['ArraySerialNumber']


            elif vmObjType == "Datastore":
                LOG.info("Create datastore policy enter:")
                datastore_mref = vmObjId
                # ScsiLun = Scsi_lun_dict.values()
                ScsiLun = scsi_lun_values
                virtual_copy_info = json_helper.plugin_virtual_copy_info()
                virtual_copy_info.Is3ParLun = ScsiLun[0].Is3ParLun
                virtual_copy_info.ItemName = ds_info.Name
                virtual_copy_info.LunUsedAs = json_helper.virtual_copy_item_type.Datastore
                virtual_copy_info.DatastoreMoref = datastore_mref
                virtual_copy_info.InServBaseVolumeWwn = ScsiLun[0].Wwn
                virtual_copy_luns.append(virtual_copy_info)
                array_serial_number = ScsiLun[0].InServSerialNumber()

            updatepolicy_info = rmc_wrapper_service.create_policy(array_serial_number, virtual_copy_luns, context,
                                                                  policy_name, wwn_list, VmType,
                                                                  policy=policy_info_dict, task_id=None)
            if updatepolicy_info:
                recoverysetid = updatepolicy_info['id']
                recoveryset_id = recoverysetid
                # create new record in rmv_snapshots db
                snapshot = {}
                self.create_db_record(context, numeric_policy, createSnapshotpolicy_input, mo_ref, db_create,
                                      recoverysetid)

                # now update client_Data in rmc
                response_data = rmc_wrapper_service.update_recovery_set(recoverysetid, policy=json_policy_info,
                                                                        input=policy_info_dict, task_id=None)
                return {
                    'snapshotsetinfo': {
                        'statusCode': "19",
                        'statusDescription': "Success",
                        'SnapshotSetID': recoverysetid
                    }}
            else:
                LOG.error(" error in RMC: update policy failed")
                return {
                    'snapshotsetinfo': {
                        'statusCode': "8",
                        'statusDescription': "Internal error in "
                                             "RMC:update policy failed"
                    }}

        except rmv_exception.WebclientInialization as e:
            LOG.exception(("update policy failed  : '%s'") % e)
            msg = "Internal error in rmv"
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            return {
                'snapshotsetinfo': {
                    'statusCode': "0",
                    'statusDescription': msg
                }}

        except (rmv_exception.VmwareException,
                rmv_exception.PyVmomiException,
                Exception, rmv_exception.TaskError) as e:
            LOG.exception(e)
            LOG.error(("update policy failed  : '%s'") % e)
            msg = "Internal error in rmc"
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                msg = str(e)
            return {
                'snapshotsetinfo': {
                    'statusCode': "8",
                    'statusDescription': msg
                }}
        finally:
            LOG.info("Attaching recovery-set to notification policy")
            if recoveryset_id and notification_policy_id != 0:
                try:
                    self.assign_new_notifcation_policy(notification_policy_id, recoveryset_id,
                                                       rmc_wrapper_service)
                except Exception as e:
                    LOG.info("manager create_snapshot_policy :Exit")
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': "Default policy creation was successful but notification "
                                                 "policy association failed, please check notification "
                                                 "policy status and try again."
                        }}

    def update_snapshot_policy_new(self, context, updateSnapshotpolicy_input, x_auth_token):
        LOG.info("manager update_snapshot_policy :Enter")
        recoveryset_id = None
        vmInfo = None
        ds_info = None
        db_create = False
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vmObjId = updateSnapshotpolicy_input['VmObjId']
        vmObjType = updateSnapshotpolicy_input['VmObjType']
        snap_count = updateSnapshotpolicy_input['NumMaxSnapshots']
        numeric_policy = updateSnapshotpolicy_input['NumericPolicy']
        mo_ref = vmObjId

        policy_info = rmv_structures.Policy()
        policy_info.ExpiryTime = updateSnapshotpolicy_input['ExpiryTime']
        policy_info.RetentionTime = updateSnapshotpolicy_input['RetentionTime']
        policy_info.NumMaxSnapshots = updateSnapshotpolicy_input['NumMaxSnapshots']
        policy_info.IsRetention = updateSnapshotpolicy_input['IsRetention']
        policy_info.SnapRetention = updateSnapshotpolicy_input['SnapRetention']
        policy_info.SnapExpiry = updateSnapshotpolicy_input['SnapExpiry']
        policy_info.AppConsistent = updateSnapshotpolicy_input['AppConsistent']
        policy_info.RemoveOldestSnap = updateSnapshotpolicy_input['RemoveOldestSnap']
        policy_info.StartsAsExpirable = updateSnapshotpolicy_input['StartsAsExpirable']
        policy_info.MakeVmConsistent = updateSnapshotpolicy_input['MakeVmConsistent']
        policy_info.NumericPolicy = updateSnapshotpolicy_input['NumericPolicy']
        policy_info.NonExpirablePolicyHandling = updateSnapshotpolicy_input['NonExpirablePolicyHandling']
        policy_info.Active = updateSnapshotpolicy_input.get('Active', True)
        policy_info.VmMorefList = updateSnapshotpolicy_input.get('VmMorefList', None)
        notification_policy_id = updateSnapshotpolicy_input.get('notificationPolicyId', None)

        try:
            # TODO move below code to pyvmomi
            # Checking whether the datastore is in accessible state or not. If not then raise an exception
            is_ds_active = self.vi_helper.isDatastoreActive(vmObjType, mo_ref)
            if not is_ds_active:
                raise rmv_exception.DatastoreUnusableError(
                    error="Selected datastore or virtual machine is inaccessible. Please verify and retry.")

            json_policy_info = jsonutils.dumps(policy_info.__dict__)
            policy_info_dict = policy_info.__dict__
            LOG.debug("json_policy_info=%s", json_policy_info)
            recoveryset_id = updateSnapshotpolicy_input['SnapshotSetID']
            ds_moref = None
            VmType = ""
            scsi_lun_values = []
            # If type is VirtualMachine, then 1st get the datastore moref and then check for ScsiLun information.
            if vmObjType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                vmInfo, hostInfo = self.get_virtual_machine_details(mo_ref)
                VmType = vmInfo.VmType
                scsi_lun_values = vmInfo.VirtualCopyPairList
                # Update DB with mo_uuid. Which is used to uniquely identify the ManagedObjects
                # In case of VM, InstanceUUID will be uqinue field
                updateSnapshotpolicy_input['mo_uuid'] = vmInfo.InstanceUUID
            elif vmObjType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                ds_moref = vmObjId
                LOG.info("Retrieving properties of Datastore : '%s' and its Lun information..." % ds_moref)
                ds_info = self.vi_helper.get_datastore_details(ds_moref, scsi_lun_values)
                # ds_info = self.pyvmomi_wrapper_obj.get_datastore_complete_info(ds_moref, scsi_lun_dict)
                VmType = ds_info.DatstoreType
                # Update DB with mo_uuid. Which is used to uniquely identify the ManagedObjects
                # In case of DS, VmfsUuid will be uqinue field
                updateSnapshotpolicy_input['mo_uuid'] = ds_info.VmfsUuid
                if scsi_lun_values and hasattr(scsi_lun_values[0], "Wwn"):
                    updateSnapshotpolicy_input['lun_wwn'] = scsi_lun_values[0].Wwn

            if vmObjType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                LOG.info("update policy for vm")

                # In case of vVol, apply_numeric_polcy from RMV
                # Then update the recovery set
                if VmType == json_helper.TpdVmHostFileSystemType.VVol:
                    task_id = None
                    task_percentage = 0
                    vm_task_helper = VmTaskHelper(self.vi_helper)
                    try:
                        kwargs = {}
                        kwargs['name'] = 'RMC-V Numeric policy updation'
                        kwargs['owner'] = 'RMC-V User'
                        kwargs['task_state'] = 'New'
                        kwargs['task_type'] = 'User'
                        kwargs['resource_name'] = 'RMC-V Numeric policy'
                        kwargs['resource_category'] = 'Policy'
                        kwargs['association_type'] = 'IS_A'

                        kwargs['resource_id'] = recoveryset_id
                        kwargs['action'] = 'Policy'
                        kwargs['resourceType'] = 'VVOL'
                        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
                        response_data = rmc_wrapper_service.create_task(kwargs)
                        task_id = response_data['id']

                        vm_task_helper.CustomVMwareTaskBegin(vmObjType, mo_ref, "UpdateSnapshotPolicyTask",
                                                             "UpdateSnapshotPolicyTaskFailedFault")
                        # TODO: task will be added once new task is created

                        task_state = 'Running'
                        task_desc_string = "Updating numeric policy"
                        task_percentage = 40
                        task_status = "Initiated"
                        self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        self.apply_numeric_policy(context, recoveryset_id, rmc_wrapper_service, x_auth_token, task_id,
                                                  snap_count)

                        task_state = 'Completed'
                        task_desc_string = "Policy updated successfully"
                        task_percentage = 100
                        task_status = "Ok"
                        self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)
                        vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                        self.vi_helper.LogEvent(mo_ref, vmObjType, task_desc_string)

                    except Exception as e:
                        LOG.exception("Exception while updating policy: %s", e)
                        msg = (_("Exception while Updating numeric policy"))
                        if hasattr(e, "msg"):
                            LOG.error(('%s'), e.msg)
                            msg = e.msg
                        elif hasattr(e, "message"):
                            LOG.error(('%s'), e.message)
                            msg = e.message

                        task_state = 'Failed'
                        task_status = "Error"
                        self._update_task(msg, task_percentage, task_state, task_id, rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        # Associating the vCenter Task with User Logged Event.
                        vm_task_helper.post_general_user_event(msg)

                        vm_task_helper.CustomVMwareTaskEnd("error", msg)
                        return

            # Let's check if the recovery set is migrated from one array
            # to another. If yes, let's create a new recovery set on the
            # new array and migrate its policy. Database is updated with
            # the newly created recovery set ID
            try:
                recoveryset_id = rset_migration.verify_and_migrate_recovery_set(context, recoveryset_id, vmObjType,
                                                                                vmObjId, ds_info, vmInfo,
                                                                                scsi_lun_values, rmc_wrapper_service)
            except Exception as e:
                msg = "Exception while migrating recovery set to new array, please logout of vCenter and login again:%s", str(
                    e)
                LOG.exception(msg)
                return {
                    'snapshotsetinfo': {
                        'statusCode': "8",
                        'statusDescription': msg
                    }}

            response_data = rmc_wrapper_service.update_recovery_set(recoveryset_id, policy=json_policy_info,
                                                                    input=policy_info_dict, task_id=None)
            if not response_data:
                LOG.error("Internal error in RMC: update snapshot policy failed")
                return {
                    'updateSnapshotpolicy': {
                        'statusCode': "8",
                        'statusDescription': "Internal error in RMC: "
                                             "update snapshot policy failed"
                    }}
            else:
                LOG.info("update snapshot policy submitted= %s",
                         response_data)
                # return response_data
                # set del_nonexpirable_snap if user migarates from
                # numeric to snapsexpiry
                self.update_db_record(context, numeric_policy, updateSnapshotpolicy_input, mo_ref, recoveryset_id)
                return {
                    'snapshotsetinfo': {
                        'statusCode': "19",
                        'statusDescription': "Success"
                    }}

        except rmv_exception.WebclientInialization as e:
            LOG.exception(("update policy failed  : '%s'") % e)
            msg = "Internal error in rmv"
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            return {
                'snapshotsetinfo': {
                    'statusCode': "0",
                    'statusDescription': msg
                }}

        except (rmv_exception.VmwareException,
                rmv_exception.PyVmomiException,
                Exception, rmv_exception.TaskError) as e:
            LOG.exception(e)
            LOG.error(("update policy failed  : '%s'") % e)
            msg = "Internal error in rmc"
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                msg = str(e)
            return {
                'snapshotsetinfo': {
                    'statusCode': "8",
                    'statusDescription': msg
                }}
        finally:
            LOG.info("Attaching recovery-set to notification policy")
            if recoveryset_id and notification_policy_id != 0:
                try:
                    self.assign_new_notifcation_policy(notification_policy_id, recoveryset_id,
                                                       rmc_wrapper_service)
                except Exception as e:
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': "Default policy creation was successful but notification "
                                                 "policy association failed, please check notification "
                                                 "policy status and try again."
                        }}

        LOG.info("manager update_snapshot_policy :Exit")

    # comment out or remove the update_snapshot_policy later on
    def update_snapshot_policy(self, context, updateSnapshotpolicy_input,
                               x_auth_token):
        LOG.info("manager update_snapshot_policy :Enter")
        recoveryset_id = None
        is_create = updateSnapshotpolicy_input['is_create']
        virtual_copy_luns = []
        scsi_luns = []
        vmInfo = None
        ds_info = None
        db_create = False
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vmObjId = updateSnapshotpolicy_input['VmObjId']
        vmObjType = updateSnapshotpolicy_input['VmObjType']
        snap_count = updateSnapshotpolicy_input['NumMaxSnapshots']
        numeric_policy = updateSnapshotpolicy_input['NumericPolicy']
        removeOldestSnap = updateSnapshotpolicy_input['RemoveOldestSnap']
        is_app_consistent = updateSnapshotpolicy_input['AppConsistent']
        expiry_in_hours = updateSnapshotpolicy_input['SnapExpiry']
        retention_in_hours = updateSnapshotpolicy_input['SnapRetention']
        IsRetention = updateSnapshotpolicy_input['IsRetention']
        mo_ref = vmObjId
        policy_info = rmv_structures.Policy()
        # Get the database record object based on mo_ref
        policy_info.ExpiryTime = updateSnapshotpolicy_input['ExpiryTime']
        policy_info.RetentionTime = updateSnapshotpolicy_input[
            'RetentionTime']
        policy_info.NumMaxSnapshots = updateSnapshotpolicy_input[
            'NumMaxSnapshots']
        policy_info.IsRetention = updateSnapshotpolicy_input['IsRetention']
        policy_info.SnapRetention = updateSnapshotpolicy_input['SnapRetention']
        policy_info.SnapExpiry = updateSnapshotpolicy_input['SnapExpiry']
        policy_info.AppConsistent = updateSnapshotpolicy_input['AppConsistent']
        policy_info.RemoveOldestSnap = updateSnapshotpolicy_input[
            'RemoveOldestSnap']
        policy_info.StartsAsExpirable = updateSnapshotpolicy_input[
            'StartsAsExpirable']
        policy_info.MakeVmConsistent = updateSnapshotpolicy_input[
            'MakeVmConsistent']
        policy_info.NumericPolicy = updateSnapshotpolicy_input['NumericPolicy']
        policy_info.NonExpirablePolicyHandling = updateSnapshotpolicy_input[
            'NonExpirablePolicyHandling']
        policy_info.Active = updateSnapshotpolicy_input.get('Active', True)
        policy_info.VmMorefList = updateSnapshotpolicy_input.get('VmMorefList', None)
        notification_policy_id = updateSnapshotpolicy_input.get('notificationPolicyId', None)

        try:
            # TODO move below code to pyvmomi
            # Checking whether the datastore is in accessible state or not. If not then raise an exception
            is_ds_active = self.vi_helper.isDatastoreActive(vmObjType, mo_ref)
            if not is_ds_active:
                raise rmv_exception.DatastoreUnusableError(
                    error="Selected datastore or virtual machine is inaccessible. Please verify and retry.")

            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # if BackupJobManager.web_client_cache.cached_vm_centers.keys():
            #     vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            #     vcenter_obj = cache.get(vcenter_ip)
            #     vm_vv_map_cache = vcenter_obj.vm_vv_map
            #     vCenter_instance_id = \
            #         BackupJobManager.web_client_cache.cached_vm_centers.values()[0].vi_helper.instance_uuid
            #     policy_name = "RMV_" + vCenter_instance_id + "_" + vmObjId
            #     LOG.info("policy_name=%s", policy_name)
            #     policy_info.PolicyName = policy_name
            #
            # else:
            #     raise rmv_exception.WebclientInialization()
            # ip_hostname, username, password, vcenteruid = self.get_vcenter_credentials()
            # if not vcenteruid:
            #     LOG.error("No vCenter is registered. Please register and retry. ")
            #     raise rmv_exception.VcenterNotFound()
            # policy_name = "RMV_" + vcenteruid + "_" + vmObjId

            json_policy_info = jsonutils.dumps(policy_info.__dict__)
            policy_info_dict = policy_info.__dict__
            LOG.debug("json_policy_info=%s", json_policy_info)

            if not is_create:
                recoveryset_id = updateSnapshotpolicy_input['SnapshotSetID']
                # response_data = rmc_wrapper_service.get_recovery_set(
                #    recoveryset_id)
                # if response_data:
                #    recovery_set = response_data['recoverySet']
                #    snapRetention = recovery_set['snapRetention']

            if IsRetention:
                LOG.info("Need to check virtual lock license exists or not")
                # TODO: call rmc get license. currently rmc spec is not present
                # islicense = check_license()
                # if islicense == False
                """return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': "virtual lock license  not "
                                                 "exists update snapshot "
                                                 "policy failed"
                        }}
                """
            try:
                if is_create:
                    recoveryset_row = self.db.get_record_based_on_mo_ref(
                        context, vmObjId)
            except exception.DBRecordNotFound as e:
                LOG.error("Record not found in DB so creating new record")
                db_create = True

            ds_moref = None
            scsi_lun_values = []
            # If type is VirtualMachine, then 1st get the datastore moref and then check for ScsiLun information.
            if vmObjType == "VirtualMachine":

                # prop_list = ["name", "datastore"]
                # vm_moref_obj = pyvmomi_util.get_moref(vmObjId, vmObjType)
                #
                # LOG.info("Retrieving properties of VirtualMachine with Moref ID '%s' " % vmObjId)
                # obj_cont = self.vi_helper.get_object_properties(vm_moref_obj, prop_list)
                # prop_dict = pyvmomi_util.extract_properties(obj_cont[0])
                # # prop_dict = self.pyvmomi_wrapper_obj.get_object_properties_common(vm_moref_obj, prop_list)
                #
                # vmInfo = json_helper.virtual_machine_info(vmObjId)
                # vmInfo.Name = prop_dict.get('name')
                # ds_moref = prop_dict.get('datastore')[0]._moId

                vmInfo, hostInfo = self.get_virtual_machine_details(mo_ref)
                VmType = vmInfo.VmType
                scsi_lun_values = vmInfo.VirtualCopyPairList

                # Update DB with mo_uuid. Which is used to uniquely identify the ManagedObjects
                # In case of VM, InstanceUUID will be uqinue field
                updateSnapshotpolicy_input['mo_uuid'] = vmInfo.InstanceUUID

            elif vmObjType == "Datastore":

                ds_moref = vmObjId

                LOG.info("Retrieving properties of Datastore : '%s' and its Lun information..." % ds_moref)
                ds_info = self.vi_helper.get_datastore_details(ds_moref, scsi_lun_values)
                # ds_info = self.pyvmomi_wrapper_obj.get_datastore_complete_info(ds_moref, scsi_lun_dict)
                VmType = ds_info.DatstoreType

                # Update DB with mo_uuid. Which is used to uniquely identify the ManagedObjects
                # In case of DS, VmfsUuid will be uqinue field
                updateSnapshotpolicy_input['mo_uuid'] = ds_info.VmfsUuid

            if vmObjType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                policy_name = rmv_utils.get_recoveryset_name(vmInfo.Name, vmObjType)
            elif vmObjType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                policy_name = rmv_utils.get_recoveryset_name(ds_info.Name, vmObjType)

            LOG.info("Policy name : %s" % policy_name)

            if vmObjType == "VirtualMachine" and is_create == False:
                LOG.info("update policy for vm")
                # vmInfo_vvol = self.get_virtual_machine_details(vmObjId)
                # VmType = vmInfo_vvol.VmType

                # Let's check if the recovery set is migrated from one array
                # to another. If yes, let's create a new recovery set on the
                # new array and migrate its policy. Database is updated with
                # the newly created recovery set ID

                # In case of vVol, apply_numeric_polcy from RMV
                # Then update the recovery set
                if VmType == json_helper.TpdVmHostFileSystemType.VVol:
                    task_id = None
                    task_percentage = 0
                    vm_task_helper = VmTaskHelper(self.vi_helper)
                    try:
                        kwargs = {}
                        kwargs['name'] = 'RMC-V Numeric policy updation'
                        kwargs['owner'] = 'RMC-V User'
                        kwargs['task_state'] = 'New'
                        kwargs['task_type'] = 'User'
                        kwargs['resource_name'] = 'RMC-V Numeric policy'
                        kwargs['resource_category'] = 'Policy'
                        kwargs['association_type'] = 'IS_A'
                        kwargs['resource_id'] = recoveryset_id
                        kwargs['action'] = 'Policy'
                        kwargs['resourceType'] = 'VVOL'
                        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
                        response_data = rmc_wrapper_service.create_task(kwargs)
                        task_id = response_data['id']

                        vm_task_helper.CustomVMwareTaskBegin(vmObjType,
                                                             mo_ref,
                                                             "UpdateSnapshotPolicyTask",
                                                             "UpdateSnapshotPolicyTaskFailedFault")
                        # TODO: task will be added once new task is created

                        task_state = 'Running'
                        task_desc_string = "Updating numeric policy"
                        task_percentage = 40
                        task_status = "Initiated"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        self.apply_numeric_policy(context,
                                                  recoveryset_id,
                                                  rmc_wrapper_service,
                                                  x_auth_token,
                                                  task_id,
                                                  snap_count)

                        task_state = 'Completed'
                        task_desc_string = "Policy updated successfully"
                        task_percentage = 100
                        task_status = "Ok"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)
                        vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                        self.vi_helper.LogEvent(mo_ref, vmObjType, task_desc_string)

                    except Exception as e:
                        LOG.exception("Exception while updating policy: %s", e)
                        msg = (_("Exception while Updating numeric policy"))
                        if hasattr(e, "msg"):
                            LOG.error(('%s'), e.msg)
                            msg = e.msg
                        elif hasattr(e, "message"):
                            LOG.error(('%s'), e.message)
                            msg = e.message

                        task_state = 'Failed'
                        task_status = "Error"
                        self._update_task(msg,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        # Associating the vCenter Task with User Logged Event.
                        vm_task_helper.post_general_user_event(msg)

                        vm_task_helper.CustomVMwareTaskEnd("error", msg)

                        # Commenting below LogEvent call, as the same event is logged using PostEvent
                        # self.vi_helper.LogEvent(mo_ref, vmObjType, msg)
                        return

                try:
                    recoveryset_id = \
                        rset_migration.verify_and_migrate_recovery_set(context,
                                                                       recoveryset_id,
                                                                       vmObjType,
                                                                       vmObjId,
                                                                       ds_info, vmInfo,
                                                                       scsi_lun_values,
                                                                       rmc_wrapper_service)

                except Exception as e:
                    msg = "Exception while migrating recovery set to new array,"
                    " please logout of vCenter and login again:%s", str(e)
                    LOG.exception("msg:%s", msg)

                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': msg
                        }}

                response_data = rmc_wrapper_service.update_recovery_set(
                    recoveryset_id,
                    policy=json_policy_info, input=policy_info_dict, task_id=None)
                LOG.info("response from update policy=%s", response_data)
                if not response_data:
                    LOG.error(" error in RMC: update policy failed")
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': "Internal error in "
                                                 "RMC:update policy failed"
                        }}
                else:
                    LOG.info("update snapshot policy submitted= %s",
                             response_data)
                    # return response_data
                    # set del_nonexpirable_snap if user migarates from
                    # numeric to snapsexpiry

                    self.update_db(context, is_create, numeric_policy,
                                   updateSnapshotpolicy_input, mo_ref, db_create)
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "19",
                            'statusDescription': "Success"
                        }}
            elif vmObjType == "VirtualMachine" and is_create == True:
                # vmInfo_vvol = self.get_virtual_machine_details(vmObjId)
                # VmType = vmInfo_vvol.VmType
                datastore_mref = None
                array_serial_number = None
                virtual_copy_luns = []
                wwn_list = None
                # for vm in vm_vv_map_cache.virtual_machines:
                #     if vm.VmMoref == vmObjId:
                #         vmInfo = vm
                #         datastore_mref = \
                #             vm.DsMorefToRestorableItemsDict.keys()[0]
                #         break
                if VmType == json_helper.TpdVmHostFileSystemType.Vmfs:
                    # Scsi_lun_dict = vm_vv_map_cache.get_scsi_lun_info_for_datastore(datastore_mref)

                    # ScsiLun = Scsi_lun_dict.values()
                    ScsiLun = scsi_lun_values

                    # array_serial_number = vmInfo.InservSerialNumbers[0]
                    if vmInfo.InservSerialNumbers:
                        array_serial_number = vmInfo.InservSerialNumbers[0]
                    # array_serial_number = ScsiLun[0].InServSerialNumber()
                    # virtual_copy_luns = vmInfo.VirtualCopyPairList
                    virtual_copy_info = json_helper.plugin_virtual_copy_info()
                    virtual_copy_info.Is3ParLun = ScsiLun[0].Is3ParLun
                    virtual_copy_info.ItemName = vmInfo.Name
                    virtual_copy_info.LunUsedAs = \
                        json_helper.virtual_copy_item_type.Datastore
                    # virtual_copy_info.DatastoreMoref = ds_info.DatastoreMoref
                    virtual_copy_info.InServBaseVolumeWwn = vmInfo.VirtualCopyPairList[0].InServBaseVolumeWwn
                    virtual_copy_luns.append(virtual_copy_info)
                    VmType = rmv_utils.VMFS_DISK_TYPE

                elif VmType == json_helper.TpdVmHostFileSystemType.VVol:
                    vm_prop_dict = self.vi_helper.get_object_prop_dict(mo_ref,
                                                                       vmObjType,
                                                                       "config.hardware")

                    # prop_list = ["config.hardware"]
                    # vm_moref_obj = pyvmomi_util.get_moref(vmObjId, vmObjType)
                    # obj_cont = self.vi_helper.get_object_properties(vm_moref_obj, prop_list)
                    # vm_prop_dict = pyvmomi_util.extract_properties(obj_cont[0])
                    # vm_prop_dict = self.pyvmomi_wrapper_obj.get_object_properties_common(vm_moref_obj, prop_list)

                    # Extract WWN list of the base Datadisk of the VM.
                    wwn_list = self.get_object_wwn_list(vm_prop_dict,
                                                        "config.hardware")

                    # array_name = vmInfo_vvol.ArrayName
                    # array_name = ds_info.VvolDS.storageArray[0].name
                    array_name = vmInfo.ArrayName
                    VmType = rmv_utils.VVOL_DISK_TYPE

                    # Get the details of the registered array using array name.
                    storage_system_details = self.get_rmc_registered_array_list(x_auth_token, array_name)

                    # Extract the array information.
                    array_serial_number = storage_system_details['ArraySerialNumber']

                updatepolicy_info = rmc_wrapper_service.create_policy(
                    array_serial_number,
                    virtual_copy_luns,
                    context,
                    policy_name,
                    wwn_list,
                    VmType,
                    policy=policy_info_dict, task_id=None)
                if updatepolicy_info:
                    # recoverySet = updatepolicy_info['recoverySet']
                    recoverysetid = updatepolicy_info['id']
                    recoveryset_id = recoverysetid
                    snapshot = {}
                    self.update_db(context, is_create, numeric_policy,
                                   updateSnapshotpolicy_input,
                                   mo_ref, db_create,
                                   recoverysetid)

                    # now update client data in rmc recovery set
                    resp = rmc_wrapper_service.update_recovery_set(
                        recoverysetid, policy=json_policy_info,
                        input=policy_info_dict, task_id=None)
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "19",
                            'statusDescription': "Success",
                            'SnapshotSetID': recoverysetid
                        }}
                else:
                    LOG.error(" error in RMC: update policy failed")
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': "Internal error in "
                                                 "RMC:update policy failed"
                        }}

            elif vmObjType == "Datastore" and is_create == False:
                LOG.info("Update datastore policy enter:")

                # Let's check if the recovery set is migrated from one array
                # to another. If yes, let's create a new recovery set on the
                # new array and migrate its policy. Database is updated with
                # the newly created recovery set ID
                try:
                    recoveryset_id = rset_migration.verify_and_migrate_recovery_set(
                        context, recoveryset_id, vmObjType, vmObjId, ds_info, vmInfo,
                        scsi_lun_values, rmc_wrapper_service)
                    recoveryset_id = recoveryset_id
                except Exception as e:
                    msg = "Exception while migrating recovery set to new array,"
                    " please logout of vCenter and login again:%s", str(e)
                    LOG.exception(msg)

                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': msg
                        }}

                response_data = rmc_wrapper_service.update_recovery_set(
                    recoveryset_id,
                    policy=json_policy_info, input=policy_info_dict, task_id=None)
                if not response_data:
                    LOG.error("Internal error in RMC: update snapshot "
                              "policy failed")
                    return {
                        'updateSnapshotpolicy': {
                            'statusCode': "8",
                            'statusDescription': "Internal error in RMC: "
                                                 "update snapshot policy failed"
                        }}
                else:
                    LOG.info("update snapshot policy submitted= %s",
                             response_data)
                    # return response_data
                    # set del_nonexpirable_snap if user migarates from
                    # numeric to snapsexpiry
                    self.update_db(context, is_create, numeric_policy,
                                   updateSnapshotpolicy_input, mo_ref, db_create)
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "19",
                            'statusDescription': "Success"
                        }}
            elif vmObjType == "Datastore" and is_create == True:
                LOG.info("Update datastore policy enter:")
                # for ds in vm_vv_map_cache.datastores:
                #     if ds.DatastoreMoref == vmObjId:
                #         datastore_info = ds
                #         break
                datastore_mref = vmObjId
                # # ds_info = self.get_datastore_details(mo_ref, scsi_luns)
                # Scsi_lun_dict = vm_vv_map_cache.get_scsi_lun_info_for_datastore(
                #      datastore_mref)
                #
                # ScsiLun = Scsi_lun_dict.values()
                ScsiLun = scsi_lun_values
                virtual_copy_info = json_helper.plugin_virtual_copy_info()
                virtual_copy_info.Is3ParLun = ScsiLun[0].Is3ParLun
                virtual_copy_info.ItemName = ds_info.Name
                virtual_copy_info.LunUsedAs = \
                    json_helper.virtual_copy_item_type.Datastore
                virtual_copy_info.DatastoreMoref = datastore_mref
                virtual_copy_info.InServBaseVolumeWwn = ScsiLun[0].Wwn
                virtual_copy_luns.append(virtual_copy_info)
                array_serial_number = ScsiLun[0].InServSerialNumber()
                updatepolicy_info = rmc_wrapper_service.create_policy(
                    array_serial_number,
                    virtual_copy_luns,
                    context,
                    policy_name,
                    policy=policy_info_dict, task_id=None)
                if updatepolicy_info:
                    # recoverysetid = ret_snap_info['id']
                    # recoverySet = updatepolicy_info['recoverySet']
                    recoverysetid = updatepolicy_info['id']
                    recoveryset_id = recoverysetid
                    # create new record in rmv_snapshots db
                    snapshot = {}
                    self.update_db(context, is_create, numeric_policy,
                                   updateSnapshotpolicy_input,
                                   mo_ref, db_create,
                                   recoverysetid)

                    # now update client_Data in rmc
                    response_data = \
                        rmc_wrapper_service.update_recovery_set(
                            recoverysetid,
                            policy=json_policy_info, input=policy_info_dict, task_id=None)
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "19",
                            'statusDescription': "Success",
                            'SnapshotSetID': recoverysetid
                        }}
                else:
                    LOG.error(" error in RMC: update policy failed")
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': "Internal error in "
                                                 "RMC:update policy failed"
                        }}

        except rmv_exception.WebclientInialization as e:
            LOG.exception(("update policy failed  : '%s'") % e)
            msg = "Internal error in rmv"
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            return {
                'snapshotsetinfo': {
                    'statusCode': "0",
                    'statusDescription': msg
                }}

        except (rmv_exception.VmwareException,
                rmv_exception.PyVmomiException,
                Exception, rmv_exception.TaskError) as e:
            LOG.exception(e)
            LOG.error(("update policy failed  : '%s'") % e)
            msg = "Internal error in rmc"
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                msg = str(e)
            return {
                'snapshotsetinfo': {
                    'statusCode': "8",
                    'statusDescription': msg
                }}
        finally:
            LOG.info("Attaching recovery-set to notification policy")
            if recoveryset_id and notification_policy_id != 0:
                try:
                    self.assign_new_notifcation_policy(notification_policy_id, recoveryset_id,
                                                       rmc_wrapper_service)
                except Exception as e:
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "8",
                            'statusDescription': "Default policy creation was successful but notification "
                                                 "policy association failed, please check notification "
                                                 "policy status and try again."
                        }}

        LOG.info("manager update_snapshot_policy :Exit")

    def get_all_remotecopy_groups(self, context, client_id, x_auth_token):
        LOG.info(_("Enter: get_all_remotecopy_groups in manager for client ID: %s"), client_id)
        rc_groups_obj = remotecopy_groups()
        db_obj = self.db
        rc_groups = dict()
        with rmv_locks.update_vcenter_cache:
            if self.is_remote_copy_group_listed is True and \
                    self.ret_rc_groups.get('remoteCopyGroups', None):
                rc_groups = self.ret_rc_groups
            else:
                rc_groups = rc_groups_obj.get_all_remotecopy_groups(context,
                                                                    client_id,
                                                                    x_auth_token,
                                                                    BackupJobManager.web_client_cache,
                                                                    self.vi_helper.ip, db_obj, self.vi_helper)
                if rc_groups:
                    # If fail over is happened on any rc group , then check and update changed moref of datstore belongs to rc group
                    moref_manage_obj = moref_manage(self.vi_helper)
                    moref_manage_obj.check_and_update_mo_ref_if_changed(context, x_auth_token, rc_groups)

                self.is_remote_copy_group_listed = True
                self.ret_rc_groups = rc_groups
        return rc_groups

    def get_rc_groups_by_rcgrp(self, context, client_id, x_auth_token, search_key):
        LOG.info("get_rc_groups_by_key : enter")
        rc_groups_obj = remotecopy_groups()
        db_obj = self.db
        return rc_groups_obj.get_rc_groups_by_rcgrp(context, search_key, client_id, x_auth_token,
                                                    BackupJobManager.web_client_cache, self.vi_helper.ip, db_obj,
                                                    self.vi_helper)

    def get_rc_groups_by_moref(self, context, client_id, x_auth_token, search_key):
        LOG.info("get_rc_groups_by_moref : enter")
        rc_groups_obj = remotecopy_groups()
        db_obj = self.db
        return rc_groups_obj.get_rc_groups_by_moref(context, search_key, client_id, x_auth_token,
                                                    BackupJobManager.web_client_cache, self.vi_helper.ip, db_obj,
                                                    self.vi_helper)

    def get_policy(self, context, vmObjType, vmObjId, xauthtoken):
        LOG.info("get_policy : enter")
        datastore_info = []
        vmInfo = []
        hostInfo = None
        vm_list = []
        recovery_set = None
        scsi_luns = []
        client_data = None
        reoveryset_id = None
        active = True
        try:
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # if BackupJobManager.web_client_cache.cached_vm_centers.keys():
            #     vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()[0]
            #     vcenter_obj = cache.get(vcenter_ip)
            #     vm_vv_map_cache = vcenter_obj.vm_vv_map
            # else:
            #     raise rmv_exception.WebclientInialization()

            # if vmObjType == 'VirtualMachine':
            #     if hasattr(vm_vv_map_cache, "virtual_machines"):
            #         for vm in vm_vv_map_cache.virtual_machines:
            #             if vm.VmMoref == vmObjId:
            #                 vmInfo = vm
            #                 datastore_mref = \
            #                     vm.DsMorefToRestorableItemsDict.keys()[0]
            #                 break
            #     """vm_host_info_dict = self.vi_helper.GetVirtualMachineInfo(
            #         vmObjId,
            #         False)"""
            #     if not vmInfo:
            #         msg = _("VMware object is not found for %s") % (vmObjId)
            #         raise exception.VMwareObjectnotfound(moref=vmObjId)
            # elif vmObjType == 'Datastore':
            #     if hasattr(vm_vv_map_cache, "datastores"):
            #         for ds in vm_vv_map_cache.datastores:
            #             if ds.DatastoreMoref == vmObjId:
            #                 datastore_info = ds
            #                 break
            #     datastore_mref = vmObjId
            #     if not datastore_info:
            #         msg = _("VMware object is not found for %s") % (vmObjId)
            #         raise exception.VMwareObjectnotfound(moref=vmObjId)
            #     else:
            #         LOG.debug("datastore_info")
            #         LOG.debug(datastore_info)
            #     #datastore_info = self.vi_helper.get_datastore(vmObjId,
            #     # scsi_luns)
            #
            #     #datastore = datastore_info.datastores
            #     #store = datastore[0]
            #     dsmoref = datastore_info.DatastoreMoref
            #     dsname = datastore_info.Name
            #     """vm_list_ret = vm_vv_map_cache.get_virtual_machine_in_datastore(
            #         dsmoref,
            #         dsname)"""
            #     virtualmachine = {}
            #     for vm in vm_vv_map_cache.virtual_machines:
            #         if vm.DsMorefToRestorableItemsDict:
            #             if dsmoref == vm.DsMorefToRestorableItemsDict.keys()[0]:
            #                 virtualmachine['Name'] = vm.Name
            #                 virtualmachine['Moref'] = vm.VmMoref
            #                 vm_list.append(virtualmachine)
            #
            # else:
            #     msg = _("Incorrect uri format")
            #     # raise exc.HTTPBadRequest(explanation=msg)

            # is_mo_exists = self.check_if_managed_object_exists(context, vmObjId, vmObjType)
            #
            # # In case of Schedule Job Edit from Group Scheduler page, MoRef may not available.
            # if not is_mo_exists:
            #     msg = "ManagedObject with ID : '%s', may not be reachable or deleted from vCenter. " \
            #           "Verify and retry. In case of SRM Failover/Failback, kindly update recovery " \
            #           "manager cache and retry." % vmObjId
            #     LOG.exception(msg)
            #     raise Exception(msg)

            datastore_mref = None
            vmInfo = json_helper.virtual_machine_info(vmObjId)
            if vmObjType == 'VirtualMachine':

                # prop_list = ["name", "config.uuid", "datastore", "runtime.connectionState"]
                # vm_moref_obj = pyvmomi_util.get_moref(vmObjId, vmObjType)
                # obj_cont = self.vi_helper.get_object_properties(vm_moref_obj, prop_list)
                # vm_prop_dict = pyvmomi_util.extract_properties(obj_cont[0])
                # # vm_prop_dict = self.pyvmomi_wrapper_obj.get_object_properties_common(vm_moref_obj, prop_list)
                #
                # vm_conn_state = vm_prop_dict.get("runtime.connectionState")
                # if vm_conn_state != "connected":
                #     msg = "VM : '%s' is not in connected state. Verify and retry." % vm_prop_dict.get("name")
                #     LOG.error(msg)
                #     raise rmv_exception.VmwareException(msg)
                #
                # vmInfo.Name = vm_prop_dict.get("name")
                # vmInfo.Uuid = vm_prop_dict.get("config.uuid")
                #
                # datastore_mref = vm_prop_dict.get("datastore")[0]._moId

                vmInfo, host_Info = self.get_virtual_machine_details(vmObjId)
                hostInfo = vmInfo.VirtualCopyPairList
                # lun_dict = []
                # datastore_info = self.vi_helper.get_datastore_details(datastore_mref, lun_dict)
                if not vmInfo:
                    msg = _("VMware object is not found for %s") % (vmObjId)
                    raise exception.VMwareObjectnotfound(moref=vmObjId)

            elif vmObjType == 'Datastore':

                datastore_mref = vmObjId

                lun_dict = []
                datastore_info = self.vi_helper.get_datastore_details(datastore_mref, lun_dict)
                # datastore_info = self.pyvmomi_wrapper_obj.get_datastore_complete_info(datastore_mref, lun_dict)
                if not datastore_info:
                    msg = _("VMware object is not found for %s") % (vmObjId)
                    raise exception.VMwareObjectnotfound(moref=vmObjId)

                if lun_dict:
                    vmInfo.InservSerialNumbers = [lun_dict[0]._InServSerialNumber]

                try:
                    # vmInfo = vm_host_info_dict['vmInfo']
                    # hostInfo = vm_host_info_dict['hostInfo']
                    # Scsi_lun_dict = vm_vv_map_cache.get_scsi_lun_info_for_datastore(datastore_mref)

                    hostInfo = lun_dict
                except:
                    #             LOG.info(('Exception from vi helper  %s'),
                    # exception)
                    msg = ("VMware object is not found for %s") % (vmObjId)
                    #   if vmError.__len__ > 0:
                    LOG.error('%s', msg)
                    raise exception.VMwareObjectnotfound(moref=vmObjId)

            # create rmc wrapper obejct
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(xauthtoken)

            recoveryset_row = None

            try:
                recoveryset_row = self.db.get_record_based_on_mo_ref(context,
                                                                     vmObjId)
            except exception.DBRecordNotFound as e:
                LOG.error("Record not found in DB.")

            # try:
            #     mo_uuid = None
            #     if vmObjType == 'VirtualMachine':
            #         mo_uuid = vmInfo.InstanceUUID
            #     elif vmObjType == 'Datastore':
            #         mo_uuid = datastore_info.VmfsUuid
            #
            #     recoveryset_row = self.db.get_rec_row_in_db_by_mo_uuid(context, mo_uuid)
            #
            #     if recoveryset_row:
            #         mo_ref_in_db = recoveryset_row['moref']
            #
            #         if mo_ref_in_db and mo_ref_in_db.strip() != vmObjId.strip():
            #             LOG.debug(("MoRef ID '%s' present in DB, with UUID : '%s', got changed. Updating DB table with "
            #                       "New MoRef ID present in vCenter: '%s' ") % (mo_ref_in_db, mo_uuid, vmObjId))
            #
            #             uuid_manage_obj = uuid_manage(self.vi_helper)
            #
            #             vm_uuid_to_moref_mapping_dict = {}
            #             vm_uuid_to_name_mapping_dict = {}
            #
            #             if vmObjType == 'Datastore':
            #                 vm_list = datastore_info.VmList
            #                 vm_moref_list = []
            #                 for vm in vm_list:
            #                     vm_moref = pyvmomi_util.get_moref(vm.Moref, "VirtualMachine")
            #                     vm_moref_list.append(vm_moref)
            #
            #                 ret_dict = self.vi_helper.build_uuid_to_moref_mapping_dict(vm_moref_list=vm_moref_list)
            #                 vm_uuid_to_moref_mapping_dict = ret_dict.get('vm_uuid_to_moref_mapping_dict')
            #                 vm_uuid_to_name_mapping_dict = ret_dict.get('vm_uuid_to_name_mapping_dict')
            #
            #             # Updaing new MoRef(present in vCenter) in DB and its recoveryset client data.
            #             uuid_manage_obj.update_changed_mo_ref_in_db_and_client_data(context=context,
            #                                                          x_auth_token=xauthtoken,
            #                                                          snapshot_row=recoveryset_row,
            #                                                          mo_ref_in_vCenter=vmObjId,
            #                                                          mo_ref_in_db=mo_ref_in_db,
            #                                                          mo_uuid=mo_uuid,
            #                                                          mo_type=vmObjType,
            #                                                          vm_uuid_to_moref_mapping_dict=vm_uuid_to_moref_mapping_dict,
            #                                                          vm_uuid_to_name_mapping_dict=vm_uuid_to_name_mapping_dict,
            #                                                          rmc_wrapper_service=rmc_wrapper_service)
            #             # After updaing DB, get updated DB values.
            #             recoveryset_row = self.db.get_rec_row_in_db_by_mo_uuid(context, mo_uuid)
            #
            # except Exception as e:
            #     LOG.exception("Unable to get Snapshot record in DB. '%s' " % e)

            response_data = None
            if recoveryset_row:
                reoveryset_id = recoveryset_row['recoverysetid']
            if not recoveryset_row or not reoveryset_id:
                recovery_set = None
                if vmObjType == 'VirtualMachine':
                    return {
                        'snapshotsetinfo':
                            rmv_utils.translate_snapshotset_summary_view(
                                context,
                                recovery_set,
                                vmInfo,
                                True,
                                hostInfo,
                                vmObjType,
                                datastore_info,
                                vm_list, client_data, active)}
                elif vmObjType == 'Datastore':
                    return {
                        'snapshotsetinfo':
                            rmv_utils.translate_snapshotset_summary_view(
                                context,
                                recovery_set,
                                vmInfo,
                                True,
                                hostInfo,
                                vmObjType,
                                datastore_info,
                                vm_list, client_data, active)}
            else:

                # if recovery set id is found in the rmv_snapshots database
                # make rmc call to get the recovery set information
                reoveryset_id = recoveryset_row['recoverysetid']
                active = recoveryset_row['is_active']
                if reoveryset_id:
                    response_data = rmc_wrapper_service.get_recovery_set(
                        reoveryset_id)
            # handle the response object returned from the create  recovery
            # set call
            # of rmc.Retrieve the recover set information from the  response
            #  data,
            # populate the data structures and return it

            if response_data:
                # retrive recoveryset information
                recovery_set = response_data['recoverySet']
                if 'clientData' in recovery_set.keys():
                    client_data = jsonutils.loads(recovery_set['clientData'])
                # Check to resolve a bug where snapshot creation fails and in
                # that case recoveryset id is not update
                # in the database.

                return {
                    'snapshotsetinfo':
                        rmv_utils.translate_snapshotset_summary_view(
                            context,
                            recovery_set,
                            vmInfo,
                            False,
                            hostInfo,
                            vmObjType,
                            datastore_info,
                            vm_list, client_data, active)}
            else:
                if reoveryset_id:
                    return {
                        'snapshotsetinfo':
                            rmv_utils.translate_snapshotset_summary_view(
                                context,
                                recovery_set,
                                vmInfo,
                                True,
                                hostInfo,
                                vmObjType,
                                datastore_info,
                                vm_list,
                                client_data, active)}
        except exception.DBRecordNotFound as e:
            if hasattr(e, "msg"):
                msg = e.msg
                LOG.error(("Exception: '%s'"), msg)
            else:
                msg = "unknow error"
                LOG.error(("Exception: '%s'"), e)
            return {
                'snapshotsetinfo': {
                    'statusCode': "9",
                    'statusDescription': msg
                }}
        except(exception.VMwareObjectnotfound) as e:
            if hasattr(e, "msg"):
                msg = e.msg
                LOG.error(("Exception: '%s'"), msg)
            else:
                msg = "unknow error"
                LOG.error(("Exception: '%s'"), e)
            return {
                'snapshotsetinfo': {
                    'statusCode': "8",
                    'statusDescription': msg
                }}

        except(rmv_exception.WebclientInialization) as e:
            if hasattr(e, "msg"):
                msg = e.msg
                LOG.error(("Exception: '%s'"), msg)
            else:
                msg = "unknow error"
                LOG.error(("Exception: '%s'"), e)
            return {
                'snapshotsetinfo': {
                    'statusCode': "0",
                    'statusDescription': msg
                }}
        except(Exception) as e:
            if hasattr(e, "msg"):
                msg = e.msg
                LOG.exception(e)
                LOG.error(("Exception: '%s'"), msg)
                if msg == "Recovery-set could not be found":
                    LOG.info("Recovery set not found in RMC")
                    dt = timeutils.utcnow()
                    del_moref = str(dt) + "_" + vmObjId
                    options = {'moref': del_moref}
                    result = self.db.update_record_based_on_mo_ref(
                        context, vmObjId, options)
                    return {
                        'snapshotsetinfo': {
                            'statusCode': "9",
                            'statusDescription': msg
                        }}
            else:
                msg = "unknow error"
                LOG.error(("Exception: '%s'"), e)
                LOG.exception(e)
            return {
                'snapshotsetinfo': {
                    'statusCode': "10",
                    'statusDescription': msg
                }}
        finally:
            collected = gc.collect()
            LOG.info("gc collected in get policy :%s", collected)

    def get_all_backup(self, context, x_auth_token):
        try:
            LOG.info(_('in get_all_backup'))

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            backup_response = rmc_wrapper_service.get_backup_all(context, x_auth_token)
            LOG.info(_('The backup details is %s') % backup_response)
            return backup_response
        except Exception as e:
            LOG.error(("Could not get backup information: '%s'") % e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Could not get backup information"

    def get_backup_for_recoveryset(self, context, recoveryset_id, x_auth_token):
        try:
            LOG.info(_('in get_backup_for_recoveryset'))

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            backup_response = rmc_wrapper_service.get_backup_for_recoveryset(context, recoveryset_id, x_auth_token)
            LOG.info(_('The backup details for recovery set is %s') % backup_response)
            return backup_response
        except Exception as e:
            LOG.exception(("Could not get backup information for recovery set: '%s'") % e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Could not get backup information for recovery set"

    def get_backup_for_backupId(self, context, backupId, x_auth_token, query_view_detail_exist=False):
        backup_response = {}
        try:
            LOG.info(_('in get_backup_for_backupId'))

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            backup_response = rmc_wrapper_service.get_backup_for_backupId(context, backupId, x_auth_token)
            LOG.debug(_('The backup details for recovery set is %s') % backup_response)

            # # MoRef might have changed in case of SRM Failover/Failback. So update the AppMetadata if required.
            # if backupId:
            #     backup_set = backup_response.get('backupSet')
            #     if backup_set:
            #         app_metadata = backup_set.get('appMetadata')
            #         changed_app_metadata = self.check_and_update_moref_in_backup_app_metadata(context=context,
            #                                                                                  x_auth_token=x_auth_token,
            #                                                                                  app_metadata=app_metadata,
            #                                                                                  backup_id=backupId)
            #         if changed_app_metadata:
            #             # TODO:SRM Test if updating backup_response is also required.
            #             backup_set['appMetadata'] = changed_app_metadata

            # Populate mount information (mountable esx host list or vm list for attaching vmdks
            # or datastore list for copying vmdk) with GET call
            if backup_response and query_view_detail_exist:
                backup_response = self.populate_backup_mount_details(context, backup_response)
                LOG.debug(_('Mountable information for backup set is  %s') % backup_response)

            return backup_response
        except (rmv_exception.RMCAPIError) as e:
            LOG.info(_("Dont worry we will fix it"))
            return
        except Exception as e:
            LOG.exception(("Could not get backup information for id: '%s'") % e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Could not get backup information for id"
        return backup_response

    def get_backup_system_from_backupPolicyId(self, context, policyId, x_auth_token):

        LOG.info(_('in get_backup_system_from_backupPolicyId'))
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            backup_response_policy = rmc_wrapper_service.get_backupId_from_policyId(context, policyId, x_auth_token)

            storage_device_id = backup_response_policy['backupPolicy']['storageDeviceId']

            backup_response = rmc_wrapper_service.get_backup_system_name_from_id(context, storage_device_id,
                                                                                 x_auth_token)
            backup_system_name = backup_response['backupSystem']['name']

            LOG.info(_('The backup details for recovery set is %s') % backup_response)
            return backup_system_name, backup_response_policy

        except (rmv_exception.RMCAPIError) as e:
            LOG.error(("Exception: '%s'"), e.msg)
            return
        except Exception as e:
            LOG.exception(("Could not get backup system information : '%s'") % e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Could not get backup system information"
            return

    def get_completed_percentage(self, context, rmc_wrapper_service, starting_rate, backup_id):
        LOG.info(_("In get_completed percentage"))
        backup_states = ['backing-up', 'restoring', 'verifying', 'backing']
        completed_percentage = starting_rate
        isverification = False
        progress_started = False
        backup_state = None
        try:
            LOG.info(_("The backup_id is %s") % backup_id)
            backupset_response = rmc_wrapper_service.get_backup_for_backupId(context, backup_id)
            LOG.debug(_('The backup id from percentage_complete %s') % backupset_response)
            total_size_in_gb = 0
            data_written = 0
            # For each of the backup element returned in backupSet
            for backup_element in backupset_response['backupSet']['backups']:
                LOG.debug(_('%s is the backup ele') % backup_element)
                LOG.debug(_("%s") % backup_element['snapName'])
                LOG.debug(_("%s") % backup_element['status'])

                # getting the size which in MB and converting it to GB
                total_size_in_gb = total_size_in_gb + (backup_element['size'] / 1024)

                # We might be backing it or restoring or verifying the backup
                LOG.debug(_('The backup_element status is %s') % backup_element['status'])
                backup_state = backup_element['status'].split(" ")[0]
                # BZ : 106547 - Completed percentage is returned by core, so no need to calculate in app
                """
                percentage = backup_element['status'].split(" ")[-1]
                if '%' in percentage:
                    percentage = int(percentage.split("%")[0])
                    LOG.debug(_('The percentage completed is %s') % percentage)
                    progress_started = True
                LOG.info(_('The backup_element state is %s') % backup_state)
                if backup_state in backup_states:
                    LOG.debug(_("Calculating the task complete percentage"))
                    LOG.debug(_("The percentage is 1 %s") % percentage)
                    #if backup_state == 'restoring' or backup_state == 'backing-up' or backup_state == 'verifying':
                    #    LOG.info(_("Operation has just begun"))
                    #    continue
                    #else:
                        #percentage = backup_element['status'].split(" ")[-1]
                    #    LOG.info(_("Calculate percentage %s") % percentage)
                    LOG.debug(_("Calculating the  task Complete Percentage %s") % percentage)
                    if progress_started:
                        #percentage = int(percentage.split("%")[0])
                        #LOG.info(_('The Rpercentage completed is %s') % percentage)
                        data_written = ((backup_element['size'] / 1024) * percentage) / 100
                        LOG.debug(_('RProgress: The data_written is %s') % data_written)
                    else:
                        LOG.info(_('In else '))
                        data_written = 0
                        percentage = starting_rate + 2
                """
                if 'creating' in backup_state:
                    LOG.debug(_('In creating state so returning the same'))
                    return starting_rate, False
                else:
                    data_written = backup_element['size'] / 1024
                    LOG.debug(_('Available: The data_written is %s') % data_written)
            LOG.debug(_("size is %s") % total_size_in_gb)
            # if total_size_in_gb != 0:
            #     completed_percentage = (data_written * 100) / total_size_in_gb
            # LOG.info(_('The completed Percentage is %s') % completed_percentage)
            if backup_state == 'verifying':
                LOG.debug(_("------Verifying is true"))
                isverification = True
            return completed_percentage, isverification
        except Exception as e:
            LOG.exception(("Could not Calculate Complete Percentage : '%s'") % e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Could not calculate complete percentage"
            return completed_percentage, isverification

    def update_backup_task(self, rmc_wrapper_service, copy_job, task_id, vm_task_helper, rmc_task,
                           rmv_backup_task, starting_rate=0, mo_ref=None, object_type=None, task_progress_share=0):
        LOG.info(_('in update_backup_task'))
        kwargs = {}
        if task_progress_share == 0:
            task_progress_share = 100 - starting_rate
        # snapshot_task_max_progress = starting_rate

        response_data = rmc_wrapper_service.get_copy_task_status(rmc_task)
        task_state = None
        isverification = False
        created_verify_task = True
        completed_percentage = 0
        vm_task_helper_verify = None
        try:
            task_state = response_data['task']['taskState']
            while ((task_state != 'Completed') and (task_state != 'Error') and (task_state != 'Aborted') and (
                    task_state != 'Failed')):

                # Below code is calculate the completed percentage
                backup_id = (response_data['task']['associatedResource']['resourceUri']).split('/')[-1]
                LOG.info(_('Calling the get_completed_percentage'))
                completed_percentage, isverification = self.get_completed_percentage(context, rmc_wrapper_service,
                                                                                     starting_rate, backup_id)
                # extract the required information.
                completed_percentage = int(response_data['task']['completedPercentage'])
                LOG.info(_("The completed percentage returned is %s") % completed_percentage)
                task_state = response_data['task']['taskState']
                kwargs['task_state'] = task_state
                kwargs['completed_percentage'] = completed_percentage
                #     rmc_wrapper_service.get_progress_rate(task_progress_share,
                #                                           completed_percentage,
                #                                           starting_rate)
                LOG.info(
                    _("The completed percentage returned from get_progress_rate %s") % kwargs['completed_percentage'])
                kwargs['task_status'] = response_data['task']['taskStatus']

                list_of_prg = response_data['task']['taskProgress']
                msg = None
                if list_of_prg is not None:
                    if len(list_of_prg) >= 1:
                        last = list_of_prg[:1][0]
                        msg = last.get('message')
                LOG.info("update_backup_task Message %s", msg)
                timeStamp = timeutils.utcnow()
                kwargs['taskProgress'] = {'message': msg, 'timeStamp': timeStamp}
                # create a new verification task here.
                LOG.info(_("Checking for verification"))
                if isverification:
                    LOG.debug(_("First time So creating the task"))
                    if created_verify_task:
                        # Create a verify task here
                        vm_task_helper_verify = VmTaskHelper(self.vi_helper)
                        LOG.debug(_('verification task started Creating a new verify task'))
                        vm_task_helper_verify.CustomVMwareTaskBegin(object_type,
                                                                    mo_ref,
                                                                    "VerificationofBackup",
                                                                    "VerificationofBackupFailedFault")
                        created_verify_task = False
                    LOG.debug(_("Verifying task already exist so updating only"))
                    rmc_wrapper_service.update_task_percentage_only(rmv_backup_task, kwargs)
                    # update vcenter task progress percentage completion here
                    task_desc_string = 'HPE StoreOnce Verification is in Progress.'
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      'Running',
                                      task_id,
                                      None,  # no need to change task status now. Keep it as earlier.
                                      vm_task_helper_verify)
                    if completed_percentage >= 100:
                        LOG.info(_('verification task is done'))
                        isverification = False
                        task_desc_string = 'HPE StoreOnce Verification is Complete.'
                        task_status = "Ok"
                        self._update_task(task_desc_string,
                                          completed_percentage,
                                          'Completed',
                                          task_id,
                                          None,  # no need to change task status now. Keep it as earlier.
                                          vm_task_helper_verify, task_status=task_status)
                        vm_task_helper_verify.CustomVMwareTaskEnd("success", task_desc_string)
                else:
                    # RP - No need to keep updating task tacker all fields specially error
                    # and recommendation with blank. It might end of crashing task tracker.
                    rmc_wrapper_service.update_task_percentage_only(rmv_backup_task, kwargs)
                    # update vcenter task progress percentage completion here
                    if copy_job:
                        task_desc_string = 'Catalyst Copy Operation is in Progress.'
                    else:
                        task_desc_string = 'Express Protect Operation is in Progress.'
                    # this fuction is being called while taking backup/catalyst or restore backup, so updating generic message to task
                    task_desc_string = "Operation is in Progress."
                    task_status = "Initiated"
                    LOG.info(_('The completed percentage is while updating task %s') % completed_percentage)
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      'Running',
                                      task_id,
                                      None,  # no need to change task status now. Keep it as earlier.
                                      vm_task_helper, task_status=task_status)
                # Sleep for 1 minutes here, as backup would take long time.
                LOG.info(_("Sleeeping for 60 seconds"))
                time.sleep(60)
                LOG.info(_("Woke up!!!!"))
                response_data = rmc_wrapper_service.get_copy_task_status(rmc_task)
                LOG.debug(_('The response data is %s') % response_data)
                task_state = response_data['task']['taskState']

            # if(task_state == 'Error' or task_state == 'Failed'):
            #     if response_data['task']['taskErrors']:
            #         for task_error in response_data['task']['taskErrors']:
            #             kwargs['error_code'] = task_error['errorCode']
            #             kwargs['error_details'] = task_error['errorDetails']
            #             kwargs['error_source'] = task_error['errorSource']
            #             kwargs['error_message'] = task_error['errorMessage']
            #             rmc_wrapper_service.update_task(rmv_backup_task, kwargs)
            # elif (task_state == 'Aborted'):
            #         LOG.info('task aborted...Id: '+str(rmv_backup_task))
            #         task_desc_string = "This task has been aborted by user."
            #         kwargs['error_message'] = 'Task aborted.'
            #         response_data['task']['taskState'] = 'Aborted'
            #         response_data['task']['taskStatus'] = "Error"
            #         task_status="Error"
            #         timeStamp = timeutils.utcnow()
            #         response_data['task']['taskProgress'] = {'message':"Aborted by user",'timeStamp':timeStamp}
            #
            #         self._update_task(task_desc_string,
            #                       completed_percentage,
            #                       'Aborted',
            #                       rmv_backup_task,
            #                       rmc_wrapper_service,
            #                       vm_task_helper,task_status=task_status)
            #
            #
            # else:
            #     rmc_wrapper_service.update_task(rmv_backup_task, kwargs)
        except Exception as e:
            LOG.exception(e)
            err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            LOG.error(_('update_backup_task: Could not '
                        'update the backup/copy tasks %s : %s') % (rmv_backup_task, err_args_msg))
            if (task_state == 'Error'):
                if response_data['task']['taskErrors']:
                    for task_error in response_data['task']['taskErrors']:
                        kwargs['error_code'] = task_error['errorCode']
                        kwargs['error_details'] = task_error['errorDetails']
                        kwargs['error_source'] = task_error['errorSource']
                        kwargs['error_message'] = task_error['errorMessage']
                        rmc_wrapper_service.update_task(rmv_backup_task, kwargs)
                else:
                    rmc_wrapper_service.update_task(rmv_backup_task, kwargs)
            raise
        finally:
            LOG.info(_('There was verification task so completing it.'))
            if vm_task_helper_verify:

                if (task_state != 'Error' and task_state != 'Aborted' and task_state != 'Failed'):
                    task_desc_string = 'HPE StoreOnce Verification is Complete.'
                    task_status = "Ok"
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      'Completed',
                                      task_id,
                                      None,  # no need to change task status now. Keep it as earlier.
                                      vm_task_helper_verify, task_status=task_status)
                    LOG.info('updating verify task success')
                    vm_task_helper_verify.CustomVMwareTaskEnd("success", task_desc_string)
                else:
                    task_desc_string = 'HPE StoreOnce Verification is Unsuccessful.'
                    task_status = "Error"
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      None,  # no need to change task status now. Keep it as earlier.
                                      vm_task_helper_verify, task_status=task_status)
                    LOG.info('updating verify task error')

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper_verify.post_general_user_event(task_desc_string)

                    vm_task_helper_verify.CustomVMwareTaskEnd("error", task_desc_string)
        LOG.info(_('taskState is %s') % response_data['task']['taskState'])
        LOG.info(_('The response data from get_backup_completed is %s') % response_data)
        return response_data

    def get_backup_state(self, context, rmc_wrapper_service, backup_id):
        LOG.info("get_backup_state : enter")

        # backup_states = ['backing-up', 'restoring', 'verifying', 'backing']
        backup_state = None
        backup_state_list = []

        try:
            LOG.info(_("The backup_id is %s") % backup_id)
            backupset_response = rmc_wrapper_service.get_backup_for_backupId(context, backup_id)
            LOG.debug(_('The backup id from percentage_complete %s') % backupset_response)

            # For each of the backup element returned in backupSet
            for backup_element in backupset_response['backupSet']['backups']:
                LOG.debug(_('%s is the backup ele') % backup_element)
                LOG.debug(_("%s") % backup_element['snapName'])
                LOG.debug(_("%s") % backup_element['status'])

                # We might be backing it or restoring or verifying the backup
                if backup_element.get('status'):
                    LOG.info("The backup_element status is '%s'" % backup_element['status'])
                    status = backup_element['status'].split(" ")[0]
                    backup_state_list.append(status)

            if len(backup_state_list) == 1:
                backup_state = backup_state_list[0]
            else:
                backup_state = "creating"

        except Exception as e:
            LOG.exception("Unable to get Backup State : '%s'" % e)

        LOG.info("get_backup_state : exit")
        return backup_state

    def update_copy_task(self, ctxt,
                         rmc_wrapper_service,
                         executor_task_id,
                         copy_type,
                         copy_id,
                         mo_ref,
                         object_type,
                         is_retry=False):
        """
        This method is to poll/monitor the Backup/CatalystCopy task. Task is created and managed by Executor.
        For the same task here we create and update the vCenter task.
        """

        LOG.debug("update_copy_task : enter")

        task_state = None
        backup_verify = False
        create_verify_task = True
        completed_percentage = 0
        vm_task_helper_verify = None
        progress_message = None
        response_data = None

        # Create the VMware task helper and populate vCenter Tasks
        vm_task_helper = VmTaskHelper(self.vi_helper)

        # Based on the copy type create the vCenter task.
        if copy_type == rmv_utils.copy_type.EXPRESS_PROTECT:
            if is_retry:
                vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                     mo_ref,
                                                     "RetryVMBackupTask",
                                                     "RetryVMBackupFailedFault")
            else:
                vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                     mo_ref,
                                                     "CreateVMBackupTask",
                                                     "CreateVMBackupFailedFault")

        elif copy_type == rmv_utils.copy_type.CATALYST_COPY:
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 "CreateVMCopyTask",
                                                 "CreateVMCopyFailedFault")

        elif copy_type == rmv_utils.copy_type.CLOUD_COPY:
            vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                 mo_ref,
                                                 "CreateVMCloudCopyTask",
                                                 "CreateVMCloudCopyFailedFault")

        try:
            response_data = rmc_wrapper_service.get_copy_task_status(executor_task_id)

            task_state = response_data['task']['taskState']
            backupStates = rmv_utils.get_backup_states()

            while task_state not in backupStates:

                backup_id = (response_data['task']['associatedResource']['resourceUri']).split('/')[-1]

                completed_percentage = int(response_data['task']['completedPercentage'])
                LOG.debug(_("The completed percentage returned is %s") % completed_percentage)

                backup_state = self.get_backup_state(ctxt, rmc_wrapper_service, backup_id)

                if backup_state == "verifying":
                    backup_verify = True

                if backup_verify:
                    LOG.info("Checking for verification")
                    LOG.debug(_("First time So creating the task"))
                    if create_verify_task:
                        # Create a verify task here
                        vm_task_helper_verify = VmTaskHelper(self.vi_helper)
                        LOG.debug(_('verification task started Creating a new verify task'))
                        vm_task_helper_verify.CustomVMwareTaskBegin(object_type,
                                                                    mo_ref,
                                                                    "VerificationofBackup",
                                                                    "VerificationofBackupFailedFault")
                        create_verify_task = False
                    LOG.debug(_("Verifying task already exist so updating only"))

                    # update vcenter task progress percentage completion here
                    if completed_percentage == 100:
                        LOG.info(_('verification task is done'))
                        backup_verify = False
                        task_desc_string = 'HPE StoreOnce Verification is Complete.'
                        vm_task_helper_verify.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)
                        vm_task_helper.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)

                    else:
                        task_desc_string = 'HPE StoreOnce Verification is in Progress.'
                        vm_task_helper_verify.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)
                        vm_task_helper.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)
                else:
                    task_desc_string = None
                    if copy_type == rmv_utils.copy_type.EXPRESS_PROTECT:
                        task_desc_string = 'Express Protect Operation is in Progress.'
                    elif copy_type == rmv_utils.copy_type.CATALYST_COPY:
                        task_desc_string = 'Catalyst Copy Operation is in Progress.'
                    elif copy_type == rmv_utils.copy_type.CLOUD_COPY:
                        task_desc_string = 'Cloud Copy Operation is in Progress.'

                    LOG.info('The completed percentage is while updating task %s' % completed_percentage)
                    vm_task_helper.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)

                # Sleep for 1 minutes here, as backup would take long time.
                LOG.info("Sleeping for 60 seconds")
                time.sleep(60)
                LOG.info("Woke up!!!!")

                response_data = rmc_wrapper_service.get_copy_task_status(executor_task_id)
                LOG.debug('The response data is %s' % response_data)

                task_state = response_data['task']['taskState']
                LOG.info(("Executor Task ID: '%s', states: '%s'") % (executor_task_id, task_state))
                progress_message = self.getLatestProgressMsg(response_data.get('task'))
                LOG.info("Copy operation progress message : '%s' " % progress_message)

        except Exception as e:
            LOG.exception("Unable to update the vCenter task for the Copy operation. '%s' " % e)

            snap_copy = self.db.get_rmcv_copy_by_id(ctxt, copy_id)
            snap_copy.status = json_helper.copy_status.error

            LOG.error("Failure while updating task status. So updating Copy table with the error status "
                      "for the copy ID: '%s'" % copy_id)
            self.db.update_rmcv_copy(ctxt, copy_id, snap_copy)

        finally:
            LOG.info("In finally block. Ending the vCenter tasks.")

            if vm_task_helper_verify:
                errorFailedBackupStates = rmv_utils.get_failed_backup_states()
                # if task_state != 'Error' and task_state != 'Aborted' and task_state != 'Failed':
                if task_state not in errorFailedBackupStates:
                    task_desc_string = 'HPE StoreOnce Verification is Complete.'
                    task_status = "success"
                else:
                    task_desc_string = 'HPE StoreOnce Verification is Unsuccessful.'
                    task_status = "error"

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper_verify.post_general_user_event(task_desc_string)

                vm_task_helper_verify.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)
                vm_task_helper_verify.CustomVMwareTaskEnd(task_status, task_desc_string)

            if task_state == 'Aborted':
                task_desc_string = "This task has been aborted by user."
                task_desc_string = task_desc_string + progress_message

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)

                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            elif task_state == 'Error' or task_state == 'Failed':
                task_desc_string = None
                if copy_type == rmv_utils.copy_type.EXPRESS_PROTECT:
                    task_desc_string = "HPE Express Protect backup failed. Reason "
                elif copy_type == rmv_utils.copy_type.CATALYST_COPY:
                    task_desc_string = "HPE StoreOnce Catalyst Copy is failed. Reason "
                elif copy_type == rmv_utils.copy_type.CLOUD_COPY:
                    task_desc_string = "HPE StoreOnce Cloud Copy is failed. Reason "

                task_desc_string = self.get_error_details(response_data, task_desc_string)

                vm_task_helper.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)
                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            else:
                task_desc_string = None
                if copy_type == rmv_utils.copy_type.EXPRESS_PROTECT:
                    task_desc_string = "HPE Express Protect Backup completed successfully."
                elif copy_type == rmv_utils.copy_type.CATALYST_COPY:
                    task_desc_string = "HPE StoreOnce Catalyst Copy is completed successfully."
                elif copy_type == rmv_utils.copy_type.CLOUD_COPY:
                    task_desc_string = "HPE StoreOnce Cloud Copy is completed successfully."

                task_desc_string = str(progress_message)

                # Update the appmetadata vitualcopylist field with corresponding backup object id
                # self.update_appmetadata(backjob_response, app_metadata, rmc_wrapper_service, x_auth_token)

                vm_task_helper.CustomVMwareTaskUpdate(completed_percentage, task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

        LOG.info(_('taskState is %s') % response_data['task']['taskState'])
        LOG.debug(_('The response data from get_backup_completed is %s') % response_data)
        LOG.debug("update_copy_task : exit")

    """
    # commented since we are changed RMC array refresh through
    # pool_id instead of recovery_set_id
    def update_rmc_cache(self, context, client_id, x_auth_token,
                         parent_task_id, child_task_id):
        LOG.debug("Enter update_rmc_cache in manager layer")
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vm_task_helper = VmTaskHelper(self.vi_helper)
        object_type = "Folder"
        mo_ref = "group-d1"
        vm_task_helper.CustomVMwareTaskBegin(object_type,mo_ref,
                                             "ArrayRefreshTask",
                                             "ArrayRefreshFailedFault")

        task_desc_string = 'Storage system refresh begin'
        task_percentage = 10
        task_state = 'Running'
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          child_task_id,
                          rmc_wrapper_service,
                          vm_task_helper, parent_task_id)
        try:
            recovery_set_id_list = []
            recovery_set_obj_list = self.db.get_all_recovery_set_ids(context)
            for recovery_set_obj in recovery_set_obj_list:
                if recovery_set_obj:
                    recovery_set_id_list.append(recovery_set_obj.recoverysetid)
                else:
                    recovery_set_id_list.append(recovery_set_obj_list.recoverysetid)

            LOG.debug("Numbe of recovery sets to refresh:  %s", str(len(recovery_set_id_list)))
            for id in recovery_set_id_list:
                LOG.debug("Rset ID:  %s", id)

            if recovery_set_id_list :
                for recovery_set_id in recovery_set_id_list:
                    if recovery_set_id:
                        LOG.debug("Going for refresh storage system for "
                                  "recovery_set_id:'%s'", recovery_set_id)
                        try:
                            response_data = rmc_wrapper_service.array_refresh(
                                context, recovery_set_id)
                            LOG.debug("response_data:'%s'", response_data)
                        except (rmv_exception.RMCAPIError, rmv_exception.TaskError) as e:
                            if hasattr(e, "msg"):
                                task_desc_string = e.msg
                            else:
                                task_desc_string = "Unknown error"
                            LOG.error("Storage system refreh failed for "
                                      "recovery_set_id:'%s', "
                                      "Error detail:'%s'",
                                      recovery_set_id, task_desc_string)
                            continue
            LOG.debug("recoveryset_ids :'%s'", recovery_set_id_list)
        except exception.RecoverySetNotFoundException as e:
            LOG.info("No recovery sets found  in DB")
            task_desc_string ="No recovery sets found  in DB"
            task_percentage = 100
            task_state = 'Completed'
            self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          child_task_id,
                          rmc_wrapper_service,
                          vm_task_helper, parent_task_id)
            vm_task_helper.CustomVMwareTaskEnd("success", task_percentage)
            return

        task_percentage = 100
        task_state = 'Completed'
        task_desc_string = "Storage system refresh completed successfully"
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          child_task_id,
                          rmc_wrapper_service,
                          vm_task_helper, parent_task_id)
        vm_task_helper.CustomVMwareTaskEnd("success", task_percentage)


        LOG.debug("Exit update_rmc_cache")
        return
        """

    def update_rmc_cache(self, context, client_id, x_auth_token,
                         parent_task_id, child_task_id):
        LOG.debug("Enter update_rmc_cache in manager layer")
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vm_task_helper = VmTaskHelper(self.vi_helper)
        object_type = "Folder"
        mo_ref = "group-d1"
        vm_task_helper.CustomVMwareTaskBegin(object_type, mo_ref,
                                             "ArrayRefreshTask",
                                             "ArrayRefreshFailedFault")

        task_desc_string = 'Storage system refresh begin'
        task_percentage = 10
        task_state = 'Running'
        task_status = "Initiated"
        self._update_task(task_desc_string,
                          task_percentage,
                          task_state,
                          child_task_id,
                          rmc_wrapper_service,
                          vm_task_helper, parent_task_id, task_status=task_status)
        is_one_or_more_array_refresh_failed = False
        error_msg = ""
        try:
            array_pool_id_list = []
            array_pool_id_list, array_system_id_list = self.get_all_pool_ids_in_use(
                rmc_wrapper_service, client_id)
            if array_pool_id_list and array_system_id_list:
                resp_list = []
                array_resp_list = []

                for pool_id in array_pool_id_list:
                    try:
                        LOG.info("Going to refresh pool_id :%s", pool_id)
                        response_data = rmc_wrapper_service.array_refresh(
                            context, pool_id, "storage-pools")
                        LOG.debug("response_data:'%s'", response_data)
                        if response_data.get('taskUri', None):
                            resp_list.append(response_data)
                    except (rmv_exception.RMCAPIError, rmv_exception.TaskError) as e:
                        if hasattr(e, "msg"):
                            task_desc_string = e.msg
                        else:
                            task_desc_string = "Unexpected error"
                        LOG.error("Storage system refresh failed for "
                                  "pool_id:'%s', "
                                  "Error detail:'%s'",
                                  pool_id, task_desc_string)

                for system_id in array_system_id_list:
                    try:
                        LOG.info("Going to refresh system_id :%s", system_id)
                        response_data = rmc_wrapper_service.array_refresh(
                            context, system_id, "storage-systems")
                        LOG.debug("response_data:'%s'", response_data)
                        if response_data.get('taskUri', None):
                            array_resp_list.append(response_data)
                    except (rmv_exception.RMCAPIError, rmv_exception.TaskError) as e:
                        LOG.exception(e)
                        if hasattr(e, "msg"):
                            task_desc_string = e.msg
                        else:
                            task_desc_string = "Unexpected error"
                        LOG.error("Storage system refresh failed for "
                                  "system_id:'%s', "
                                  "Error detail:'%s'",
                                  system_id, task_desc_string)

                for task_uri in resp_list:
                    try:
                        resp = \
                            rmc_wrapper_service.rmc_low_level.wait_on_task(
                                task_uri)
                    except (rmv_exception.RMCAPIError, rmv_exception.TaskError) as e:
                        if hasattr(e, "msg"):
                            task_desc_string = e.msg
                        else:
                            task_desc_string = "Unexpected error"
                        is_one_or_more_array_refresh_failed = True
                        LOG.error("%s", task_desc_string)
                        error_msg = task_desc_string
        except Exception as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                task_desc_string = e.msg
            else:
                task_desc_string = "Internal error"
                LOG.info("%s", str(e))
            LOG.error("got exception in array refresh :%s", task_desc_string)
            task_percentage = 100
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              child_task_id,
                              rmc_wrapper_service,
                              vm_task_helper, parent_task_id, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            return
        if not is_one_or_more_array_refresh_failed:
            task_percentage = 100
            task_state = 'Completed'
            task_status = "Ok"
            task_desc_string = "Storage system refresh completed successfully"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              child_task_id,
                              rmc_wrapper_service,
                              vm_task_helper, parent_task_id, task_status=task_status)
            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
        else:
            task_percentage = 100
            task_state = 'Failed'
            task_status = "Error"
            task_desc_string = "One or more array refresh failed:" + error_msg
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              child_task_id,
                              rmc_wrapper_service,
                              vm_task_helper, parent_task_id, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

        # Refresh remote RMV server StoreServ now
        array_records = self.db_base.db.array_get_all(context)
        remote_host_list = []
        # Find out all configured remote RMV server first. There is possibility
        # that same remote RMV server is configured for multiple target StoreServ.
        # Avoid sending cache refresh call to same remote RMV server multiple times.

        for array_record in array_records:
            server_detail = self.db_base.db.appliance_get(context, array_record['associated_appliance_id'])
            remote_host_name = server_detail.name
            # Store only unique remote RMV server in remote_host_list.
            if remote_host_name not in remote_host_list:
                remote_host_list.append(remote_host_name)

        # If client id is not rmv_utils.dummy_refresh_client_id than refresh remote RMV server
        # Otherwise infinite loop of refresh can occur.

        if not (client_id in rmv_utils.dummy_refresh_client_id):
            # refresh remote RMV server for storeServ details
            for remote_host_name in remote_host_list:
                # Refresh remote RMV server for StoreServ now.
                try:
                    rmc_wrapper_service.update_remote_server_cache(context, remote_host_name, parent_task_id)
                except Exception as e:
                    LOG.exception(e)
                    # Continue for next remote remv server. don't raise exception. Just log it.
        LOG.debug("Exit update_rmc_cache")
        return

    def getsnapshot_from_task(self, context, rmc_wrapper_service, task_id):
        response_data = rmc_wrapper_service.get_copy_task_status(task_id)
        if response_data:
            if (response_data['task']['taskState'] == 'Completed'):
                LOG.debug(_("The response data is %s") % response_data)
                id = response_data['task']['associatedResource']['resourceUri'].split('/')[-1]
                return id
        return None

    def get_rs_from_task_resp(self, backjob_response):
        if backjob_response:
            if (backjob_response['taskState'] == 'Completed'):
                LOG.debug(_("The response data is %s") % backjob_response)
                associatedData = backjob_response['associatedData']
                if associatedData:
                    id = associatedData[0]['resourceUri'].split('/')[-1]
                    return id
        return None

    def get_vm_configuration_info(self, backup_id, rmc_wrapper_service):
        LOG.info('get_vm_configuration_info : Enter')
        response_data = rmc_wrapper_service.get_backup_clientMetadata(backup_id)
        prop_dict = response_data['metadata']['clientMetadata']
        LOG.info("Property dictionary : %s" % prop_dict)
        LOG.info('get_vm_configuration_info : Exit')
        return prop_dict

    def get_folder_properties(self, folder_moref, dc_vmfolder_name):
        """
        get the default vmfolder name
        :param folder_moref:Default vmfolder moref
        :param dc_vmfolder_name: Default vm folder name
        :param vm_vv_map_cache: vmware cache
        :return: returns default vmfolder name
        """
        try:
            if folder_moref == None:
                msg = (("Error:Unable to fetch VM folder property from parent VM Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            my_folder_name = self.vi_helper.GetObjectProperties(folder_moref, "name")
            if my_folder_name == None:
                msg = (
                ("Error:Unable to fetch folder property from parent VmFolder Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            grandfolder_name = my_folder_name.objects[0].propSet[0].val
            if grandfolder_name == None:
                msg = (("Error:Unable to fetch VM Folder name  for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            dc_vmfolder_name = dc_vmfolder_name + "/" + grandfolder_name
            self.vv_map_obj.put_folder_in_dcfolderlist(folder_moref.value, dc_vmfolder_name)
            childfolder_name = self.vi_helper.GetObjectProperties(my_folder_name.objects[0].obj, "childEntity")
            if childfolder_name == None:
                msg = (
                ("Error:Unable to fetch Child property from parent VmFolder Moref  for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            if childfolder_name.objects[0].propSet[0].val != "":
                child_property_dict = vim_util.extract_properties(childfolder_name.objects[0])
                if child_property_dict != None:
                    for cmoref in range(len(child_property_dict['childEntity'].ManagedObjectReference)):
                        if child_property_dict['childEntity'].ManagedObjectReference[cmoref]._type == "Folder":
                            result = self.get_folder_properties(
                                child_property_dict['childEntity'].ManagedObjectReference[cmoref], dc_vmfolder_name)

            else:
                return
        except Exception as e:
            LOG.exception("Exception occured fetching object properties in get_folder_properties: %s", e)

    def get_host_folder_properties(self, folder_moref, host_name):
        """
        get the default resouce pool name
        :param folderMoref: resource pool moref
        :param hostName: Default resource pool name
        :param vm_vv_map_cache: vm ware cache
        :return: returns default resource pool name
        """
        try:
            if folder_moref == None:
                msg = ((
                    "Error:Unable to fetch resource folder property from parent resourcepool Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            my_folder_name = self.vi_helper.GetObjectProperties(folder_moref, "name")
            if my_folder_name == None:
                msg = (("Error:Unable to fetch property from parent resourcepool Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            grandfolder_name = my_folder_name.objects[0].propSet[0].val
            if grandfolder_name == None:
                msg = (("Error:Unable to fetch Resource Folder name  for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            host_name = host_name + "/" + grandfolder_name
            self.vv_map_obj.put_resource_pool_in_respoollist(folder_moref.value, host_name)
            childfoldername = self.vi_helper.GetObjectProperties(my_folder_name.objects[0].obj, "resourcePool")
            if childfoldername == None:
                msg = (("Error:Unable to fetch child property from resourcepool Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            if childfoldername.objects[0].propSet[0].val != "":
                child_property_dict = vim_util.extract_properties(childfoldername.objects[0])
                if child_property_dict != None:
                    for cmoref in range(len(child_property_dict['resourcePool'].ManagedObjectReference)):
                        result = self.get_host_folder_properties(
                            child_property_dict['resourcePool'].ManagedObjectReference[cmoref], host_name)

            else:
                return
        except Exception as e:
            LOG.exception("Exception occured fetching object properties in get_hostFolder_properties: %s", e)

    def get_parent_folder_properties(self, folder_moref, dc_vmfolder_name):
        """
        get the parent vmfolder information
        :param folder_moref: parent vmfolder name
        :param dc_vmfolder_name: parent vmfolder name
        :param vm_vv_map_cache:vm ware cache
        :return: parent vmfolder name
        """
        try:
            if folder_moref == None:
                msg = ((
                    "Error:Unable to fetch parent  VM folder property from parent VM Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            my_folder_name = self.vi_helper.GetObjectProperties(folder_moref, "name")
            if my_folder_name == None:
                msg = (
                ("Error:Unable to fetch parent folder property from VmFolder Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            child_folder_name = self.vi_helper.GetObjectProperties(my_folder_name.objects[0].obj, "childEntity")
            if child_folder_name == None:
                msg = (
                ("Error:Unable to fetch Child property from parent VmFolder Moref  for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            child_property_dict = vim_util.extract_properties(child_folder_name.objects[0])
            if child_folder_name.objects[0].propSet[0].val != "":
                if child_property_dict['childEntity'].ManagedObjectReference != None:
                    for cmoref in range(len(child_property_dict['childEntity'].ManagedObjectReference)):
                        if child_property_dict['childEntity'].ManagedObjectReference[cmoref]._type == "Folder":
                            result = self.get_folder_properties(
                                child_property_dict['childEntity'].ManagedObjectReference[cmoref], dc_vmfolder_name)
            else:
                return
        except Exception as e:
            LOG.exception("Exception occured fetching object properties in get_parent_folder_properties: %s", e)

    def get_parent_host_folder_properties(self, folder_moref, host_name):
        """
        get the parent resource pool information
        :param folder_moref: resource moref needed for getting child the resource
        :param host_name: parent resource name
        :param vm_vv_map_cache: vmware cache
        :return: recursively found resouce pool name
        """
        try:
            if folder_moref == None:
                msg = (
                ("Error:Unable to fetch parent resource moref from parent resourcepool for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            my_folder_name = self.vi_helper.GetObjectProperties(folder_moref, "name")
            if my_folder_name == None:
                msg = ((
                    "Error:Unable to fetch parent folder name property from resourcepool Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            grand_folder_name = my_folder_name.objects[0].propSet[0].val
            host_name = host_name + "/" + grand_folder_name
            child_folder_name = self.vi_helper.GetObjectProperties(my_folder_name.objects[0].obj, "resourcePool")
            if child_folder_name == None:
                msg = (("Error:Unable to fetch parent property from resourcepool Moref for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            child_property_dict = vim_util.extract_properties(child_folder_name.objects[0])
            self.vv_map_obj.put_resource_pool_in_respoollist(my_folder_name.objects[0].obj.value, host_name)
            if child_folder_name.objects[0].propSet[0].val != "":
                if child_property_dict['resourcePool'].ManagedObjectReference != None:
                    for cmoref in range(len(child_property_dict['resourcePool'].ManagedObjectReference)):
                        result = self.get_host_folder_properties(
                            child_property_dict['resourcePool'].ManagedObjectReference[cmoref], host_name)
            else:
                return
        except Exception as e:
            LOG.exception("Exception occured fetching object properties in get_parent_host_folder_properties: %s", e)

    def get_registered_vm_details(self, esx_hosts, hostname):
        """
        This call is for the get registered vm details
        :param vm_vv_map_cache:vmware cache
        :param hostname: Mounted Host
        :return:
        """

        LOG.info("get_registered_vm_details called:Enter")
        backup_appmetadata = {}
        try:
            hostname_moref = None
            for esx_host in esx_hosts.values():
                hostNam = esx_host.HostName
                hostRef = esx_host.HostSystemMoref
                if hostname == hostNam:
                    hostname_moref = hostRef
            if hostname_moref == None:
                msg = (("Error:User has not provided the proper mounted info to get the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            host_moref = vim.get_moref(hostname_moref, "HostSystem")
            if host_moref == None:
                msg = (("Error:Unable to fetch Host Moref for vcenter detail"))
                raise exception.VcenterDetailException(msg)
            data_center_moref = self.vi_helper.get_parent_datacenter(host_moref)
            if data_center_moref == None:
                msg = (("Error:Unable to get the Datacenter Moref from the host moref"))
                raise exception.VcenterDetailException(msg)

            # Start implementaion of VMFolder list:Start
            dc_name_propery = self.vi_helper.GetObjectProperties(data_center_moref, "name")
            if dc_name_propery == None:
                msg = (("Error:Unable to fetch the Datacenter Obj from DatacenterMoref"))
                raise exception.VcenterDetailException(msg)
            dc_vmfolder_name = dc_name_propery.objects[0].propSet[0].val
            if dc_vmfolder_name == None:
                msg = (("Error:Unable to fetch the Default VM Folder name for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            dc_vmfolder_name = dc_vmfolder_name + "/" + "vm"
            vm_folder_obj = self.vi_helper.GetObjectProperties(data_center_moref, "vmFolder")
            if vm_folder_obj == None:
                msg = (("Error:Unable to fetch the VM Folder from Datacenter for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            child_folder_name = self.vi_helper.GetObjectProperties(vm_folder_obj.objects[0].propSet[0].val,
                                                                   "childEntity")
            if child_folder_name == None:
                msg = (("Error:Unable to fetch the child information from VM Folder for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            self.vv_map_obj.put_folder_in_dcfolderlist(vm_folder_obj.objects[0].propSet[0].val.value, dc_vmfolder_name)
            property_dict = vim_util.extract_properties(child_folder_name.objects[0])
            if child_folder_name.objects[0].propSet[0].val != "":
                for moref in range(len(property_dict['childEntity'].ManagedObjectReference)):
                    dc_vmfolder_name = None
                    dc_vmfolder_name = dc_name_propery.objects[0].propSet[0].val
                    if dc_vmfolder_name == None:
                        msg = (("Error:Unable to fetch the VM Folder name for getting the vcenter detail"))
                        raise exception.VcenterDetailException(msg)
                    dc_vmfolder_name = dc_vmfolder_name + "/" + "vm"
                    if property_dict['childEntity'].ManagedObjectReference[moref]._type == "Folder":
                        myFolderName = self.vi_helper.GetObjectProperties(
                            property_dict['childEntity'].ManagedObjectReference[moref], "name")
                        if myFolderName == None:
                            msg = (("Error:Unable to fetch the child propery for getting the vcenter detail"))
                            raise exception.VcenterDetailException(msg)
                        folder_name = myFolderName.objects[0].propSet[0].val
                        if folder_name == None:
                            msg = (("Error:Unable to fetch the VM Folder name for getting the vcenter detail"))
                            raise exception.VcenterDetailException(msg)
                        dc_vmfolder_name = dc_vmfolder_name + "/" + folder_name
                        self.vv_map_obj.put_folder_in_dcfolderlist(
                            property_dict['childEntity'].ManagedObjectReference[moref].value, dc_vmfolder_name)
                        result = self.get_parent_folder_properties(
                            property_dict['childEntity'].ManagedObjectReference[moref], dc_vmfolder_name)

            backup_appmetadata['VmFolderList'] = self.vv_map_obj.get_vmfolder_list()
            self.vv_map_obj.reset_VMFolder_list()
            # Start implementaion of VMFolder list:End

            # Implementation on the Resouce pool:start
            resource_obj = self.vi_helper.GetObjectProperties(host_moref, "parent")
            if resource_obj == None:
                msg = (
                ("Error:Unable to fetch the compute Resource information from host for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            current_host = self.vi_helper.GetObjectProperties(resource_obj.objects[0].propSet[0].val, "host")
            if current_host == None:
                msg = (("Error:Unable to fetch the Host propery from compute Resource for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            host_name_obj = self.vi_helper.GetObjectProperties(current_host.objects[0].obj, "name")
            if host_name_obj == None:
                msg = (("Error:Unable to fetch the Host obj from Host propery for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            host_name = host_name_obj.objects[0].propSet[0].val
            if host_name == None:
                msg = ((
                    "Error:Unable to fetch the Host Name from Host propery of resource Object for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            current_resource_pool = self.vi_helper.GetObjectProperties(resource_obj.objects[0].propSet[0].val,
                                                                       "resourcePool")
            if current_resource_pool == None:
                msg = (("Error:Unable to fetch resource pool property from the Host for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            child_resource_pool = self.vi_helper.GetObjectProperties(current_resource_pool.objects[0].propSet[0].val,
                                                                     "resourcePool")
            if child_resource_pool == None:
                msg = (
                ("Error:Unable to fetch child resource pool property from the Host for getting the vcenter detail"))
                raise exception.VcenterDetailException(msg)
            child_property_dict = vim_util.extract_properties(child_resource_pool.objects[0])
            if child_resource_pool.objects[0].propSet[0].val != "":
                self.vv_map_obj.put_resource_pool_in_respoollist(current_resource_pool.objects[0].propSet[0].val.value,
                                                                 host_name)
                for rpoolmoref in range(len(child_property_dict['resourcePool'].ManagedObjectReference)):
                    result = self.get_host_folder_properties(
                        child_property_dict['resourcePool'].ManagedObjectReference[rpoolmoref], host_name)
            else:
                self.vv_map_obj.put_resource_pool_in_respoollist(current_resource_pool.objects[0].propSet[0].val.value,
                                                                 host_name)

            backup_appmetadata['EsxHostToResourcePoolList'] = self.vv_map_obj.get_resourcepool_list()
            self.vv_map_obj.reset_resoucepoollist()
            # Implementation on the Resouce pool:End

            backup_appmetadata = self.get_host_info_for_vcenter_detail(backup_appmetadata, esx_hosts)
            backup_appmetadata = rmv_utils.convert_object_to_dict_recursively(backup_appmetadata)

        except Exception as e:
            LOG.exception("Exception occured in the get_registered_vm_details: %s", e)
        return backup_appmetadata

    def get_vcenter_details(self, context, x_auth_token, hostname, query_view_detail_exist=False, vm_backup_flag=False):

        LOG.info("get_vcenter_details :Enter")

        dataStoreDict = {}
        ds_host_dict = {}

        prop_list = ["name", "datastore", "configManager.storageSystem"]
        esx_hosts = self.vi_helper.get_esx_host_info(prop_list)

        # Cache is removed from RMC-V 4.0
        # LOG.info("Accessing Cache info")
        # vm_vv_map_cache = None
        # cache = BackupJobManager.web_client_cache.cached_vm_centers
        # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()
        # for ip in range(len(vcenter_ip)):
        #     vcenter_obj = cache.get(vcenter_ip[ip])
        #     vm_vv_map_cache = vcenter_obj.vm_vv_map

        if query_view_detail_exist == True:
            response_data = self.get_registered_vm_details(esx_hosts, hostname)
            return response_data

        LOG.info("Retriving properties of all the Datastores in vCenter...")
        ds_info_list = self.vi_helper.get_all_ds_info_in_esx(esx_hosts)

        for dstr in ds_info_list:
            if vm_backup_flag == False:
                if dstr.DatstoreType == json_helper.TpdVmHostFileSystemType.VVol:
                    dataStoreName = dstr.Name
                    ds_Moref = dstr.DatastoreMoref
                    ds_hostList = dstr.MountedHostsList
                    ds_host_dict[dataStoreName] = ds_hostList
                    # ds_host_dict[dataStoreName] = ds_hostList
                    dataStoreDict[ds_Moref] = ds_host_dict
            else:
                dataStoreName = dstr.Name
                ds_Moref = dstr.DatastoreMoref
                ds_hostList = dstr.MountedHostsList
                ds_host_dict[dataStoreName] = ds_hostList
                # ds_host_dict[dataStoreName] = ds_hostList
                dataStoreDict[ds_Moref] = ds_host_dict

        LOG.debug(_("datastore Dict : %s " % dataStoreDict))

        hostnr_dict = {}
        for esx_host in esx_hosts.values():
            hostNam = esx_host.HostName
            hostRef = esx_host.HostSystemMoref
            hostnr_dict[hostNam] = hostRef

        compute_resource_path_set = ["host", "name", "resourcePool"]

        vim_object = self.vi_helper._session.vim
        client_factory = vim_object.client.factory

        travSpec = vim_util.build_recursive_traversal_spec(client_factory)

        property_spec = vim_util.build_property_spec(
            client_factory,
            type="ComputeResource",
            properties_to_collect=compute_resource_path_set,
            all_properties=False)

        object_contents = self.vi_helper._session._call_method(
            vim_util,
            "get_object_properties_2",
            vim_object.get_service_content().rootFolder,
            travSpec,
            property_spec)

        hostResPoolDict_1 = {}
        hostResPoolDict = {}
        clust_host_dict = {}
        hostIpDict = {}
        hostResPoolDict = {}
        for index in range(len(object_contents)):
            comp_res_dict = dict(object_contents[index])
            cr_list = None
            hostDict = {}
            resPoolDict = {}
            hostSysList = []
            hostIpDict = {}
            for key in comp_res_dict:
                if key == 'obj':
                    cr_list = comp_res_dict['obj']
                elif key == 'propSet':
                    for index in range(len(comp_res_dict['propSet'])):
                        if comp_res_dict['propSet'][index]['name'] == 'host':
                            hostSysList = comp_res_dict['propSet'][index]['val']
                            for hostSys in range(len(hostSysList)):
                                for hs in range(len(hostSysList[hostSys])):
                                    for hostKey in hostnr_dict:
                                        if hostSysList[hostSys][hs]['value'] == hostnr_dict[hostKey]:
                                            hostIpDict[hostKey] = hostSysList[hostSys][hs]['value']

                        elif comp_res_dict['propSet'][index]['name'] == 'name':
                            host = comp_res_dict['propSet'][index]
                            hostDict[host['val']] = host['name']
                            clust_host_dict[host['val']] = hostIpDict

                        elif comp_res_dict['propSet'][index]['name'] == 'resourcePool':
                            resPool = comp_res_dict['propSet'][index]
                            resPoolDict[resPool['name']] = resPool['val']['value']
                            for hkey in hostDict:
                                hostResPoolDict_1[hkey] = resPoolDict
                                for hrkey in hostResPoolDict_1:
                                    for ckey in clust_host_dict:
                                        if hrkey == ckey:
                                            for kkey in clust_host_dict[ckey]:
                                                if kkey == ckey:
                                                    hostResPoolDict[kkey] = hostResPoolDict_1[kkey]
                                                else:
                                                    hostResPoolDict[kkey] = hostResPoolDict_1[hrkey]

        for hkey in hostnr_dict:
            for ds in dataStoreDict:
                for ds_name in dataStoreDict[ds]:
                    for hs in range(len(dataStoreDict[ds][ds_name])):
                        if dataStoreDict[ds][ds_name][hs] == hostnr_dict[hkey]:
                            dataStoreDict[ds][ds_name][hs] = hkey

        LOG.debug("Host ResourcePool and Datastore Dict : %s" % hostResPoolDict)

        for hhkey in hostResPoolDict:
            ds_list = []
            for ds in dataStoreDict:
                for ds_name in dataStoreDict[ds]:
                    for i in range(len(dataStoreDict[ds][ds_name])):
                        if dataStoreDict[ds][ds_name][i] == hhkey:
                            ds_list.append(ds_name)
                            ds_set = set(ds_list)
                            ds_list = list(ds_set)
                            hostResPoolDict[hhkey]['Datastore'] = ds_list

        hostDataResPoolDict = {}
        ds_list_len = None

        for hhkey in hostResPoolDict:
            for hdskey in hostResPoolDict[hhkey]:
                if hdskey == 'Datastore':
                    ds_list_len = len(hostResPoolDict[hhkey][hdskey])
                    if ds_list_len > 0:
                        hostDataResPoolDict[hhkey] = hostResPoolDict[hhkey]

        response_data = hostDataResPoolDict

        LOG.info("Response data : %s " % response_data)

        LOG.info("get_vcenter_details :Exit")

        return response_data

    def recreateVM_for_restore(self, vmname, datastore, resPool, backup_id,
                               rmc_wrapper_service, task_id, vm_task_helper, host_ref):

        # get the client metadata for backup object
        try:
            # Update Tasks (Task Tracker and VMware Task)
            LOG.info("recreateVM_for_restore : Enter")
            task_desc_string = 'Retrieve the config info'
            task_percentage = 2
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            prop_dict = self.get_vm_configuration_info(backup_id, rmc_wrapper_service)

            task_desc_string = 'Validating the datastore for restore operation'
            task_percentage = 3
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            # Validate the selected datastore size. Check if the size is 0GB
            ds_name_to_moref_dict = self.vi_helper.get_ds_names_to_moref_dict()
            ds_moref = ds_name_to_moref_dict.get(datastore)
            self.vi_helper.validate_VVOL_datastore_for_recreateVM(datastore, ds_moref, "Datastore")

            # LOG.info("Accessing Cache info")
            # cache = BackupJobManager.web_client_cache.cached_vm_centers
            # vcenter_ip = BackupJobManager.web_client_cache.cached_vm_centers.keys()
            # for ip in range(len(vcenter_ip)):
            #     vcenter_obj = cache.get(vcenter_ip[ip])
            #     vm_vv_map_cache = vcenter_obj.vm_vv_map

            # for dstr in range(len(vm_vv_map_cache.datastores)):
            #     if vm_vv_map_cache.datastores[dstr].Name == datastore:
            #         ds_moref = vm_vv_map_cache.datastores[dstr].DatastoreMoref

            LOG.info("Calling buildSpec recreate VM in vi_helper")
            vm_spec = self.vi_helper.buildSpec_for_VM_ConfigInfo(vmname, datastore, ds_moref, prop_dict)
            vm_moref = self.vi_helper.recreate_VM(vm_spec, vmname, ds_moref, resPool, host_ref)
            if vm_moref:
                return vm_moref
            else:
                raise Exception("VM Recreate failed")

        except Exception as e:
            msg = "Failed to recreate the VM"
            LOG.exception("Failed to recreate the VM : %s", e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
                LOG.exception("Exception: %s", str(e.msg))
            elif hasattr(e, "message"):
                msg = e.message
                LOG.exception("Exception: %s", str(e.message))

            task_desc_string = msg
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service, task_status=task_status)

            raise e
            return

    def pre_restore_vmBackup(self, vDiskFiles, vm_moref, vmInfo, serialNumber, vm_task_helper, rmc_wrapper_service,
                             task_id):
        vCenterDetails = {}
        vDisks = []
        arrayAgnostic = True
        volWWN_list = []
        vmVendor = self.get_vm_vendor_info(vmInfo)
        supportedStorageVendors = rmv_utils.get_supported_storage_vendors()
        if vmVendor and (vmVendor.strip() in supportedStorageVendors) and (
                vmInfo.VmType == json_helper.TpdVmHostFileSystemType.Vmfs):
            arrayAgnostic = False
            if vmInfo.VirtualCopyPairList:
                for VirtualCopyList in vmInfo.VirtualCopyPairList:
                    if VirtualCopyList:
                        wwn = VirtualCopyList.InServBaseVolumeWwn
                        if type(wwn) is list:
                            for lun_wwn in wwn:
                                volWWN_list.append(lun_wwn)
                        else:
                            volWWN_list.append(wwn)

        if volWWN_list and arrayAgnostic == False:
            # HardCoding it now, will change it later
            recovery_set_name = rmv_utils.get_recoveryset_name(vm_moref, rmv_utils.VMWARE_OBJECT_TYPE_DS)

            # Create the recovery-set from RMC

            # get the Pool for the storage serial number
            LOG.info(_('Checking for array'))
            serialNumber = vmInfo.InservSerialNumbers[0]

            # Checking if the given storage system is registered in RMC.
            response_data = rmc_wrapper_service.check_array_registration(serialNumber)

            # Fetching the pool-id for the storage system
            pool_id = rmc_wrapper_service.get_storage_pool(response_data['id'], serialNumber)
            vol_list = []

            # create Recovery set by WWN names
            LOG.debug(_('Creating Recovery Set by WWN '))
            vol_list = [str(x) for x in volWWN_list]
            response_data = rmc_wrapper_service.create_rmc_recoveryset(recovery_set_name,
                                                                       vol_list,
                                                                       pool_id, task_id=task_id)
            LOG.debug(_('The response from recovery set id is %s') % response_data)

            LOG.info(_("Created the recovery set"))

            if response_data:
                LOG.info(_("Checking the status of volumes"))
                status = response_data['status']
                if status == 'available':
                    LOG.debug(_("Checking the list of volumes is available"))
                    # Update Task Tracker
                    msg = "Initialized Volumes for Restore Operation"
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                    # Update Tasks (Task Tracker and VMware Task)
                    task_desc_string = 'RecoverySet Created for Restore'
                    task_percentage = 7
                    task_state = 'Running'
                    task_status = "Initiated"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                else:
                    msg = "Volumes are not in  proper state." + status
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                    # Update Tasks (Task Tracker and VMware Task)
                    task_desc_string = msg
                    task_percentage = 7
                    task_state = 'Failed'
                    task_status = "Error"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    # Update Task tracker
                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                    raise rmv_exception.RMCRecoverySetStatusException(
                        status=status)

        elif arrayAgnostic:
            recoveryset_name = rmv_utils.get_recoveryset_name(vmInfo.Name, rmv_utils.VMWARE_OBJECT_TYPE_VM)
            vmType = "vDisk"
            objType = "VirtualMachine"
            wwn_list = None
            storage_pool_id = None

            response_data = rmc_wrapper_service.create_recovery_set(recoveryset_name,
                                                                    wwn_list,
                                                                    storage_pool_id,
                                                                    vmType,
                                                                    task_id=task_id)

        if 'id' in response_data:
            recovery_set_id = response_data['id']

        vCenterHost, vCenterUser, vCenterPassword, vCenteruuid, vCenterThumbPrint = self.vi_helper.get_vcenter_credentials()

        vCenterDetails['host'] = vCenterHost
        vCenterDetails['user'] = vCenterUser
        vCenterDetails['password'] = vCenterPassword
        vCenterDetails['thumbPrint'] = vCenterThumbPrint

        vmdk_path_list = self.get_vmdk_path(vm_moref)

        for i in range(len(vDiskFiles)):
            backupVMDKdict = {}
            backupVMDKdict['fileName'] = vDiskFiles[i].get('fileName')
            backupVMDKdict['filePath'] = vmdk_path_list[i]
            backupVMDKdict['fileSize'] = vDiskFiles[i].get('fileSize')
            backupVMDKdict['systemId'] = "moref=" + str(vm_moref)
            vDisks.append(backupVMDKdict)

        LOG.info("*** Disks details to be restored *** : %s" % vDisks)

        return (vCenterDetails, vDisks, recovery_set_id)

    def pre_restore_for_VvolBackup(self, vm_moref, vmInfo, x_auth_token, vmname, vm_task_helper, rmc_wrapper_service,
                                   task_id):
        config_key = "config.hardware"
        vm_prop_dict = self.vi_helper.get_object_prop_dict(vm_moref,
                                                           rmv_utils.VMWARE_OBJECT_TYPE_VM,
                                                           config_key)

        # Extract WWN list of the base Datadisk of the VM.
        volWWN_list = self.get_object_wwn_list(vm_prop_dict,
                                               config_key)

        array_name = vmInfo.ArrayName

        # Get the details of the registered array using array name.
        storage_system_details = self.get_rmc_registered_array_list(x_auth_token, array_name)

        # Extract the array information.
        array_ID = storage_system_details['ArrayID']
        serialNumber = storage_system_details['ArraySerialNumber']
        array_IP = storage_system_details['ArrayIP']
        array_user = storage_system_details['ArrayUserName']
        device_type = storage_system_details['deviceType']

        LOG.info("Sleeping for a while to initialize volumes for restore")

        time.sleep(60)

        recovery_set_name = rmv_utils.get_recoveryset_name(vmname, rmv_utils.VMWARE_OBJECT_TYPE_VM)

        # Create the recovery-set from RMC
        vmType = rmv_utils.VVOL_DISK_TYPE

        # Extract storage pool id
        storage_pools_list = rmc_wrapper_service.get_storage_pools(array_ID)
        # extract storage pool details from storage pool list
        storage_pool_id = self.select_pool_id(storage_pools_list, array_ID)

        recovery_set_details = rmc_wrapper_service.create_recovery_set(recovery_set_name,
                                                                       volWWN_list,
                                                                       storage_pool_id,
                                                                       vmType, task_id=task_id, device_type=device_type)

        recovery_set_id = recovery_set_details['id']

        if recovery_set_details:

            if 'id' in recovery_set_details:
                recovery_set_id = recovery_set_details['id']

            # Update Tasks (Task Tracker and VMware Task)
            task_desc_string = 'Initialising the volumes for restore'
            task_percentage = 4
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # DO array refresh to detach the recovery set from VM

            vm_power_state, vm_name = self.vi_helper.get_vm_power_state(vm_moref)
            if vm_power_state == 'poweredOn':
                msg = (_("Restore cannot be performed on a powered on VM, power off the VM and try again."))
                task_state = 'Failed'
                task_status = "Error"
                task_desc_string = msg
                task_percentage = 2
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                raise rmv_exception.VMNotPoweredOffError(vm_name=vm_name)

            # Refresh the recovery set for detach from VM if powered off
            task_desc_string = 'Refreshing volume information'
            task_percentage = 7
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            map_wwn_hostlist = self.get_attach_status_of_recovery_set(rmc_wrapper_service, recovery_set_id)
            LOG.info("Map wwn list : %s" % map_wwn_hostlist)


        else:
            msg = "Error in Preparing For Restore."
            # self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
            # Update Tasks (Task Tracker and VMware Task)
            task_desc_string = msg
            task_percentage = 7
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            # Update Task tracker

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            raise rmv_exception.RMCRecoverySetCreationException(
                id=storage_pool_id,
                wwn_list=volWWN_list)

        return recovery_set_id

    def is_catalyst_copy(self, backupSet):
        f = False
        if backupSet.get('backupSetId'):
            f = True
        return f

    # TODO: Santosh: Please make this function modular
    def restore_to_any_vol(self, context, copy_id, volName_list, volWWN_list, serialNumber, moref,
                           x_auth_token, task_id, vm_objType, recreateVM,
                           vmname, datastore, resPool, powerOn,
                           esxHostAddr=None, volumeCreationDetails=None, volume_type=None, inventoryMoref=None,
                           objectId=None, vm_name_dict={}, resource_list=list()):

        LOG.debug(_('In Restore to ANY Volume'))

        task_state = None
        task_desc_string = None
        vcenter_task_result = None
        type_for_vcenter_log = vm_objType
        msg_event = ""
        rmc_wrapper_service = None
        vm_task_helper = None
        msg_event = None
        vm_moref = None
        host_moref = None
        datastore_name = datastore
        parent_id = None
        base_wwn_list = list()
        cloned_resources = None
        try:
            mount = Mount()
            recovery_set_id = None
            vol_list = []
            # Create an instance of RMC Wrapper, to make any RMC or TaskTracker calls
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            # Create an instance of VMware Task Helper to populate vCenter Tasks
            vm_task_helper = VmTaskHelper(self.vi_helper)

            obj_exists = self.check_if_object_exists(moref, vm_objType)
            if obj_exists:
                type_for_vcenter_logevent = vm_objType
                type_for_vcenter_log = vm_objType
                mo_ref_for_vcenter_logevent = moref
            else:
                LOG.info("The parent object has either been removed or deleted, so proceeding with folder level task")
                # These 2 values are used for vCenter Events and Tasks logging
                type_for_vcenter_logevent = "Folder"
                type_for_vcenter_log = "Folder"
                mo_ref_for_vcenter_logevent = "group-d1"

            if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                copy_detail = self.db.get_rmcv_copy_by_id_with_ds_details(context, copy_id, moref)
                name = copy_detail.ds_name
                parent_id = copy_detail.ds_id
            else:
                copy_detail = self.db.get_rmcv_copy_by_id_with_vm_details(context, copy_id, moref)
                name = copy_detail.vm_name
                vm_name_dict[name] = copy_detail.moref
                parent_id = copy_detail.vm_id
            copy_name = copy_detail.name
            recovery_set_id = copy_detail.recovery_set_id
            copy_type = copy_detail.copy_type
            backup_id = copy_detail.rmc_copyset_id

            vCenterDetails = {}
            vmLevelBackup = False
            vDisks = []
            if copy_type == "nbd":
                vmLevelBackup = True

            # Create a VMware Task, The task name will change later
            # once available in plugin.
            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_logevent,
                                                 mo_ref_for_vcenter_logevent,
                                                 "RestoreToAnyVolume",
                                                 "RestoreToAnyVolumeFailedFault")

            rmcv_copy_info = self.db_base.db.get_rmcv_copy_by_id(context, copy_id)
            # update copy status to restoring
            rmcv_copy_info.status = rmv_utils.copy_states.RESTORING
            self.db.update_rmcv_copy(context, copy_id, rmcv_copy_info)

            # check if the object type is Virtual machine and if recreateVM is true, call the function to recreateVM
            if volume_type == rmv_utils.VVOL_DISK_TYPE or vmLevelBackup:
                LOG.info("RecreateVM is true")
                task_desc_string = 'Recreate VM for restore'
                task_percentage = 1
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                if esxHostAddr:
                    host_moref = self.get_host_moref_from_hostname_or_ip(esxHostAddr)
                    host_ref = vim.get_moref(host_moref, "HostSystem")
                else:
                    host_ref = None
                # creating a new data store in case of restore to new data store
                if volumeCreationDetails and vmLevelBackup:
                    datastore_name = self.create_vmfs_datastore(volumeCreationDetails, serialNumber, esxHostAddr,
                                                                moref, x_auth_token, task_id, vm_task_helper)
                vm_moref = self.recreateVM_for_restore(vmname, datastore_name, resPool, backup_id,
                                                       rmc_wrapper_service, task_id, vm_task_helper, host_ref)
                # get the virtual machine properties on the moref ,
                # from the prop, get serial number and volume list to create recovery set
                vmInfo, hostInfo = self.get_virtual_machine_details(vm_moref)
                arrayAgnostic = True
                if vmLevelBackup:
                    # TODO: Revisit below statement, how we can get "vDiskFiles" in granular backup
                    # vDiskFiles = backupSet['appMetadata'].get('files')
                    vCenterDetails, vDisks, recovery_set_id = self.pre_restore_vmBackup(vDiskFiles, vm_moref, vmInfo,
                                                                                        serialNumber,
                                                                                        vm_task_helper,
                                                                                        rmc_wrapper_service, task_id)

                if volume_type == rmv_utils.VVOL_DISK_TYPE:
                    recovery_set_id = self.pre_restore_for_VvolBackup(vm_moref, vmInfo, x_auth_token,
                                                                      vmname, vm_task_helper, rmc_wrapper_service,
                                                                      task_id)

            else:

                # type_for_vcenter_log = vm_objType
                # Log an event in Vcenter
                msg = "Restoring to another Volume begins"
                self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                # Update Tasks (Task Tracker and VMware Task)
                task_desc_string = 'Validating the volume list'
                task_percentage = 1
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # HardCoding it now, will change it later
                recovery_set_name = rmv_utils.get_recoveryset_name(moref, rmv_utils.VMWARE_OBJECT_TYPE_DS)

                # Create the recovery-set from RMC

                # get the Pool for the storage serial number
                LOG.info(_('Checking for array'))

                # Checking if the given storage system is registered in RMC.
                response_data = rmc_wrapper_service.check_array_registration(serialNumber)

                # Fetching the pool-id for the storage system
                pool_id = rmc_wrapper_service.get_storage_pool(response_data['id'], serialNumber)

                LOG.info(_("Checking the list of volumes"))
                if len(volName_list) > 0:
                    # create Recovery set by Volume names
                    vol_list = [str(x.get('name')) for x in volName_list if x.get('name')]
                    LOG.debug(_('The Vol list is %s') % volName_list)
                    response_data = rmc_wrapper_service.create_rmc_recoveryset_by_volnames(recovery_set_name,
                                                                                           volName_list,
                                                                                           pool_id, task_id=task_id)

                elif len(volWWN_list) > 0:
                    # create Recovery set by WWN names
                    LOG.debug(_('Creating Recovery Set by WWN '))
                    vol_list = [str(x) for x in volWWN_list]
                    response_data = rmc_wrapper_service.create_rmc_recoveryset(recovery_set_name,
                                                                               vol_list,
                                                                               pool_id, task_id=task_id)
                    LOG.debug(_('The response from recovery set id is %s') % response_data)

                elif len(volumeCreationDetails) > 0:
                    # Create recovery set along with creating new volumes
                    LOG.debug(('Creating Recovery set by new volume creation'))
                    vol_list = [str(x.get("volumeName")) for x in volumeCreationDetails]
                    response_data = rmc_wrapper_service.create_rmc_recoveryset_by_newvol(recovery_set_name,
                                                                                         volumeCreationDetails,
                                                                                         pool_id, task_id=task_id)

                LOG.info(_("Created the recovery set"))

                if response_data:
                    LOG.info(_("Checking the status of volumes"))
                    status = response_data['status']
                    if status == 'available':
                        LOG.debug(_("Checking the list of volumes is available"))
                        # Update Task Tracker
                        msg = "Initialized Volumes for Restore Operation"
                        self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                        # Update Tasks (Task Tracker and VMware Task)
                        task_desc_string = 'RecoverySet Created for Restore'
                        task_percentage = 7
                        task_state = 'Running'
                        task_status = "Initiated"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                    else:
                        msg = "Volumes are not in  proper state." + status
                        self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                        # Update Tasks (Task Tracker and VMware Task)
                        task_desc_string = msg
                        task_percentage = 7
                        task_state = 'Failed'
                        task_status = "Error"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        # Associating the vCenter Task with User Logged Event.
                        vm_task_helper.post_general_user_event(task_desc_string)

                        # Update Task tracker
                        vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                        raise rmv_exception.RMCRecoverySetStatusException(
                            status=status)
                else:
                    msg = "Error in Preparing For Restore."
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                    # Update Tasks (Task Tracker and VMware Task)
                    task_desc_string = msg
                    task_percentage = 7
                    task_state = 'Failed'
                    task_status = "Error"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    # Update Task tracker
                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                    raise rmv_exception.RMCRecoverySetCreationException(
                        id=pool_id,
                        wwn_list=vol_list)
                if 'id' in response_data:
                    recovery_set_id = response_data['id']
            # If resource_list is available, Do partial restore to any volume
            if resource_list:
                wwn_response_dict = self.get_rmcv_copy_wwn_details_by_resource_list(context, copy_id, resource_list)
                base_wwn_list = wwn_response_dict.get('wwn_list', list())
                cloned_resources = wwn_response_dict.get('cloned_resources')

            # Do restore
            # restore to any operation
            response = rmc_wrapper_service.restore_to_any(backup_id, recovery_set_id, vmLevelBackup,
                                                          vCenterDetails, vDisks, task_id=task_id,
                                                          wwn_list=base_wwn_list)

            if response:
                msg = "Restore Job Successfully Submitted"
                LOG.info(msg)
                task_desc_string = msg
                task_percentage = 12
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)

            ### Should consider to make the below LOC into a common function across all backup Operation.
            if 'taskUri' in response:
                LOG.debug(_('The RMC task is %s ') % response)
                rmc_task_id = response['taskUri'].split("/")[-1]
                backjob_response = self.update_backup_task(rmc_wrapper_service, False, task_id,
                                                           vm_task_helper, rmc_task_id, task_id, 10)
                LOG.info(_('The backup job response is %s') % backjob_response)
                # now update the task to backup tasks and also VMware Tasks
                task_state = backjob_response['task']['taskState']

                LOG.debug(_('The task_state is %s') % task_state)
                completed_percentage = backjob_response['task']['completedPercentage']
                # response_error_datas = rmc_wrapper_service.get_backup_task_tree_status(rmc_task_id)
                # LOG.debug(_('The response_error_datas response is %s')%response_error_datas)
                if task_state == 'Aborted':
                    task_desc_string = "This task has been aborted by user."
                    task_status = "Error"
                    task_desc_string = task_desc_string + self.getLatestProgressMsg(backjob_response.get('task'))
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                elif task_state == 'Error' or task_state == 'Failed':
                    task_desc_string = "Restore to Other Volumes is Unsuccessful."
                    task_desc_string = self.get_error_details(backjob_response, task_desc_string)
                    LOG.debug(_('The backup job task_state is %s') % task_state)
                    # #Get detailed error detail from task-tree GET output of backup job.
                    # #response_error_datas = rmc_wrapper_service.get_backup_task_tree_status(rmc_task_id)
                    # tasks = response_error_datas['task']['subTasks']['tasks']
                    # for response_error_data in tasks:
                    #     temp_msg = response_error_data['taskStatus']
                    #     childTaskState = response_error_data['taskState']
                    #     #Removing the repeated messages getting appended to task description
                    #     if temp_msg not in task_desc_string and childTaskState == 'Error' or childTaskState == 'Aborted' or childTaskState == 'Failed':
                    #         task_desc_string = task_desc_string + self.getLatestProgressMsg(response_error_datas.get('task'))
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                    msg_event = "Restore to Other Volumes is Unsuccessful."
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg_event)
                else:
                    LOG.debug(_('The backup job task_state is %s') % task_state)

                    if volume_type == rmv_utils.VVOL_DISK_TYPE or vmLevelBackup:
                        # Insert clone details in DB
                        clones_table_obj = json_helper.clones_table()
                        clones_table_obj.esxi_host_name = esxHostAddr
                        clones_table_obj.esxi_host_moref = host_moref
                        clones_table_obj.recovery_set_id = recovery_set_id
                        clone_type = json_helper.clone_type()
                        clones_table_obj.type = clone_type.permanant
                        clone_status = json_helper.clone_status
                        clones_table_obj.status = clone_status.cloned
                        clones_table_obj.parent_copy_id = copy_id
                        clones_table_obj.resources = cloned_resources
                        recovery_set_resp = rmc_wrapper_service.get_recovery_set(recovery_set_id)
                        if recovery_set_resp:
                            recovery_set = recovery_set_resp.get("recoverySet", None)
                            if recovery_set:
                                clones_table_obj.point_in_time = recovery_set.get('createdAt')
                                # clones_table_obj.status = recovery_set.get('status')
                                clones_table_obj.name = recovery_set.get('name')
                                volumes_details = recovery_set.get('volumes', [])
                                if volumes_details and len(volumes_details) > 0:
                                    volume = volumes_details[0]
                                    if "attach" in volume:
                                        attach = volume.get("attach", None)
                                        if attach and "hosts" in attach:
                                            hosts = attach.get("hosts", [])
                                            if hosts and len(hosts) > 0:
                                                attached_host_name = hosts[0]['hostname']
                                                clones_table_obj.store_serv_host_name = attached_host_name
                        registered_vm_info = []
                        vm_detail = json_helper.registerd_vm_detail_json()
                        vm_detail.moref = vm_moref
                        vm_detail.name = vmInfo.Name
                        vm_detail.parent_id = parent_id
                        try:
                            vmware_object = self.db.get_virtual_machine_by_id(context, parent_id)
                            vm_detail.parent_vm_moref = vmware_object.moref
                            vm_detail.parent_vm_name = vmware_object.name
                        except Exception as e:
                            msg = ("Failed to get virtual machine from DB by ID: " + parent_id)
                            LOG.error(msg)

                        registered_vm_info.append(vm_detail.__dict__)

                        clones_table_obj.clone_details = {}
                        clones_table_obj.clone_details['cloned_virtual_machines'] = registered_vm_info
                        clones_table_obj.clone_details['cloned_ds_details'] = []

                        self.db.create_rmcv_clones(context, clones_table_obj.__dict__)
                        if powerOn:
                            pow_moref = vim.get_moref(vm_moref, "VirtualMachine")
                            self.vi_helper.powerOn_VM(pow_moref)
                    export_status = None
                    rescanhba_status = None
                    refresh_hostds_status = None
                    task_status = "Ok"
                    # Check if the object type is datastore and restoring to new volumes
                    if not vmLevelBackup and volume_type != rmv_utils.VVOL_DISK_TYPE:
                        esx_host_add_format = None
                        is_host_ip = rmv_utils.is_IP(esxHostAddr)
                        if is_host_ip:
                            esx_host_add_format = 'esxHostIP'
                        else:
                            esx_host_add_format = 'esxHostName'
                        try:
                            # exporting/attaching the created volume to host
                            self.export_volume_to_host(esxHostAddr, x_auth_token, esx_host_add_format,
                                                       vol_list, recovery_set_id, task_id, vm_task_helper, serialNumber)
                            msg = "Restore backup to other volume: " + str(vol_list) + ".volume attached back to host"
                            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)

                            # rescan the host hbas once export completed successfully
                            self.rescan_host_hba(esxHostAddr)

                            # refresh the host datastores once HBA rescan completed successfully
                            self.refresh_host_datastores(esxHostAddr)

                            ds_list, recovery_set = self.get_restored_datastore_details(rmc_wrapper_service,
                                                                                        esxHostAddr,
                                                                                        recovery_set_id)
                            # Get esxi host info
                            host_info = self.get_esx_hot_inofo(esxHostAddr)
                            ds_mount_path_dir = json.loads(copy_detail.ds_mount_path_dir)

                            if copy_detail.host_name == esxHostAddr and not ds_list:
                                ds_list = self.resignature_exported_lun(rmc_wrapper_service, host_info, recovery_set_id,
                                                                        ds_mount_path_dir, mount)
                            if not ds_list:
                                # get restored datastore details
                                ds_list, recovery_set = self.get_restored_datastore_details(rmc_wrapper_service,
                                                                                            esxHostAddr,
                                                                                            recovery_set_id)

                            if not ds_list:
                                msg = ("Failed to get restored datastore(s)")
                                LOG.error(msg)
                                raise rmv_exception.FailedToGetRestoredDatastores(msg=msg)
                            # construct clone details
                            clone_details = self.construct_clone_details_for_db(context, self.vi_helper, ds_list,
                                                                                parent_id,
                                                                                vm_objType, self.db, recovery_set,
                                                                                mount,
                                                                                host_info, recovery_set_id, copy_id,
                                                                                cloned_resources)

                            # register vm in the backup with provided list
                            clone_details_resp = self.register_vm_from_restored_ds(context, x_auth_token,
                                                                                   rmc_wrapper_service,
                                                                                   host_info.HostName, vm_name_dict,
                                                                                   inventoryMoref, copy_id, objectId,
                                                                                   resPool, clone_details, task_id,
                                                                                   vmname, powerOn)
                            clone_details_resp['parent_copy_id'] = copy_id
                            self.db.create_rmcv_clones(context, clone_details_resp)
                            task_desc_string = "Clone operation completed succesfully "
                            task_state = 'Completed'
                            task_status = "Ok"
                            msg_event = "Successfully Restored to {" + str(esxHostAddr) + "}"
                        except rmv_exception.ExportVolumeToHostException as e:
                            LOG.exception(e)
                            msg = e.msg
                            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                            task_desc_string = 'Backup clone completed successfully to ' + str(
                                vol_list) + ', but it fails attaching ' \
                                            'volumes to host. Try to attach these volumes manually'
                            task_state = 'Warning'
                            task_status = "Warning"
                            msg_event = task_desc_string
                        except rmv_exception.RescanHostHBAException as e:
                            LOG.exception(e)
                            task_desc_string = 'Backup clone completed successfully to ' + str(
                                vol_list) + '.volume attached to host.' \
                                            'But if fails to rescan the host HBAs. Try to rescan the host ' + str(
                                esxHostAddr) + ' HBAs manually'
                            task_state = 'Warning'
                            task_status = "Warning"
                            msg_event = task_desc_string
                        except rmv_exception.RefreshHostDatastores as e:
                            LOG.exeception(e)
                            task_desc_string = 'Backup clone completed successfully to ' + str(
                                vol_list) + '.volume attached to host.' \
                                            'Rescan host HBAs completed, but it fails to refresh the host datastores.' \
                                            'Try to refresh the host ' + str(esxHostAddr) + ' datastores manually'
                            task_state = 'Warning'
                            task_status = "Warning"
                            msg_event = task_desc_string
                        except rmv_exception.FailedToGetRestoredDatastores as e:
                            LOG.exception(e)
                            task_desc_string = "Successfully restored to new volumes but, Failed to identify datastore(s) form restored volumes."
                            msg_event = task_desc_string
                        except rmv_exception.FailedToResignatureLun as e:
                            LOG.exception(e)
                            task_desc_string = "Successfully restored to new volumes but Failed to re-signature the restored volume(s)." \
                                               " Try manually to add the datastore in vSphere webclient "
                        except Exception as e:
                            LOG.exception(e)
                            task_desc_string = "Successfully restored to new volumes but Failed to clone the vm(s) from the restored volume(s)." \
                                               " Try manually to add the datastore in vSphere webclient and register the vm(s) "
                            task_state = 'Warning'
                            task_status = "Warning"
                            msg_event = task_desc_string

                    else:
                        task_desc_string = "Successfully Restored to Volumes"
                        task_state = 'Completed'
                        msg_event = "Successfully Restored to {" + recovery_set_id + "}"
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)
                    vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg_event)
                    # if recreateVM == True:
                    #     if powerOn:
                    #         pow_moref = vim.get_moref(vm_moref,"VirtualMachine")
                    #         self.vi_helper.powerOn_VM(pow_moref)
            else:
                LOG.info(_('Got an Unknown Error'))
                msg_event = response
                msg = response
                LOG.error(msg)
                raise

        except (rmv_exception.VirtualCopySystemBusy,
                rmv_exception.VIMPropertyNotFoundError,
                rmv_exception.VMNotPoweredOffError,
                rmv_exception.UnknownVMwareObjectError,
                rmv_exception.DatastoreUnusableError,
                rmv_exception.DatastoreUnsupportedTypeError,
                rmv_exception.DatastoreSpannedError,
                rmv_exception.DatastoreNon3parError,
                rmv_exception.DatastoreMoreThanOneIn3parVolumeError,
                rmv_exception.RMCAPIError,
                rmv_exception.RMCStorageSystemNotRegisteredException,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.DatastoreSpaceError,
                rmv_exception.EsxHostNotConfiguredException,
                rmv_exception.PyVmomiException,
                rmv_exception.CreateDataStoreException,
                rmv_exception.TaskError
                )as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Restore to Other Volumes is Unsuccessful : "
            if hasattr(e, "msg"):
                task_desc_string = task_desc_string + str(e.msg)
            task_state = 'Failed'
            vcenter_task_result = 'error'
            msg_event = "Restore to Other Volumes is Unsuccessful"

            if recreateVM == True and vm_moref:
                msg_event = "Restore to other Volume is unsuccessful. Cleaning Up..!!"
                del_moref = vim.get_moref(vm_moref, "VirtualMachine")
                self.vi_helper.delete_VM(del_moref)
            task_status = "Error"

            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg_event)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd(vcenter_task_result, task_desc_string)
        except Exception as e:
            LOG.exception(("Exception____: '%s'"), e)
            if hasattr(e, "message"):
                LOG.error(("Exception____: '%s'"), e.message)
            task_percentage = 20
            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, str(e))
            task_desc_string = "Restore to Other Volumes is Unsuccessful : Internal Error. " + str(e)
            task_state = 'Failed'
            task_status = "Error"
            vcenter_task_result = 'error'
            msg_event = task_desc_string
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Commenting below LogEvent call, as the same event is logged using PostEvent
            # self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg_event)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd(vcenter_task_result, task_desc_string)
            # raise e
        finally:
            self.update_copy_status(context, x_auth_token, copy_id)
            rmv_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, vm_objType, moref)
            rmv_obj['object_type'] = vm_objType
            rmv_copy = self.db.get_rmcv_copy_by_id(context, copy_id)
            nu.BackupNotification(rmv_copy, rmv_obj, task_id, 'restoreExpressProtect', rmc_wrapper_service).start()
            LOG.info(('Exiting restore_to_any_vol '))

    # def create_rc_snapshot(self, context, rc_snapshot_id, x_auth_token, task_id, request_body):
    #     """Create remote copy snapshot"""
    #
    #     LOG.info("Enter create_rc_snapshot")
    #     rc_snapshot_obj = remote_copy_snapshots()
    #     rc_snapshot_obj.create_rc_snapshot(context, rc_snapshot_id,
    #                                           x_auth_token, task_id, request_body,
    #                                           BackupJobManager.web_client_cache, self.vi_helper)

    def create_group_level_snapshot_single(self, context, protection_group_id, x_auth_token, task_id, copy_id,
                                           request_body, rmc_version):
        """Create remote copy snapshot"""
        start_time = time.time()
        thread_index = 0
        LOG.info("Remote copy Eventlet - Enter create_rc_snapshot - :" + str(
            protection_group_id) + " Thread Idx " + str(thread_index) + " st time " + str(start_time))
        LOG.debug("Enter create_group_level_snapshot")
        try:
            if not self.rmc_version:
                self.rmc_version = self.get_rmc_version()
        except Exception as e:
            pass

        rc_snapshot_obj = remote_copy_snapshots(vi_helper=self.get_vi_helper())
        rc_snapshot_obj.create_group_level_snapshot_single(context, protection_group_id, x_auth_token, task_id, copy_id,
                                                           request_body,
                                                           self.vi_helper, rmc_version)
        end_time = time.time()
        LOG.info("Remote copy Eventlet - Exit create_rc_snapshot - :" + str(protection_group_id) + " Thread Idx " + str(
            thread_index) + " end time " + str(end_time) + " Total " + str((end_time - start_time)))

    def create_group_level_snapshot_single_generic(self, context, protection_group_id, x_auth_token, task_id, copy_id,
                                                   request_body):
        """Create remote copy snapshot"""
        start_time = time.time()
        thread_index = 0
        LOG.info("Enter: create snapshot for protection group id - :" + str(
            protection_group_id) + " Thread Idx " + str(thread_index) + " st time " + str(start_time))
        LOG.debug("Enter create_group_level_snapshot_single_generic")
        pg_snapshot_obj = single_generic_group_snapshots(vi_helper=self.get_vi_helper())
        pg_snapshot_obj.create_group_level_snapshot_single_generic(context, protection_group_id, x_auth_token, task_id,
                                                                   copy_id, request_body,
                                                                   self.vi_helper, mgr=self)
        end_time = time.time()
        LOG.info("Exit: create snapshot for protection group id - :" + str(protection_group_id) + " Thread Idx " + str(
            thread_index) + " end time " + str(end_time) + " Total " + str((end_time - start_time)))

    def relocateVm(self, vm_moref_id, ds_moref, folder_moref, relocate_disk_spec_list):
        try:
            vm_moref_obj = pyvmomi_util.get_moref(vm_moref_id, "VirtualMachine")
            ds_moref_obj = pyvmomi_util.get_moref(ds_moref, "Datastore")
            folder_moref_obj = pyvmomi_util.get_moref(folder_moref, "Folder")
            relocate_spec = pyvmomi_util.get_vm_relocate_spec(ds_moref_obj, folder_moref_obj, relocate_disk_spec_list)
            self.vi_helper.relocateVm_task(vm_moref_id, relocate_spec)
        except Exception as exp:
            LOG.error("Relocate VM failed")
            raise exp

    def checkRelocateVm(self, vm_moref_id, ds_moref, folder_moref, relocate_disk_spec_list):
        try:
            vm_moref_obj = pyvmomi_util.get_moref(vm_moref_id, "VirtualMachine")
            ds_moref_obj = pyvmomi_util.get_moref(ds_moref, "Datastore")
            folder_moref_obj = pyvmomi_util.get_moref(folder_moref, "Folder")
            relocate_spec = pyvmomi_util.get_vm_relocate_spec(ds_moref_obj, folder_moref_obj, relocate_disk_spec_list)
            self.vi_helper.check_relocateVm_task(vm_moref_id, relocate_spec)
        except Exception as exp:
            LOG.error("Relocate VM failed")
            raise exp

    def renameVm(self, vm_moref_id, new_vm_name):
        try:
            self.vi_helper.renameVm_task(vm_moref_id, new_vm_name)
        except Exception as exp:
            LOG.error("Rename VM failed")
            raise exp

    def power_off_vm(self, vm_moref_id, vm_current_state=None):
        try:
            vm_power_state, vm_name = self.vi_helper.get_vm_power_state(vm_moref_id)
            if vm_power_state == 'poweredOff':
                if vm_current_state:
                    vm_current_state[vm_moref_id]['powerState'] = 'poweredOff'
                LOG.debug("virtual machine is in poweredOff state")
            else:
                if vm_current_state:
                    vm_current_state[vm_moref_id]['powerState'] = 'poweredOn'
                self.vi_helper.power_off_vm(vm_moref_id)
        except Exception as exp:
            LOG.error("powering off VM failed")
            raise exp

    def power_on_vm(self, vm_moref_id, vm_current_state=None):
        try:
            vm_power_state, vm_name = self.vi_helper.get_vm_power_state(vm_moref_id)
            if vm_power_state == 'poweredOn':
                if vm_current_state:
                    vm_current_state[vm_moref_id]['powerState'] = 'poweredOn'
                LOG.debug("virtual machine is in poweredOn state")
            else:
                if vm_current_state:
                    vm_current_state[vm_moref_id]['powerState'] = 'poweredOff'
                self.vi_helper.power_on_vm(vm_moref_id)
        except Exception as exp:
            LOG.error("Powering on vm failed")
            raise exp

    def delete_vm(self, vm_moref_id):
        try:
            self.power_off_vm(vm_moref_id)
            self.vi_helper.delete_vm(vm_moref_id)
        except Exception as exp:
            LOG.error("Delete VM failed")
            raise exp

    def reconfigVM_for_restore(self, backup_id, rmc_wrapper_service, vm_name, vm_moref):

        config_prop_dict = self.get_vm_configuration_info(backup_id, rmc_wrapper_service)

        vm_moref_obj = pyvmomi_util.get_moref(vm_moref, "VirtualMachine")
        prop_list = ["datastore", "config.uuid"]
        obj_cont = self.vi_helper.get_object_properties(vm_moref_obj, prop_list)

        if obj_cont:
            vm_prop_dict = pyvmomi_util.extract_properties(obj_cont[0])
            # Check if the moid object exists
            ds_moref_obj = vm_prop_dict.get("datastore")
            if ds_moref_obj:
                ds_moref = ds_moref_obj[0]._moId
            vm_uuid = vm_prop_dict.get("config.uuid")

        # Need to pass vim moref object for this method
        ds_moref_vim_obj = vim.get_moref(ds_moref, "Datastore")
        vm_moref_vim_obj = vim.get_moref(vm_moref, "VirtualMachine")
        if ds_moref_vim_obj:
            datastoreName = self.vi_helper.get_managed_object_ref_name(ds_moref_vim_obj)

        vm_spec = self.vi_helper.buildSpec_for_VM_ConfigInfo(vm_name, datastoreName, ds_moref, config_prop_dict, True)

        self.vi_helper.reconfig_VM_vmops(vm_moref_vim_obj, vm_spec)

    def get_vmdk_path(self, vm_moref):
        try:
            LOG.info("get_vmdk_path : Enter")
            vm_moref_obj = pyvmomi_util.get_moref(vm_moref, "VirtualMachine")
            vm_config_info = self.vi_helper.get_object_properties(vm_moref_obj, "config")
            conf_prop_obj = pyvmomi_util.extract_properties(vm_config_info[0])
            snap_config_dict = pyvmomi_util.process_config_obj(conf_prop_obj)
            hw = snap_config_dict['hardware']
            vmdkPathList = []
            for device in range(len(hw)):
                for hkeys in hw[device]:
                    if rmv_utils.VMWARE_VM_VIRTUAL_DISK == hkeys:
                        h_dict = hw[device].values()[0]
                        deviceBacking = h_dict.get('backing', None)
                        parentDevice = deviceBacking.get('parent', None)
                        if parentDevice:
                            vmdkPath = parentDevice.get('fileName', None)
                        else:
                            vmdkPath = deviceBacking.get('fileName', None)  # just return vmdk path....
                        vmdkPathList.append(vmdkPath)
            LOG.info("get_vmdk_path : Exit")
        except Exception as e:
            LOG.exception("Exception occurred while retrieving the VMDK list for backup: %s" % e)
            raise rmv_exception.VmVddkBackupException(e.message)
        return vmdkPathList

    def restore_to_new_vm(self, context, x_auth_token, vm_task_helper, task_id,
                          rmv_backup, recreate_vm_info):

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        volume_creation_details = recreate_vm_info['volumeCreationDetails']
        esx_host_addr = recreate_vm_info['esxHostAddr']
        host_moref = self.get_host_moref_from_hostname_or_ip(esx_host_addr)
        serial_number = recreate_vm_info['serialNumber']
        host_ref = vim.get_moref(host_moref, "HostSystem")
        vmname = recreate_vm_info['vmName']
        res_pool = recreate_vm_info['resPool']
        datastore_name = recreate_vm_info['datastoreName']
        backup_set_id = rmv_backup.rmc_copyset_id

        vm_moref = rmv_backup.moref

        if volume_creation_details:
            datastore_name = self.create_vmfs_datastore(volume_creation_details, serial_number, esx_host_addr,
                                                        vm_moref, x_auth_token, task_id, vm_task_helper)

        vm_moref = self.recreateVM_for_restore(vmname, datastore_name, res_pool, backup_set_id,
                                               rmc_wrapper_service, task_id, vm_task_helper, host_ref)

        self._update_task("Successfully created a VM: " + vmname,
                          6,
                          'Running',
                          task_id,
                          rmc_wrapper_service,
                          vm_task_helper, task_status='Initiated')

        vCenterDetails = {}
        vCenterHost, vCenterUser, vCenterPassword, vCenteruuid, vCenterThumbPrint = self.vi_helper.get_vcenter_credentials()
        vCenterDetails['host'] = vCenterHost
        vCenterDetails['user'] = vCenterUser
        vCenterDetails['password'] = vCenterPassword
        vCenterDetails['thumbPrint'] = vCenterThumbPrint
        vDisks = []

        vmdk_backups = self.db.rmv_vmdk_backups_get_by_rmvbackup_id(context, rmv_backup.id)
        new_vmdk_path_list = self.get_vmdk_path(vm_moref)

        for i in range(len(vmdk_backups)):
            backupVMDKdict = {}
            vmdk_backup = vmdk_backups[i]
            vmdk_info = self.db.get_vmdk_by_id(context, vmdk_backup.vmdk_id)
            backupVMDKdict['fileName'] = vmdk_info.path
            backupVMDKdict['filePath'] = new_vmdk_path_list[i]
            backupVMDKdict['fileSize'] = vmdk_info.capacity_in_bytes
            backupVMDKdict['systemId'] = "moref=" + str(vm_moref)
            vDisks.append(backupVMDKdict)

        return vm_moref, vCenterDetails, vDisks

    def restore_to_parent_vm(self, context, task_id, vm_task_helper, rmc_wrapper_service, moref, rmv_backup):
        vm_power_state, vm_name = self.vi_helper.get_vm_power_state(moref)
        vm_moref_obj = vim.get_moref(moref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
        backup_set_id = rmv_backup.rmc_copyset_id
        if vm_power_state == 'poweredOn':
            LOG.info("%s VM is powered on.. " % vm_name)
            self.vi_helper.powerOff_VM(vm_moref_obj)
            task_desc_string = 'Powering of the VM for restore'
            task_percentage = 7
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

        self.reconfigVM_for_restore(backup_set_id, rmc_wrapper_service, vm_name, moref)
        vCenterDetails = self.vi_helper.get_vCenter_credential_dict()
        vmdk_backups = self.db.rmv_vmdk_backups_get_by_rmvbackup_id(context, rmv_backup.id)
        vDisks = []
        for vmdk_backup in vmdk_backups:
            backupVMDKdict = {}
            vmdk_info = self.db.get_vmdk_by_id(context, vmdk_backup.vmdk_id)
            backupVMDKdict['fileName'] = vmdk_info.path
            backupVMDKdict['filePath'] = vmdk_info.path
            backupVMDKdict['fileSize'] = vmdk_info.capacity_in_bytes
            backupVMDKdict['systemId'] = "moref=" + str(moref)
            vDisks.append(backupVMDKdict)

        return moref, vCenterDetails, vDisks

    def restore_to_vm(self, context, x_auth_token, task_id, rmv_backup_id, re_create_vm_info=None):
        """
        Manager function which recieves rpc call
        :param context: request context
        :param x_auth_token: Login token
        :param task_id: rmc task
        :param rmv_backup_id: Id from rmv_table
        :param re_create_vm_info: Parameters which will used to create new VM
        :return:
        """
        LOG.debug("In restore_to_vm(), Enter")
        try:
            # need to pass parent vm moref for the below query to get the details
            rmv_backup = self.db.get_rmcv_copy_by_id_with_vm_details(context, rmv_backup_id)

            vm_name = rmv_backup.vm_name
            vm_moref = rmv_backup.moref
            backup_status = rmv_backup.status

            type_for_vcenter_log_event, mo_ref_for_vcenter_log_event = self.get_vcenter_logging_params("VirtualMachine",
                                                                                                       vm_moref)

            # Create an instance of RMC Wrapper, to make any RMC or TaskTracker calls
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            # Create an instance of VMware Task Helper to populate vCenter Tasks
            vm_task_helper = VmTaskHelper(self.vi_helper)

            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_log_event,
                                                 mo_ref_for_vcenter_log_event,
                                                 "RestoreToAnyVolume",
                                                 "RestoreToAnyVolumeFailedFault")

            if (re_create_vm_info):
                # This is restore to new vm
                vm_moref, vCenter_detail, vDisks = self.restore_to_new_vm(context, x_auth_token, vm_task_helper,
                                                                          task_id,
                                                                          rmv_backup, re_create_vm_info)

            else:
                # retore to parent
                vm_moref, vCenter_detail, vDisks = self.restore_to_parent_vm(context, task_id, vm_task_helper,
                                                                             rmc_wrapper_service, vm_moref, rmv_backup)

            vm_power_state, vm_name = self.vi_helper.get_vm_power_state(vm_moref)
            if vm_power_state == 'poweredOn':
                LOG.info("%s VM is powered on.. " % vm_name)
                vm_moref_obj = vim.get_moref(vm_moref, rmv_utils.VMWARE_OBJECT_TYPE_VM)
                self.vi_helper.powerOff_VM(vm_moref_obj)
                task_status = "Initiated"
                self._update_task('Powering of the VM for restore',
                                  7,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

            response = rmc_wrapper_service.restore_to_parent_vol(rmv_backup.rmc_copyset_id, vmBackupType=True,
                                                                 vCenterDetails=vCenter_detail, vDisks=vDisks,
                                                                 task_id=task_id)

            if 'taskUri' in response:
                rmc_task_id = response['taskUri'].split("/")[-1]
                self.update_nbd_backup_process(context, rmv_backup_id, 'restoring')
                backjob_response = self.update_backup_task(rmc_wrapper_service, False, task_id,
                                                           vm_task_helper, rmc_task_id, task_id, 10)
                LOG.info(_('The backup job response is %s') % backjob_response)
                task_state = backjob_response['task']['taskState']
                LOG.info(_('The task_state is %s') % task_state)
                completed_percentage = backjob_response['task']['completedPercentage']

                if task_state == 'Aborted':
                    task_desc_string = "This task has been aborted by user."
                    task_status = "Error"
                    task_desc_string = task_desc_string + self.getLatestProgressMsg(backjob_response.get('task'))
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

                elif task_state == 'Error' or task_state == 'Failed':
                    task_desc_string = "HPE StoreOnce restore is unsuccessful."
                    LOG.info(_('The backup job task_state is %s') % task_state)
                    task_desc_string = self.get_error_details(backjob_response, task_desc_string)
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                    msg_event = "Restore to Virtual Machine failed."

                else:
                    LOG.info(_('The backup job task_state is %s') % task_state)
                    task_desc_string = "Successfully restored"
                    task_state = 'Completed'
                    task_status = "Ok"
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)
                    msg_event = "Successfully restored "
                    vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

            msg = "Restore to Virtual Machine completed"
            LOG.info(msg)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_log_event, type_for_vcenter_log_event, msg)
        except rmv_exception.TaskError as e:
            msg = e.msg
            LOG.error(msg)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_log_event, type_for_vcenter_log_event, msg)

        except (rmv_exception.DatastoreRetrieveFailed,
                rmv_exception.vCenterMoRefError)as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Restore could not be performed. %s" % e.msg + " " + rmv_utils.RESTORE_OPERATION_REQUISITE
            task_state = 'Failed'
            vcenter_task_result = 'error'
            task_status = "Error"
            msg_event = task_desc_string

        except (rmv_exception.VirtualCopySystemBusy,
                rmv_exception.SnapshotNotFound,
                rmv_exception.VIMPropertyNotFoundError,
                rmv_exception.VMNotPoweredOffError,
                rmv_exception.UnknownVMwareObjectError,
                rmv_exception.DatastoreUnusableError,
                rmv_exception.DatastoreUnsupportedTypeError,
                rmv_exception.DatastoreSpannedError,
                rmv_exception.DatastoreNon3parError,
                rmv_exception.DatastoreMoreThanOneIn3parVolumeError,
                rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.DatastoresWwnMissmatch
                ) as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Restore could not be performed. "
            if hasattr(e, "msg"):
                task_desc_string = task_desc_string + str(e.msg)
            task_state = 'Failed'
            task_status = "Error"
            vcenter_task_result = 'error'
            msg_event = "Restore to VM: " + vm_name + " " + "unsuccessful"


        except Exception as e:
            if hasattr(e, "msg"):
                msg = e.msg
            elif hasattr(e, "message"):
                msg = e.message
            else:
                msg = "Internal error"
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Restore could not be performed. " + msg
            task_state = 'Failed'
            task_status = "Error"
            vcenter_task_result = 'error'
            msg_event = "Restore to VM: " + vm_name + " " + "unsuccessful"

        finally:
            task_percentage = 100
            LOG.info(('%s'), task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd(vcenter_task_result, task_desc_string)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_log_event, type_for_vcenter_log_event, task_desc_string)
            self.update_nbd_backup_process(context, rmv_backup_id, 'available')

    def restore_to_parent_vol(self, context, copy_id, moref, vm_objType, x_auth_token, task_id,
                              restoreIncremental, restoreParentSnapshotId, optimized, ds_moref_list_to_restore):
        """Method to Promote Express Protect Backup"""
        """
        :param context: rmc context set in this parameter
        :param backup_id : backup object id on which restore is performed
        :param recoveryset_id : recoveryset id for restore
        :param moref: moref of the VMWare object
        :param vm_objType: Type of the VMWare object
        :param x_auth_token: auth token required to communicate to RMC service
        :param task_id : task id to keep track of the restore operation
        """
        backup_recovery_set_id = ""
        vc_ds_to_vm_dict = {}
        ds_moref_list = []
        ds_moref_wwn_dict = {}
        register_vm_failed_count = 0
        unregister_vm_failed_count = 0

        try:
            '''
            Step # 1 : Initializing, Constructing required objects
            '''
            task_state = None
            task_desc_string = None
            vcenter_task_result = None
            type_for_vcenter_log = vm_objType
            mo_ref_for_vcenter_log = moref
            msg_event = None
            base_volume = None
            response = None
            vmware_obj_name = ""
            ds_uuid_to_moref_dict = {}
            is_restore_success = True
            restore_status = ""
            volume_type = ""

            # Create an instance of RMC Wrapper, to make any RMC or TaskTracker calls
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            rmv_copy = self.db.get_rmcv_copy_by_id(context, copy_id)

            if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                copy_detail = self.db.get_rmcv_copy_by_id_with_ds_details(context, copy_id, moref)
                vmware_obj_name = copy_detail.ds_name
            elif vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                copy_detail = self.db.get_rmcv_copy_by_id_with_vm_details(context, copy_id, moref)
                vmware_obj_name = copy_detail.vm_name
                volume_type = copy_detail.volume_type
            elif vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                copy_detail = self.db.get_rmcv_copy_by_copy_id_with_group_details(context, copy_id)
                pg_recovery_set_id = self.db.get_recovery_set_id_by_protection_group_id(context, moref)

            copy_name = vmware_obj_name
            if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                recovery_set_id = pg_recovery_set_id
            else:
                recovery_set_id = copy_detail.recovery_set_id

            copy_type = copy_detail.copy_type
            backup_id = copy_detail.rmc_copyset_id

            # update copy status to restoring
            rmv_copy.status = rmv_utils.copy_states.RESTORING
            self.db.update_rmcv_copy(context, copy_id, rmv_copy)

            # Create an instance of VMware Task Helper to populate vCenter Tasks
            vm_task_helper = VmTaskHelper(self.vi_helper)

            vCenterDetails = {}
            vDisks = []

            ## Hard coding it to disable Granular Restore
            if copy_type == 'nbd':
                vmBackupType = True
            else:
                vmBackupType = False

            try:
                '''
                Step # 2 : Get Snapshot Record (using RMC APIs)
                '''

                obj_exists = self.check_if_object_exists(moref, vm_objType)
                if obj_exists:
                    type_for_vcenter_logevent = vm_objType
                    type_for_vcenter_log = vm_objType
                    mo_ref_for_vcenter_logevent = moref
                else:
                    LOG.info(
                        "The parent object has either been removed or deleted, so proceeding with folder level task")
                    # These 2 values are used for vCenter Events and Tasks logging
                    type_for_vcenter_logevent = "Folder"
                    type_for_vcenter_log = "Folder"
                    mo_ref_for_vcenter_logevent = "group-d1"
                    mo_ref_for_vcenter_log = "group-d1"

                # The task name has to be changed, as of keeping it same as
                # that of Promote
                vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_logevent,
                                                     mo_ref_for_vcenter_logevent,
                                                     "RestoreToParentVolume",
                                                     "RestoreToParentVolumeFailedFault")

                # Fetch the below volume, needed for reporting
                # Do a get_recovery-set-details and collect the volume details.
                base_volume = backup_recovery_set_id

                # Log an event in vCenter
                msg = "Restoring to volume begins"
                self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)

                '''
                Step # 3 : Validate the given datastore
                '''

                if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_DS or \
                        vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP or \
                        (
                                vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM and volume_type == rmv_utils.VMFS_DISK_TYPE and not vmBackupType):
                    # Update Tasks (Task Tracker and VMware Task)
                    task_desc_string = 'Validating datastore to Restore'
                    task_percentage = 2
                    task_state = 'Running'
                    task_status = "Initiated"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    copy_info = None
                    try:
                        copy_info = self.db.get_rmcv_ds_with_base_wwn_by_copy_id(context, copy_id)
                        # copy_info = self.db.get_rmcv_ds_copy_assoc_by_copy_id(context, copy_id)
                    except Exception as e:
                        msg = "Unable to retrieve copy details"
                        raise Exception(msg)

                    if copy_info:
                        for copy_row in copy_info:
                            # restore to parent on copy level
                            if not ds_moref_list_to_restore:
                                if copy_row.moref not in ds_moref_list:
                                    ds_moref_list.append(copy_row.moref)
                                    wwn_details_list = jsonutils.loads(copy_row.wwn_details)
                                    ds_moref_wwn_dict[copy_row.moref] = rmv_utils.extract_wwn_list(wwn_details_list)
                            # restore to parent on ds level
                            else:
                                if copy_row.moref not in ds_moref_list and copy_row.moref in ds_moref_list_to_restore:
                                    ds_moref_list.append(copy_row.moref)
                                    wwn_details_list = jsonutils.loads(copy_row.wwn_details)
                                    ds_moref_wwn_dict[copy_row.moref] = rmv_utils.extract_wwn_list(wwn_details_list)

                    # add moref in ds_moref_list to ds_moref_list_to_restore
                    if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP or vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                        ds_moref_list_to_restore.extend(ds_moref_list)

                    if ds_moref_list_to_restore:
                        self.validate_virtualmachines_power_on_state_for_promote(ds_moref_list_to_restore,
                                                                                 vc_ds_to_vm_dict)
                    else:
                        self.validate_virtualmachines_power_on_state_for_promote(ds_moref_list, vc_ds_to_vm_dict)

                    # get backup details from backup_id
                    backup_resp = rmc_wrapper_service.get_backup_for_backupId(context, backup_id)
                    if backup_resp:
                        backup_details = backup_resp.get("backupSet", {})
                        backup_recovery_set_id = backup_details.get("recoverySetId", "")
                    base_volume = backup_recovery_set_id

                    # validate requested copy recovery set wwn's with requested object wwn's
                    obj_recovery_set_wwn = list()
                    backup_recovery_set_wwn = None
                    backup_recovery_set = rmc_wrapper_service.get_recovery_set(backup_recovery_set_id)
                    recovery_set = backup_recovery_set.get("recoverySet", {})
                    backup_recovery_set_wwn = recovery_set.get("wwnlist", None)

                    for ds_moref in ds_moref_list:
                        scsi_luns = []
                        ds_info = self.vi_helper.get_datastore_details(ds_moref, scsi_luns)
                        # If datastore does not contain VMs at the time of restore,
                        # after restore new moref will be assigned to the datastore
                        # But lun wwn and vmfs uuid will be same. In this case we have to update RMCV db with new moref
                        if hasattr(ds_info, "VmList"):
                            if len(ds_info.VmList) == 0:
                                ds_uuid_to_moref_dict[ds_info.VmfsUuid] = ds_info.DatastoreMoref
                        for lun in scsi_luns:
                            obj_recovery_set_wwn.append(lun.Wwn)

                    # if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_DS or \
                    #     vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                    #     if ds_moref_list_to_restore:
                    #         # Incase of partial restore will iterate through each datastore
                    #         # those are requested for restore
                    #         for ds_moref in ds_moref_list_to_restore:
                    #             scsi_luns = []
                    #             ds_info = self.vi_helper.get_datastore_details(ds_moref, scsi_luns)
                    #             # If datastore does not contain VMs at the time of restore,
                    #             # after restore new moref will be assigned to the datastore
                    #             # But lun wwn and vmfs uuid will be same. In this case we have to update RMCV db with new moref
                    #             if hasattr(ds_info, "VmList"):
                    #                 if len(ds_info.VmList) == 0:
                    #                     ds_uuid_to_moref_dict[ds_info.VmfsUuid] = ds_info.DatastoreMoref
                    #             obj_recovery_set_wwn = list()
                    #             for lun in scsi_luns:
                    #                 obj_recovery_set_wwn.append(lun.Wwn)
                    #     elif moref:
                    #         scsi_luns = []
                    #         ds_info = self.vi_helper.get_datastore_details(moref, scsi_luns)
                    #         # If datastore does not contain VMs at the time of restore,
                    #         # after restore new moref will be assigned to the datastore
                    #         # But lun wwn and vmfs uuid will be same. In this case we have to update RMCV db with new moref
                    #         if hasattr(ds_info,"VmList"):
                    #             if len(ds_info.VmList) == 0:
                    #                 ds_uuid_to_moref_dict[ds_info.VmfsUuid] = ds_info.DatastoreMoref
                    #         obj_recovery_set_wwn = list()
                    #         for lun in scsi_luns:
                    #             obj_recovery_set_wwn.append(lun.Wwn)
                    if backup_recovery_set_wwn and obj_recovery_set_wwn:
                        if ((set(backup_recovery_set_wwn) != set(
                                obj_recovery_set_wwn) and not ds_moref_list_to_restore) or
                                not set(backup_recovery_set_wwn).issuperset(set(obj_recovery_set_wwn))):
                            msg = "Could not perform restore. Mismatch detected in volume(s) between the copy and the " \
                                  "Datastore. This could be because 1) New volumes have been added or existing volumes " \
                                  "have been removed from the Datastore 2) The snapshot was performed at a different " \
                                  "resource or a resource group (Folder or Datastore or  VM). Restore is not allowed in " \
                                  "these cases, however, the Datastore or VMs can be recovered by performing Mount/Clone."
                            raise rmv_exception.RestoreNotallowed(msg=msg)

                    # get vm assoc with vm details by copy id
                    vm_assoc_details = self.db.get_vm_assoc_with_vm_and_ds_details_by_copy_id(context, copy_id)
                    db_ds_to_vm_dict = rmv_utils.extract_ds_to_vm_mapping(context, vm_assoc_details)
                    if ds_moref_list_to_restore:
                        ds_to_vm_dict = {}
                        for ds_moref in ds_moref_list_to_restore:
                            ds_to_vm_dict[ds_moref] = db_ds_to_vm_dict.get(ds_moref, [])

                        db_ds_to_vm_dict = ds_to_vm_dict

                    # if any vm is moved form one DS to another DS then we will not allow restore to parent, this may lead in vm conflict
                    self.validate_virtualmahines_moment_acrros_vcenter(vc_ds_to_vm_dict, db_ds_to_vm_dict)

                    # wwn_details_list = copy_info.wwn_details
                    # ds_moref_wwn_dict[moref] = rmv_utils.extract_wwn_list(wwn_details_list)

                    # Need to revisit this code when PEER motion is supported.
                    host_moref_ds_moref_dict = {}
                    if ds_moref_list_to_restore:
                        for ds_moref in ds_moref_list_to_restore:
                            scsi_luns = []
                            ds_info = self.vi_helper.get_datastore_details(ds_moref, scsi_luns)
                            if (len(scsi_luns) > 0):
                                LOG.debug(("Volume WWN: '%s'"), scsi_luns[0].Wwn)
                            else:
                                LOG.debug("The Volume WWN list is empty")
                            bkp_base_volume_wwn_list = ds_moref_wwn_dict.get(ds_moref, [])
                            self.validate_datastore_wwn_with_snap_or_bkp_base_volume_wwn(bkp_base_volume_wwn_list,
                                                                                         scsi_luns, ds_info)

                            # Maintaining dictionary of mounted hosts lists and correspondng ds_moref
                            # this dictionary is will be used for rescan and then delete snaphosts using single call
                            if not tuple(ds_info.MountedHostsList) in host_moref_ds_moref_dict:
                                host_moref_ds_moref_dict[tuple(ds_info.MountedHostsList)] = []
                            host_moref_ds_moref_dict[tuple(ds_info.MountedHostsList)].append(ds_moref)
                    elif moref:
                        scsi_luns = []
                        ds_info = self.vi_helper.get_datastore_details(moref, scsi_luns)
                        if (len(scsi_luns) > 0):
                            LOG.debug(("Volume WWN: '%s'"), scsi_luns[0].Wwn)
                        else:
                            LOG.debug("The Volume WWN list is empty")
                        bkp_base_volume_wwn_list = ds_moref_wwn_dict.get(moref, [])
                        self.validate_datastore_wwn_with_snap_or_bkp_base_volume_wwn(bkp_base_volume_wwn_list,
                                                                                     scsi_luns, ds_info)

                    '''
                    Step # 4 : Get attach status of the volumes (this info will be used to attach post restore task)
                    '''

                    # before performing 'detach', persisting the attach status of the recovery set in 'map_wwn_hostlist'
                    map_wwn_hostlist = self.get_attach_status_of_recovery_set(rmc_wrapper_service,
                                                                              backup_recovery_set_id)
                    LOG.info(("map_wwn_hostlist: '%s'"), map_wwn_hostlist)

                    # Update Tasks (Task Tracker and VMware Task)
                    task_desc_string = 'Detaching volumes from the host'
                    task_percentage = 7
                    task_state = 'Running'
                    task_status = "Initiated"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Use RMC to detach the recovery-set
                    response = rmc_wrapper_service.detach_recoveryset(backup_recovery_set_id, True, task_id=task_id)

                elif vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM and vmBackupType:
                    # vDiskFiles = backupSet['appMetadata'].get('files')
                    vDiskFiles = None  # TODO :Revisit how we can get vDiskFiles for granular backup
                    type_for_vcenter_logevent = vm_objType
                    mo_ref_for_vcenter_logevent = moref
                    vm_power_state, vm_name = self.vi_helper.get_vm_power_state(moref)
                    LOG.info("Moref ..... : %s" % moref)
                    vm_moref_obj = vim.get_moref(moref, vm_objType)
                    if vm_power_state == 'poweredOn':
                        LOG.info("%s VM is powered on.. " % vm_name)
                        self.vi_helper.powerOff_VM(vm_moref_obj)
                        task_desc_string = 'Powering of the VM for restore'
                        task_percentage = 7
                        task_state = 'Running'
                        task_status = "Initiated"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                    self.reconfigVM_for_restore(backup_id, rmc_wrapper_service, vm_name, moref)

                    vCenterDetails = self.vi_helper.get_vCenter_credential_dict()

                    for i in range(len(vDiskFiles)):
                        backupVMDKdict = {}
                        backupVMDKdict['fileName'] = vDiskFiles[i].get('fileName')
                        backupVMDKdict['filePath'] = vDiskFiles[i].get('fileName')
                        backupVMDKdict['fileSize'] = vDiskFiles[i].get('fileSize')
                        backupVMDKdict['systemId'] = "moref=" + str(moref)
                        vDisks.append(backupVMDKdict)

                    LOG.info("*** Disks details to be restored *** : %s" % vDisks)

                elif vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                    type_for_vcenter_logevent = vm_objType
                    mo_ref_for_vcenter_logevent = moref
                    vm_power_state, vm_name = self.vi_helper.get_vm_power_state(moref)
                    if vm_power_state == 'poweredOn':
                        msg = (_("Restore cannot be performed on a powered on VM, power off the VM and try again."))
                        task_state = 'Failed'
                        task_status = "Error"
                        task_desc_string = msg
                        task_percentage = 2
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)
                        raise rmv_exception.VMNotPoweredOffError(vm_name=vm_name)

                    # recovery_set_id = recoveryset_id

                    # Refresh the recovery set for detach from VM if powered off
                    task_desc_string = 'Refreshing volume information'
                    task_percentage = 7
                    task_state = 'Running'
                    task_status = "Initiated"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    response_data = rmc_wrapper_service.array_refresh(context, recovery_set_id, None, task_id=task_id)
                    if response_data:
                        response_data = rmc_wrapper_service.rmc_low_level.wait_on_task(response_data)

                # Update Tasks (Task Tracker and VMware Task)
                task_desc_string = 'Restoring, this may take sometime based on the volume size.'
                task_percentage = 10
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                try:
                    LOG.info("Calling RMC restore backup...")
                    # Use RMC to restore Express Protect Backup. Catch exception in case of error during
                    # restore Express Protect Backup operation
                    wwn_list = []

                    # if protection group then do not create wwn list,
                    if vm_objType != rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                        if ds_moref_list_to_restore:
                            for ds_moref in ds_moref_list_to_restore:
                                wwn_list.extend(ds_moref_wwn_dict.get(ds_moref))
                    response = rmc_wrapper_service.restore_to_parent_vol(
                        backup_id, restoreIncremental, restoreParentSnapshotId, optimized, vmBackupType, vCenterDetails,
                        vDisks, task_id=task_id, wwn_list=wwn_list)
                    msg = "Restore to parent volume completed"
                    LOG.info(msg)
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                except rmv_exception.TaskError as e:
                    # "TaskError" exception would contain the failure reason, populated by RMC
                    msg = e.msg
                    LOG.error(msg)
                    raise e
                    # we should not triger event on datastore as the base volume is already unexported for restore purpose
                    # so vcenter will throw an error object not found
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                except Exception as e:
                    msg = e
                    LOG.exception(e)
                    raise e
                    # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)
                # *****************************************************************************#
                if 'taskUri' in response:
                    LOG.info(_('The RMC task is %s ') % response)
                    rmc_task_id = response['taskUri'].split("/")[-1]
                    backjob_response = self.update_backup_task(rmc_wrapper_service, False, task_id,
                                                               vm_task_helper, rmc_task_id, task_id, 10)
                    LOG.info(_('The backup job response is %s') % backjob_response)
                    # now update the task to backup tasks and also VMware Tasks
                    task_state = backjob_response['task']['taskState']

                    LOG.info(_('The task_state is %s') % task_state)
                    completed_percentage = backjob_response['task']['completedPercentage']
                    # response_error_datas = rmc_wrapper_service.get_backup_task_tree_status(rmc_task_id)
                    # LOG.info(_('The response_error_datas response is %s')%response_error_datas)
                    if task_state == 'Aborted':
                        task_desc_string = "This task has been aborted by user."
                        task_status = "Error"
                        task_desc_string = task_desc_string + self.getLatestProgressMsg(backjob_response.get('task'))
                        self._update_task(task_desc_string,
                                          completed_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        # Associating the vCenter Task with User Logged Event.
                        vm_task_helper.post_general_user_event(task_desc_string)
                        is_restore_success = False
                        restore_status = task_desc_string

                    elif task_state == 'Error' or task_state == 'Failed':
                        task_desc_string = "HPE StoreOnce restore is unsuccessful."
                        LOG.info(_('The backup job task_state is %s') % task_state)
                        task_desc_string = self.get_error_details(backjob_response, task_desc_string)

                        self._update_task(task_desc_string,
                                          completed_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper)

                        # Associating the vCenter Task with User Logged Event.
                        vm_task_helper.post_general_user_event(task_desc_string)
                        is_restore_success = False
                        restore_status = task_desc_string
                        msg_event = "Restore to parent volume failed."
                    else:
                        LOG.info(_('The backup job task_state is %s') % task_state)
                        task_desc_string = "Successfully restored"
                        task_state = 'Running'
                        task_status = "Initiated"
                        self._update_task(task_desc_string,
                                          completed_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)
                        msg_event = "Successfully restored "
                        is_restore_success = True

                # *****************************************************************************#
                try:
                    if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_DS or \
                            vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP or \
                            (
                                    vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM and volume_type == rmv_utils.VMFS_DISK_TYPE and not vmBackupType):
                        LOG.info("Attaching volumes back to the host")

                        # Update Tasks (Task Tracker and VMware Task)
                        task_desc_string = 'Attaching Volumes back to the host'
                        task_percentage = 70
                        task_state = 'Running'
                        task_status = "Initiated"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        '''
                        sample format that is parsed in the code below:
                        "hosts":[
                            {
                            "hostname":"15.213.71.143-QA-TMP"
                            }
                        ]
                        '''

                        # host_list = map_wwn_hostlist.values()[0]
                        # for host_item in host_list:
                        #     host_name = host_item["hostname"]
                        host_name = None
                        # no need to send the hostname to be attached we will pass the replay = ture
                        # during detach, "RetainAttachInfo" will be passed, so rmc will retian the attached host info
                        response = rmc_wrapper_service.attach_recoveryset(backup_recovery_set_id, host_name, True,
                                                                          task_id=task_id)
                        LOG.info("Volume attach - success")

                        '''
                        Perform HBA re-scan
                        '''
                        task_desc_string = 'Performing HBA re-scan'
                        task_percentage = 90
                        task_state = 'Running'
                        task_status = "Initiated"
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          vm_task_helper, task_status=task_status)

                        if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                            ds_moref_list = list()
                            ds_moref_list.append(moref)
                            mounted_hosts_list = ds_info.MountedHostsList
                            self.rescan_hosts_and_remove_internal_snaps(context, mounted_hosts_list, ds_moref_list,
                                                                        ds_uuid_to_moref_dict, rmc_wrapper_service,
                                                                        is_restore_success)
                        elif vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP or vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                            for mounted_host_tuple, ds_moref_list in host_moref_ds_moref_dict.items():
                                mounted_hosts_list = list(mounted_host_tuple)
                                self.rescan_hosts_and_remove_internal_snaps(context, mounted_hosts_list, ds_moref_list,
                                                                            ds_uuid_to_moref_dict, rmc_wrapper_service,
                                                                            is_restore_success)

                        # TODO : Need to call the same method for protection group restore to parent also.
                        register_vm_failed_count, unregister_vm_failed_count = self.post_restore_verify_and_register_unregistered_vms(
                            context, x_auth_token,
                            task_id, rmc_wrapper_service, vm_task_helper, copy_id, ds_moref_list)

                        # msg = "Restore snapshot: " + base_volume + ". Base volume attached back"
                        # self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)

                except Exception as e:
                    msg = "Failure while attaching back the volumes to the host: '%s'" % e
                    LOG.exception(msg)
                    self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg)

                    task_desc_string = "Restore could not be performed. " + msg
                    task_state = 'Failed'
                    vcenter_task_result = 'error'
                    msg_event = "Restore To Volume: " + base_volume + " " + "unsuccessful"
                    task_status = "Error"

                else:
                    if is_restore_success:
                        task_desc_string = "Restore to volume is successful: "
                        task_state = 'Completed'
                        task_status = "Ok"
                        vcenter_task_result = 'success'
                        msg_event = "Restore to volume: " + base_volume + " " + "successful"
                    else:
                        task_desc_string = "Restore could not be performed. " + restore_status
                        task_state = 'Failed'
                        vcenter_task_result = 'error'
                        msg_event = "Restore To Volume: " + base_volume + " " + "unsuccessful"
                        task_status = "Error"


            except (rmv_exception.DatastoreRetrieveFailed,
                    rmv_exception.vCenterMoRefError)as e:
                LOG.exception(("Exception: '%s'"), e)
                task_desc_string = "Restore could not be performed. %s" % e.msg + " " + rmv_utils.RESTORE_OPERATION_REQUISITE
                task_state = 'Failed'
                vcenter_task_result = 'error'
                task_status = "Error"
                msg_event = task_desc_string

            except (rmv_exception.VirtualCopySystemBusy,
                    rmv_exception.SnapshotNotFound,
                    rmv_exception.VIMPropertyNotFoundError,
                    rmv_exception.VMNotPoweredOffError,
                    rmv_exception.UnknownVMwareObjectError,
                    rmv_exception.DatastoreUnusableError,
                    rmv_exception.DatastoreUnsupportedTypeError,
                    rmv_exception.DatastoreSpannedError,
                    rmv_exception.DatastoreNon3parError,
                    rmv_exception.DatastoreMoreThanOneIn3parVolumeError,
                    rmv_exception.RMCAPIError,
                    rmv_exception.RMCAPIUnknownError,
                    rmv_exception.DatastoresWwnMissmatch,
                    rmv_exception.RestoreNotallowed,
                    rmv_exception.VmMovedToDifferentDatastore
                    ) as e:
                LOG.exception(("Exception: '%s'"), e)
                task_desc_string = "Restore could not be performed. "
                if hasattr(e, "msg"):
                    task_desc_string = task_desc_string + str(e.msg)
                task_state = 'Failed'
                task_status = "Error"
                vcenter_task_result = 'error'
                msg_event = "Restore to volume: " + base_volume + " " + "unsuccessful"

            except Exception as e:
                if hasattr(e, "msg"):
                    msg = e.msg
                elif hasattr(e, "message"):
                    msg = e.message
                else:
                    msg = "Internal error"
                LOG.exception(("Exception: '%s'"), e)
                task_desc_string = "Restore could not be performed. " + msg
                task_state = 'Failed'
                task_status = "Error"
                vcenter_task_result = 'error'
                msg_event = "Restore to volume: " + base_volume + " " + "unsuccessful"

            finally:
                task_percentage = 100
                LOG.info(('%s'), task_desc_string)
                # updating the task_desc_string if register/unregister got failed
                if register_vm_failed_count > 0:
                    task_desc_string = task_desc_string + "Unable to Register vm(s) on restored Datastore. " \
                                                          "However you can register the vm(s) by login to vCenter."
                if unregister_vm_failed_count > 0:
                    task_desc_string = task_desc_string + "Unable to remove the inaccessible vm(s) from restored datastore. " \
                                                          "However you can unregister the vm(s) from inventory by login to vCenter."
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd(vcenter_task_result, task_desc_string)
                self.vi_helper.LogEvent(mo_ref_for_vcenter_log, type_for_vcenter_log, msg_event)

        except Exception as excep:
            LOG.exception("Unknown exception during Restore to Parent Volume '%s'", excep)
        finally:
            self.update_copy_status(context, x_auth_token, copy_id)
            rmv_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, vm_objType, moref)
            rmv_obj['object_type'] = vm_objType
            nu.BackupNotification(rmv_copy, rmv_obj, task_id, 'restoreExpressProtect', rmc_wrapper_service).start()

    def update_ds_moref_rmv_db_and_workflow_post_restore(self, context, host_moref_list, ds_uuid_to_moref_dict,
                                                         rmc_wrapper_service):
        """
         Method to update ds object moref in db and workflows
        :param context: request context
        :param host_moref_list: base luns ESXi host moref list
        :param ds_uuid_to_moref_dict: datastore uuid to moref mapping
        :param rmc_wrapper_service: rmc_wrapper_service
        :return: datastore new moref list
         """
        LOG.debug("update ds moref rmv db and workflow postrestore::Enter")

        ds_uuid_list = ds_uuid_to_moref_dict.keys()
        post_restore_ds_uuid_to_moref_dict = {}
        old_to_new_moref_mapping = {}
        for host_moref in host_moref_list:
            try:
                host_moref_obj = pyvmomi_util.get_moref(host_moref, "HostSystem")
                host_oc_list = self.vi_helper.get_object_properties(host_moref_obj, ["datastore"])
                host_props = pyvmomi_util.extract_properties(host_oc_list[0])
                ds_moref_list = host_props.get("datastore")

                ds_oc_list = self.vi_helper.get_object_properties(ds_moref_list, ["info"])
                for oc in ds_oc_list:
                    vc_ds_obj_moref = oc.obj._moId
                    props = pyvmomi_util.extract_properties(oc)
                    ds_info = props.get("info")
                    if ds_info._wsdlName == "VmfsDatastoreInfo":
                        vmfs_obj = ds_info.vmfs
                        vc_ds_obj_uuid = vmfs_obj.uuid
                        if vmfs_obj.uuid in ds_uuid_list:
                            db_obj_moref = ds_uuid_to_moref_dict.get(vc_ds_obj_uuid)
                            if db_obj_moref != vc_ds_obj_moref:
                                LOG.info("Datastore '%s' moref got changed from '%s' to '%s' after restore. "
                                         "Updating the same into RMCV DB" % (
                                         ds_info.name, db_obj_moref, vc_ds_obj_moref))
                                post_restore_ds_uuid_to_moref_dict[vmfs_obj.uuid] = vc_ds_obj_moref
                                # data store moref got changed updating the db
                                self.db.update_rmcv_datastore_by_moref(context, db_obj_moref,
                                                                       {"moref": vc_ds_obj_moref})
                                old_to_new_moref_mapping[db_obj_moref] = vc_ds_obj_moref

            except Exception as e:
                LOG.exception(e)

        # update the moref id in workflow
        moref_manage_obj = moref_manage(self.vi_helper)
        moref_manage_obj.check_and_update_resource_id_in_workflow_by_wwn(rmc_wrapper_service, old_to_new_moref_mapping)

        LOG.debug("update ds moref rmv db and workflow postrestore::Exit")
        return post_restore_ds_uuid_to_moref_dict.values()

    def check_if_object_exists(self, moref, objType):
        LOG.debug("check_if_object_exists : Enter")
        obj_exists = False
        try:
            name_prop = self.vi_helper.get_object_prop_dict_pyvmomi(moref, objType, "name")
            obj_exists = True
        except (rmv_exception.PyVmomiException, Exception) as e:
            if hasattr(e, 'msg'):
                LOG.exception("Exception while getting the object name : %s" % e)
                obj_exists = False
            else:
                LOG.exception("The object has been deleted from the inventory:%s" % e)
                obj_exists = False
        LOG.debug("check_if_object_exists : Exit")
        return obj_exists

    def restore_to_snapshot(self, context, copy_id, x_auth_token, task_id, request_body):
        """Method to Restore Backup to Snapshot"""
        LOG.debug("Enter restore_to_snapshot_vol")
        LOG.info(_("Perform restore to snapshot on copy_id: %s") % copy_id)
        notification_kwargs = {}

        task_state = None
        task_desc_string = None
        vcenter_task_result = None
        msg_event = ""
        vmware_obj_name = ''
        parent_id = None
        rmc_copyset_id = None
        cloned_resources = None
        esxHostName = request_body.get('esxHostAddr')
        recreateVM = request_body.get('recreateVM', False)
        inventoryMoref = request_body.get('inventoryMoref')
        powerOnVM = request_body.get('powerOnVM', False)
        newVmName = request_body.get('newVmName')
        vmNameDict = request_body.get('vmNameDict')
        moref = request_body.get('moref')
        vm_objType = request_body.get('vm_objType')
        restoreIncremental = request_body.get('restoreIncremental', None)
        restoreParentSnapshotId = request_body.get('restoreParentSnapshotId', None)
        optimized = request_body.get('optimized', None)
        # resource list will be used to perform granular/partial clone
        resource_list = request_body.get('resourceList', list())
        # Create an instance of RMC Wrapper, to make any RMC or TaskTracker calls
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        # Create an instance of VMware Task Helper to populate vCenter Tasks
        vm_task_helper = VmTaskHelper(self.vi_helper)
        # These 2 values are used for vCenter Events and Tasks logging
        type_for_vcenter_log = vm_objType
        notification_kwargs['vmwObjType'] = vm_objType
        notification_kwargs['eventType'] = 'restoreExpressProtect'

        obj_exists = None
        if vm_objType != rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
            obj_exists = self.check_if_object_exists(moref, vm_objType)

        if obj_exists:
            type_for_vcenter_logevent = vm_objType
            type_for_vcenter_log = vm_objType
            mo_ref_for_vcenter_logevent = moref
        else:
            LOG.info("The parent object has either been removed or deleted, so proceeding with folder level task")
            # These 2 values are used for vCenter Events and Tasks logging
            type_for_vcenter_logevent = "Folder"
            type_for_vcenter_log = "Folder"
            mo_ref_for_vcenter_logevent = "group-d1"

        # Create a VMware Task, The task name will change later
        # once available in plugin.
        vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_logevent,
                                             mo_ref_for_vcenter_logevent,
                                             "RestoreToSnapshot",
                                             "RestoreToSnapshotFailedFault")

        try:
            rmv_copy = self.db.get_rmcv_copy_by_id(context, copy_id)
            rmc_copyset_id = rmv_copy.rmc_copyset_id
            if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                copy_detail = self.db.get_rmcv_copy_by_id_with_ds_details(context, copy_id, moref)
                vmware_obj_name = copy_detail.ds_name
                parent_id = copy_detail.ds_id
            elif vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                copy_detail = self.db.get_rmcv_copy_by_id_with_vm_details(context, copy_id, moref)
                vmware_obj_name = copy_detail.vm_name
                vmNameDict[vmware_obj_name] = copy_detail.moref
                parent_id = copy_detail.vm_id
            elif vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                copy_detail = self.db.get_rmcv_copy_by_copy_id_with_group_details(context, copy_id)
                pg_recovery_set_id = self.db.get_recovery_set_id_by_protection_group_id(context, moref)

            # update copy status to restoring
            rmv_copy.status = rmv_utils.copy_states.RESTORING
            self.db.update_rmcv_copy(context, copy_id, rmv_copy)

            copy_name = copy_detail.name
            if vm_objType == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                recovery_set_id = pg_recovery_set_id
            else:
                recovery_set_id = copy_detail.recovery_set_id
            notification_kwargs['recoverySetId'] = recovery_set_id
            notification_kwargs['vmwObjType'] = vm_objType
            if copy_detail.copy_type == 'express_protect':
                notification_kwargs['eventType'] = 'restoreExpressProtect'
            else:
                notification_kwargs['eventType'] = 'restoreExpressProtectCatalystCopy'
            notification_kwargs['backupName'] = copy_name
            notification_kwargs['rmcvTaskId'] = task_id
            notification_kwargs['vmwObjName'] = vmware_obj_name

            # validating ESXi host in vCenter
            mount = Mount()
            mo_type = "HostSystem"
            host_moref_list = self.vi_helper.get_all_mo_moref_in_vcenter(mo_type)
            prop_list = ["name", "runtime"]
            host_oc_list = self.vi_helper.get_object_properties(host_moref_list, prop_list)
            esxHostName_ip = mount.get_ip(esxHostName)
            # Check if the host is configured on the Vcenter
            host_detail = mount.get_host_moref(
                rmv_utils.REQUEST_BODY_PARAM_ESX_HOST_IP,
                esxHostName,
                host_oc_list, esxHostName_ip)
            if host_detail['host_configured']:
                host_moref = host_detail['host_moref']
                host_ip = host_detail['host_ip']
                if ((host_detail['connection_state']).lower() != "connected" or (
                        host_detail['power_state']).lower() != "poweredon"):
                    LOG.info("ESX host connection_state:%s power_state :%s", host_detail['connection_state'],
                             host_detail['power_state'])
                    raise exception.EsxHostNotReachable(esx_HostName=esxHostName)
            else:
                msg = ("Esx host not reachable :" + esxHostName)
                raise exception.EsxHostNotConfiguredException(
                    esx_HostName=esxHostName)
            host_wwn = mount.get_host_wwn(host_ip, host_moref, self.vi_helper)

            # Log an event in vCenter
            msg = "Restoring to snapshot begins"
            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
            # Update Tasks (Task Tracker and VMware Task)
            task_desc_string = 'Validating VmObject to Restore'
            task_percentage = 10
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Validate anything related to VM here. As of now nothing is to validate
            # Placeholder for the same.

            # validating ESXI host is configured in array or not
            array_serial_number = copy_detail.array_serial_number
            tmp_ds_mount_path_dir = copy_detail.ds_mount_path_dir
            ds_mount_path_dir = jsonutils.loads(tmp_ds_mount_path_dir)

            host_list = mount.get_hosts_from_storage_pools(context,
                                                           rmc_wrapper_service,
                                                           copy_id,
                                                           task_id,
                                                           vm_task_helper,
                                                           array_serial_number)

            host_config = mount.check_if_host_configured(
                rmc_wrapper_service,
                host_list,
                host_wwn,
                x_auth_token,
                task_id,
                vm_task_helper)
            if not host_config:
                LOG.error("ESXi Host Not configured")
                raise exception.EsxHostNotConfiguredException(
                    esx_HostName=esxHostName)
            else:
                LOG.info("ESXi Host is configured ")

            # recovery_set_id = backup_id
            # Update Tasks (Task Tracker and VMware Task)

            task_desc_string = 'Restoring, this may take sometime based on the volume size.'

            LOG.info("Calling RMC restore backup...")
            # Use RMC to restore snapshot. Catch exception in case of error during
            #  restore snapshot operation
            backup_id = copy_detail.rmc_copyset_id
            wwn_list = []
            # if resource_list is available perform partial restore to snapshot based on base wwn details of resource
            if resource_list:
                wwn_response_dict = self.get_rmcv_copy_wwn_details_by_resource_list(context, copy_id, resource_list)
                wwn_list = wwn_response_dict.get('wwn_list', list())
                cloned_resources = wwn_response_dict.get('cloned_resources')

            response = rmc_wrapper_service.restore_to_snapshot(backup_id, restoreIncremental,
                                                               restoreParentSnapshotId, optimized, task_id=task_id,
                                                               wwn_list=wwn_list)
            if response:
                msg = "Restore job successfully submitted"
                LOG.info(msg)
                self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)

            ### Should consider to make the below LOC into a common function across all backups.
            if 'taskUri' in response:
                LOG.info(_('The RMC task is %s ') % response)
                rmc_task_id = response['taskUri'].split("/")[-1]
                notification_kwargs['rmcTaskId'] = rmc_task_id
                backjob_response = self.update_backup_task(rmc_wrapper_service, False, task_id,
                                                           vm_task_helper, rmc_task_id, task_id, 10)
                LOG.debug(_('The backup job response is %s') % backjob_response)
                # now update the task to backup tasks and also VMware Tasks
                task_state = backjob_response['task']['taskState']

                LOG.info(_('The task_state is %s') % task_state)
                completed_percentage = backjob_response['task']['completedPercentage']
                # response_error_datas = rmc_wrapper_service.get_backup_task_tree_status(rmc_task_id)
                # LOG.info(_('The response_error_datas response is %s')%response_error_datas)
                if (task_state == 'Aborted'):
                    task_desc_string = "This task has been aborted by user."
                    task_status = "Error"
                    task_desc_string = task_desc_string + self.getLatestProgressMsg(backjob_response.get('task'))
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                elif (task_state == 'Error' or task_state == 'Failed'):
                    task_desc_string = "Restore to snapshot is unsuccessful."
                    task_desc_string = self.get_error_details(backjob_response, task_desc_string)
                    LOG.info(_('The backup job task_state is %s') % task_state)
                    # Get detailed error detail from task-tree GET output of backup job.
                    # response_error_datas = rmc_wrapper_service.get_backup_task_tree_status(rmc_task_id)
                    # for response_error_data in response_error_datas['taskTree']['children']:
                    # task_desc_string = task_desc_string + rmv_utils.RMC_ACTIVITY_PAGE_MSG
                    task_status = "Error"
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    msg_event = "Restore to snapshot is unsuccessful."

                    # Associating the vCenter Task with User Logged Event.
                    vm_task_helper.post_general_user_event(task_desc_string)

                    vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                else:
                    LOG.debug(_('The backup job task_state is %s') % task_state)
                    # tasks = backjob_response['task']['subTasks']['tasks']
                    cloned_rs_id = self.get_rs_from_task_resp(backjob_response['task'])

                    task_desc_string = "Restore to snapshot operation is in progress"
                    task_state = 'Running'
                    task_status = "Initiated"
                    completed_percentage = 20
                    self._update_task(task_desc_string,
                                      completed_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)
                    msg_event = "Successfully restored to snapshot"

                    response = mount.attach_recovery_set(context, cloned_rs_id, copy_id,
                                                         rmc_copyset_id,
                                                         x_auth_token,
                                                         host_config,
                                                         esxHostName,
                                                         host_moref,
                                                         ds_mount_path_dir,
                                                         vm_task_helper,
                                                         rmc_wrapper_service,
                                                         task_id,
                                                         self.vi_helper,
                                                         vm_objType,
                                                         parent_id,
                                                         self.db, cloned_resources)

                    clone_status = json_helper.clone_status
                    # Now we are supporting recreate VM for Virtual Machine clone only
                    if recreateVM:
                        object = vm_objType + ':' + moref
                        LOG.info("VMs to register:%s", vmNameDict)
                        response = self.register_vm_from_restored_ds(context, x_auth_token,
                                                                     rmc_wrapper_service, esxHostName,
                                                                     vmNameDict, inventoryMoref, copy_id, object,
                                                                     None, response, task_id, newVmName, powerOnVM)
                        task_desc_string = "Virtual clone operation completed succesfully "
                        task_state = 'Completed'
                        response['status'] = clone_status.cloned
                    else:
                        response['status'] = clone_status.mounted
                        msg_event = "Virtual clone operation completed succesfully"
                        task_desc_string = "Virtual clone operation completed succesfully"
                        task_state = 'Completed'
                        task_status = "Ok"

                    self.db.create_rmcv_clones(context, response)
                    LOG.debug(_("The client data for snapshot is sucessfully populated from the backup app metadata "))
                    # vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                    vcenter_task_result = "success"

            else:
                LOG.info(_('Got an Unknown Error'))
                msg = response
                LOG.error(msg)
                self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)
                raise

        except rmv_exception.TaskError as e:
            # "TaskError" exception would contain the failure reason, populated by RMC
            msg = e.msg
            LOG.exception(e)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg)

        except (rmv_exception.VirtualCopySystemBusy,
                rmv_exception.SnapshotNotFound,
                rmv_exception.VIMPropertyNotFoundError,
                rmv_exception.VMNotPoweredOffError,
                rmv_exception.UnknownVMwareObjectError,
                rmv_exception.DatastoreUnusableError,
                rmv_exception.DatastoreUnsupportedTypeError,
                rmv_exception.DatastoreSpannedError,
                rmv_exception.DatastoreNon3parError,
                rmv_exception.DatastoreMoreThanOneIn3parVolumeError,
                rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.EsxHostNotReachable,
                rmv_exception.EsxHostNotConfiguredException,
                rmv_exception.EsxMountException
                )as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Restore to snapshot is unsuccessful : "
            if hasattr(e, "msg"):
                task_desc_string = task_desc_string + str(e.msg)
            elif hasattr(e, "message"):
                task_desc_string = task_desc_string + str(e.message)
            task_state = 'Failed'
            task_status = "Error"
            vcenter_task_result = 'error'
            msg_event = "Restore to snapshot is unsuccessful"
        except rmv_exception.PreconditionFailed as e:
            LOG.exception(e)
            task_desc_string = "Restore to snapshot is unsuccessful : "
            if hasattr(e, "msg"):
                task_desc_string = task_desc_string + str(e.msg)
            task_desc_string = task_desc_string + ":Incremental restore parent not found"
            task_state = 'Failed'
            task_status = "Error"
            vcenter_task_result = 'error'
            msg_event = "Restore to snapshot is snsuccessful"
        except Exception as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Restore to snapshot is unsuccessful : Internal Error"
            task_state = 'Failed'
            task_status = "Error"
            vcenter_task_result = 'error'
            msg_event = "Restore to snapshot is unsuccessful"
        finally:
            self.update_copy_status(context, x_auth_token, copy_id)
            task_percentage = 100
            LOG.info(('%s'), task_desc_string)
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd(vcenter_task_result, task_desc_string)
            self.vi_helper.LogEvent(mo_ref_for_vcenter_logevent, type_for_vcenter_log, msg_event)

            rmv_obj = self.db_utils.get_vmware_object_by_object_type_and_moref(context, vm_objType, moref)
            rmv_obj['object_type'] = vm_objType
            nu.BackupNotification(rmv_copy, rmv_obj, task_id, 'restoreExpressProtect', rmc_wrapper_service).start()

    def create_backup_from_snapshot(self, context, snapshot_id, x_auth_token, task_id, request_body):
        #:param snapshot: snapshot for backup in rmv db
        #:param x_auth_token: autho token required to communicate to RMC service
        #:param task_id: task id to keep track of the entire backup tasks
        #:param request_body: backup params request_body
        #:return: taskid
        # Create the rmc-wrapper to use to make the RMC Calls
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        notification_kwargs = {}
        backup_policy_id = ""
        notification_kwargs['backupName'] = request_body.get('backupName', 'No Name')
        protectionPolicyId = request_body.get("protectionPolicyId", None)

        # task_detail = rmc_wrapper_service.get_backup_task_status()
        # get the snapshot details.
        # snapshot_id_in_rmc = None
        try:
            snapshot_id_in_rmc = request_body['snapshotSetId']
            snap_response = rmc_wrapper_service.get_rmc_snapshot(snapshot_id_in_rmc, x_auth_token)
            notification_kwargs['recoverySetId'] = snap_response['snapshotSet'].get('recoverySetId')

            if not snap_response:
                LOG.error(_('Could not get the snapshot information'))
                raise rmv_exception.InvalidSnapshot

        except(rmv_exception.InvalidSnapshot) as e:
            msg = "Could not Fetch Snapshot Information"
            LOG.exception(msg)
        try:
            # fetch the details of VM from the snapshot
            details_from_snapshot = snap_response['snapshotSet']
            vm_details_from_snapshot = jsonutils.loads(details_from_snapshot['clientData'])

            # get the moref, vmware-objectName, vmware-objectType
            if vm_details_from_snapshot:
                # # MoRef might have changed in case of SRm Failover/Failback. So check and update the ClientData
                # if snapshot_id_in_rmc:
                #     changed_client_data = self.check_and_update_moref_in_snap_cd(context=context,
                #                                                       x_auth_token=x_auth_token,
                #                                                       dict_client_data=vm_details_from_snapshot,
                #                                                       snap_gui_id=snapshot_id_in_rmc)
                #     if changed_client_data:
                #         vm_details_from_snapshot = changed_client_data

                mo_ref = vm_details_from_snapshot['ObjectRefID']
                vmware_object_name = vm_details_from_snapshot['VmWareObjectName']
                vmware_object_type = vm_details_from_snapshot['VmWareObjectType']
                notification_kwargs['vmwObjName'] = vmware_object_name
                notification_kwargs['vmwObjType'] = vmware_object_type
                snapshot_id_in_rmc = request_body['snapshotSetId']

            notification_kwargs['rmc_wrapper_service'] = rmc_wrapper_service
            notification_kwargs["rmcvTaskId"] = task_id

            # Create the vmware task
            vm_task_helper = VmTaskHelper(self.vi_helper)
            vm_task_helper.CustomVMwareTaskBegin(vmware_object_type,
                                                 mo_ref,
                                                 "CreateVMBackupTask",
                                                 "CreateVMBackupFailedFault")

            # update task
            task_desc_string = "Fetched Vm-Ware Object information from Snapshot"
            task_percentage = 5
            task_state = "Running"
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Add event to the Vm
            msg = 'Finished Collecting VM Information'
            self.vi_helper.LogEvent(mo_ref, vmware_object_type, msg)

            backup_name = request_body.get('backupName', None)
            if (backup_name is None or backup_name == ""):
                timestamp_in_utc_time = snap_response['snapshotSet']['createdAt']
                timestamp_in_local_time = rmv_utils.convert_utc_to_local_format(timestamp_in_utc_time)
                LOG.info("Backup name created by local time: '%s'" % timestamp_in_local_time)
                backup_name = timestamp_in_local_time

            if ('backupDescription' in request_body):
                backup_description = request_body['backupDescription']
            else:
                backup_description = "backup of snapshot " + snapshot_id_in_rmc

            # backup_policy_id
            if ('backupPolicyId' in request_body):
                backup_policy_id = request_body['backupPolicyId']
            else:
                # backupPolicyId is an optional keyword if protectionPolicyId is given then no need to pass backupPolicyId
                if not protectionPolicyId:
                    raise exception.RMCBackupPolicyError()

            snapshot_config_obj = None

            ###################
            app_metadata = {}
            temp = {}
            app_metadata['CreatedVcUserName'] = vm_details_from_snapshot['CreatedVcUserName']
            app_metadata['VirtualCenterInstanceId'] = vm_details_from_snapshot['VirtualCenterInstanceId']
            app_metadata['VirtualCenterUrl'] = vm_details_from_snapshot['VirtualCenterUrl']
            app_metadata['ObjectUUID'] = vm_details_from_snapshot['ObjectUUID']
            app_metadata['ObjectRefID'] = vm_details_from_snapshot['ObjectRefID']
            app_metadata['MoUuid'] = vm_details_from_snapshot.get('MoUuid')
            app_metadata['VmWareObjectType'] = vm_details_from_snapshot['VmWareObjectType']
            app_metadata['VmWareObjectName'] = vm_details_from_snapshot['VmWareObjectName']
            app_metadata['IsAppConsistent'] = vm_details_from_snapshot['IsAppConsistent']
            app_metadata['VirtualCopyList'] = vm_details_from_snapshot['VirtualCopyList']
            app_metadata['Version'] = rmv_utils.RMCV_VERSION
            app_metadata['snapshot_timestamp'] = snap_response['snapshotSet']['createdAt']
            app_metadata['DatastoreMountPathDict'] = vm_details_from_snapshot.get('DatastoreMountPathDict', {})
            for VirtualCopyList in vm_details_from_snapshot['VirtualCopyList']:
                if VirtualCopyList:
                    app_metadata['Vendor'] = VirtualCopyList.get('Vendor',
                                                                 None)
                    break

            if vm_details_from_snapshot.has_key('VmType'):
                LOG.debug(_("Snapshot response has vmType with value : %s ") % (vm_details_from_snapshot['VmType']))
                if vm_details_from_snapshot['VmType'] == rmv_utils.VMFS_DISK_TYPE:
                    LOG.info(_("Updating the Vmtype"))
                    app_metadata['VmType'] = vm_details_from_snapshot['VmType']
                    app_metadata['EsxHostToVmListDict'] = vm_details_from_snapshot['EsxHostToVmListDict']
                    app_metadata['EsxHostToDatastoreListDict'] = vm_details_from_snapshot['EsxHostToDatastoreListDict']
                    app_metadata['ArraySerialNum'] = vm_details_from_snapshot['ArraySerialNum']
                    app_metadata['MountableEsxHostList'] = vm_details_from_snapshot['MountableEsxHostList']
                    app_metadata['isERTEnabled'] = True
                    app_metadata['HasVmfsSnapshots'] = vm_details_from_snapshot.get("HasVmfsSnapshots", False)
                elif vm_details_from_snapshot['VmType'] == rmv_utils.VVOL_DISK_TYPE:
                    app_metadata['VmType'] = vm_details_from_snapshot['VmType']
                    # Fetch the config object for backing up on store once
                    snapshot_config_obj = self.get_snapshot_configuration_info(snapshot_id_in_rmc, x_auth_token,
                                                                               task_id, vm_task_helper)
                else:
                    app_metadata['EsxHostToVmListDict'] = vm_details_from_snapshot['EsxHostToVmListDict']
                    app_metadata['EsxHostToDatastoreListDict'] = vm_details_from_snapshot['EsxHostToDatastoreListDict']
                    app_metadata['ArraySerialNum'] = vm_details_from_snapshot['ArraySerialNum']
                    app_metadata['MountableEsxHostList'] = vm_details_from_snapshot['MountableEsxHostList']
                    app_metadata['isERTEnabled'] = True
                    app_metadata['HasVmfsSnapshots'] = vm_details_from_snapshot.get("HasVmfsSnapshots", False)

            elif vm_details_from_snapshot['VmWareObjectType'] == rmv_utils.VMWARE_OBJECT_TYPE_DS:
                app_metadata['EsxHostToVmListDict'] = vm_details_from_snapshot['EsxHostToVmListDict']
                app_metadata['EsxHostToDatastoreListDict'] = vm_details_from_snapshot['EsxHostToDatastoreListDict']
                app_metadata['ArraySerialNum'] = vm_details_from_snapshot['ArraySerialNum']
                app_metadata['MountableEsxHostList'] = vm_details_from_snapshot['MountableEsxHostList']
                app_metadata['isERTEnabled'] = True
                app_metadata['HasVmfsSnapshots'] = vm_details_from_snapshot.get("HasVmfsSnapshots", False)
            else:
                app_metadata['VmType'] = rmv_utils.VMFS_DISK_TYPE

            LOG.info(_('The app_metadata is %s ') % app_metadata)
            """
            From RMC we support only two modes of backup,
            1. Auto mode performs a backup as efficiently as possible, optimising reads from array source and using previous backups as sources.
            2. Full backup mode performs a full backup by reading all the data from the source array with no optimisation or use of prior backups
            """
            LOG.info("Checking whether the backup is auto mode or full mode")
            increment = None
            optimized = None
            if ('incremental' in request_body):
                if request_body['incremental'] is False:
                    LOG.info("Full backup initiated")
                    increment = False
                    optimized = False
            else:
                LOG.info("Auto Backup Initiated")
                increment = None
                optimized = None

            task_desc_string = 'Initiating Backup'
            task_percentage = 10
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Add event to the VM
            self.vi_helper.LogEvent(mo_ref, vmware_object_type, msg)

            # Call the RMC API to do backup

            # setting request body, which will provide details to send email
            notification_kwargs['backupName'] = backup_name
            try:
                response_data = rmc_wrapper_service.create_backup(snapshot_id_in_rmc, backup_policy_id,
                                                                  backup_description, backup_name,
                                                                  app_metadata, increment, snapshot_config_obj,
                                                                  optimized, protectionPolicyId=protectionPolicyId,
                                                                  task_id=task_id)
                LOG.info(_("Create_backup_manager: The response_data is %s") % response_data)
                LOG.info(_("Create_backup_manager: The response_data is %s") % response_data)
                LOG.info(_('Backup Task Id in RMC is %s') % response_data['taskUri'])
            except (rmv_exception.TaskError,
                    rmv_exception.RMCAPIError,
                    rmv_exception.RMCAPIUnknownError,
                    rmv_exception.RMCFieldNotFoundException,
                    Exception
                    ) as e:
                LOG.exception(e)
                err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
                LOG.error(_('create_backup_from_snapshot exception: %s') % (err_args_msg))
                task_desc_string = err_args_msg
                task_percentage = 25
                task_state = 'Failed'
                task_status = "Error"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                return

            task_desc_string = 'Backup In Progress'
            task_percentage = 25
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Read the response from RMC task-id and update to backup-task-id in RMV.
            # Looping inside this function, returns only after backup job is completed successfully/errored out.
            # extract the task if from the response_data
            rmc_backup_taskid = response_data['taskUri'].split('/')[-1]
            notification_kwargs['rmcTaskId'] = rmc_backup_taskid
            starting_rate = 25
            backjob_response = self.update_backup_task(rmc_wrapper_service, False, task_id, vm_task_helper,
                                                       rmc_backup_taskid,
                                                       task_id, starting_rate, mo_ref, vmware_object_type)
            LOG.info(_('The backup job response is %s') % backjob_response)

            # now update the task to backup tasks and also VMware Tasks
            task_state = backjob_response['task']['taskState']
            completed_percentage = backjob_response['task']['completedPercentage']
            if task_state == 'Aborted':
                task_desc_string = "This task has been aborted by user."
                task_status = "Error"
                task_desc_string = task_desc_string + self.getLatestProgressMsg(backjob_response.get('task'))
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            elif task_state == 'Error' or task_state == 'Failed':
                task_desc_string = "HPE Express Protect backup failed. Reason "
                task_desc_string = self.get_error_details(backjob_response, task_desc_string)
                # # Get detailed error detail from task-tree GET output of backup job.
                # response_error_datas = rmc_wrapper_service.get_backup_task_tree_status(rmc_backup_taskid)
                # tasks = response_error_datas['task']['subTasks']['tasks']
                # for response_error_data in tasks :
                #     temp_msg = response_error_data['taskStatus']
                #     childTaskState = response_error_data['taskState']
                #     #Removing the repeated messages getting appended to task description
                #     if temp_msg not in task_desc_string and childTaskState == 'Error' or childTaskState == 'Aborted' or childTaskState == 'Failed':
                #         task_desc_string = task_desc_string + self.getLatestProgressMsg(response_error_datas.get('task'))
                task_status = "Error"
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

            else:
                task_desc_string = "HPE Express Protect backup completed successfully. "
                task_desc_string = task_desc_string + str(self.getLatestProgressMsg(backjob_response.get('task')))
                task_state = 'Completed'
                task_status = "Ok"

                # Update appmetadata virtualcopylist field with individual backup object id
                self.update_appmetadata(backjob_response, app_metadata, rmc_wrapper_service, x_auth_token)
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
        except (rmv_exception.TaskError,
                rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.RMCFieldNotFoundException,
                Exception
                ) as e:
            LOG.exception(e)
            err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            LOG.error(_('create_backup_from_snapshot exception: %s') % (err_args_msg))

            task_desc_string = err_args_msg
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

        except Exception as e:
            LOG.exception(e)
            err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            LOG.error(_('create_backup_from_snapshot exception: %s') % (err_args_msg))

            task_desc_string = err_args_msg
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
        finally:
            notification_kwargs['eventType'] = 'createExpressProtect'

        return

    def update_appmetadata(self, backjob_response, app_metadata, rmc_wrapper_service, x_auth_token, task_id=None):
        """
        This method will update the appmetadata virtualcopylist with corresponding backup object id
        obtained from backups returned from RMC GET backupid call. This is required becauase, if
        snapshot is deleted then the virualCoplylist doesn't have anyway to associate itself with
        corresponding backup object returned by RMC.
        :param backjob_response: backup job response
        :param app_metadata: app meatadata field of backup
        :param rmc_wrapper_service:
        :param x_auth_token:
        :return: none
        """
        LOG.info("update_appmetadata : Enter")
        try:
            if not backjob_response:
                LOG.error("Unable to udpate appMetadata for backup. backjob_response is null")

            if not app_metadata:
                LOG.error("Unable to udpate appMetadata for backup. app_metadata is null")

            # Update backup appmetada virtualcopylist with individual volume backupid
            backup_id = (backjob_response['task']['associatedResource']['resourceUri']).split('/')[-1]
            backup_details = rmc_wrapper_service.get_backup_for_backupId(context, backup_id, x_auth_token)
            backups = backup_details['backupSet']['backups']

            if app_metadata.get('VirtualCopyList') is None:
                LOG.error("Unable to udpate appMetadata for backup. VirtualCopyList is null")
                app_metadata['VirtualCopyList'] = []

            # for each VC in VritualcopyList find the corresponding backup object and update the id
            for vc in app_metadata.get('VirtualCopyList', []):
                # Get corresponding backup object to populate the VirtualCopyList Mount Information
                # From 6.0 'InServROVolume' field is removed from clientdata. So now matching with WWN
                # backup = rmv_utils.first_or_default(backups, lambda i: i['snapName'] in vc['InServROVolume'])
                backup = rmv_utils.first_or_default(backups,
                                                    lambda i: i['copyOfVolumeWwn'] in vc['InServBaseVolumeWwn'])
                if backup is not None:
                    vc['id'] = backup.get('id')

            # update appmetadata with RMC
            LOG.debug("app_meatadata : %s", app_metadata)
            rmc_wrapper_service.update_backup(backup_id, backupAppMetadata=jsonutils.dumps(app_metadata))
        except Exception as e:
            LOG.exception(e)
            LOG.error("Unable to udpate appMetadata for backup %s", backup_id)

        LOG.info("update_appmetadata : Exit")
        return

    def build_client_data_for_snapshot_after_restore(self, context, moref, snapshot_id, x_auth_token, backup_id,
                                                     obj_type):
        LOG.info("build_client_data_for_snapshot_after_restore : Enter")
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            snap_info = rmv_structures.SnapshotInfo()

            backupSet = rmc_wrapper_service.get_backup_for_backupId(context, backup_id).get('backupSet')

            LOG.debug("Backup set : %s" % backupSet)
            bkp_appMetadata = backupSet.get('appMetadata', None)
            snapshot_details = rmc_wrapper_service.get_snapshot(snapshot_id)
            LOG.debug(_("Populating the snap information %s") % snapshot_details)
            # snapshot_timestamp = snapshot_details['snapshotSet']['createdAt']
            snap_info.CreationTime = snapshot_details['snapshotSet']['createdAt']
            snap_info.VcSetName = snapshot_details['snapshotSet']['name']

            CreatedVcUserName = bkp_appMetadata.get('CreatedVcUserName', None)
            snap_info.CreatedVcUserName = CreatedVcUserName if CreatedVcUserName else self.vi_helper.validated_username
            snap_info.VirtualCenterUrl = bkp_appMetadata.get('VirtualCenterUrl')
            snap_info.VmWareObjectName = bkp_appMetadata.get('VmWareObjectName')
            snap_info.VmWareObjectType = bkp_appMetadata.get('VmWareObjectType')
            snap_info.ObjectUUID = bkp_appMetadata.get('ObjectUUID')
            snap_info.ObjectRefID = bkp_appMetadata.get('ObjectRefID')
            # snap_info.ExpiryInSeconds = None
            # snap_info.RetentionInSeconds = None
            snap_info.SnapshotGuid = snapshot_id
            # snap_info.Expirable = False

            snap_info.ArraySerialNum = bkp_appMetadata['ArraySerialNum']
            array_details = rmc_wrapper_service.check_array_registration(bkp_appMetadata['ArraySerialNum'])
            snap_info.ArrayName = array_details['name']
            snap_info.ArraySerialNum = array_details['serialNumber']
            snap_info.CreatedArrayUserName = array_details['username']

            if 'RestoreFromBackup' in snapshot_details['snapshotSet']['clientData']:
                LOG.debug(_("The type of %s") % type(snapshot_details['snapshotSet']['clientData']))
                LOG.debug(_("The client data is %s") % snapshot_details['snapshotSet']['clientData'])
                snap_info.RestoreFromBackup = jsonutils.loads(snapshot_details['snapshotSet']['clientData'])[
                    'RestoreFromBackup']
                LOG.info(_('Assigned the restore from backup'))
            else:
                snap_info.RestoreFromBackup = None
            if 'IsAppConsistent' in snapshot_details['snapshotSet']['clientData']:
                LOG.info(_("The backup app consistency is %s") % snapshot_details['snapshotSet']['clientData'])
                snap_info.IsAppConsistent = jsonutils.loads(snapshot_details['snapshotSet']['clientData'])[
                    'IsAppConsistent']
                IsAppConsistentFlag = snap_info.IsAppConsistent
            else:
                snap_info.IsAppConsistent = False

            ret_snap_info = rmv_structures.SnapshotInfo()

            virtual_copy_luns = bkp_appMetadata['VirtualCopyList']
            virtual_copy_luns_list = []

            resp = rmc_wrapper_service.get_volume_wwn(snapshot_details['snapshotSet'], ret_snap_info)
            for virtual_copy in virtual_copy_luns:
                # TODO:6.0 Delete commented code after CD removal
                # virtual_copy['State'] = json_helper.TpdVmPluginVirtualCopyState.Available
                base_volume_wwn = virtual_copy['InServBaseVolumeWwn']
                if type(base_volume_wwn) is list:
                    # virtual_copy['InServROVolume'] = []
                    # virtual_copy['InServROCopyOfId'] = []
                    # virtual_copy['InServBaseVolume'] = []
                    for volume_wwn in base_volume_wwn:
                        if volume_wwn in resp.ArrayBaseVolumeWwnDict:
                            # virtual_copy['InServROVolume'].append(ret_snap_info.ArrayROVolumeWwnDict[volume_wwn])
                            # virtual_copy['InServROCopyOfId'].append(ret_snap_info.ArrayROCopyOfIdDict[volume_wwn])
                            # virtual_copy['InServBaseVolume'].append(ret_snap_info.ArrayBaseVolumeWwnDict[volume_wwn])
                            for i in range(len(virtual_copy['RestorableItemsList'])):
                                # virtual_copy['RestorableItemsList'][i]['InServVolume'] = virtual_copy['InServBaseVolume']
                                # virtual_copy['RestorableItemsList'][i]['InServTargetVolume'] = virtual_copy['InServROVolume']
                                virtual_copy['RestorableItemsList'][i]['IsAppConsistent'] = IsAppConsistentFlag

                                if obj_type == 'VirtualMachine':
                                    virtual_copy['RestorableItemsList'][i]['IsAppConsistent'] = IsAppConsistentFlag
                else:
                    if virtual_copy['InServBaseVolumeWwn'] in resp.ArrayBaseVolumeWwnDict:
                        # virtual_copy['InServROVolume'] = ret_snap_info.ArrayROVolumeWwnDict[base_volume_wwn]
                        # virtual_copy['InServROCopyOfId'] = ret_snap_info.ArrayROCopyOfIdDict[base_volume_wwn]
                        # virtual_copy['InServBaseVolume'] = ret_snap_info.ArrayBaseVolumeWwnDict[base_volume_wwn]
                        for i in range(len(virtual_copy['RestorableItemsList'])):
                            # virtual_copy['RestorableItemsList'][i]['InServVolume'] = virtual_copy['InServBaseVolume']
                            # virtual_copy['RestorableItemsList'][i]['InServTargetVolume'] = virtual_copy[
                            #     'InServROVolume']
                            virtual_copy['RestorableItemsList'][i]['IsAppConsistent'] = IsAppConsistentFlag

                            if obj_type == 'VirtualMachine':
                                virtual_copy['RestorableItemsList'][i]['IsAppConsistent'] = IsAppConsistentFlag
                virtual_copy_luns_list.append(virtual_copy)

            snap_info.VirtualCopyList = virtual_copy_luns_list

            # Update to RMC.
            LOG.debug(_("Updating the RMC with client data after restore to snapshot : %s") % snap_info)
            json_snap_info = jsonutils.dumps(snap_info.__dict__)
            LOG.debug(_("Updating the RMC with client data JSON after restore to snapshot : %s") % snap_info)
            rmc_wrapper_service.update_snapshot(snapshot_id, snapshotClientData=json_snap_info)

        except(rmv_exception.RMCStorageSystemNotRegisteredException,
               rmv_exception.RMCAPIError,
               rmv_exception.RMCAPIUnknownError,
               rmv_exception.RMCFieldNotFoundException,
               rmv_exception.VmwareException, rmv_exception.PyVmomiException,
               Exception
               ) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Internal error"

        finally:
            LOG.info("hs_and_hss_properties - '%s' Before " % len(pyvmomi_util.hs_and_hss_properties))
            pyvmomi_util.hs_and_hss_properties.clear()
            LOG.info("hs_and_hss_properties - '%s' After " % pyvmomi_util.hs_and_hss_properties)

            LOG.info("build_client_data_for_snapshot_after_restore : Exit")
        return

    # TODO : Not using this method. nedd to remove this method in  RMV 6.0
    def remove_non_expirable_snapshot(self, recovery_set_id,
                                      rmc_wrapper_service, vm_task_helper):
        LOG.info("removing non-expirable snapshot:Enter")
        snapshot_list = []
        vmware_object_type = "Folder"
        mo_ref = "group-d1"

        try:
            is_found_numeric_snap = False
            # get the list of all snapshots in recovery set
            response_data = \
                rmc_wrapper_service.get_snapshots_by_recoveryset(recovery_set_id)
            if response_data:
                snapshotSets = response_data['snapshotSets']
                snapshot_list.extend(snapshotSets)
                for temp in snapshot_list:
                    if 'clientData' in temp:
                        json_client_data = temp['clientData']
                        dict_client_data = jsonutils.loads(json_client_data)
                        if "SnapshotGuid" in dict_client_data:
                            snap_shot_guid = dict_client_data['SnapshotGuid']
                            # find the numeric snapshot
                            # expirable = dict_client_data['Expirable']
                            # From 6.0 Expirable will be stored in CD. So calculating it dynamically.
                            expirable = True if dict_client_data.get('snapExpiry') > 0 else False
                            if not expirable:
                                is_found_numeric_snap = True
                                LOG.info("Going to delete "
                                         "snapshot : %s",
                                         snap_shot_guid)
                                # delete only one numeric oldest snapshot
                                vm_task_helper.CustomVMwareTaskBegin(vmware_object_type, mo_ref,
                                                                     "RemoveNonExpirableSnapTask",
                                                                     "RemoveNonExpirableSnapFailedFault")
                                resp = rmc_wrapper_service.delete_snapshot(
                                    snap_shot_guid)
                                task_desc_string = "successfully removed " \
                                                   "oldest non-expirable snapshot:%s" % \
                                                   snap_shot_guid
                                vm_task_helper.CustomVMwareTaskUpdate(100,
                                                                      task_desc_string)
                                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
                                break
                if not is_found_numeric_snap:
                    LOG.info("Non-Expirable  snapshots not found")

            else:
                LOG.info("There are no snapshots to remove")
            LOG.info("removing non-expirable snapshot: Exit")
        except(rmv_exception.TaskError, Exception) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.error(('%s'), e)
                msg = "Unknown error"
            task_desc_string = "Failed to remove non-expirable " \
                               "snapshot'%s'" % msg
            # LOG.info("%s", task_desc_string)
            LOG.info("%s ", task_desc_string)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

    def update_db(self, context, is_create, numeric_policy,
                  updateSnapshotpolicy_input, mo_ref=None, db_create=None,
                  recoverysetid=None):
        LOG.info("Enetr update db:")
        active = updateSnapshotpolicy_input.get('Active', True)
        if not is_create:
            if not numeric_policy:
                options = {'del_nonexpirable_snap':
                               updateSnapshotpolicy_input[
                                   'NonExpirablePolicyHandling'],
                           'is_active': active}
            else:
                options = {'del_nonexpirable_snap': False,
                           'is_active': active}

            options.update({'mo_uuid': updateSnapshotpolicy_input['mo_uuid']})
            if updateSnapshotpolicy_input.get('lun_wwn'):
                options.update({'lun_wwn': updateSnapshotpolicy_input['lun_wwn']})

            result = self.db.update_record_based_on_mo_ref(context, mo_ref, options)
        else:
            if db_create:
                if numeric_policy:
                    options = {'moref': mo_ref, 'recoverysetid':
                        recoverysetid, 'is_active': active}
                else:
                    # Expirabble policy so create record with user
                    # input for del_nonexpirable_snap
                    options = {'moref': mo_ref, 'recoverysetid':
                        recoverysetid, 'del_nonexpirable_snap':
                                   updateSnapshotpolicy_input[
                                       'NonExpirablePolicyHandling'],
                               'is_active': active}

                options.update({'mo_uuid': updateSnapshotpolicy_input['mo_uuid']})

                if updateSnapshotpolicy_input.get('lun_wwn'):
                    options.update({'lun_wwn': updateSnapshotpolicy_input['lun_wwn']})

                snapshot = self.db.snapshot_create(context, options)
            else:
                if numeric_policy:
                    options = {'recoverysetid': recoverysetid,
                               'del_nonexpirable_snap': False, 'is_active':
                                   active}
                else:
                    # Expirabble policy so update record with user
                    # input for del_nonexpirable_snap
                    options = {'recoverysetid': recoverysetid,
                               'del_nonexpirable_snap':
                                   updateSnapshotpolicy_input[
                                       'NonExpirablePolicyHandling'],
                               'is_active': active}

                options.update({'mo_uuid': updateSnapshotpolicy_input['mo_uuid']})

                if updateSnapshotpolicy_input.get('lun_wwn'):
                    options.update({'lun_wwn': updateSnapshotpolicy_input['lun_wwn']})

                result = self.db.update_record_based_on_mo_ref(
                    context, mo_ref, options)
        LOG.info("Exit update db:")

    def update_db_record(self, context, numeric_policy, updateSnapshotpolicy_input, mo_ref, recoverysetid):
        LOG.info("update_db_record :Enter")
        active = updateSnapshotpolicy_input.get('Active', True)

        if not numeric_policy:
            options = {'del_nonexpirable_snap': updateSnapshotpolicy_input['NonExpirablePolicyHandling'],
                       'is_active': active, 'recoverysetid': recoverysetid}
        else:
            options = {'del_nonexpirable_snap': False, 'is_active': active, 'recoverysetid': recoverysetid}
        options.update({'mo_uuid': updateSnapshotpolicy_input['mo_uuid']})
        if updateSnapshotpolicy_input.get('lun_wwn'):
            options.update({'lun_wwn': updateSnapshotpolicy_input['lun_wwn']})

        result = self.db.update_record_based_on_mo_ref(context, mo_ref, options)
        LOG.info("update_db_record :Exit")

    def create_db_record(self, context, numeric_policy, createSnapshotpolicy_input, mo_ref=None, db_create=None,
                         recoverysetid=None):
        LOG.info("create_db_record : Enter")
        active = createSnapshotpolicy_input.get('Active', True)
        if db_create:
            if numeric_policy:
                options = {'moref': mo_ref, 'recoverysetid': recoverysetid, 'is_active': active}
            else:
                # Expirabble policy so create record with user
                # input for del_nonexpirable_snap
                options = {'moref': mo_ref, 'recoverysetid': recoverysetid, 'del_nonexpirable_snap':
                    createSnapshotpolicy_input['NonExpirablePolicyHandling'], 'is_active': active}
            options.update({'mo_uuid': createSnapshotpolicy_input['mo_uuid']})

            if createSnapshotpolicy_input.get('lun_wwn'):
                options.update({'lun_wwn': createSnapshotpolicy_input['lun_wwn']})

            snapshot = self.db.snapshot_create(context, options)
        else:
            if numeric_policy:
                options = {'recoverysetid': recoverysetid, 'del_nonexpirable_snap': False, 'is_active': active}
            else:
                # Expirabble policy so update record with user
                # input for del_nonexpirable_snap
                options = {'recoverysetid': recoverysetid, 'del_nonexpirable_snap':
                    createSnapshotpolicy_input['NonExpirablePolicyHandling'], 'is_active': active}
            options.update({'mo_uuid': createSnapshotpolicy_input['mo_uuid']})

            if createSnapshotpolicy_input.get('lun_wwn'):
                options.update({'lun_wwn': createSnapshotpolicy_input['lun_wwn']})

            result = self.db.update_record_based_on_mo_ref(context, mo_ref, options)
        LOG.info("create_db_record : Exit")

    def get_snapshot_status(self, x_auth_token, snapshot_id):
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

            snapshot = rmc_wrapper_service.get_rmc_snapshot(
                snapshot_id,
                x_auth_token)
        except (
                rmv_exception.RMCAPIError, rmv_exception.RMCAPIUnknownError) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.info(('%s'), e.msg)
                msg = e.msg
            else:
                LOG.info(('%s'), e)
                msg = "Internal error"
            raise rmv_exception.StorageSystemVirtualCopyDeletionException(
                msg=msg)

        # attach=snapshot['attach']
        # attach_status=attach['status']

        snap_shot_dtl = snapshot['snapshotSet']
        status = snap_shot_dtl['status']
        return status

    def migration(self, context, migration_body, x_auth_token, task_id):
        new_migration_task = True
        try:
            if not self._lock_migration.locked():
                LOG.info(("Waiting for migration lock ..."))
                with self._lock_migration:
                    message = "Total remote copy group and virtual machine or datastore snapshots to import : " + str(
                        migration_body['total_snapshots'])
                    rmv_utils.initialize_migration_log(migration_log_path, message)
                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    message = "  The count of remote copy group snapshots to import : " + str(
                        migration_body['rcopy_snapshots_count'])
                    rmv_utils.write_in_migration_log_file(migration_log_path, message)
                    message = "  The count of virtual machine or datastore snapshots to import : " + str(
                        migration_body['local_snapshots_count'])
                    rmv_utils.write_in_migration_log_file(migration_log_path, message)
                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")

                    rmv_utils.write_in_migration_log_file(migration_log_path,
                                                          "The recovery set creation of virtual machine or datastore started.")
                    rmv_utils.write_in_migration_log_file(migration_log_path,
                                                          "  Validating/Creating virtual machine or datastore configuration and importing policy setting of virtual machine or datastore.")
                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    uuid_to_moref_mapping = {}
                    rmc_host_list_input = migration_body['applianceList']
                    try:
                        uuid_to_moref_mapping = self.check_create_recovery_set(context, x_auth_token,
                                                                               rmc_host_list_input)
                    except Exception as e:
                        # Don't stop here. Move to next item migration.
                        pass

                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    rmv_utils.write_in_migration_log_file(migration_log_path,
                                                          "The recovery set creation of virtual machine or datastore finished.")
                    # Reset invalid snapshot counter
                    invalid_snapshots = migration_body[
                        'invalid_snapshots']  # Keep in temo variable so we can use it after schedule job migration
                    migration_body['invalid_snapshots'] = 0
                    uuid_to_host_mapping = {}
                    host_to_uuid_mapping = {}
                    rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
                    host_to_uuid_mapping, uuid_to_host_mapping = self.get_host_to_uuid_mapping(context,
                                                                                               rmc_host_list_input,
                                                                                               uuid_to_host_mapping,
                                                                                               rmc_wrapper_service)
                    # Schedule job migration can use above mapping to import scheduled job on respective rmc appliance.
                    # Local schedule job migration for Vmware and datastore objects.
                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    try:
                        self.scheduledjob_migration(context, migration_body, x_auth_token, task_id,
                                                    uuid_to_host_mapping, uuid_to_moref_mapping=uuid_to_moref_mapping)
                    except Exception as e:
                        # Don't stop here. Move to next item migration.
                        pass

                    # Remote copy snapshot migration
                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    rc_snapshot_obj = remote_copy_snapshots(vi_helper=self.vi_helper)
                    kwargs = {}
                    rmv_utils.write_in_migration_log_file(migration_log_path,
                                                          "The recovery set creation of remote copy group started.")
                    kwargs = rc_snapshot_obj.rc_recovery_sets_migration(context, migration_body, x_auth_token, task_id,
                                                                        self.vi_helper)
                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    rmv_utils.write_in_migration_log_file(migration_log_path,
                                                          "The recovery set creation of remote copy group finished.")
                    storage_system_mapping_with_remote_rmv_server = rc_snapshot_obj.get_storage_system_mapping_with_remote_rmv_server(
                        context)

                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    try:
                        self.scheduledjob_migration(context, migration_body, x_auth_token, task_id,
                                                    uuid_to_host_mapping, rmc_host_list_input[0],
                                                    storage_system_mapping_with_remote_rmv_server,
                                                    "remote copy group schedule job")
                    except Exception as e:
                        # Don't stop here. Move to next item migration.
                        pass

                    # Local snapshot migration for Vmware and datastore objects.
                    rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                    migration_body['invalid_snapshots'] = invalid_snapshots
                    try:
                        self.snapshot_migration(context, migration_body, x_auth_token, task_id)
                    except Exception as e:
                        # Don't stop here. Move to next item migration.
                        pass

                    # remote copy schedule job migration
                    # rest this counter now
                    migration_body['invalid_snapshots'] = 0
                    try:
                        rc_snapshot_obj.rc_snapshot_migration(context, migration_body, x_auth_token, task_id,
                                                              self.vi_helper,
                                                              kwargs)  # get mapping of StoreServe with remote RMC-V VSA Ipp adress/Hostname
                    except Exception as e:
                        # Don't stop here. Move to next item migration.
                        pass
            else:
                task_desc_string = "Please retry after sometime. The previous migration is still in progress."
                vm_task_helper = VmTaskHelper(self.vi_helper)
                vm_task_helper.CustomVMwareTaskBegin("Folder", "group-d1", "InitiateMigrationTask",
                                                     "IniatiateMigrationTaskFailedFault")  # Todo
                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
                rmv_utils.write_in_migration_log_file(migration_log_path, " ")
                rmv_utils.write_in_migration_log_file(migration_log_path, task_desc_string)
                new_migration_task = False

        except Exception as e:
            # This Rest API is sync call so end user will tracke it using task tracker, vcenter or migration.log file.
            LOG.exception(e)
        if new_migration_task is True:
            rmv_utils.write_in_migration_log_file(migration_log_path, " ")
            rmv_utils.write_in_migration_log_file(migration_log_path, " ")
            rmv_utils.write_in_migration_log_file(migration_log_path,
                                                  "The import operation is finished. Please check above for recommendation (if any) and take appropriate action as recommended.")

    def snapshot_migration(self, context, migration_body, x_auth_token, task_id):
        kwargs = {}
        try:
            kwargs['type_of_migration'] = "virtual machine or datastore snapshot"
            kwargs['x_auth_token'] = x_auth_token
            kwargs['task_id'] = task_id
            kwargs['migration_body'] = migration_body
            kwargs['task_percentage'] = 1
            kwargs['vm_task_helper'] = VmTaskHelper(self.vi_helper)
            kwargs['rmc_wrapper_service'] = rmc_wrapper.rmc_wrapper(x_auth_token)
            kwargs['count_success'] = 0
            kwargs['count_failed'] = 0
            kwargs['completed_steps'] = 0
            kwargs['err_args_msg'] = ""
            kwargs['snapsnot_name_to_migrate'] = ""
            kwargs['task_state'] = 'Error'
            kwargs['b_success'] = True
            kwargs['parent_task_id'] = None
            kwargs['output_of_task'] = None
            kwargs['local_snapshots_count'] = None
            kwargs['moref_to_host_mapping'] = {}
            kwargs['host_to_moref_mapping'] = {}
            kwargs['rmc_host_list_input'] = kwargs['migration_body']['applianceList']
            # Get moref from all RMC Appliance and set/initliase it here.
            kwargs['host_to_moref_mapping'] = rmv_utils.initialize_mapping(kwargs['rmc_host_list_input'])
            kwargs['host_to_moref_mapping'], kwargs['moref_to_host_mapping'] = self.set_host_to_moref_mapping(context,
                                                                                                              kwargs[
                                                                                                                  'rmc_host_list_input'],
                                                                                                              kwargs[
                                                                                                                  'moref_to_host_mapping'],
                                                                                                              kwargs[
                                                                                                                  'rmc_wrapper_service'])

            # Create the VMware task helper and populate vCenter Tasks
            kwargs['vm_task_helper'].CustomVMwareTaskBegin("Folder", "group-d1", "InitiateMigrationTask",
                                                           "IniatiateMigrationTaskFailedFault")  # Todo

            task_desc_string = "Waiting to start " + kwargs['type_of_migration'] + "  migration."
            self._update_task(task_desc_string, kwargs['task_percentage'], "Running", task_id,
                              kwargs['rmc_wrapper_service'], kwargs['vm_task_helper'])
            LOG.info("local snapshots migration started")
            rmv_utils.write_in_migration_log_file(migration_log_path, "The import operation of " + kwargs[
                'type_of_migration'] + " is started.")
            rmv_utils.write_in_migration_log_file(migration_log_path, " ")
            snapshots_detail = rmv_utils.get_snapshot_id_client_data_from_sqlite_db()
            step_counter = 1
            completed_steps = step_counter
            total_steps = len(snapshots_detail)
            output_for_task = "  The number of " + kwargs['type_of_migration'] + "s to import is " + str(
                total_steps) + "."
            rmv_utils.write_in_migration_log_file(migration_log_path, output_for_task)
            rmv_utils.write_in_migration_log_file(migration_log_path, " ")
            for snapshot_detail in snapshots_detail:
                kwargs['completed_steps'] = step_counter
                kwargs['snapshot_id'] = snapshot_detail[0]
                kwargs['groupd_id'] = snapshot_detail[1]
                kwargs['creation_time'] = snapshot_detail[3]
                kwargs['client_data'] = snapshot_detail[4]
                kwargs['snapsnot_name_to_migrate'] = kwargs['creation_time']
                kwargs['task_percentage'] = (step_counter * 100) / total_steps
                step_counter = step_counter + 1
                try:
                    kwargs = self.import_single_snapshot(context, kwargs)
                except Exception as e:
                    LOG.exception(e)
                    continue  # Continue to migrate next snapshot. Error is already captured for last snapshot migration failure

        except Exception as e:
            LOG.exception(e)
            kwargs['b_success'] = False
            kwargs['err_args_msg'] = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            kwargs['count_failed'] = kwargs['count_failed'] + 1
            kwargs['output_of_task'] = None
            kwargs['task_state'] = 'Error'
            self._update_migration_task_failed_end(kwargs)

        if kwargs['b_success']:  # else error part must be handled in exception section above.
            self._update_migration_task_finished(kwargs)

    def import_single_snapshot(self, context, kwargs):
        kwargs['err_args_msg'] = ""
        kwargs['snapsnot_name_to_migrate'] = ""
        try:
            kwargs['snap_info'] = rmv_utils.get_snapshot_info_by_client_data(kwargs['snapshot_id'],
                                                                             kwargs['client_data'])
            # Get snapshot name as per legacy RMV approach
            kwargs['snapsnot_name_to_migrate'] = str(kwargs['snap_info'].CreationTime)
            if len(kwargs['snap_info'].VcSetName.strip()) != 0:
                kwargs['snapsnot_name_to_migrate'] = kwargs['snap_info'].VcSetName

            kwargs['json_snap_info'] = jsonutils.dumps(kwargs['snap_info'].__dict__)
            kwargs['client_data'] = jsonutils.dumps(kwargs['snap_info'].__dict__)
            kwargs['mo_ref'] = kwargs['snap_info'].ObjectRefID
            kwargs['VmWareObjectName'] = kwargs['snap_info'].VmWareObjectName
            kwargs['recovery_set_id'] = None

            kwargs['recoveryset_policy'] = rmv_utils.get_snapshot_id_policy_client_data_from_sqlite_db(
                kwargs['groupd_id'])
            # Call remote import snapshot REST API for RMC-V here. This is to support multi rmc appliance.
            response = ""
            kwargs['host_to_moref_mapping'], kwargs[
                'moref_to_host_mapping'] = rmv_utils.update_rmc_appliance_by_moref_mapping(
                kwargs['host_to_moref_mapping'], kwargs['moref_to_host_mapping'], kwargs['mo_ref'])
            kwargs['moref_mapped_rmc_appliance'] = rmv_utils.get_rmc_appliance_by_moref_mapping(kwargs['mo_ref'],
                                                                                                kwargs[
                                                                                                    'moref_to_host_mapping'])
            if rmv_utils.does_vcenter_instance_id_match(kwargs['snap_info'].VirtualCenterInstanceId,
                                                        kwargs['migration_body']['vCenterInstanceIdList']) is False:
                # Error out this snapshot in this case self.vi_helper.instance_uuid
                msg = "The vCenter instance id '%s' is not matching." % kwargs['snap_info'].VirtualCenterInstanceId
                raise exception.OtherException(message=msg)
            # Check if it's already migrated during last import operation.
            # RMC-V 1.0 search string.. Check this first
            search_string_available_10 = kwargs['moref_mapped_rmc_appliance'] + "->" + kwargs[
                'snapsnot_name_to_migrate'] + " : Migrated successfully."
            # RMC-V 1.1 search string.. Check this later
            search_string_available_11 = "  The " + kwargs['type_of_migration'] + " '" + kwargs[
                'snapsnot_name_to_migrate'] + "' of '" + kwargs[
                                             'VmWareObjectName'] + "' is migrated successfully on RMC-V Appliance '" + \
                                         kwargs['moref_mapped_rmc_appliance'] + "'."
            if rmv_utils.is_available_in_file(search_string_available_10) is True:
                response = {}
                response['status'] = 'available'
            elif rmv_utils.is_available_in_file(search_string_available_11) is True:
                response = {}
                response['status'] = 'available'
            else:  # Make remote call if and only if it is not migrated succesffully. Assumption is if it's migrated first time successfully
                # User is not chaning rmc appliance list.
                response = kwargs['rmc_wrapper_service'].import_snapshot_remote(context, kwargs, is_remote=False)
            # Make RMC-V REST API call for snapshot migration.
            response = response['status']
            if (response == 'available'):  # Todo
                kwargs['count_success'] = kwargs['count_success'] + 1
                kwargs['task_state'] = 'Running'
                self._update_migration_task_success(kwargs)
            else:
                raise  # It means failed. return from here and continue to migrate next snapshot.
        except Exception as e:
            LOG.exception(e)
            kwargs['err_args_msg'] = (_("%s") % e.msg if hasattr(e, 'msg') else str(e))
            kwargs['count_failed'] = kwargs['count_failed'] + 1
            kwargs['task_state'] = 'Running'
            kwargs['output_of_task'] = None
            self._update_migration_task_failed(kwargs)
            raise

        return kwargs

    def get_vm_name_list_in_datastore(self, context, id, x_auth_token):

        # To get the VM List for a specific datastore

        LOG.info("get_vm_name_list_in_datastore : enter")
        vm_list_result = {}

        try:
            # vmlist = self.rmvjob_api.get_vmlist_datastore(context, id,
            # x_auth_token)
            vm_name_list = []
            vm_obj = []
            data = None

            datastoreInfo = id.split(":")

            # It does not come through web client session initialization.

            self.verify_vcenter_initialization()

            # Get All VM details for a specific datastore
            LOG.info("Getting VM List for datastore : '%s'" % datastoreInfo[1])
            data = self.vi_helper.get_virtual_machine_in_datastore(
                datastoreInfo[0],
                datastoreInfo[1])

            for vmObj in data:
                vm_name_list.append(vmObj.Name)
                vm_obj.append(vmObj.__dict__)

            # Get the size of the Datastore size info
            sizeinfo_dict = self.vi_helper.get_datastore_size_info(
                datastoreInfo[0],
                datastoreInfo[1])

            # create the dictionary of VM details and Datastore Size details
            vm_list_result["vmNameList"] = vm_name_list
            vm_list_result["VmObjects"] = vm_obj
            vm_list_result["datastoreTotalCapacity"] = sizeinfo_dict[
                "vmfsTotalSize"]
            vm_list_result["datastoreFreeSpace"] = sizeinfo_dict[
                "vmfsFreeSize"]

        except (Exception, rmv_exception.VcenterIntializationFailed) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                msg = "Internal error"

            vm_list_result["statusDescription"] = msg
            vm_list_result["StatusCode"] = \
                json_helper.TpdVmPluginWebOperationStatusCode.ObjectNotFound
            return vm_list_result

        # If no error then set the statuscode to Ready
        vm_list_result[
            "StatusCode"] = json_helper.TpdVmPluginWebOperationStatusCode.Ready

        LOG.debug("vm_list_result %s ", vm_list_result)
        LOG.info("get_vm_name_list_in_datastore : exit")

        return vm_list_result

    def verify_vcenter_initialization(self):
        try:
            if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                LOG.info("vCenter not initialized. Let's do it")
                with self.lock:
                    self.vi_helper = ViHelper()
                    # DB could be empty
                    if ((not self.vi_helper.ip) or (self.vi_helper.ip == "")):
                        msg = "Please make sure vCenter is registered with RMC"
                        LOG.error(msg)
                        raise rmv_exception.VcenterNotInitialized(msg)
        except (Exception, rmv_exception.VcenterNotInitialized) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                LOG.error(('%s'), e.msg)
                msg = e.msg
            else:
                msg = "Internal error"
            raise rmv_exception.VcenterNotInitialized(msg)

    # TODO: Bad...bad...Move all these utility functions to right place.
    def get_vcenter_credentials(self):
        ip_hostname = None
        username = None
        password = None
        vcenteruid = None
        try:
            ctxt = context.get_admin_context()
            vcenter_config = self.db.vcenter_configuration_get_first(ctxt)
            if vcenter_config:
                LOG.info("vCenter config exists...")
                ip_hostname = vcenter_config.host_name
                username = vcenter_config.host_username
                password = rmv_utils.decrypt(vcenter_config.host_password)
                vcenteruid = vcenter_config.server_guid
                LOG.info("vCenter IP/Hostname: <%s>, Username: <%s>", ip_hostname, username)
        except exception as ex:
            LOG.info("Error while reading database: %s", str(ex))

        return (ip_hostname, username, password, vcenteruid)

    def scheduledjob_migration(self, context, migration_body, x_auth_token, parent_task_id, uuid_to_host_mapping,
                               remote_copy_source_rmc_hostname=None, storage_system_mapping_with_remote_rmv_server=None,
                               type_of_migration="virtual machine or datastore schedule job",
                               uuid_to_moref_mapping=None):
        LOG.info("scheduledjob_migration : enter")

        kwargs = {}
        try:
            kwargs['x_auth_token'] = x_auth_token
            kwargs['task_percentage'] = 1
            kwargs['vm_task_helper'] = VmTaskHelper(self.vi_helper)
            kwargs['rmc_wrapper_service'] = rmc_wrapper.rmc_wrapper(x_auth_token)
            kwargs['count_success'] = 0
            kwargs['count_failed'] = 0
            kwargs['completed_steps'] = 0
            kwargs['err_args_msg'] = ""
            kwargs['snapsnot_name_to_migrate'] = ""
            kwargs['task_state'] = 'Error'
            kwargs['parent_task_id'] = parent_task_id
            kwargs['output_of_task'] = None
            kwargs['local_snapshots_count'] = None
            kwargs['migration_body'] = migration_body
            kwargs['task_id'] = self.create_schedular_task(kwargs['rmc_wrapper_service'])
            kwargs['type_of_migration'] = type_of_migration

            output_for_task = "The import operation of " + kwargs['type_of_migration'] + " is started."
            rmv_utils.write_in_migration_log_file(migration_log_path, output_for_task)
            rmv_utils.write_in_migration_log_file(migration_log_path, " ")

            # Download csv file now. If any error occurs, exit scheduled job migariont task.
            rmv_utils.enable_iptables_port(rmv_utils.get_ov4vc_port_number(migration_body['systemRoot']))
            rmv_utils.download_legacy_rmv_metadata_file(migration_body['systemRoot'], migration_body['sessionCookie'],
                                                        "rmv_scheduler.csv", "csv")
            # Read the exported CSV file and construct the request body
            LOG.info("Constructing scheduler request body ... ")
            scheduler_request_body_list = rmv_utils.construct_scheduler_request_body(uuid_to_host_mapping,
                                                                                     kwargs['rmc_wrapper_service'],
                                                                                     remote_copy_source_rmc_hostname,
                                                                                     storage_system_mapping_with_remote_rmv_server,
                                                                                     uuid_to_moref_mapping)
            scheduler_request_body_list_length = len(scheduler_request_body_list)
            kwargs['local_snapshots_count'] = scheduler_request_body_list_length

            kwargs['vm_task_helper'].CustomVMwareTaskBegin("Folder", "group-d1", "InitiateMigrationTask",
                                                           "IniatiateMigrationTaskFailedFault")

            task_desc_string = "Starting Scheduler migration"
            task_percentage = 2
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              kwargs['task_id'],
                              kwargs['rmc_wrapper_service'],
                              kwargs['vm_task_helper'],
                              kwargs['parent_task_id'], task_status=task_status)

            task_desc_string = "Getting Windows Scheduler information"
            task_percentage = 5
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              kwargs['task_id'],
                              kwargs['rmc_wrapper_service'],
                              kwargs['vm_task_helper'],
                              kwargs['parent_task_id'], task_status=task_status)

            # If no Scheduler requests then update the tasktracker and return.
            if not scheduler_request_body_list_length:
                task_desc_string = "No " + kwargs['type_of_migration'] + " " + " to migrate."
                task_percentage = 100
                task_state = 'Completed'
                task_status = "Ok"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  kwargs['task_id'],
                                  kwargs['rmc_wrapper_service'],
                                  kwargs['vm_task_helper'],
                                  kwargs['parent_task_id'], task_status=task_status)
                kwargs['vm_task_helper'].CustomVMwareTaskEnd("success", task_desc_string)

            # Get the names of created schedulers
            scheduler_names = self.get_created_scheduler_names(kwargs['rmc_wrapper_service'])

            count = 1
            for req_body in scheduler_request_body_list:
                scheduler_name = req_body['schedule']['name']
                kwargs['completed_steps'] = count
                count = count + 1

                resource_uri = req_body['schedule']['resourceList'][0]['resourceUri']
                index = resource_uri.index('/rest')
                host_ip = resource_uri[8:index]
                # if scheduler by same name already exists then do not create
                if scheduler_name not in scheduler_names:
                    # if StartTime is empty then the scheduler is of type One Time scheduler.
                    if req_body['schedule']['startTime']:
                        # If monthly scheduler is based on days like second monday or fourth tuesday of every month.
                        # This type of scheduler is not supported in RMC-V.
                        if req_body['schedule']['frequency'] == 'monthly' and not req_body['schedule']['dayofmonth']:
                            msg = ((
                                       "The schedule job '%s' cannot be migrated. This type of job is not supported") % scheduler_name)
                            LOG.info(msg)
                            rmv_utils.write_in_migration_log_file(migration_log_path, msg)
                            continue
                        task_desc_string = "Migrating %s name '%s'" % (kwargs['type_of_migration'], scheduler_name)
                        kwargs['task_percentage'] = (count * 100) / scheduler_request_body_list_length
                        task_state = 'Running'
                        task_status = "Initiated"
                        self._update_task(task_desc_string,
                                          kwargs['task_percentage'],
                                          task_state,
                                          kwargs['task_id'],
                                          None,
                                          kwargs['vm_task_helper'],
                                          kwargs['parent_task_id'], task_status=task_status)

                        try:
                            LOG.info(("Execute remote Create Scheduler call: '%s'") % scheduler_name)
                            # Get the RMC IP from the request body.
                            resource_uri = req_body['schedule']['resourceList'][0]['resourceUri']
                            index = resource_uri.index('/rest')
                            host_ip = resource_uri[8:index]

                            response = kwargs['rmc_wrapper_service'].import_schedulejob_remote(context, x_auth_token,
                                                                                               req_body, host_ip,
                                                                                               is_remote=False,
                                                                                               parent_task_id=parent_task_id)
                            status = response['status']
                            if status == "success":
                                kwargs['count_success'] = kwargs['count_success'] + 1
                                kwargs['task_state'] = 'Running'
                                kwargs['moref_mapped_rmc_appliance'] = str(host_ip)
                                kwargs['snapsnot_name_to_migrate'] = scheduler_name
                                self._update_migration_task_success(kwargs)
                            else:
                                kwargs['count_failed'] = kwargs['count_failed'] + 1
                                kwargs['task_state'] = 'Running'

                        except Exception as e:
                            LOG.exception(e)
                            kwargs['err_args_msg'] = (_("%s") % e.msg if hasattr(e, 'msg') else str(e))
                            kwargs['count_failed'] = kwargs['count_failed'] + 1
                            kwargs['task_state'] = 'Running'
                            kwargs['output_of_task'] = None
                            continue
                else:
                    kwargs['count_success'] = kwargs['count_success'] + 1
                    kwargs['task_state'] = 'Running'
                    kwargs['moref_mapped_rmc_appliance'] = str(host_ip)
                    kwargs['snapsnot_name_to_migrate'] = scheduler_name
                    self._update_migration_task_success(kwargs)
                    LOG.info(("The %s with name '%s' already exists.") % (kwargs['type_of_migration'], scheduler_name))

            # Update the vCenter and Trast tracker
            self._update_migration_task_finished(kwargs)

        except Exception as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                msg = e.msg
            else:
                msg = e
            LOG.error(("Exception in %s scheduled job Migration '%s' ") % (kwargs['type_of_migration'], msg))

            task_desc_string = "Exception in %s migration : '%s'" % (kwargs['type_of_migration'], msg)
            task_percentage = 100
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              kwargs['task_id'],
                              kwargs['rmc_wrapper_service'],
                              kwargs['vm_task_helper'],
                              kwargs['parent_task_id'], task_status=task_status)
            kwargs['vm_task_helper'].CustomVMwareTaskEnd("error", task_desc_string)
            rmv_utils.write_in_migration_log_file(migration_log_path, task_desc_string)
            raise e

        LOG.info("scheduledjob_migration : exit")

    def import_recoveryset_snapshot(self, context, snapshot_set, x_auth_token):
        LOG.info(("Waiting to acquire snapshot_op_lock lock for import ..."))
        with rmv_locks.snapshot_op_lock:
            LOG.info(("Got the snapshot_op_lock lock for import..."))
            response = ""
            try:
                rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
                snapshot_set['clientData'] = jsonutils.loads(snapshot_set['clientData'])
                try:
                    if snapshot_set.get('remoteCopyKeyName', None) is None:  # Local snapshot
                        snapshot_db = self.db.get_record_based_on_mo_ref(context,
                                                                         snapshot_set['clientData']['ObjectRefID'])
                        snapshot_set['recoverySetId'] = snapshot_db['recoverysetid']
                    else:
                        snapshot_db = self.db.get_rc_record_by_key(context, snapshot_set['remoteCopyKeyName'])
                        snapshot_set['recoverySetId'] = snapshot_db['recoveryset_id']
                        snapshot_set['remoteEnabled'] = True
                    # Read the recovery-set-id

                    LOG.debug(("recovery_set_id: %s"), snapshot_set['recoverySetId'])
                except Exception as e:
                    # This exception must be ignored.
                    LOG.debug("recovery set id record not found in rmc-v db")

                if snapshot_set.get('remoteCopyKeyName', None) is None:  # Local snapshot
                    snapshot_set['recoverySetId'] = rmc_wrapper_service._get_recovery_set_id(context,
                                                                                             snapshot_set['clientData'],
                                                                                             snapshot_set[
                                                                                                 'snapshotSetId'],
                                                                                             snapshot_set[
                                                                                                 'recoverySetId'],
                                                                                             snapshot_set[
                                                                                                 'recoverysetPolicy'])
                rmc_wrapper_service.import_snapshot(context, snapshot_set)
                snapshot_id_status = None
                try:
                    snapshot_id_status = self.get_snapshot_status(x_auth_token, snapshot_set['snapshotSetId'])
                except Exception as e:
                    LOG.debug("Ignoring get_snapshto_status error")
                if (snapshot_id_status == 'available'):
                    response = "available"
                    # Set client data here so rmc-v should not list it in case of failure.
                    rmc_wrapper_service.update_snapshot(snapshot_set['snapshotSetId'],
                                                        snapshotClientData=jsonutils.dumps(snapshot_set['clientData']))
                else:
                    response = ""
            except Exception as e:
                LOG.exception(e)
                raise
            d = {}
            d['status'] = response
            return d

    # This will create a mapping between host to moref.
    # e.g
    # host_to_moref_mapping_list['host1'] =  moref1
    # host_to_moref_mapping_list['host2'] =  moref2
    # This mapping will be used to decide for moref snapshot migration on an RMC appliance.
    def set_host_to_moref_mapping(self, context, rmc_host_list_input, moref_to_host_mapping, rmc_wrapper_service):
        # Exception is handled inside caller.
        host_to_moref_mapping_list = {}
        try:
            for rmc_host_name_ip in rmc_host_list_input:
                # Make remote RMC Rest API call find out all Moref
                response_data = rmc_wrapper_service.get_remote_appliance_snashots(context, rmc_host_name_ip)
                snapshot_detail_list = response_data['SnapshotArray']
                moref_associated = []
                host_to_moref_mapping_list[rmc_host_name_ip] = []
                for snap_details in snapshot_detail_list:
                    # snap_details['ObjectUUID']
                    if snap_details['ObjectRefID'] not in host_to_moref_mapping_list[rmc_host_name_ip]:
                        moref_associated.append(snap_details['ObjectRefID'])
                    host_to_moref_mapping_list[rmc_host_name_ip] = moref_associated
                    moref_to_host_mapping[snap_details['ObjectRefID']] = rmc_host_name_ip
        except Exception as e:
            LOG.exception(e)
            raise
        return host_to_moref_mapping_list, moref_to_host_mapping

    # This will create a mapping between host to uuid. This will be used for legacy rmc scheduled job migration
    # The legacy rmv scheduled job are created based on uuid only not moref.
    # e.g
    # host_to_uuid_mapping_list['host1'] =  uuid1
    # host_to_uuid_mapping_list['host2'] =  uiid2
    # This mapping will be used to decide for uuid schedule job migration on an RMC appliance.
    def get_host_to_uuid_mapping(self, context, rmc_host_list_input, uuid_to_host_mapping, rmc_wrapper_service):
        # Exception is handled inside caller.
        host_to_uuid_mapping_list = {}
        try:
            for rmc_host_name_ip in rmc_host_list_input:
                # Make remote RMC Rest API call find out all Moref
                response_data = rmc_wrapper_service.get_remote_appliance_snashots(context, rmc_host_name_ip)
                snapshot_detail_list = response_data['SnapshotArray']
                moref_associated = []
                host_to_uuid_mapping_list[rmc_host_name_ip] = []
                for snap_details in snapshot_detail_list:
                    # snap_details['ObjectUUID']
                    if snap_details['ObjectUUID'] not in host_to_uuid_mapping_list[rmc_host_name_ip]:
                        moref_associated.append(snap_details['ObjectUUID'])
                    host_to_uuid_mapping_list[rmc_host_name_ip] = moref_associated
                    uuid_to_host_mapping[snap_details['ObjectUUID']] = rmc_host_name_ip
        except Exception as e:
            LOG.exception(e)
            raise
        return host_to_uuid_mapping_list, uuid_to_host_mapping

    def update_snapshot_migration_status_in_vcenter(self, kwargs, task_desc_string):
        vm_task_helper = VmTaskHelper(self.vi_helper)
        # Create the VMware task helper and populate vCenter Tasks
        vm_task_helper.CustomVMwareTaskBegin("Folder", "group-d1", "ImportSnapshotEvent", "ImportSnapshotFailedFault")
        self._update_task(task_desc_string, 100, "Running", None, None, vm_task_helper)
        vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

    def update_scheduler_migration_status_in_vcenter(self, kwargs, task_desc_string):
        vm_task_helper = VmTaskHelper(self.vi_helper)
        # Create the VMware task helper and populate vCenter Tasks
        vm_task_helper.CustomVMwareTaskBegin("Folder", "group-d1", "ImportScheduledJobEvent",
                                             "ImportScheduledJobFailedFault")
        self._update_task(task_desc_string, 100, "Running", None, None, vm_task_helper)
        vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)

    # Add implementation for scheduled job migration
    def import_scheduled_job(self, context, scheduled_job, x_auth_token):
        status = "failed"
        # kwargs = {}
        LOG.info("inside manager layer import_scheduled_job api : enter")
        # ret = {}
        # ret['ScheduleResponse'] = None
        schedule_create_response_list = []
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        scheduler_name = scheduled_job['schedule']['name']
        try:
            LOG.info(("Creating Scheduled Job : '%s'") % scheduler_name)
            schedule_create_response = rmc_wrapper_service.create_schedule_jobs(scheduled_job)
            if schedule_create_response:
                LOG.info(("Create Scheduled Job : '%s' - Success") % scheduler_name)
                status = "success"
                schedule_create_response_list.append(schedule_create_response)
        except Exception as e:
            # If exception the log the error and continue creating other schedulers
            LOG.exception(("Exception in create scheduler : '%s'") % e)
            task_desc_string = "Failed in creating the scheduler : '%s'" % scheduler_name
            self.update_scheduler_migration_status_in_vcenter(None, task_desc_string)

        d = {}
        d['status'] = status
        return d

    def create_schedular_task(self, rmc_wrapper_service):
        task_id = None
        kwargs = {}
        kwargs['name'] = 'Scheduler Migration operation'
        kwargs['owner'] = 'RMC-V User'
        kwargs['task_state'] = 'New'
        kwargs['task_type'] = 'User'
        kwargs['resource_name'] = 'RMC-V Scheduler Migration'
        kwargs['resource_category'] = 'migration'
        kwargs['association_type'] = 'IS_A'
        kwargs['resource_id'] = ""
        # kwargs['total_steps'] = scheduler_request_body_list_length
        try:
            response_data = rmc_wrapper_service.create_task(kwargs)
            task_id = response_data['id']
        except:
            msg = ("Failed to create task. Please check if tasktracker service is running")
            raise Exception(msg)

        return task_id

    def get_created_scheduler_names(self, rmc_wrapper_service):

        schedulers_created = rmc_wrapper_service.get_schedule_jobs()
        schedeler_names_list = []

        for scheduler in schedulers_created['schedules']:
            schedeler_names_list.append(scheduler['name'])

        return schedeler_names_list

    def get_all_pool_ids_in_use(self, rmc_wrapper_service, client_id):
        array_system_id_list = []
        array_pool_id_list = []

        # Get registered array list from RMC
        rmc_registered_array_list = \
            rmc_wrapper_service.get_storage_system_details()
        rmc_array_list = rmc_registered_array_list['storageSystems']
        # array_list = rmc_array_list
        # if client id is rmv_utils.dummy_refresh_client_id than refresh all StoreServ
        # we can not decide which storeServ Luns are exported to Vcenter.
        # If client id is not rmv_utils.dummy_refresh_client_id than go ahead with previous logic.
        if client_id in rmv_utils.dummy_refresh_client_id:
            for store_serv in rmc_array_list:
                array_system_id_list.append(store_serv['id'])
        else:
            # Get array cabid and array serial number from vcenter cache
            # array_list = self.getarraylist()
            # extract storage_system_id by  comparing array serial number form
            # vcenter cache and RMC
            # for store_serv_serial_number in array_list.values():

            # vCenter cache is removed from 4.0 release.
            # So Cache refresh is done for all the storage systems registered in RMC.
            for store_serv in rmc_array_list:
                # if store_serv_serial_number == store_serv["serialNumber"]:
                array_system_id_list.append(store_serv['id'])
        # Get pool id's for each registered storage system from RMC
        for array_system_id in array_system_id_list:
            pool_list = rmc_wrapper_service.get_storage_pools(
                array_system_id)
            for pool in pool_list:
                array_pool_id_list.append(pool['id'])
        LOG.info("Storage pools:%s", array_pool_id_list)
        return array_pool_id_list, array_system_id_list

    def add_target_server_to_response(self, context, storage_system_obj):
        serial_number = storage_system_obj.serialNumber
        array_detail = self.db.array_get(context, serial_number)

        if array_detail:
            associated_appliance_id = array_detail.associated_appliance_id
            server_detail = self.db.appliance_get(context, associated_appliance_id)
            fqdn = server_detail.name
            try:
                fqdn = socket.getfqdn(server_detail.name)
            except Exception:
                LOG.info("Exception while fetching DNS name for host: %s", server_detail.name)

            storage_system_obj.target_host = fqdn
            storage_system_obj.target_username = server_detail.username

        return storage_system_obj

    def rc_get_policy(self, context, vmObjType, vmObjId, src_arr_serial_num,
                      rmc_host_list,
                      xauthtoken):
        LOG.info("Enter RC Get policy")
        rc_snapshot_obj = remote_copy_snapshots(vi_helper=self.vi_helper)
        return rc_snapshot_obj.rc_get_policy(context, vmObjType, vmObjId,
                                             src_arr_serial_num, rmc_host_list,
                                             xauthtoken,
                                             self.vi_helper)

    def rc_update_snapshot_policy(self, context, updateSnapshotpolicy_input,
                                  x_auth_token):
        rc_snapshot_obj = remote_copy_snapshots(vi_helper=self.vi_helper)
        return rc_snapshot_obj.rc_update_snapshot_policy(context, updateSnapshotpolicy_input,
                                                         x_auth_token, self.vi_helper)

    def validate(self, context, body, taskId, xAuthToken):
        LOG.info("In validate(), inside manager, Enter ")
        obj = validate_util.Validator(body, taskId, self, xAuthToken)
        res = obj.validate()
        LOG.info("In validate(), inside manager, Exit ")
        return res

    def rmv_get_policies(self, context, xauthtoken, input_parameters, filters=None):
        LOG.info("rmv_get_policies inside manager layer: Enter")
        policy_util = policyutil.PolicyController(context, xauthtoken, self.vi_helper)
        response = policy_util.getPolicies(context, input_parameters, filters)
        return response

    def rmv_update_policies(self, context, x_auth_token, body, task_id):
        LOG.info("rmv_update_policies inside manager layer: Enter")
        policy_util = policyutil.PolicyController(context, x_auth_token, self.vi_helper)
        response = policy_util.updateRmvPolicies(body, task_id, self)
        return response

    def remote_update_policy(self, context, update_rc_policy, x_auth_token):
        rc_snapshot_obj = remote_copy_snapshots(vi_helper=self.vi_helper)
        return rc_snapshot_obj.remote_update_policy(context,
                                                    update_rc_policy,
                                                    x_auth_token, self.vi_helper)

    def get_datastore_type(self, context, mo_ref, object_type):
        LOG.info("get_datastore_type : enter")
        datastore_type_list = []
        datastore_type = None
        ds_list_having_VMDK = []

        try:
            if object_type == 'Datastore':
                LOG.info("Getting type of datastore : '%s'" % mo_ref)
                try:
                    datastore_type = self.vi_helper.get_datastore_type(mo_ref)
                except rmv_exception.VIMPropertyNotFoundError as e:
                    LOG.error(("Exception: '%s'"), e.msg)
                    datastore_type = json_helper.TpdVmHostFileSystemType.Unknown
                datastore_type_list.append(datastore_type)

            elif object_type == 'VirtualMachine':
                datastore_list = []
                LOG.info("Getting list of datastores of the VM : '%s'" % mo_ref)
                datastores_list = self.vi_helper.get_datastores_of_vm(mo_ref)
                try:
                    LOG.info("Get vm hardware configuration")
                    ds_list_having_VMDK = self.vi_helper.get_vm_ds_list_having_VMDK(mo_ref)
                except Exception as e:
                    LOG.exception(e)
                for datastore_moref in datastores_list:
                    LOG.info("Getting type of datastore : '%s'" % datastore_moref)
                    try:
                        if ds_list_having_VMDK:
                            if datastore_moref in ds_list_having_VMDK:
                                datastore_type = self.vi_helper.get_datastore_type(datastore_moref)
                                datastore_type_list.append(datastore_type)
                        # Bug Fix : 102546. In case of VM with no VMDK attached, is not supported.
                        # else:
                        #     datastore_type = self.vi_helper.get_datastore_type(datastore_moref)
                        #     datastore_type_list.append(datastore_type)
                    except rmv_exception.VIMPropertyNotFoundError as e:
                        LOG.error(("Exception: '%s'"), e.msg)
                        datastore_type = json_helper.TpdVmHostFileSystemType.Unknown
                        datastore_type_list.append(datastore_type)
        except (rmv_exception.VIMPropertyNotFoundError,
                rmv_exception.vCenterMoRefError
                ) as e:
            LOG.exception(("Exception: '%s'"), e)
        except Exception as e:
            LOG.exception(("Exception: '%s'"), e)

        LOG.debug("datastore_type_list %s ", datastore_type_list)
        LOG.info("get_datastore_type : exit")

        return datastore_type_list

    def update_vcenter_task_import(self, task_desc_string, status):
        if self.vi_helper is not None:
            vm_task_helper = VmTaskHelper(self.vi_helper)
            vm_task_helper.CustomVMwareTaskBegin("Folder", "group-d1", "InitiateMigrationTask",
                                                 "IniatiateMigrationTaskFailedFault")
            vm_task_helper.CustomVMwareTaskUpdate(100, task_desc_string)
            vm_task_helper.CustomVMwareTaskEnd(status, task_desc_string)

    # This will sync StoreServ crendential on remote server
    # The remote server will be decided based on configured remote remote host by user.
    # The user will configure remote server for every target StoreServ in case of remote copy.
    def update_remote_rmcv_server(self, context, x_auth_token, remote_rmv_server_hostname, store_serv_serial_number):
        LOG.info("update_remote_rmcv_server Inside manager Layer:Enter")
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        # Get StoreServ by serial number
        storage_system_details = rmc_wrapper_service.is_array_registered(store_serv_serial_number)
        if storage_system_details['registered'] == 'True':
            storage_system_detail = storage_system_details['response_data']
            storserv = {}
            storserv['ipHostname'] = storage_system_detail.get('ipHostname', '')
            storserv['username'] = storage_system_detail.get('username', '')
            storserv['password'] = rmv_utils.decrypt_rmc(storage_system_detail.get('password', ''))
            # Update storeServ details to remote_rmv_server
            try:
                rmc_wrapper_service.update_remote_server_storeserv_details(context, remote_rmv_server_hostname,
                                                                           storserv)
                msg = "The StoreServ configuration of '" + storserv[
                    'ipHostname'] + "' is imported successfully on remote RMC server '" + remote_rmv_server_hostname + "'."
                self.update_vcenter_task_import(msg, "success")
            except Exception as e:
                LOG.exception(e)
                if remote_rmv_server_hostname is None:
                    remote_rmv_server_hostname = ""
                msg = "The StoreServ configuration of '" + storserv[
                    'ipHostname'] + "' failed to import on remote RMC server '" + remote_rmv_server_hostname + "'. Reason:"
                failure_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
                LOG.error(msg + failure_msg)
                self.update_vcenter_task_import(msg + failure_msg, "error")
        else:
            msg = "The StoreServ '" + store_serv_serial_number + "' is not registered. Unable to import on remote RMC server '" + remote_rmv_server_hostname + "'."
            LOG.error(msg)
        LOG.info("update_remote_rmcv_server Inside manager Layer:Exit")

    def check_create_recovery_set(self, context, x_auth_token, rmc_host_list_input):
        response = ""
        uuid_to_moref_mapping = {}
        try:
            rmc_host = "127.0.0.1"
            for rmc_host_name_ip in rmc_host_list_input:
                rmc_host = rmc_host_name_ip
            snapshots_detail = rmv_utils.get_snapshot_id_client_data_from_sqlite_db()
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            recovery_set_id_map = {}
            recovery_set_creation_tried_map = {}
            for snapshot_detail in snapshots_detail:
                kwargs = {}
                snapshot_set = {}
                kwargs['snapshot_id'] = snapshot_detail[0]
                kwargs['groupd_id'] = snapshot_detail[1]
                kwargs['creation_time'] = snapshot_detail[3]
                kwargs['client_data'] = snapshot_detail[4]

                kwargs['snap_info'] = rmv_utils.get_snapshot_info_by_client_data(kwargs['snapshot_id'],
                                                                                 kwargs['client_data'])
                snapshot_set['client_data'] = jsonutils.dumps(kwargs['snap_info'].__dict__)
                snapshot_set['mo_ref'] = kwargs['snap_info'].ObjectRefID
                snapshot_set['VmWareObjectName'] = kwargs['snap_info'].VmWareObjectName
                snapshot_set['recovery_set_id'] = None
                snapshot_set['recoverySetId'] = None

                snapshot_set['recoveryset_policy'] = rmv_utils.get_snapshot_id_policy_client_data_from_sqlite_db(
                    kwargs['groupd_id'])
                snapshot_set['clientData'] = jsonutils.loads(snapshot_set['client_data'])
                try:
                    if snapshot_set.get('remoteCopyKeyName', None) is None:  # Local snapshot
                        snapshot_db = self.db.get_record_based_on_mo_ref(context,
                                                                         snapshot_set['clientData']['ObjectRefID'])
                        snapshot_set['recoverySetId'] = snapshot_db['recoverysetid']
                    else:
                        snapshot_db = self.db.get_rc_record_by_key(context, snapshot_set['remoteCopyKeyName'])
                        snapshot_set['recoverySetId'] = snapshot_db['recoveryset_id']
                        snapshot_set['remoteEnabled'] = True
                except Exception as e:
                    # This exception must be ignored.
                    LOG.debug("recovery set id record not found in rmc-v db")

                if snapshot_set.get('remoteCopyKeyName', None) is None:  # Local snapshot
                    if uuid_to_moref_mapping.get(snapshot_set['clientData']['ObjectUUID'], None) is None:
                        try:
                            if recovery_set_creation_tried_map.get(snapshot_set['VmWareObjectName'], False) is False:
                                recovery_set_creation_tried_map[snapshot_set['VmWareObjectName']] = True
                                snapshot_set['recoverySetId'] = rmc_wrapper_service._get_recovery_set_id(context,
                                                                                                         snapshot_set[
                                                                                                             'clientData'],
                                                                                                         kwargs[
                                                                                                             'snapshot_id'],
                                                                                                         snapshot_set[
                                                                                                             'recoverySetId'],
                                                                                                         snapshot_set[
                                                                                                             'recoveryset_policy'])
                        except Exception as e:
                            # Don't stop here. Move to next item migration.
                            rmv_utils.write_in_migration_log_file(migration_log_path,
                                                                  "  The recovery set creation failed for '" +
                                                                  snapshot_set['VmWareObjectName'] + "'. Reason: " + (
                                                                      _("%s") % e.msg if hasattr(e, 'msg') else str(e)))
                            pass
                # Generate UUID to Moref mapping
                if snapshot_set.get('recoverySetId', None) is not None:
                    if uuid_to_moref_mapping.get(snapshot_set['clientData']['ObjectUUID'], None) is None:
                        rmv_utils.write_in_migration_log_file(migration_log_path,
                                                              "  The recovery set is created or available for '" +
                                                              snapshot_set['VmWareObjectName'] + "'.")
                        uuid_info = {}
                        uuid_info['moref'] = snapshot_set['clientData']['ObjectRefID']
                        uuid_info['obj_type'] = snapshot_set['clientData']['VmWareObjectType']
                        uuid_info['host_ip'] = rmc_host
                        uuid_info['vcenter_instance_id'] = snapshot_set['clientData']['VirtualCenterInstanceId']
                        uuid_to_moref_mapping[snapshot_set['clientData']['ObjectUUID']] = uuid_info

        except Exception as e:
            pass
        return uuid_to_moref_mapping

    def config_options_update(self, context, conf_options):
        LOG.info("update_config_options : enter")
        try:
            rmv_config_path = FLAGS.rmv_config_path
            conf_file = rmv_utils.parse_conf_file(rmv_config_path)
            # conf_options contains all the paramaters
            for key, value in conf_options.iteritems():
                try:
                    # Override the default value of parameter. Updated values get reflected immediately.
                    FLAGS.set_override(key, value)

                    # Update /etc/rmv/rmv.conf file. Updated value will get reflected on restarting services.
                    # If Key not available in rmv.conf file then it will add a new entry.
                    conf_file.set('DEFAULT', key, value)

                    LOG.info(("Config Parameters '%s' : '%s', successfully updated.") % (key, value))

                except Exception as e:
                    msg = ("Exception while setting the default value for '%s'. Invalid key/value pair. '%s'") % (
                    key, e)
                    LOG.error(msg)
                    raise rmv_exception.UpdateConfigException(error=msg)

            rmv_utils.write_conf_changes(conf_file, rmv_config_path)

        except (Exception,
                rmv_exception.UpdateConfigException) as e:
            LOG.error("Exception in Update Config options.")
            LOG.exception(e)
            raise e

        LOG.info("update_config_options : exit")
        # If no exceptions, return True after successfully updating all the parameters.
        return True

    def update_ssl_conf(self, context, enable_tls):
        try:
            LOG.info("update_ssl_conf  : enter")
            resp = os.system("service httpd restart")
            LOG.info("resp:%s ", resp)
            if resp == 0:
                LOG.info("Successfully restarted httpd service")
            else:
                LOG.info("Failed to restart httpd service")
        except Exception as e:
            LOG.exception(e)

    def create_copy_from_backup(self, context, backup_id, copy_name, copy_description, copy_policy_id, x_auth_token,
                                task_id, mo_ref, vm_task_helper, vmware_object_type, protectionPolicyId=None,
                                starting_rate=25):

        LOG.debug(_("create_copy_from_backup: Enter"))
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        # Call the RMC API to do catalyst copy
        try:
            task_desc_string = "Initiating Catalyst Copy"
            task_state = "Running"
            task_percentage = starting_rate
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper)

            response_data = rmc_wrapper_service.create_copy(backup_id, copy_name, copy_description, copy_policy_id,
                                                            protectionPolicyId, task_id=task_id)
            LOG.debug(_("create_copy_from_backup: The response_data is %s") % response_data)

            # Read the response from RMC task-id and update to backup-task-id in RMV.
            # Looping inside this function, returns only after catalyst copy job is completed successfully/errored out.
            # extract the task if from the response_data
            rmc_copy_taskid = response_data['taskUri'].split('/')[-1]
            # starting_rate = 25
            copy_job_response = self.update_backup_task(rmc_wrapper_service, True, task_id, vm_task_helper,
                                                        rmc_copy_taskid,
                                                        task_id, starting_rate, mo_ref, vmware_object_type)
            LOG.debug(_('create_copy_from_backup: The Catalyst Copy job response is %s') % copy_job_response)

            # now update the task to backup tasks and also VMware Tasks
            copy_task = copy_job_response.get('task', None)
            task_state = copy_task.get('taskState', None)
            completed_percentage = copy_task.get('completedPercentage', None)
            if task_state == 'Aborted':
                task_desc_string = "This task has been aborted by user."
                task_status = "Error"
                task_desc_string = task_desc_string + self.getLatestProgressMsg(copy_job_response.get('task'))
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            elif task_state == 'Error' or task_state == 'Failed':
                task_desc_string = "HPE StoreOnce Catalyst Copy is failed. Reason "
                task_desc_string = self.get_error_details(copy_job_response, task_desc_string)
                # # Get detailed error detail from task-tree GET output of copy job.
                # response_error_datas = rmc_wrapper_service.get_backup_task_status(rmc_copy_taskid)
                # tasks = response_error_datas['task']['subTasks']['tasks']
                # for response_error_data in tasks :
                #     temp_msg = response_error_data['taskStatus']
                #     childTaskState = response_error_data['taskState']
                #     #Removing the repeated messages getting appended to task description
                #     if temp_msg not in task_desc_string and childTaskState == 'Error' or childTaskState == 'Aborted' or childTaskState == 'Failed':
                #         task_desc_string = task_desc_string + self.getLatestProgressMsg(response_error_datas.get('task'))
                task_status = "Error"
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
            else:
                task_desc_string = "HPE StoreOnce Catalyst Copy is completed successfully."
                task_state = 'Completed'
                task_status = "Ok"
                self._update_task(task_desc_string,
                                  completed_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
        except (rmv_exception.TaskError,
                rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.RMCFieldNotFoundException,
                Exception
                ) as e:
            LOG.exception(e)
            err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            LOG.error(_('create_copy_from_backup exception: %s') % (err_args_msg))
            task_desc_string = "HPE StoreOnce Catalyst Copy is failed. Reason: " + err_args_msg
            task_percentage = 25
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
        LOG.info(_("create_copy_from_backup: Exit"))
        return

    def create_normal_copy(self, context, snapshot_id, x_auth_token, task_id, request_body):
        LOG.debug(("create_normal_copy : Enter"))
        catalystCopySet = request_body.get('catalystCopySet', None)
        LOG.debug(("create_normal_copy request_body catalystCopySet %s ") % catalystCopySet)
        notification_kwargs = {}
        copy_name = ''
        # Create the rmc-wrapper to use to make the RMC Calls
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        vmware_object_details_from_backup = None
        # get the snapshot details.
        try:
            backupset_response = self.get_backup_for_backupId(context, snapshot_id, x_auth_token)
            LOG.debug(("create_normal_copy backupset_response %s ") % backupset_response)
            backup_set = backupset_response.get('backupSet', None)
            vmware_object_details_from_backup = backup_set.get('appMetadata', None)
            snapshot_id_in_rmc = backup_set.get('snapshotSetId', None)
            LOG.debug(("create_normal_copy snapshot_id_in_rmc %s ") % snapshot_id_in_rmc)

            # commented below code to avoid  dependency of parent snapshot.
            # mo_ref,VmWareObjectType and recoverySetId values are available in existing backup
            # snap_response = rmc_wrapper_service.get_rmc_snapshot(snapshot_id_in_rmc, x_auth_token)
            # LOG.debug(("create_normal_copy snap_response %s ")%snap_response)
            # if not snap_response:
            #     LOG.exception(_('Could not get the snapshot information'))
            #     raise rmv_exception.InvalidSnapshot
            # LOG.debug(("create_normal_copy fetched the details of VM from the snapshot"))
            # fetch the details of VM from the snapshot
            # details_from_snapshot = snap_response.get('snapshotSet', None)
            # vm_details_from_snapshot = jsonutils.loads(details_from_snapshot.get('clientData', None))
            # LOG.debug(("create_normal_copy fetched the details of VM from
            # the snapshot  %s ") % vm_details_from_snapshot)
            # get the moref, vmware-objectType

            mo_ref = vmware_object_details_from_backup.get('ObjectRefID', None)
            vmware_object_type = vmware_object_details_from_backup.get('VmWareObjectType', None)
            notification_kwargs['vmwObjType'] = vmware_object_type

            # Create the vmware task
            vm_task_helper = VmTaskHelper(self.vi_helper)
            vm_task_helper.CustomVMwareTaskBegin(vmware_object_type,
                                                 mo_ref,
                                                 "CreateVMCopyTask",
                                                 "CreateVMCopyFailedFault")

            task_desc_string = 'Catalyst Copy In Progress'
            task_state = 'Running'
            task_percentage = 5
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Add event to the Vm
            msg = "Fetched Vm-Ware Object information from Snapshot"
            self.vi_helper.LogEvent(mo_ref, vmware_object_type, msg)
            catalyst_copy_set = request_body.get('catalystCopySet', None)
            copy_name = catalyst_copy_set.get('copyName', None)
            if not copy_name:
                timestamp_in_utc_time = backup_set.get('createdAt', None)
                LOG.debug("create_normal_copy BackupSet timestamp: '%s'" % timestamp_in_utc_time)
                timestamp_in_local_time = rmv_utils.convert_utc_to_local_format(timestamp_in_utc_time)
                LOG.debug(
                    "create_normal_copy BackupSet timestamp converted to local time: '%s'" % timestamp_in_local_time)
                copy_name = timestamp_in_local_time

            copy_description = catalyst_copy_set.get('copyDescription', None)

            copy_policy_id = catalyst_copy_set.get('copyPolicyId', None)
            protectionPolicyId = catalyst_copy_set.get("protectionPolicyId", None)
            if protectionPolicyId:
                LOG.info("creating Catalyst Copy using protection policy id ")
            else:
                # if protectionPolicyId is empty then validate the copy_policy_id
                if not copy_policy_id:
                    msg = (_("exception in getting copyPolicyId "))
                    LOG.error(_(msg))
                    LOG.exception("Exception: %s", msg)
                    raise exception.RMCCopyPolicyError()

            task_desc_string = 'Catalyst Copy In Progress'
            task_state = 'Running'
            task_percentage = 5
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            LOG.debug(("create_copy_from_backup calling create_copy_from_backup"))
            self.create_copy_from_backup(context, snapshot_id, copy_name, copy_description, copy_policy_id,
                                         x_auth_token, task_id, mo_ref, vm_task_helper, vmware_object_type,
                                         protectionPolicyId=protectionPolicyId)
            LOG.debug(("create_copy_from_backup calling create_copy_from_backup returned"))
        except (rmv_exception.TaskError,
                rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.RMCFieldNotFoundException,
                rmv_exception.RMCCopyPolicyError,
                Exception
                ) as e:
            err_args_msg = (_("%s") % e.get_description() if hasattr(e, 'get_description') else str(e))
            LOG.error(_('create_normal_copy exception: %s') % (err_args_msg))
            LOG.exception("Exception: %s", err_args_msg)
            task_desc_string = err_args_msg
            task_percentage = 25
            task_state = 'Failed'
            task_status = "Error"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            # Associating the vCenter Task with User Logged Event.
            vm_task_helper.post_general_user_event(task_desc_string)

            vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
        except(rmv_exception.InvalidSnapshot) as e:
            msg = "Catalyst Copy Failed. Could not Fetch Snapshot Information."
            LOG.exception(msg)
        finally:
            try:
                notification_kwargs['Copy Name'] = copy_name
                notification_kwargs['rmcvTaskId'] = task_id

                clientData = vmware_object_details_from_backup
                if clientData:
                    notification_kwargs['vmwObjName'] = clientData.get('VmWareObjectName', None)
                    notification_kwargs['vmwObjType'] = clientData.get('VmWareObjectType', None)
                    notification_kwargs[clientData.get('VmWareObjectType', None)] = clientData.get('VmWareObjectName',
                                                                                                   None)
            except Exception:
                LOG.exception('skipping..')
            notification = nu.GenericNotification(backup_set.get('recoverySetId'),
                                                  rmc_wrapper_service, 'createCatalystCopy',
                                                  'createExpressProtect', notificationParams=notification_kwargs)
            notification.start()

        LOG.debug(("create_normal_copy : Exit"))
        return

    '''def notify_app(self,context,resource_type,resource_info):

        LOG.info("notify_app: Enter")
        object_type = "Folder"
        mo_ref = "group-d1"
        msg = None
        lst_count = 0
        enable_notify_app = FLAGS.enable_notify_app
        if enable_notify_app:
            if not self.vi_helper:
                self.initialize_vi_helper_object()
            if resource_type == "snapshot":
                if resource_info:
                    for x in resource_info:
                        lst_count += 1
                        if((lst_count) > 10 & (lst_count % 10 == 0)):
                            msg = "Following Snapshot are expired :" + str(x.get("name"))
                            self.vi_helper.LogEvent(mo_ref,object_type,msg)
            elif resource_type == "backup":
                if resource_info:
                    lst_count += 1
                    for x in resource_info:
                        LOG.info("Expirable Backup Name: %s",str(x.get("name")))
                        if((lst_count) > 10 & (lst_count % 10 == 0)):
                            msg = "Following Backups are expired :" + str(x.get("name"))
                            self.vi_helper.LogEvent(mo_ref,object_type,msg)
        else:
            LOG.info("Notify app is disabled")
        LOG.info("notify_app: Exit")'''

    def initialize_vi_helper_object(self):
        if not self.vi_helper:
            LOG.info("Creating vCenter Session...")
            ip_hostname, username, password, vcenteruid = self.get_vcenter_credentials()
            if ip_hostname and username:
                try:
                    self.vi_helper = ViHelper(ip_hostname, username,
                                              password, vcenteruid, self.topic)
                except Exception as e:
                    err_msg = 'Error.. vCenter object not initialized'
                    LOG.exception(e)
                    if hasattr(e, "msg"):
                        err_msg = e.msg
                    elif hasattr(e, "message"):
                        err_msg = e.message
                    LOG.error("%s", err_msg)

    def getLatestProgressMsg(self, task):
        """
        find latest msg in task progress.
        :param task:
        :return:
        """
        msg = None
        taskPrgs = task.get('taskProgress')
        if taskPrgs is None or len(taskPrgs) < 1:
            return msg
        lastPrg = taskPrgs[len(taskPrgs) - 1]
        msg = lastPrg.get('message')
        return msg

    def get_rmv_usage_data(self, context, x_auth_token, snapshots):
        rmvinfo = {}
        vcenter_info = {}
        complete_snapshot_info = {}
        copies_list = []
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            # Method intializes vi_helper if it not present.
            self.initialize_vi_helper_object()

            if self.vi_helper:
                LOG.debug("get_rmv_usage_data: get_rmv_usage_data: getting vcenter info")
                # vcenter info
                vc_info = {}
                vc_info["linkedmode"] = self.vi_helper.is_vcenter_linked_mode()
                vc_info["vendor"] = self.vi_helper._session.vim.get_service_content().about.vendor
                vc_info["version"] = self.vi_helper._session.vim.get_service_content().about.version
                vc_info["osType"] = self.vi_helper._session.vim.get_service_content().about.osType
                vcenter_info[self.vi_helper.vcenteruid] = vc_info

                # Get all host information
                hostmorefs = self.vi_helper.pyvmomi_wrapper_obj.get_all_mo_moref_in_vcenter("HostSystem")
                for hostmoref in hostmorefs:
                    key = hostmoref._moId + "_" + self.vi_helper.vcenteruid
                    info_obj = self.vi_helper.get_info_for_rsvs(hostmoref._moId, "HostSystem")
                    ds_list = info_obj.get('datastores')
                    vm_list = info_obj.get('vms')
                    for ds in ds_list:
                        workflow_response = rmc_wrapper_service.get_workflow_by_app_resource_id(
                            rmv_utils.VMWARE_OBJECT_TYPE_DS, ds.get('moref_id'))
                        workflow_list = []
                        workflows = workflow_response.get('workflows')
                        for workflow in workflows:
                            workflow_dict = {}
                            workflow_dict['policyName'] = workflow.get('policyName')
                            workflow_dict['state'] = workflow.get('state')
                            workflow_dict['policyId'] = workflow.get('policyId')
                            workflow_dict['policyType'] = workflow.get('policyType')
                            workflow_dict['once'] = workflow.get('once')
                            workflow_list.append(workflow_dict)

                        ds['workFlows'] = workflow_list

                    for vm in vm_list:
                        workflow_response = rmc_wrapper_service.get_workflow_by_app_resource_id(
                            rmv_utils.VMWARE_OBJECT_TYPE_VM, vm.get('moref_id'))
                        workflow_list = []
                        workflows = workflow_response.get('workflows')
                        for workflow in workflows:
                            workflow_dict = {}
                            workflow_dict['policyName'] = workflow.get('policyName')
                            workflow_dict['state'] = workflow.get('state')
                            workflow_dict['policyId'] = workflow.get('policyId')
                            workflow_dict['policyType'] = workflow.get('policyType')
                            workflow_dict['once'] = workflow.get('once')
                            workflow_list.append(workflow_dict)

                        vm['workFlows'] = workflow_list

                    complete_snapshot_info[key] = info_obj

                copies_list = []

                copies = self.db_base.db.get_all_rmcv_copies(context)
                for copy_info in copies:
                    copies_list.append(self.transform_rmv_copy_details(context, copy_info))

                # TODO : remove later
                """snapshot_data = {}
                # Iterate through snapshots and find unique object refs
                for snapshot in snapshots:
                    if snapshot["clientData"]:
                        dict_client_data = jsonutils.loads(snapshot["clientData"])
                        LOG.debug("Snapshot data is %s", dict_client_data)
                        if dict_client_data['VirtualCenterInstanceId'] \
                                and dict_client_data['ObjectRefID'] \
                                and self.vi_helper:
                            snap_key = dict_client_data['ObjectRefID'] + "_" + dict_client_data[
                                'VirtualCenterInstanceId']
                            snap_info = {}
                            snap_info['ObjectRefID'] = dict_client_data['ObjectRefID']
                            snap_info['VmWareObjectType'] = dict_client_data['VmWareObjectType']
                            snap_info['VirtualCenterInstanceId'] = dict_client_data['VirtualCenterInstanceId']
                            snapshot_data[snap_key] = snap_info

                # Fetch information about each object ref
                if snapshot_data.__len__ > 0:
                    for key, snapshot in snapshot_data.items():
                        LOG.debug("Fetching %s of type %s with in %s", snapshot['ObjectRefID'],
                                  snapshot['VmWareObjectType'], snapshot['VirtualCenterInstanceId'])
                        info_obj = self.vi_helper.get_info_for_rsvs(snapshot['ObjectRefID'],
                                                                snapshot['VmWareObjectType'])
                        complete_snapshot_info[key] = info_obj"""

                if (complete_snapshot_info.__len__() == 0):
                    LOG.info("get_rmv_usage_data: Failed to get rmv information from snapshot")

            else:
                LOG.debug("get_rmv_usage_data: Failed to get vcenter information")

        except Exception as e:
            LOG.exception("get_rmv_usage_data: Failed to get the registered vCenter information %s" % e)

        finally:
            rmvinfo["vcenter"] = vcenter_info
            # retaining the snapshot tag for compatability with olser versions we can remove it later
            rmvinfo["snapshot"] = {}
            rmvinfo["resources"] = complete_snapshot_info
            rmvinfo["copies"] = copies_list
            response = {}
            response["rmv-usage-data"] = rmvinfo
            LOG.debug("get_rmv_usage_data: Called to get all VMware info - Exit")
            return response

    def transform_rmv_copy_details(self, context, copy_info):

        return_dict = {}
        try:
            copy_id = copy_info.id
            return_dict['id'] = copy_info.id
            return_dict['name'] = copy_info.name
            return_dict['state'] = copy_info.status
            # return_dict['objectRefID'] = copy_info.moref
            # return_dict['objectUUID'] = copy_info.vmware_uuid
            # return_dict['vmfsSnapMoref'] = copy_info.vmfs_snap_moref
            return_dict['expiry'] = copy_info.expiry
            # return_dict['isAppConsistent'] = copy_info.is_app_consistent
            return_dict['arrayName'] = copy_info.array_name
            return_dict['copyType'] = copy_info.type
            return_dict['copySetId'] = copy_info.rmc_copyset_id
            return_dict['arraySerialNumber'] = copy_info.array_serial_number
            return_dict['retention'] = copy_info.retention
            return_dict['pointInTime'] = copy_info.point_in_time
            # return_dict['volumeType'] = copy_info.volume_type
            return_dict['createdAt'] = copy_info.created_at
            return_dict['storeName'] = copy_info.store_name
            return_dict['backupSystemName'] = copy_info.backup_system_name
            return_dict['copyPolicyId'] = copy_info.copy_policy_id
            return_dict['verified'] = copy_info.verified
            return_dict['maxSnapshotCount '] = copy_info.vmfs_snap_count

            datastores_from_db = self.db.get_datastores_by_copy_id(context, copy_id)
            vms_from_db = self.db.get_vms_by_copy_id(context, copy_id)

            vm_id_obj_map = {}
            for row in vms_from_db:
                vm_id_obj_map[row.vm_id] = row

            datastores_list = []

            if datastores_from_db:
                for row in datastores_from_db:
                    datastore_ret = self.transform_datastore_props(row)

                    if row.vmdks:
                        vmdk_list = []
                        vmdks = json.loads(row.vmdks)
                        if vmdks:
                            for vmdk in vmdks:

                                vmdk_from_db = None
                                try:
                                    vmdk_from_db = self.db.get_vmdk_by_id(context, vmdk['vmdk_id'])
                                except Exception as e:
                                    msg = ("Failed to get rmcv VMDK from DB by ID:" + vmdk['vmdk_id'])
                                    LOG.error(msg)

                                if vmdk_from_db:
                                    # We should not list the RDM Disks in GUI
                                    if vmdk_from_db.type != "rdm":
                                        vmdk_response = {'type': vmdk_from_db.type, 'fileName': vmdk_from_db.path,
                                                         'rdmType': vmdk_from_db.rdm_type, 'id': vmdk_from_db.id}

                                        if vmdk['vm_id'] and vm_id_obj_map.get(vmdk['vm_id']):
                                            vmdk_response['vm_id'] = vm_id_obj_map[vmdk['vm_id']].vm_id
                                            vmdk_response['vm_name'] = vm_id_obj_map[vmdk['vm_id']].vm_name
                                            vmdk_response['vm_moref'] = vm_id_obj_map[vmdk['vm_id']].moref
                                        vmdk_list.append(vmdk_response)

                            datastore_ret['vmdks'] = vmdk_list
                    datastores_list.append(datastore_ret)

            return_dict['restorableItems'] = datastores_list

        except Exception as e:
            err_args_msg = (_("%s") % e.msg if hasattr(e, 'msg') else str(e))
            LOG.error(err_args_msg)
            exception_msg = ("Failed to get copy details for id: " + copy_id + ". Check the Id and retry.")
            raise Exception(exception_msg)

        return return_dict

    def transform_datastore_props(self, datastore):
        copy_response = {}
        """"Transforms the DB response into the GET JSON response"""
        copy_response['id'] = datastore.ds_id
        copy_response['name'] = datastore.ds_name
        copy_response['objectRefID'] = datastore.moref
        copy_response['objectUUID'] = datastore.vmware_uuid
        copy_response['recoverySetId'] = datastore.recovery_set_id
        copy_response['volumeType'] = datastore.volume_type
        copy_response['vmwareObjectType'] = rmv_utils.VMWARE_OBJECT_TYPE_DS
        # copy_response['vCenterUrl'] =
        # copy_response['vmType'] =
        copy_response['vCenterInstanceId'] = datastore.vcenter_uuid

        # datacenter_name
        # host_name
        # folder_name
        # recovery_set_id
        return copy_response

    def get_error_details(self, response_data, task_error_details):
        subtask_count = 0
        error_count = 1
        if response_data.get('task', None):
            if response_data.get('task').get('subTasks', None) and response_data.get('task').get('subTasks').get(
                    'count') > 0:
                tasks = response_data.get('task').get('subTasks').get('tasks')
                if (len(tasks) > 0):
                    subtask_count = response_data.get('task').get('subTasks').get('count')
                    for index in range(subtask_count):
                        taskState = tasks[index].get('taskState')
                        if taskState == 'Failed' or taskState == 'Error' or taskState == 'Aborted':
                            task_errors = tasks[index].get('taskErrors')
                            for i in range(len(task_errors)):
                                error_details = task_errors[i].get('errorDetails')
                                error_message = task_errors[i].get('errorMessage')
                                if not task_error_details:
                                    task_error_details = str(error_count) + ":  " + str(
                                        error_message) + " Details: " + str(error_details) + "\n"
                                else:
                                    task_error_details = task_error_details + str(error_count) + ":  " + str(
                                        error_message) + " Details: " + str(error_details) + "\n"
                                error_count += 1
            else:
                if response_data['task'].get('taskErrors', None):
                    error_Detail = ''
                    error_Message = ''
                    if response_data['task']['taskErrors'][0].get('errorDetails', None):
                        if len(response_data['task']['taskErrors'][0]['errorDetails']) > 0:
                            error_Detail = response_data['task']['taskErrors'][0]['errorDetails']
                    if response_data['task']['taskErrors'][0].get('errorMessage', None):
                        if len(response_data['task']['taskErrors'][0]['errorMessage']) > 0:
                            error_Message = response_data['task']['taskErrors'][0]['errorMessage']
                    task_error_details = task_error_details + error_Message + \
                                         " Details: " + error_Detail
        LOG.debug(" response_data :%s task_error_details:%s", response_data,
                  task_error_details)
        return task_error_details

    def check_datastore_accessible_state(self, object_ref_id, vm_ware_object_type):

        LOG.info("check datastore accessible state : Enter")

        obj_content = None
        ds_access_state = False
        moref_obj = pyvmomi_util.get_moref(object_ref_id, vm_ware_object_type)

        try:
            obj_content = self.vi_helper.get_object_properties(moref_obj, "summary")

        except rmv_exception.PyVmomiException as e:
            LOG.exception(e)
            ds_access_state = False
        except Exception as e:
            LOG.exception(e)

        if obj_content:
            summary_obj_content = vim_util.extract_properties(obj_content[0])
            summury = summary_obj_content.get("summary", None)
            if summury:
                ds_access_state = summury.accessible
        LOG.info("check datastore accessible state : End")
        return ds_access_state

    def get_host_moref_from_hostname_or_ip(self, esxHostAddr):

        LOG.info("get host moref : Enter")
        is_host_ip = rmv_utils.is_IP(esxHostAddr)
        if is_host_ip:
            is_host_fqdn = False
        else:
            is_host_fqdn = True

        host_obj = self.vi_helper.get_host_moref_by_name_or_ip(esxHostAddr, is_host_fqdn)

        LOG.info("get host moref : End")
        return host_obj._moId

    def get_vmware_object_name_based_on_moref(self, context, mo_ref, obj_type):

        LOG.info("get_vmware_object_name_based_on_moref :Enter")
        vmware_obj_name = None
        try:
            if not self.vi_helper:
                self.vi_helper = ViHelper()

            if self.vi_helper:
                moref = pyvmomi_util.get_moref(mo_ref, obj_type)
                object_content = self.vi_helper.get_object_properties(moref, "name")
                prop = pyvmomi_util.extract_properties(object_content[0])
                vmware_obj_name = prop.get('name')
            else:
                LOG.info("vi_helper is not initialized failed to fetch the "
                         "object properties")

        except Exception as e:
            LOG.exception(e)

        LOG.info("get_vmware_object_name_based_on_moref :End")
        return vmware_obj_name

    def get_schedule_jobs(self, context, x_auth_token):
        '''
        To get the list of RMC-V schedule jobs from RMC
        '''
        LOG.info("get_schedule_jobs : enter")

        schedule_jobs = {}
        schedule_jobs_updated = {}
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        try:
            # RMC call to get the list of Schedule Jobs
            schedule_jobs = rmc_wrapper_service.get_rmcv_schedule_jobs()

        except Exception as e:
            LOG.exception("Unable to retrieve Schedule Jobs details. %s " % e)
            raise e

        try:
            # Backup System name is required in Scheduler jobs response. So retrieve and update.
            backup_system_dict = {}
            backup_details_dict = {}
            backup_policies_response = rmc_wrapper_service.get_backup_policies()
            backup_policies = backup_policies_response.get('backupPolicies')
            for backup_policy in backup_policies:
                backup_system_id = backup_policy.get('backupSystemId')
                backup_policy_id = backup_policy.get('id')

                backup_system = backup_system_dict.get(backup_system_id)
                if not backup_system:
                    backup_system = rmc_wrapper_service.get_backup_system_name_from_id(context, backup_system_id,
                                                                                       x_auth_token)
                    backup_system_dict[backup_system_id] = backup_system

                bckup_system = backup_system.get('backupSystem')

                backup_policy_dict = {}
                backup_policy_dict['backupSystemName'] = bckup_system.get('name')
                backup_policy_dict['storeName'] = backup_policy.get('storeName')

                backup_details_dict[backup_policy_id] = backup_policy_dict

                # backup_policy.get('backupPolicy')['backupSystemName'] = backup_system.get('name')

            cc_bkp_id_dict = {}
            cc_policies_response = rmc_wrapper_service.get_catalyst_copy_policies()
            cc_policies = cc_policies_response.get("catalystCopyPolicies")
            for cc_policy in cc_policies:
                cc_policy_id = cc_policy.get("id")
                cc_bkp_policy_id = cc_policy.get("backupPolicyList")[0]
                cc_bkp_id_dict[cc_policy_id] = cc_bkp_policy_id

            # Save schedule jobs in pyVmomi wrapper and update required info the same response.
            schedule_jobs_updated = self.vi_helper.update_vm_backup_info_in_schedule_jobs(schedule_jobs,
                                                                                          backup_details_dict,
                                                                                          cc_bkp_id_dict)

            if schedule_jobs_updated:
                schedule_jobs = schedule_jobs_updated

            # TODO:6.0 As old Schedule Job get call is changed in RMC, commenting this code. Need to rewrite with workflow changes
            # # Save the protection info and use the same in Scheduler Add screen response.
            # self.save_protection_info(x_auth_token, schedule_jobs)

        except Exception as e:
            LOG.exception("Unable to retrieve Schedule Jobs details. %s " % e)

        LOG.info("get_schedule_jobs : exit")
        return schedule_jobs

    # def get_vmware_objects(self,
    #                        context = None,
    #                        x_auth_token = None,
    #                        page = None,
    #                        count = None,
    #                        refresh = None,
    #                        op_type = None,
    #                        query_params = None):
    #
    #     LOG.info("get_vmware_objects : enter")
    #
    #     vmware_objects = vi_objects.vmware_objects()
    #     # On click of refresh in GUI, invalidate all the temporarily stored variables
    #     # so that any newly added VMWare objects are fetched again.
    #     if refresh:
    #         self.vmware_objects_cache = vi_objects.vmware_objects_cache()
    #
    #     else:
    #         # TODO:6.0 As old Schedule Job get call is changed in RMC, commenting this code. Need to rewrite with workflow changes
    #         # protection_info is saved in Get all Scheduler REST call. If in case not there then retrieve again.
    #         # if not self.vmware_objects_cache.protection_info_dict:
    #         #     self.save_protection_info(x_auth_token)
    #
    #         vmware_objects_class = vmware_obj(self.vi_helper, self.vmware_objects_cache)
    #
    #         vmware_objects = vmware_objects_class.get_vmware_objects(page,
    #                                                                  count,
    #                                                                  op_type,
    #                                                                  query_params)
    #
    #     ret = rmv_utils.convert_object_to_dict_recursively(vmware_objects)
    #     LOG.info("get_vmware_objects : exit")
    #     return ret

    def get_vmware_objects(self,
                           context=None,
                           x_auth_token=None,
                           page=None,
                           count=None,
                           refresh=None,
                           op_type=None,
                           query_params=None):

        LOG.info("get_vmware_objects : enter")

        vmware_objects = self.vmware_objects_class.get_vmware_objects(context,
                                                                      page,
                                                                      count,
                                                                      op_type,
                                                                      query_params)

        ret = rmv_utils.convert_object_to_dict_recursively(vmware_objects)
        LOG.info("get_vmware_objects : exit")
        return ret

    def save_protection_info(self, x_auth_token, schedule_jobs=None):
        """
        Protection info is required in Schedule job add screen.
        So instead of fetching again, save the required properties and use it later.
        """
        LOG.info("save_protection_info : enter")

        self.get_protected_info(x_auth_token, schedule_jobs)

        LOG.info("save_protection_info : exit")

    def get_protected_info(self, x_auth_token, schedule_jobs=None):
        """
        Get all the RMC-V schedule jobs from RMC and
        find out the list of VMs and DS for which Schedule Jobs are created.
        If a Schedule Job is created then consider it as Protected.
        """
        LOG.info("get_protected_info : enter")

        try:
            if not schedule_jobs:
                # RMC call to get the list of Schedule Jobs
                rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
                schedule_jobs = rmc_wrapper_service.get_rmcv_schedule_jobs()

            schedule_job_list = schedule_jobs.get('schedules')

            # Loop to collect all the vmware objects moref which is protected.
            for job in schedule_job_list:

                try:
                    protection_info = vi_objects.protection_info()
                    protection_info_list = []
                    vmware_snapshot = {}

                    if job.get('resourceCategory') == "cache":
                        continue

                    if job.get('resourceCategory') == "backup-sets" or job.get('resourceCategory') == "one-click-copy":
                        vmware_snapshot = job.get('resourceList')[0].get('requestInput').get('backup').get(
                            'vmwareSnapshot')

                    elif job.get('resourceCategory') == "snapshots":
                        vmware_snapshot = job.get('resourceList')[0].get('requestInput').get('snapshot').get(
                            'vmwareSnapshot')

                    protection_info.job_status = job.get('state')
                    protection_info.job_name = job.get('name')

                    mo_ref = vmware_snapshot.get('vmWareMoref')
                    if mo_ref:
                        protection_info.is_protected = True
                        # If multiple schedules for a MO then update protection_info in the same list
                        if mo_ref in self.vmware_objects_cache.protection_info_dict.keys():
                            protection_info_list = self.vmware_objects_cache.protection_info_dict.get(mo_ref)

                        protection_info_list.append(protection_info)
                        self.vmware_objects_cache.protection_info_dict[mo_ref] = protection_info_list

                except Exception as e:
                    LOG.exception("Unable to get the properties of a Scheduled Job. Ignore and continue. '%s' " % e)
                    continue

        except Exception as e:
            LOG.exception("Unable to retrieve Schedule Jobs details. %s " % e)
            raise e

        LOG.info("get_protected_info : exit")

    def refresh_snapshot_or_recovery_set(self, context, rmc_wrapper_service, id, resource=None, task_id=None):
        try:
            response_data = rmc_wrapper_service.array_refresh(context, id, resource, task_id=task_id)
            if response_data:
                response_data = rmc_wrapper_service.rmc_low_level.wait_on_task(response_data)
            LOG.debug("response_data:'%s'", response_data)
        except (rmv_exception.RMCAPIError, rmv_exception.RMCAPIUnknownError, rmv_exception.TaskError, Exception) as e:
            task_desc_string = ""
            if hasattr(e, "msg"):
                task_desc_string = e.msg
            else:
                task_desc_string = "Unknown error"
            LOG.error("Storage system refresh failed for snapshot ID:'%s' Error detail:'%s'", id, task_desc_string)

    def pre_restore(self, context, ds_moref_list, mo_ref, recovery_set_id, rmc_wrapper_service, vm_task_helper,
                    ds_info, task_id, ds_moref_wwn_dict, db_ds_to_vm_dict):

        LOG.info("pre restore :Enter")

        '''
         Validate the given datastore
        '''
        mounted_host_list = []
        ds_uuid_to_moref_dict = {}

        # Update Tasks (Task Tracker and VMware Task)
        task_desc_string = 'Validating datastore(s) for restore'
        task_status = "Initiated"
        task_percentage = 10
        task_state = 'Running'
        self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)

        ds_moref_list = list(set(ds_moref_list))
        vc_ds_to_vm_dict = {}
        self.validate_virtualmachines_power_on_state_for_promote(ds_moref_list, vc_ds_to_vm_dict)
        # if any snapshot vm is moved form one DS to another DS then we will not allow restore to parent,
        # restore may lead to conflict in vm(s)
        self.validate_virtualmahines_moment_acrros_vcenter(vc_ds_to_vm_dict, db_ds_to_vm_dict)

        for mo_ref in ds_moref_list:
            scsi_luns = []
            ds_info = self.vi_helper.get_datastore_details(mo_ref, scsi_luns)
            LOG.info(("Volume WWN: '%s'"), scsi_luns[0].Wwn)
            snap_base_volume_wwn_list = ds_moref_wwn_dict.get(mo_ref, [])
            self.validate_datastore_wwn_with_snap_or_bkp_base_volume_wwn(snap_base_volume_wwn_list, scsi_luns, ds_info)
            mounted_host_list.extend(ds_info.MountedHostsList)
            if hasattr(ds_info, "VmList"):
                if len(ds_info.VmList) == 0:
                    ds_uuid_to_moref_dict[ds_info.VmfsUuid] = ds_info.DatastoreMoref
        ''' Let's refresh and get attach status of the
        volumes (this info will be used to attach post restore task)
        '''
        # resource = None
        # self.refresh_snapshot_or_recovery_set(context,rmc_wrapper_service,recovery_set_id, resource, task_id)

        # before performing 'detach', persisting the attach status of the recovery set in 'map_wwn_hostlist'
        map_wwn_hostlist = self.get_attach_status_of_recovery_set(rmc_wrapper_service, recovery_set_id)
        LOG.info(("map_wwn_hostlist: '%s'"), map_wwn_hostlist)

        # Update Tasks (Task Tracker and VMware Task)
        task_desc_string = 'Detaching volumes from the host'
        task_status = "Initiated"
        task_percentage = 30
        task_state = 'Running'
        self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service, vm_task_helper,
                          task_status=task_status)

        # if (len(map_wwn_hostlist.values()) > 0) and (len(map_wwn_hostlist.values()[0]) > 0):
        # Use RMC to detach the recovery-set
        response = rmc_wrapper_service.detach_recoveryset(recovery_set_id, True, task_id=task_id)

        # Update Tasks (Task Tracker and VMware Task)
        task_desc_string = 'Restore from snapshot in progress. Restore time depends on the volume and delta data size.'
        task_status = "Initiated"
        task_percentage = 50
        task_state = 'Running'
        self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)
        LOG.info("pre restore :Exit")
        return list(set(mounted_host_list)), ds_uuid_to_moref_dict

    def post_restore(self, context, recovery_set_id, mounted_host_list, ds_uuid_to_moref_dict, task_id,
                     rmc_wrapper_service, vm_task_helper, base_volume_list, ds_moref_list):
        LOG.info("post restore: Enter Attaching volumes back to the host")
        rescan_success = False
        # Update Tasks (Task Tracker and VMware Task)
        task_desc_string = 'Attaching Volumes back to the host'
        task_status = "Initiated"
        task_percentage = 70
        task_state = 'Running'
        self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                          vm_task_helper, task_status=task_status)

        host_name = None
        # During detach we had pass "RetainAttachInfo" therefore for attach we just pass"reply=true",
        # RMC core retains the host info required for re-attaching the detached volumes back to the same host.
        response = rmc_wrapper_service.attach_recoveryset(recovery_set_id, host_name, True, task_id=task_id)
        LOG.info("Volume attach - success")

        '''
        Perform HBA re-scan
        '''
        task_desc_string = 'Performing HBA re-scan'
        task_status = "Initiated"
        task_percentage = 90
        task_state = 'Running'
        self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service, vm_task_helper,
                          task_status=task_status)
        self.rescan_hosts_and_remove_internal_snaps(context, mounted_host_list, ds_moref_list, ds_uuid_to_moref_dict,
                                                    rmc_wrapper_service)

        LOG.info("post restore: Exit")

    def check_if_managed_object_exists(self, context, mo_ref_id, mo_type):

        return self.vi_helper.check_if_managed_object_exists(mo_ref_id, mo_type)

    def build_uuid_to_moref_mapping_dict(self, context, mo_type_list=None):
        """
        Based on mo_type_list, ie either VirtualMachine or Datastore,
        fetch its UUID and construct a mapping betwieen them
        """

        return self.vi_helper.build_uuid_to_moref_mapping_dict(mo_type_list=mo_type_list)

    def update_changed_mo_ref_in_db_and_client_data(self, context, x_auth_token=None,
                                                    snapshot_row=None,
                                                    mo_ref_in_vCenter=None,
                                                    mo_ref_in_db=None,
                                                    mo_uuid=None,
                                                    mo_type=None,
                                                    vm_uuid_to_moref_mapping_dict=None,
                                                    vm_uuid_to_name_mapping_dict=None):
        """
        After Failover/Failback, Update the changed MoRef in DB and RecoverySet Clientdata
        """

        uuid_manage_obj = uuid_manage(self.vi_helper)

        uuid_manage_obj.update_changed_mo_ref_in_db_and_client_data(context=context,
                                                                    x_auth_token=x_auth_token,
                                                                    snapshot_row=snapshot_row,
                                                                    mo_ref_in_vCenter=mo_ref_in_vCenter,
                                                                    mo_ref_in_db=mo_ref_in_db,
                                                                    mo_uuid=mo_uuid,
                                                                    mo_type=mo_type,
                                                                    vm_uuid_to_moref_mapping_dict=vm_uuid_to_moref_mapping_dict,
                                                                    vm_uuid_to_name_mapping_dict=vm_uuid_to_name_mapping_dict)

    def get_mo_uuid(self, context, mo_ref, obj_type):

        return self.vi_helper.get_mo_uuid(mo_ref, obj_type)

    def check_and_update_moref_in_snap_cd(self, context,
                                          x_auth_token=None,
                                          dict_client_data=None,
                                          snap_gui_id=None):
        """
        Update the changed MoRef in Snapshot Clientdata, if MoRef got changed after SRM Failover/Failback.
        """

        uuid_manage_obj = uuid_manage(self.vi_helper)

        updated_client_data = uuid_manage_obj.check_and_update_moref_in_snap_cd(x_auth_token=x_auth_token,
                                                                                dict_client_data=dict_client_data,
                                                                                snap_gui_id=snap_gui_id)

        return updated_client_data

    def check_and_update_moref_in_backup_app_metadata(self, context,
                                                      x_auth_token=None,
                                                      app_metadata=None,
                                                      backup_id=None):
        """
        Update the changed MoRef in Backup app_metadata, if MoRef got changed after SRM Failover/Failback.
        """

        uuid_manage_obj = uuid_manage(self.vi_helper)

        updated_app_metadata = uuid_manage_obj.check_and_update_moref_in_backup_app_metadata(x_auth_token=x_auth_token,
                                                                                             app_metadata=app_metadata,
                                                                                             backup_id=backup_id)

        return updated_app_metadata

    def validate_virtualmachines_power_on_state_for_promote(self, ds_mo_ref_list, vc_ds_to_vm_dict):

        one_or_more_vms_powered_on = False
        vm_name_list = list()
        for moref in ds_mo_ref_list:
            vm_morefs = self.vi_helper.get_vm_morefs_used_by_datastore(moref)
            # current ds and vm association in vcenter
            vc_ds_to_vm_dict[moref] = vm_morefs
            for vm_moref in vm_morefs:
                vm_power_state, vm_name = self.vi_helper.get_vm_power_state(vm_moref)
                if vm_power_state.lower() != "poweredOff".lower():
                    one_or_more_vms_powered_on = True
                    vm_name_list.append(vm_name)
        if one_or_more_vms_powered_on:
            raise rmv_exception.OneOrMoreVMSNotPoweredOffError(vm_name_list=vm_name_list)

    def validate_virtualmahines_moment_acrros_vcenter(self, vc_ds_to_vm_dict, db_ds_to_vm_dict):

        LOG.debug("validate virtualmahines moment acrros vcenter :Enter")
        if db_ds_to_vm_dict:
            for ds_moref in db_ds_to_vm_dict.keys():
                db_vm_list = db_ds_to_vm_dict.get(ds_moref)
                vc_vm_list = vc_ds_to_vm_dict.get(ds_moref)
                if vc_vm_list:
                    vc_vm_list = set(vc_vm_list)
                diff_vm_list = [vm_moref for vm_moref in db_vm_list if vm_moref not in vc_vm_list]
                ds_moref_name_dict = {}
                if diff_vm_list:
                    for vm_moref in diff_vm_list:
                        try:
                            vm_details = self.vi_helper.get_object_prop_dict_pyvmomi(vm_moref, "VirtualMachine",
                                                                                     ["name", "datastore"])
                            vm_name = vm_details.get("name")
                            datastores = vm_details.get("datastore")
                            for ds in datastores:
                                ds_moref_name_dict[ds._moId] = ds.name
                            if ds_moref not in ds_moref_name_dict:
                                msg = " VirtualMachine " + vm_name + " has been moved to another data store(s) " \
                                      + str(
                                    ds_moref_name_dict.values()) + ". Restore may lead to conflict in VM(s). Restore not allowed in this state."
                                LOG.error("Restore not allowed:%s", msg)
                                raise rmv_exception.VmMovedToDifferentDatastore(msg=msg)
                        except rmv_exception.VmMovedToDifferentDatastore as e:
                            raise e
                        except Exception as e:
                            LOG.exception(e)
        LOG.debug("validate virtualmahines moment acrros vcenter :Exit")

    def remove_internal_snapshot_on_vm_after_restore(self, ds_mo_ref_list):
        vm_name_list = list()
        for moref in ds_mo_ref_list:
            vm_morefs = self.vi_helper.get_vm_morefs_used_by_datastore(moref)
            for vm_moref in vm_morefs:
                try:
                    # This call will throw error if the vm has been deleted
                    vmInfo, hostInfo = self.get_virtual_machine_details(vm_moref)
                    # Check if VM is accessible and then proceed for delete
                    self.check_and_delete_vmfs_sapshots_vm(True, vmInfo, "VirtualMachine", vm_moref)
                except Exception as e:
                    LOG.exception(e)
                    LOG.error("Unable to remove internal snapshots on vm '%s' after restore" % vm_moref)

    def verify_backup(self, context, backup_id, request_body, x_auth_token, task_id):

        LOG.info("Verify backup : Enter")

        type_for_vcenter_logevent = "Folder"
        mo_ref_for_vcenter_logevent = "group-d1"
        if not self.vi_helper:
            self.initialize_vi_helper_object()
        vm_task_helper = VmTaskHelper(self.vi_helper)
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        backup_name = request_body.get("name", "")

        try:

            vm_task_helper.CustomVMwareTaskBegin(type_for_vcenter_logevent, mo_ref_for_vcenter_logevent,
                                                 "VerificationofBackup", "VerificationofBackupFailedFault")
            task_desc_string = 'Verification is in progress.'
            task_percentage = 5
            self._update_task(task_desc_string, task_percentage, 'Running', task_id, rmc_wrapper_service,
                              vm_task_helper)
            backup = rmc_wrapper_service.get_backup_for_backupId(context, backup_id)
            operation_type = rmv_utils.ACTION_VERIFY_BACKUP
            with rmv_locks.backup_op_lock:
                # Acquire operation lock on backup object
                self.acquire_backup_operation_lock(backup_id, operation_type)
            LOG.info("Locked Backup Object for verify operation: '%s'" % backup_id)

            if backup:
                backupSet = backup.get("backupSet")
                if backupSet and backupSet.get("status") != "available":
                    raise rmv_exception.BackupInbadState()

            resp = rmc_wrapper_service.verify_backup(backup_id, request_body, task_id, vm_task_helper)
            # updating RMCV db with verified status, here backup_id is rmc-copyset-id
            copy_obj = self.db.get_rmcv_copy_by_rmc_copyset_id(context, backup_id)
            rmc_backup = rmc_wrapper_service.get_backup_for_backupId(context, backup_id)
            copy_set = rmc_backup.get("backupSet")
            copy_obj.verified = copy_set.get('verified')
            self.db.update_rmcv_copy(context, copy_obj.id, copy_obj)

            task_percentage = 100
            task_desc_string = 'verification completed for backup: '
            task_desc_string = task_desc_string + backup_name
            task_status = "Ok"
            self._update_task(task_desc_string, task_percentage, 'Completed', task_id, rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)
            vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)

        except (rmv_exception.RMCAPIError, rmv_exception.BackupInbadState, Exception) as e:
            LOG.exception(e)
            task_desc_string = 'Verification failed for backup: '
            task_desc_string = task_desc_string + backup_name + ".  Error "
            msg = ''
            if hasattr(e, "msg"):
                LOG.error('%s', e.msg)
                msg = e.msg
            elif hasattr(e, "message"):
                LOG.error('%s', e.message)
                msg = e.message
            task_state = 'Failed'
            task_status = "Error"
            task_percentage = 100
            msg = task_desc_string + msg
            self._update_task(msg, task_percentage, task_state, task_id, rmc_wrapper_service, vm_task_helper,
                              task_status=task_status)
            vm_task_helper.CustomVMwareTaskEnd("error", msg)
        finally:
            with rmv_locks.backup_op_lock:
                # Release operation lock on backup object
                self.release_backup_operation_lock(backup_id)
                LOG.info("Lock released on Backup Object for verify operation: '%s'" % backup_id)
        LOG.info("Verify backup : Exit")

    def upgrade_rmcv(self, context, x_auth_token=None, upgrade_req_body=None, mem_cache_id=None):
        """
        RMC-V Upgrade : Check the request body and upgrade the RMC-V DB and other details as required.
        """

        moref_manage_obj = moref_manage(self.vi_helper)

        if upgrade_req_body.get('lun_wwn'):
            return moref_manage_obj.upgrade_wwn(context=context,
                                                x_auth_token=x_auth_token,
                                                mem_cache_id=mem_cache_id)

    def check_if_srm_configured_and_update_required(self, context, x_auth_token=None):
        """
        Check if SRM is configured. If yes then check for any recent recovery events.
        """

        moref_manage_obj = moref_manage(self.vi_helper)

        update_required = moref_manage_obj.check_if_srm_configured_and_update_required(x_auth_token=x_auth_token)

        return update_required

    def check_and_update_mo_ref_if_srm_configured(self, context, x_auth_token=None):
        """
        Due to SRM Failover/Failback, MoRef got changed in RMC-V. So update with new values.
        """

        moref_manage_obj = moref_manage(self.vi_helper)

        return moref_manage_obj.check_and_update_mo_ref_if_srm_configured(context=context,
                                                                          x_auth_token=x_auth_token)

    def create_vmfs_datastore(self, volumeCreationDetails, serialNumber, esxHostAddr,
                              moref, x_auth_token, task_id, vm_task_helper):

        LOG.info(('Create VMFS data store : Enter'))
        esx_host_add_format = None
        datastore_name = None
        device_path = None

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        # Create an instance of VMware Task Helper to populate vCenter Tasks

        try:
            is_host_ip = rmv_utils.is_IP(esxHostAddr)
            if is_host_ip:
                esx_host_add_format = 'esxHostIP'
            else:
                esx_host_add_format = 'esxHostName'

            volume_Names = [str(x.get("volumeName")) for x in volumeCreationDetails]
            # creating recovery set along with new volumes
            recovery_setid = self.create_recoveryset_by_newvol(serialNumber, moref,
                                                               x_auth_token, task_id, volumeCreationDetails,
                                                               vm_task_helper)
            LOG.info("Recovery set id is: '%s' ", recovery_setid)
            # exporting/attaching the created volume to host
            self.export_volume_to_host(esxHostAddr, x_auth_token, esx_host_add_format,
                                       volume_Names, recovery_setid, task_id, vm_task_helper, serialNumber)

            response_data = rmc_wrapper_service.get_recovery_set(recovery_setid)
            recovery_set_details = response_data['recoverySet']
            recoveryset_wwn = None
            if recovery_set_details:
                recoveryset_wwn = str(recovery_set_details["wwnlist"][0]).lower()
            LOG.info("recoveryset wwn is %s" % recoveryset_wwn)
            # rescan the host hba once export is successful
            self.rescan_host_hba(esxHostAddr)
            # Creating a hostdatastoresystem object to create a vmfs datastore
            host_moref = self.get_host_moref_from_hostname_or_ip(esxHostAddr)
            host_moref_obj = pyvmomi_util.get_moref(host_moref, "HostSystem")
            host_dssystem_prop_list = ["configManager.datastoreSystem"]
            host_dsinfo_dict = self.vi_helper.get_object_properties(host_moref_obj, host_dssystem_prop_list)
            host_ds_obj = pyvmomi_util.extract_properties(host_dsinfo_dict[0])
            host_dssystem_obj = host_ds_obj.get("configManager.datastoreSystem")
            rethInfo = self.vi_helper.get_host_system_and_storage_info(host_moref)
            for ScsiLun in rethInfo.ScsiLuns:
                if recoveryset_wwn.lower() in ScsiLun.devicePath.lower().strip():
                    device_path = ScsiLun.devicePath
                    break
            datastore_name = "ds_" + volume_Names[0]
            # Create a vmfs data store
            self.vi_helper.create_ds(host_dssystem_obj, device_path, datastore_name)
            LOG.info(('Data store created successfully with the name %s' % datastore_name))
            task_desc_string = 'VMFS data store is created successfully'
            task_percentage = 20
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

            return datastore_name

        except (rmv_exception.RMCAPIError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.TaskError,
                rmv_exception.EsxHostNotConfiguredException,
                rmv_exception.PyVmomiException,
                rmv_exception.vCenterMoRefError,
                rmv_exception.CreateRecoverysetWithNewVolumeException,
                rmv_exception.ExportVolumeToHostException,
                rmv_exception.RescanHostHBAException,
                Exception
                )as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Create vmfs datastore is Unsuccessful : "
            if hasattr(e, "msg"):
                task_desc_string = task_desc_string + str(e.msg)
            elif hasattr(e, "message"):
                task_desc_string = task_desc_string + str(e.message)
            else:
                task_desc_string = task_desc_string + str(e)

            # vm_task_helper.post_general_user_event(task_desc_string)
            raise rmv_exception.CreateDataStoreException(msg=task_desc_string)

        LOG.info(('Create VMFS data store : Exit'))

    def create_recoveryset_by_newvol(self, serialNumber, moref,
                                     x_auth_token, task_id, volumeCreationDetailsList, vm_task_helper):

        LOG.info(('Create recovery set along with new volume : enter'))

        recovery_set_id = None
        status = None
        # Create an instance of RMC Wrapper, to make any RMC or TaskTracker calls
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        try:
            recovery_set_name = rmv_utils.get_recoveryset_name(moref, rmv_utils.VMWARE_OBJECT_TYPE_DS)
            # get the Pool for the storage serial number
            LOG.info(('Checking for array'))
            # Checking if the given storage system is registered in RMC.
            response_data = rmc_wrapper_service.check_array_registration(serialNumber)
            # Fetching the pool-id for the storage system
            pool_id = rmc_wrapper_service.get_storage_pool(response_data['id'], serialNumber)
            # creating recovery set along with new volume
            create_recoveryset_response_data = rmc_wrapper_service.create_rmc_recoveryset_by_newvol(recovery_set_name,
                                                                                                    volumeCreationDetailsList,
                                                                                                    pool_id,
                                                                                                    task_id=task_id)
            LOG.info(_("Created the recovery set"))

            if create_recoveryset_response_data:
                LOG.info(_("Checking the status of volumes"))
                status = create_recoveryset_response_data['status']
                if status == 'available':
                    LOG.debug(_("Checking the list of volumes is available"))
                    # Update Tasks (Task Tracker and VMware Task)
                    task_desc_string = 'RecoverySet Created along with new volumes'
                    task_percentage = 7
                    task_state = 'Running'
                    task_status = "Initiated"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                else:
                    msg = "Volumes are not in  proper state." + status
                    # Update Tasks (Task Tracker and VMware Task)
                    task_desc_string = msg
                    task_percentage = 7
                    task_state = 'Failed'
                    task_status = "Error"
                    self._update_task(task_desc_string,
                                      task_percentage,
                                      task_state,
                                      task_id,
                                      rmc_wrapper_service,
                                      vm_task_helper, task_status=task_status)

                    # Associating the vCenter Task with User Logged Event.
                    if vm_task_helper:
                        vm_task_helper.post_general_user_event(task_desc_string)

                    raise rmv_exception.RMCRecoverySetStatusException(
                        status=status)

        except (rmv_exception.RMCStorageSystemNotRegisteredException,
                rmv_exception.StoragePoolNotAvailableException,
                rmv_exception.RMCRecoverySetStatusException,
                rmv_exception.RMCAPIError,
                rmv_exception.TaskError,
                rmv_exception.RMCAPIUnknownError,
                Exception
                )as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Create recovery set along with new volumes is Unsuccessful : "
            if hasattr(e, "msg"):
                task_desc_string = task_desc_string + str(e.msg)
            elif hasattr(e, "message"):
                task_desc_string = task_desc_string + str(e.message)
            else:
                task_desc_string = task_desc_string + str(e)

            # Associating the vCenter Task with User Logged Event.
            # vm_task_helper.post_general_user_event(task_desc_string)
            raise rmv_exception.CreateRecoverysetWithNewVolumeException(msg=task_desc_string)

        if 'id' in create_recoveryset_response_data:
            recovery_set_id = create_recoveryset_response_data['id']
        LOG.info(('Create recovery set along with new volume : exit'))
        return recovery_set_id

    def export_volume_to_host(self, esxHostAddr, x_auth_token, esx_host_add_format,
                              volume_Names, recovery_set_id, task_id, vm_task_helper, serialNumber=None):
        LOG.info(('Export/Attach volume to host : Enter'))
        # Create an instance of Mount, to call host iqn list function
        mount = Mount()
        # Create an instance of RMC Wrapper, to make any RMC or TaskTracker calls
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        try:
            # Retrieve all the Hosts moref from vCenter
            mo_type = "HostSystem"
            host_moref_list = self.vi_helper.get_all_mo_moref_in_vcenter(mo_type)

            prop_list = ["name", "runtime"]
            host_oc_list = self.vi_helper.get_object_properties(host_moref_list, prop_list)

            # Check if the host is configured on VCenter and obtain Host Managed Object ref.
            esx_host_add_format = 'esxHostIP'
            host_moref = mount.get_moref_if_host_configured(esxHostAddr,
                                                            esx_host_add_format,
                                                            host_oc_list)
            # Get ESXi host wwn list
            host_wwn_list = mount.get_host_wwn(esxHostAddr, host_moref,
                                               self.vi_helper)
            LOG.debug("ESX Host ['%s'] wwn list : '%s' ", esxHostAddr, host_wwn_list)
            # Checking if the given storage system is registered in RMC.
            response_data = rmc_wrapper_service.check_array_registration(serialNumber)
            # Fetching the pool-id for the storage system
            storage_pools = rmc_wrapper_service.get_storage_pools(response_data['id'])
            host_list = []
            # Fetch hosts for all the pools(ie FC and ISCSI)
            for storage_pool in storage_pools:
                pool_id = storage_pool['id']
                hosts = rmc_wrapper_service.get_all_registered_hosts_by_pool_id(pool_id)
                host_list.extend(hosts['hosts'])
                break
            LOG.debug("Host list fetched from storage pool %s", host_list)
            host_config = mount.check_if_host_configured(rmc_wrapper_service, host_list, host_wwn_list,
                                                         x_auth_token, task_id, vm_task_helper)
            # If Host is not configured raise the exception
            if not host_config:
                msg = ("ESXi Host not configured :%s", esxHostAddr)
                LOG.error(msg)
                raise rmv_exception.EsxiHostNotConfiguredInArray(host=esxHostAddr)
            if 'iqn' not in host_config:
                esxHostWWNFormat = 'wwn'
            else:
                esxHostWWNFormat = 'iqn'
            rmc_wrapper_service.attach_recoveryset(recovery_set_id, None, False, volume_Names,
                                                   host_config, esxHostWWNFormat, task_id)
            LOG.info(("Export/Attach volume to host - Success"))
            # Update Tasks (Task Tracker and VMware Task)
            task_desc_string = 'Volumes are successfully attached to the host'
            task_percentage = 10
            task_state = 'Running'
            task_status = "Initiated"
            self._update_task(task_desc_string,
                              task_percentage,
                              task_state,
                              task_id,
                              rmc_wrapper_service,
                              vm_task_helper, task_status=task_status)

        except (exception.EsxHostNotReachable,
                rmv_exception.RMCAPIError,
                rmv_exception.TaskError,
                rmv_exception.RMCAPIUnknownError,
                rmv_exception.EsxiHostNotConfiguredInArray,
                rmv_exception.InvalidHostNameException,
                Exception
                )as e:
            LOG.exception(("Exception: '%s'"), e)
            task_desc_string = "Export volumes to host is Unsuccessful : "
            if hasattr(e, "msg"):
                task_desc_string = task_desc_string + str(e.msg)
            elif hasattr(e, "message"):
                task_desc_string = task_desc_string + str(e.message)
            else:
                task_desc_string = task_desc_string + str(e)

            # Associating the vCenter Task with User Logged Event.
            # vm_task_helper.post_general_user_event(task_desc_string)
            raise rmv_exception.ExportVolumeToHostException(msg=task_desc_string)

        LOG.info(('Export/Attach volume to host : Exit'))

    def rescan_host_hba(self, esxHostAddr):
        LOG.info(('Rescan host hbas : Enter'))
        host_moref = self.get_host_moref_from_hostname_or_ip(esxHostAddr)
        # rescan the host hbas
        try:
            host_moref_obj = pyvmomi_util.get_moref(host_moref, "HostSystem")
            prop_list = ["configManager.storageSystem"]
            host_info_dict = self.vi_helper.get_esx_host_info(prop_list, host_moref_obj)
            host_info = host_info_dict.get(host_moref)
            self.vi_helper.rescan_all_hbas(host_info.HostStorageSystemMoref)
        except Exception as e:
            LOG.exception(("Exception____: '%s'"), e)
            if hasattr(e, "message"):
                LOG.error(("Exception____: '%s'"), e.message)
            elif hasattr(e, "msg"):
                LOG.error(("Exception____: '%s'"), e.msg)
            msg = "Rescan host hbas is Unsuccessful: " + str(e)
            raise rmv_exception.RescanHostHBAException(msg=msg)
        LOG.info(('Rescan host hbas : Exit'))

    def refresh_host_datastores(self, esxHostAddr):
        LOG.debug(('Rescan host datastores : Enter'))
        host_moref = self.get_host_moref_from_hostname_or_ip(esxHostAddr)
        # rescan the host hbas
        try:
            host_moref_obj = pyvmomi_util.get_moref(host_moref, "HostSystem")
            prop_list = ["configManager.storageSystem"]
            host_info_dict = self.vi_helper.get_esx_host_info(prop_list, host_moref_obj)
            host_info = host_info_dict.get(host_moref)
            self.vi_helper.refresh_host_storage_system(host_info.HostStorageSystemMoref)
        except Exception as e:
            LOG.exception(("Exception____: '%s'"), e)
            if hasattr(e, "message"):
                LOG.error(("Exception____: '%s'"), e.message)
            elif hasattr(e, "msg"):
                LOG.error(("Exception____: '%s'"), e.msg)
            msg = "Refresh host datastores is Unsuccessful: " + str(e)
            raise rmv_exception.RefreshHostDatastores(msg=msg)
        LOG.debug(('Refresh host datastores : Exit'))

    def get_esx_hot_inofo(self, esxHostAddr):
        LOG.debug("get_esx_hot_inofo : Enter")
        host_info = None
        try:
            host_moref = self.get_host_moref_from_hostname_or_ip(esxHostAddr)
            host_info = self.vi_helper.get_host_system_complete_info(host_moref)
        except Exception as e:
            LOG.exception(e)
            msg = "Unable to fetch host details"
            raise rmv_exception.FailedToGetHostInfo(msg=msg)
        LOG.debug("get_esx_hot_inofo : Exit")
        return host_info

    def get_restored_datastore_details(self, rmc_wrapper_service, esxHostAddr, recovery_set_id):
        try:
            host_info = self.get_esx_hot_inofo(esxHostAddr)
            wwn_list = []
            ds_list = []
            recovery_set = None
            recovery_set_details = rmc_wrapper_service.get_recovery_set(recovery_set_id)
            recovery_set = recovery_set_details.get("recoverySet", None)
            if recovery_set:
                wwn_list = recovery_set.get("wwnlist", [])
            for wwn in wwn_list:
                lun = rmv_utils.first_or_default(host_info.ScsiLuns, lambda i: i.Is3ParLun and str(i.Wwn) and
                                                                               (i.Wwn.lower() == wwn.lower()))

                if not lun or not lun.VmfsVolumeUuidDict:
                    continue

                for vol in lun.VmfsVolumeUuidDict.values():
                    ds_info = rmv_utils.first_or_default(host_info.DatastoreDict.values(), lambda i: i.Name == vol)
                    if ds_info:
                        ds_list.append(ds_info.DatastoreMoref)
            return ds_list, recovery_set
        except Exception as e:
            LOG.error("Unable to fetch the restored datastores")
            LOG.exception(e)

    def register_vm_from_restored_ds(self, context, x_auth_token, rmc_wrapper_service, host_name, vm_name_dict,
                                     inventoryMoref, copy_id, objectid, resourcePoolMoref, clone_details, task_id,
                                     vm_name_to_register=None, power_on_vm=False, redirectIODatastoreName=None,
                                     is_vm_relocate_task=False):
        LOG.debug("register_vm_from_restored_ds:Enter")
        try:

            clone_info = clone_details.get('clone_details')
            mounted_ds_info = clone_info.get('cloned_ds_details')
            registered_vm_info = clone_info.get('cloned_virtual_machines', list())
            cloned_recovery_set = clone_details.get('recovery_set_id')
            clone_status = json_helper.clone_status
            # cloned_vm_name = vm_name_to_register
            vm_name_to_vmx_path = {}

            for vm_name in vm_name_dict.keys():
                for ds_dict in mounted_ds_info:
                    vmx_path = self.get_recoverable_vm_vmx_file_path(ds_dict['moref'], ds_dict['name'], vm_name,
                                                                     vm_name_dict.get(vm_name))
                    if vmx_path:
                        vm_vmxpath_to_ds = {}
                        vmx_file = vmx_path.split("] ")[1]
                        vm_vmxpath_to_ds[vmx_file] = ds_dict
                        vm_name_to_vmx_path[vm_name] = vm_vmxpath_to_ds
                        break

            for vm_name in vm_name_to_vmx_path.keys():
                cloned_vm_name = vm_name_to_register
                for vmx_file in vm_name_to_vmx_path[vm_name].keys():
                    registervm_obj = json_helper.register_vm()
                    registervm_obj.esxHostName = host_name  # host_info.HostName
                    registervm_obj.sourceDatastoreName = vm_name_to_vmx_path[vm_name][vmx_file]['name']
                    registervm_obj.inventoryMoref = inventoryMoref
                    registervm_obj.resourcePoolMoref = resourcePoolMoref
                    # registervm_obj.vmName = vm_name
                    registervm_obj.vmxFilePath = vmx_file
                    registervm_obj.objectId = objectid
                    registervm_obj.redirectIODatastoreName = redirectIODatastoreName
                    registervm_obj.asTemplate = False
                    registervm_obj.inventoryType = "Folder"
                    registervm_obj.powerOnVM = power_on_vm

                    vm_obj_info = self.db_utils.get_vmware_object_by_object_type_and_moref(context,
                                                                                           rmv_utils.VMWARE_OBJECT_TYPE_VM,
                                                                                           vm_name_dict[vm_name])
                    if vm_obj_info:
                        registervm_obj.vm_id = vm_obj_info.id
                    if not cloned_vm_name:
                        trimmed_vm_name = rmv_utils.get_vm_name_from_cloned_vm_name(vm_name)
                        timestamp_in_local_time = rmv_utils.get_current_date_time()
                        cloned_vm_name = "clone_" + trimmed_vm_name + "_" + timestamp_in_local_time
                        registervm_obj.vmName = cloned_vm_name
                    else:
                        registervm_obj.vmName = cloned_vm_name

                    register_vm_task = self._create_task_recover(rmc_wrapper_service, 'Create', vm_name, task_id,
                                                                 'Registering the VM on the Datastore', copy_id,
                                                                 cloned_vm_name, 'Clone')

                    try:

                        registered_vm_details = self.register_vm_operations(context, copy_id, x_auth_token,
                                                                            registervm_obj.__dict__, register_vm_task,
                                                                            clone_details, is_vm_relocate_task)
                        if registered_vm_details:
                            task_state = 'Running'
                            task_status = "Initiated"
                            task_desc_string = "VM -" + vm_name + "successfully recovered"
                            LOG.info(task_desc_string)
                            moref_id = vm_name_dict[vm_name]
                            vmware_object_info = self.db_utils.get_vmware_object_by_object_type_and_moref(context,
                                                                                                          rmv_utils.VMWARE_OBJECT_TYPE_VM,
                                                                                                          moref_id)
                            vm_detail = json_helper.registerd_vm_detail_json()
                            vm_detail.moref = registered_vm_details['vm_moref']
                            vm_detail.name = registered_vm_details['vm_name']
                            if vmware_object_info:
                                vm_detail.parent_id = vmware_object_info.id
                                vm_detail.parent_vm_name = vmware_object_info.name
                                vm_detail.parent_vm_moref = vmware_object_info.moref

                            registered_vm_info.append(vm_detail.__dict__)


                    except Exception as e:
                        LOG.exception(e)
                        task_state = 'Running'
                        task_status = "Initiated"
                        task_desc_string = "Registering the VM" + vm_name + " was unsuccessful"
                        LOG.error(task_desc_string)

                        task_percentage = 90
                        self._update_task(task_desc_string,
                                          task_percentage,
                                          task_state,
                                          task_id,
                                          rmc_wrapper_service,
                                          None, task_status=task_status)
            clone_info['cloned_virtual_machines'] = registered_vm_info
            if registered_vm_info:
                clone_details['status'] = clone_status.cloned
            else:
                clone_details['status'] = clone_status.mounted
            clone_details['clone_details'] = clone_info
            return clone_details
        except Exception as e:
            LOG.exception(e)
        LOG.debug("register_vm_from_restored_ds:Exit")

    def construct_clone_details_for_db(self, context, vi_helper_obj, ds_ref_list, parent_id, vm_objType, db_obj,
                                       recovery_set, mount, host_info, recovery_set_id,
                                       copy_id, cloned_resources=None):

        clone_details_list = mount.construct_clone_details(context, vi_helper_obj, ds_ref_list, parent_id, vm_objType,
                                                           db_obj, copy_id)
        clone_details = json_helper.clone_detail_json()
        clone_details.cloned_ds_details = clone_details_list
        clone_details.cloned_virtual_machines = []
        clone_details.attached_vmdks_details = []

        clones_table_obj = json_helper.clones_table()
        clones_table_obj.esxi_host_name = host_info.HostName
        clones_table_obj.esxi_host_moref = host_info.HostSystemMoref
        clones_table_obj.recovery_set_id = recovery_set_id
        clones_table_obj.clone_details = clone_details.__dict__
        if recovery_set:
            clones_table_obj.point_in_time = recovery_set.get('createdAt')
            clones_table_obj.status = recovery_set.get('status')
            clones_table_obj.name = recovery_set.get('name')
        clone_type = json_helper.clone_type()
        clones_table_obj.type = clone_type.permanant
        clones_table_obj.resources = cloned_resources
        volumes_details = recovery_set.get('volumes', [])
        if volumes_details and len(volumes_details) > 0:
            volume = volumes_details[0]
            if "attach" in volume:
                attach = volume.get("attach", None)
                if attach and "hosts" in attach:
                    hosts = attach.get("hosts", [])
                    if hosts and len(hosts) > 0:
                        attached_host_name = hosts[0]['hostname']
                        clones_table_obj.store_serv_host_name = attached_host_name

        return clones_table_obj.__dict__

    def resignature_exported_lun(self, rmc_wrapper_service, host_info, recovery_set_id, ds_mount_path_dir, mount):
        try:
            iTotalDiscoveredLunCount = 0
            UnresolvedSnapVolHeadextentPaths = set()
            numRetry = int(FLAGS.mount_retry)
            iTotalMountedLunCount = 0
            repeat = True
            rmc_vol_wwn_list = []
            recoveryset = rmc_wrapper_service.get_recovery_set(recovery_set_id)
            recoveryset_detail = recoveryset['recoverySet']
            attach_status = recoveryset_detail['attachStatus']
            if attach_status == 'attached':
                rmc_vol_wwn_list = recoveryset_detail['wwnlist']
            dict = self.vi_helper.rescan_all_hbas_and_enumerate_unresolved_vmfs_volumes(
                host_info.HostStorageSystemMoref, host_info.HostDatastoreSystemMoref, -1)
            rethInfo = self.vi_helper.get_host_system_and_storage_info(host_info.HostSystemMoref)
            try:
                for ScsiLun in rethInfo.ScsiLuns:
                    is_unresolved_lun = rmv_utils.first_or_default(
                        dict.values(), lambda i: i.lower().strip().__contains__(ScsiLun.devicePath.lower().strip()))
                    if is_unresolved_lun:
                        if ScsiLun.Wwn in rmc_vol_wwn_list:
                            UnresolvedSnapVolHeadextentPaths.add(is_unresolved_lun)
                if len(UnresolvedSnapVolHeadextentPaths) != len(rmc_vol_wwn_list):
                    LOG.error("unable to fetch unresolved volumes")
            except Exception as e:
                LOG.exception(e)

            host_resignature_results = []
            if len(UnresolvedSnapVolHeadextentPaths) > 0:
                for vol in UnresolvedSnapVolHeadextentPaths:
                    try:
                        resVol = self.vi_helper.mount_unresolved_vmfs_volumes(host_info.HostDatastoreSystemMoref, -1,
                                                                              vol)
                    except Exception as e:
                        LOG.exception(e)
                        msg = ''
                        if hasattr(e, "msg"):
                            msg = e.msg
                            LOG.error('%s', e)
                        task_desc_string = "Error mounting unresolved volumes.'%s'" % msg
                        raise rmv_exception.EsxMountException(explaination=msg)
                    if not resVol:
                        msg = ("Error mounting unresolved volumes." + ','.join(vol))
                        task_desc_string = msg
                        raise rmv_exception.EsxMountException(explaination=msg)
                    else:
                        iTotalMountedLunCount = iTotalMountedLunCount + 1
                        host_resignature_results.append(resVol.result)
                        msg = _("Successfully mounted volume." + ','.join(vol))
                        LOG.info(msg)

                if iTotalMountedLunCount == len(UnresolvedSnapVolHeadextentPaths):
                    msg = "Successfully mounted unresolved volumes"
                    LOG.info(msg)
                    mount.update_datastore_vm_config_files(host_resignature_results,
                                                           self.vi_helper, ds_mount_path_dir)
                ds_ref_list = mount.extract_ref_values(host_resignature_results)
                return ds_ref_list
        except Exception as e:
            LOG.exception(e)
            msg = "Failed to resignature the restored lun"
            raise rmv_exception.FailedToResignatureLun(msg=msg)

    # TODO : Below 2 methods will be replaced later
    def pre_protection_copy_call_back(self, ctxt, copy_info):
        """
        This is a call back method
        Workflow executor calls this method upon
        receiving a request to create a store once backup
        This method is expected to return id of associate backup
        :param copy_info:
        Expected format:
        pre_create_kwargs = {"parent_resource_id": rmco_snapshot_id(or backup_id),
                             "parent_resource_type": snapshot or backup,
                             "status": rmc_const.RMC_STATUS_CREATING,
                             "name": "resource_name",
                             "target_id": "id of the target where backup/copy is performed"
                             "resource_list":
                             [{'type': 'data'/'archive', 'rmc_resource_set_id': 'backup_set_id',
                             'executor_task_id': 'executor_task_id', 'status': 'creating'}]}
        :return: id of backup /cat copy record created.
        """
        copy_id = None
        rmc_resource_set_id = None
        is_cloud_volumes_copy = False
        try:
            # As this the same call back methods for both Backup and catalystCopy.
            # Below code should be locked for a single thread else tasks may overlap.
            with rmv_locks.copy_task_update_task:

                LOG.info("Received a call back from RMC "
                         "before creation of backup/cc with pre backup/cc info = %s" % copy_info)
                try:
                    if not self.rmc_version:
                        self.rmc_version = self.get_rmc_version()
                except Exception as e:
                    pass

                rmv_resources = []
                mo_ref = None
                mo_type = None
                recovery_set_id = None

                resource_list = copy_info.get('resource_list')
                resource_type = copy_info.get('resource_type')
                # incase of retry we will get action
                action = copy_info.get("action")

                # if granular vm backup
                if resource_type == 'vm_backup':
                    return self.pre_backup_call_back_vmdk_backup(ctxt, copy_info)

                for resource in resource_list:
                    # parent_resource_id will be parent rmc_copyset_id
                    parent_resource_id = resource.get('parent_resource_id')
                    executor_task_id = resource.get('executor_task_id')
                    mo_details = None
                    vm_copies_assoc_list = []
                    ds_copies_assoc_list = []
                    is_retry = False
                    # if resource_type == "express_protect":
                    #     LOG.info("Creating express_protect for copySetId : '%s' " % parent_resource_id)
                    #     snapshot_details = rmc_wrapper_service.get_snapshot(parent_resource_id)
                    #     snapshot_set = snapshot_details.get('snapshotSet')
                    #     recovery_set_id = snapshot_set.get('recoverySetId') if snapshot_set else None
                    #     copy_type = rmv_utils.copy_type.EXPRESS_PROTECT
                    # # If parent_resource_type is backup then the current running task is CatalystCopy
                    # elif resource_type == "catalyst_copy" or resource_type == "cloud_copy":
                    #     LOG.info("Creating CatalystCopy for copySetId : '%s' " % parent_resource_id)
                    #     backup_details = rmc_wrapper_service.get_backup_for_backupId(ctxt, parent_resource_id)
                    #     backup_set = backup_details.get('backupSet')
                    #     recovery_set_id = backup_set.get('recoverySetId') if backup_set else None
                    #     copy_type = resource_type

                    rmc_wrapper_service = rmc_wrapper.rmc_wrapper(None)
                    rmc_resource_set_id = resource.get('rmc_resource_set_id')
                    backup_details = rmc_wrapper_service.get_backup_for_backupId(ctxt, rmc_resource_set_id)
                    copy_set = backup_details.get('backupSet')
                    if action is not None and action.lower() == "retry":
                        is_retry = True
                        parent_resource_id = copy_set.get("snapshotSetId")
                        vm_copies_assoc_list = self.db.get_all_rmcv_vm_copy_assoc_by_copy_id(ctxt, copy_info.get(
                            "resource_id"))
                        ds_copies_assoc_list = self.db.get_all_rmcv_ds_copy_assoc_by_copy_id(ctxt, copy_info.get(
                            "resource_id"))

                    # Fields which are same across copies is updated from the previous copy
                    # snap_copy_obj = self.db.get_rmcv_copy_by_rmc_copyset_id(ctxt, parent_resource_id)
                    snap_copy_db_obj = self.db.get_rmcv_copies_by_rmc_copyset_id(ctxt, parent_resource_id)
                    # if parent resource for Express Protect is remote snapshot multiple copies(2) will be available
                    # in rmcv_copies table with same rmc_copy_set id
                    # one with copy type as snapshot without any vm assocs entries
                    # one with copy type as remote_snapshot with vm_assoc and ds_assoc entries
                    # need to get remote_snapshot copy obj to update the assoc details
                    if snap_copy_db_obj and len(snap_copy_db_obj) > 1:
                        LOG.info(
                            "Multiple copies found in the rmcv database for the copy set id '%s'" % parent_resource_id)

                    for copy_obj in snap_copy_db_obj:
                        if copy_obj.type == rmv_utils.copy_type.REMOTE_SNAPSHOT:
                            snap_copy_obj = copy_obj
                            break
                    else:
                        snap_copy_obj = copy_obj

                    # Updating RMC-V tables - Backup/CC information
                    copies_table_obj = json_helper.copies_table()
                    copies_table_obj.name = copy_set.get('name')
                    copies_table_obj.rmc_copyset_id = rmc_resource_set_id
                    copies_table_obj.point_in_time = copy_set.get('createdAt')
                    copy_policy = copy_set.get('backupPolicy')
                    copies_table_obj.store_name = copy_policy.get('storeName')
                    copies_table_obj.backup_system_name = copy_policy.get('name')
                    # TODO:6.0 rename to copy policy id
                    copies_table_obj.copy_policy_id = copy_policy.get('id')

                    # For both Backup and CC, till post callback we will maintain our DB status as 'creating'.
                    # And in Post callback, get the latest status from RMC and update.
                    status = "creating"
                    copies_table_obj.status = status
                    copies_table_obj.type = resource_type
                    copies_table_obj.array_name = snap_copy_obj.array_name
                    copies_table_obj.array_serial_number = snap_copy_obj.array_serial_number
                    copies_table_obj.ds_mount_path_dir = snap_copy_obj.ds_mount_path_dir
                    copies_table_obj.vmfs_snap_moref = snap_copy_obj.vmfs_snap_moref
                    copies_table_obj.has_vmfs_snapshots = snap_copy_obj.has_vmfs_snapshots
                    copies_table_obj.group_id = snap_copy_obj.group_id
                    if resource_type == rmv_utils.copy_type.CLOUD_COPY:
                        is_cloud_volumes_copy = copy_info.get('is_cloud_volumes_copy')
                        if is_cloud_volumes_copy:
                            copies_table_obj.cloud_backup_type = rmv_utils.CLOUD_VOLUMES_COPY
                        else:
                            copies_table_obj.cloud_backup_type = rmv_utils.CLOUD_BANK_COPY

                    if is_retry:
                        copies_table_obj.status = "retrying"
                        copy_id = copy_info.get("resource_id")
                        copies_table_obj.id = copy_id
                        self.db.update_rmcv_copy(ctxt, copy_id, copies_table_obj.__dict__)
                    else:
                        copies_table_obj.version = self.rmc_version
                        copies_table_response = self.db.create_rmcv_copy(copies_table_obj.__dict__)
                        copy_id = copies_table_response.id
                    rmv_resources.append(copy_id)
                    if not vm_copies_assoc_list:
                        try:
                            vm_copies_assoc_list = self.db.get_all_rmcv_vm_copy_assoc_by_copy_id(ctxt,
                                                                                                 snap_copy_obj.id)
                            for vm_copies_assoc in vm_copies_assoc_list:
                                copies_assoc_vm_obj = json_helper.vm_copies_assoc_table()
                                copies_assoc_vm_obj.copy_id = copy_id
                                copies_assoc_vm_obj.virtual_machine_id = vm_copies_assoc.virtual_machine_id
                                copies_assoc_vm_obj.is_app_consistent = vm_copies_assoc.is_app_consistent
                                copies_assoc_vm_obj.vmdks = vm_copies_assoc.vmdks

                                self.db.create_rmcv_vm_copy_assoc(copies_assoc_vm_obj.__dict__)

                        except Exception as e:
                            LOG.exception("Unable to update vm_copy_assoc table. Copy ID not present in DB. %s " % e)

                    if not ds_copies_assoc_list:
                        try:
                            ds_copies_assoc_list = self.db.get_all_rmcv_ds_copy_assoc_by_copy_id(ctxt,
                                                                                                 snap_copy_obj.id)
                            for ds_copies_assoc in ds_copies_assoc_list:
                                copies_assoc_ds_obj = json_helper.ds_copies_assoc_table()
                                copies_assoc_ds_obj.copy_id = copy_id
                                copies_assoc_ds_obj.datastore_id = ds_copies_assoc.datastore_id
                                copies_assoc_ds_obj.is_app_consistent = ds_copies_assoc.is_app_consistent
                                copies_assoc_ds_obj.vmdks = ds_copies_assoc.vmdks
                                copies_assoc_ds_obj.wwn_details = ds_copies_assoc.wwn_details

                                self.db.create_rmcv_ds_copy_assoc(copies_assoc_ds_obj.__dict__)

                        except Exception as e:
                            LOG.exception(("Unable to update ds_copy_assoc table. Copy ID '%s' not present in DB. "
                                           "%s ") % (snap_copy_obj.id, e))
                    # updating parent copy status
                    # for btaas copy source is snapshot so we can update the snapshot status here.
                    if resource_type == rmv_utils.copy_type.EXPRESS_PROTECT or (
                            resource_type == rmv_utils.copy_type.CLOUD_COPY and is_cloud_volumes_copy):
                        parent_copy_details = rmc_wrapper_service.get_snapshot(parent_resource_id)
                        copy_set = parent_copy_details.get("snapshotSet")
                        snap_copy_obj.status = copy_set.get("status")
                    elif resource_type in [rmv_utils.copy_type.CLOUD_COPY, rmv_utils.copy_type.CATALYST_COPY]:
                        parent_copy_details = rmc_wrapper_service.get_backup_for_backupId(ctxt, parent_resource_id)
                        copy_set = parent_copy_details.get("backupSet")
                        snap_copy_obj.status = copy_set.get("status")
                    self.db.update_rmcv_copy(ctxt, snap_copy_obj.id, snap_copy_obj)

                    recovery_set_id = copy_set.get('recoverySetId') if copy_set else None
                    if recovery_set_id:
                        mo_details = self.db_utils.get_vmware_object_by_recovery_set_id(ctxt, recovery_set_id)
                    else:
                        LOG.info("recovery_set_id not found for the Copy ID - '%s' " % rmc_resource_set_id)

                    if mo_details:
                        mo_ref = mo_details.get('moref')
                        mo_type = mo_details.get('object_type')
                    else:
                        mo_ref = rmv_utils.TASK_MO_REF
                        mo_type = rmv_utils.TASK_OBJECT_TYPE

                    if mo_type == rmv_utils.VMWARE_OBJECT_TYPE_PROTECTION_GROUP:
                        LOG.debug("mo_type is protection group. Hence setting mo_ref to group-d1")
                        mo_ref = rmv_utils.TASK_MO_REF
                        mo_type = rmv_utils.TASK_OBJECT_TYPE

                    # rmc_resource_set_id = resource.get('rmc_resource_set_id')
                    # backup_details = rmc_wrapper_service.get_backup_for_backupId(ctxt, rmc_resource_set_id)
                    # backup_set = backup_details.get('backupSet')

                    # As this is the pre copy callback for both backup and CatalystCopy,
                    # polling of each task is done in separate thread.
                    thread.start_new_thread(self.update_copy_task, (ctxt,
                                                                    rmc_wrapper_service,
                                                                    executor_task_id,
                                                                    resource_type,
                                                                    copy_id,
                                                                    mo_ref,
                                                                    mo_type,
                                                                    is_retry,))

                # TODO:6.0 Returning only one element may not work for Folder level Backup/CatalystCopy. This needs be re-verified.
                return rmv_resources[0]

        except Exception as e:
            LOG.exception(e)

            if copy_id:
                snap_copy = self.db.get_rmcv_copy_by_id(ctxt, copy_id)
                snap_copy.status = json_helper.copy_status.error
                self.db.update_rmcv_copy(ctxt, copy_id, snap_copy)
            else:
                copy_set = {}
                if rmc_resource_set_id:
                    rmc_wrapper_service = rmc_wrapper.rmc_wrapper(None)
                    backup_details = rmc_wrapper_service.get_backup_for_backupId(ctxt, rmc_resource_set_id)
                    copy_set = backup_details.get('backupSet')

                snap_copy = json_helper.copies_table()
                snap_copy.name = copy_set.get('name')
                snap_copy.point_in_time = copy_set.get('createdAt')
                snap_copy.rmc_copyset_id = rmc_resource_set_id
                snap_copy.status = json_helper.copy_status.error
                snap_copy = self.db.create_rmcv_copy(snap_copy.__dict__)

            LOG.error("Failure while updating task status. So updating Copy table with the error status "
                      "for the copy ID: '%s'" % copy_id)

            raise e

    def post_protection_copy_call_back(self, ctxt, copy_info):
        """
        This is a call back method
        Workflow executor calls this method upon
        termination of execution a request to create a store once backup/copy
        This method is expected to do any clean up activities
        :param copy_info:
        Expected format:
        pre_create_kwargs = {"parent_resource_id": rmco_snapshot_id(or backup_id),
                             "parent_resource_type": snapshot or backup,
                             "parent_resource_state": "initial state of parent resource",
                             "resource_id" : resource_id,
                             "resource_type": "backup/cat copy
                             "status": rmc_const.RMC_STATUS_CREATING,
                             "resource_list":
                             [{'type': 'data'/'archive', 'rmc_resource_set_id': 'backup_set_id',
                             'executor_task_id': 'executor_task_id', 'status': 'creating'}]}
        :return: id of backup /cat copy record created.
        """
        try:
            LOG.info("Received a call back from RMC "
                     "after creation of backup with post backup info = %s" % copy_info)

            resource_type = copy_info.get('resource_type')
            resource_list = copy_info.get('resource_list')
            notification_resources = []
            is_cloud_volumes_copy = False
            if resource_type == rmv_utils.copy_type.CLOUD_COPY:
                is_cloud_volumes_copy = copy_info.get('is_cloud_volumes_copy')

            if resource_type == 'vm_backup':
                self.post_backup_call_back_vmdk_backup(ctxt, copy_info)
                return

            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(None)

            for resource in resource_list:
                parent_resource_id = resource.get('parent_resource_id')
                rmc_resource_set_id = resource.get('rmc_resource_set_id')
                task_id = resource.get('executor_task_id')

                copy_details = rmc_wrapper_service.get_backup_for_backupId(ctxt, rmc_resource_set_id)
                copy_set = copy_details.get('backupSet')
                recovery_set_id = copy_set.get('recoverySetId') if copy_set else None

                if recovery_set_id:
                    mo_details = self.db_utils.get_vmware_object_by_recovery_set_id(ctxt, recovery_set_id)
                else:
                    # TODO:6.0 raise proper exception here
                    raise

                volume_type = mo_details.get('volume_type') if mo_details else None
                if volume_type == 'vvol':  # and mo_details.get('object_type') == rmv_utils.VMWARE_OBJECT_TYPE_VM:
                    # Updating ClientMetadata is required only for VVOL.
                    backup_client_metadata = self.get_vmfs_snapshot_config_info(ctxt, parent_resource_id)
                    rmc_wrapper_service.update_backup_client_metadata(rmc_resource_set_id, backup_client_metadata)

                copy_obj = self.db.get_rmcv_copy_by_rmc_copyset_id(ctxt, rmc_resource_set_id)
                expiry = copy_set.get('backupExpiry')
                retention = copy_set.get('backupRetention')

                copy_obj.expiry = expiry if expiry else 0
                copy_obj.retention = retention if retention else 0
                copy_obj.verified = copy_set.get('verified')
                copy_obj.status = copy_set.get('status')

                self.db.update_rmcv_copy(ctxt, copy_obj.id, copy_obj)

                # Below is to update the AssociatedData to Backup/CC Task, used in Dashboard.
                associated_data_list = []
                try:
                    vm_copies_assoc_list = self.db.get_all_rmcv_vm_copy_assoc_by_copy_id(ctxt, copy_obj.id)
                    for vm_copies_assoc in vm_copies_assoc_list:
                        vm_db_details = self.db.get_virtual_machine_by_id(ctxt,
                                                                          vm_copies_assoc.virtual_machine_id)
                        associated_data = {}
                        associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_VM
                        associated_data['resourceName'] = vm_db_details.name
                        associated_data['resourceUri'] = vm_db_details.moref
                        associated_data['status'] = copy_set.get('status')
                        associated_data['errorReason'] = None
                        associated_data_list.append(associated_data)

                except Exception as e:
                    LOG.exception(("Unable to update associated data for Task - %s. %s ") % (task_id, e))

                try:
                    ds_copies_assoc_list = self.db.get_all_rmcv_ds_copy_assoc_by_copy_id(ctxt, copy_obj.id)
                    for ds_copies_assoc in ds_copies_assoc_list:
                        ds_db_details = self.db.get_datastore_by_id(ctxt, ds_copies_assoc.datastore_id)
                        associated_data = {}
                        associated_data['resourceType'] = rmv_utils.VMWARE_OBJECT_TYPE_DS
                        associated_data['resourceName'] = ds_db_details.name
                        associated_data['resourceUri'] = ds_db_details.moref
                        associated_data['status'] = copy_set.get('status')
                        associated_data['errorReason'] = None
                        associated_data_list.append(associated_data)

                except Exception as e:
                    LOG.exception(("Unable to update associated data for Task - %s. %s ") % (task_id, e))

                task_response_data = rmc_wrapper_service.get_copy_task_status(task_id)
                rmc_wrapper_service.update_rmc_created_task(task_id, task_response_data, associated_data_list)

                # snap_copy_obj = self.db.get_rmcv_copy_by_rmc_copyset_id(ctxt, parent_resource_id)

                snap_copy_db_obj = self.db.get_rmcv_copies_by_rmc_copyset_id(ctxt, parent_resource_id)
                # if parent resource for Express Protect is remote snapshot multiple copies(2) will be available
                # in rmcv_copies table with same rmc_copy_set id
                # need to get remote_snapshot copy obj to update status
                if snap_copy_db_obj and len(snap_copy_db_obj) > 1:
                    LOG.info("Multiple copies found in the rmcv database for the copy set id '%s'" % parent_resource_id)

                for copy_obj in snap_copy_db_obj:
                    if copy_obj.type == rmv_utils.copy_type.REMOTE_SNAPSHOT:
                        snap_copy_obj = copy_obj
                        break
                else:
                    snap_copy_obj = copy_obj
                # updating parent copy status
                # for btaas copy source is snapshot so we can update the snapshot status here.
                if resource_type == rmv_utils.copy_type.EXPRESS_PROTECT or (
                        resource_type == rmv_utils.copy_type.CLOUD_COPY and is_cloud_volumes_copy):
                    parent_copy_details = rmc_wrapper_service.get_snapshot(parent_resource_id)
                    copy_set = parent_copy_details.get("snapshotSet")
                    snap_copy_obj.status = copy_set.get("status")
                elif resource_type in [rmv_utils.copy_type.CLOUD_COPY, rmv_utils.copy_type.CATALYST_COPY]:
                    parent_copy_details = rmc_wrapper_service.get_backup_for_backupId(ctxt, parent_resource_id)
                    copy_set = parent_copy_details.get("backupSet")
                    snap_copy_obj.status = copy_set.get("status")
                self.db.update_rmcv_copy(ctxt, snap_copy_obj.id, snap_copy_obj)
                notification_resources.append({'taskId': task_id, 'copyObj': copy_obj, 'rmvObj': mo_details})


        except Exception as e:
            LOG.exception(e)

        finally:
            for one in notification_resources:
                email_notification = nu.BackupNotification(one.get('copyObj'), one.get('rmvObj'), one.get('taskId'),
                                                           'createExpressProtect', rmc_wrapper_service)
                email_notification.start()

    def pre_backup_call_back_vmdk_backup(self, context, copy_info):

        resource_list = copy_info.get('resource_list')
        rmv_resource_list = []
        parent_resource_id = copy_info.get('parent_resource_id')
        for resource in resource_list:
            rmc_resource_set_id = resource.get('rmc_resource_set_id')
            state = copy_info.get('state').lower()
            LOG.info("post backup callback for G Backup, resource set id: " + str(rmc_resource_set_id))
            rmv_vm_object = self.db.get_virtual_machine_by_moref(context, parent_resource_id)
            rmv_backup_obj = self.db.get_latest_rmcv_backup_by_status_and_vm_id(context, rmv_vm_object.id, 'running')
            rmv_resource_list.append(rmv_backup_obj.id)
            self.db.update_rmcv_copy(context, rmv_backup_obj.id, {'rmc_copyset_id': rmc_resource_set_id, })
            self.update_nbd_backup_process(context, rmv_backup_obj.id, state)

        return rmv_resource_list

    def post_backup_call_back_vmdk_backup(self, context, copy_info):

        resource_list = copy_info.get('resource_list')
        parent_resource_id = copy_info.get('parent_resource_id')
        for resource in resource_list:
            rmc_resource_set_id = resource_list[0].get('rmc_resource_set_id')
            rmc_wrappper_service = rmc_wrapper.rmc_wrapper(None)
            backup_set = rmc_wrappper_service.get_backup_for_backupId(context, rmc_resource_set_id)
            status = backup_set.get('backupSet').get('status')
            LOG.info("post backup callback for G Backup, resource set id: " + str(rmc_resource_set_id))
            rmv_backup_obj = self.db.get_rmcv_copy_by_rmc_copyset_id(context, rmc_resource_set_id)
            self.db.update_rmcv_copy(context, rmv_backup_obj.id, {'rmc_copyset_id': rmc_resource_set_id, })
            self.update_nbd_backup_process(context, rmv_backup_obj.id, status)
            self.delete_input_file(rmv_backup_obj.id)
            vmInfo, hostInfo = self.get_virtual_machine_details(parent_resource_id, vmLevelBackup=True)
            self.delete_all_vmfs_snapshot_vm(vmInfo, parent_resource_id)

    # Below two methods moved from hypervisors.py API layer
    def validate_vcenter_obj_creation(self, context, vcenter_dict):
        """
        This will be called whenever adding new vCenter in RMC
        if vCenter session is active will destroy that session and
        will create a new Vcenter session and pyvmomi session with newly added vCenter credentials.
        once session is created will verify the user permissions in vCenter
        :param venter_dict:
        :return:
        """
        LOG.info("validate vcenter obj creation:Enter")
        ip_hostname = vcenter_dict.get('ipHostname', None)
        user_name = vcenter_dict.get('username', None)
        password = vcenter_dict.get('password', None)
        try:
            if self.vi_helper:
                # deleting vihelper object will do the session logout also.
                # If session logout is required before deleteing then enable the below two lines.
                # self.vi_helper.pyvmomi_session_logout()
                # self.vi_helper.logout()
                del self.vi_helper
            # creating a new vCenter session
            self.vi_helper = ViHelper(ip_hostname, user_name, password)
            # creating a new pyvmomi session
            self.vi_helper.create_pyvmomi_session(ip_hostname, user_name, password)
            # checking for the user permission in vCenter to perform RMC-V operations
            self.check_user_permissions_in_vcenter(vcenter_dict)
            return True

        except Exception as e:
            LOG.exception(e)
            err_msg = "Unable to create session with vCenter: '%s' " % ip_hostname
            if hasattr(e, "exception_obj"):
                if hasattr(e.exception_obj, "message"):
                    err_msg = e.exception_obj.message
            elif hasattr(e, "msg"):
                err_msg = e.msg
            elif hasattr(e, "message"):
                err_msg = e.message
            e.get_description = err_msg
            if self.vi_helper:
                del self.vi_helper
            raise e

    def get_vcenter_product_details(self, context):
        LOG.debug("Enter: get_vcenter_product_details")
        try:
            server_details = self.vi_helper.get_server_details()
            LOG.debug("Exit: get_vcenter_product_details")
            return server_details
        except Exception as e:
            msg = "Unable to fetch Server Product and Version details."
            if hasattr(e, "msg"):
                msg = e.msg
            elif hasattr(e, "message"):
                msg = e.message
            LOG.exception("%s: %s", msg, e)
            raise e

    def check_user_permissions_in_vcenter(self, vcenter_dict):
        """
        check user permisssion in the vcenter
        :param vcenter_dict:
        :return:
        """
        LOG.info("check user permissions in vcenter: Enter")
        user_name = vcenter_dict.get('username', None)
        user_name_wb = None
        try:
            user_privilege_list = []
            if "@" in user_name:
                user_name_wb = user_name[0:user_name.lower().strip().find("@")]
            elif "\\" in user_name:
                user_name_wb = user_name[user_name.lower().strip().find("\\") + 1:]
            else:
                user_name_wb = user_name
            LOG.info("Acquiring check_user_permission_lock...")
            with rmv_locks.check_user_permission_lock:
                obj_content = self.vi_helper.GetObjectProperties(
                    self.vi_helper.vim_object._service_content.sessionManager, "sessionList")
                obj = obj_content.objects[0]
                property_dict = vim_util.extract_properties(obj)
                previous_user_session = None
                for user_session in property_dict['sessionList'].UserSession:
                    if "@" in user_session['userName']:
                        user_name_in_session = user_session['userName'][
                                               0:user_session['userName'].lower().strip().find("@")]
                    elif "\\" in user_session['userName']:
                        user_name_in_session = user_session['userName'][
                                               user_session['userName'].lower().strip().find("\\") + 1:]
                    else:
                        user_name_in_session = user_session['userName']
                    # To get Session ID, check logged-in user name is equal to UserSession's username.
                    LOG.info("user_name_in_session:%s and user_name_wb:%s",
                             user_name_in_session.lower(), user_name_wb.lower())
                    if user_name_in_session.lower().strip() == \
                            user_name_wb.lower().strip():
                        # Session list in vCenter may have multiple sessions for a user. Consider latest session.
                        if previous_user_session:
                            if user_session.loginTime < previous_user_session.loginTime:
                                continue

                        LOG.info(("Checking required privilege for the user : '%s' having Session ID : '%s'") % (
                        user_session.userName, user_session.key))
                        user_privilege_list = self.vi_helper.check_user_privilege(user_session.key)

                        previous_user_session = user_session
                    else:
                        LOG.info("User name did not matched: "
                                 "user_name_in_session:%s user_name_wb:%s",
                                 user_name_in_session.lower(), user_name_wb.lower())
                LOG.info("user_privilege_list :%s", user_privilege_list)
                # In user_privilege_list, if there is atleast one entry of False then it means user doesn't have required privilege.
                if user_privilege_list:
                    if False in user_privilege_list:
                        missingPrivilegeList = list()
                        priv_list = ViHelper.rmv_required_privileges
                        for i in range(len(user_privilege_list)):
                            if user_privilege_list[i]:
                                missingPrivilegeList.append(priv_list[i])

                        msg = "User '%s' doesn't have required privileges to access RMC-V. Missing privileges:'%s'" % (
                        user_name, missingPrivilegeList)
                        raise rmv_exception.InvalidUser(error=msg)

                    else:
                        task_desc_string = "User '%s' has the required privileges to access RMC-V." % user_name
                        LOG.info(task_desc_string)
                else:
                    msg = "User '%s' doesn't have required privileges to access RMC-V" % user_name
                    raise rmv_exception.InvalidUser(error=msg)
            LOG.info("check user permissions in vcenter: End")
        except (Exception, rmv_exception.InvalidUser) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                message = e.msg
            else:
                message = ("Exception in evaluating the permissions of the User '%s'. "
                           "Exception : '%s'") % (user_name, e)
            e.get_description = message
            raise e

    def validate_datastore_wwn_with_snap_or_bkp_base_volume_wwn(self, base_volume_wwn_list, scsi_luns, ds_info):
        LOG.debug("validate datastore wwn with snap wwn:Enter")
        try:

            if base_volume_wwn_list:
                Wwn_list = list()
                for lun in scsi_luns:
                    Wwn_list.append(lun.Wwn)
                LOG.info("Current datastore wwn list :%s  and snapshot/backup base volume wwn list:%s", Wwn_list,
                         base_volume_wwn_list)
                if type(base_volume_wwn_list) is list and set(Wwn_list) != set(base_volume_wwn_list):
                    LOG.info("snapshot restore not allowed. There are mismatches found in WWN of snapshot/backup "
                             "base volume(s)-%s with datastore volume(s) - %s", Wwn_list, base_volume_wwn_list)
                    raise rmv_exception.DatastoresWwnMissmatch(name=ds_info.Name)
        except (rmv_exception.DatastoresWwnMissmatch) as e:
            LOG.exception(e)
            raise e
        except Exception as e:
            LOG.exception(e)
        LOG.debug("validate datastore wwn with snap wwn:Exit")

    def refresh_rmv_vmware_objects(self, context, x_auth_token=None, task_id=None, isExplicit_refresh=False):
        '''
             To refresh the vmware objects stored in rmcv database
        '''
        LOG.debug('Refresh RMV vmware objects::Enter')
        try:
            if isExplicit_refresh:
                rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
                vm_task_helper = VmTaskHelper(self.vi_helper)
                object_type = "Folder"
                mo_ref = "group-d1"
                vm_task_helper.CustomVMwareTaskBegin(object_type,
                                                     mo_ref,
                                                     "RefreshvmwareobjectsTask",
                                                     "RefreshvmwareobjectsFailedFault")

                task_desc_string = 'Updating rmv vmware objects'
                task_percentage = 10
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

            # If SRM configured then check and update if DS MoRefs got changed during Failover/Failback
            try:
                moref_manage_obj = moref_manage(self.vi_helper)
                moref_manage_obj.check_and_update_mo_ref_if_srm_configured(context, x_auth_token)
            except Exception as e:
                LOG.exception("Unable to update the changed MoRef. %s " % e)

            # get all virtual machine morefs from rmcv DB
            rmcv_vm_moref_list = self.db.get_all_virtual_machine_morefs(context)
            # get all virtual machine morefs from vCenter
            vCenter_all_vms_moref_list = self.vi_helper.get_all_mo_moref_in_vcenter("VirtualMachine")
            vCenter_all_vms_moref_id_list = [moref._moId for moref in vCenter_all_vms_moref_list]
            # finding the deleted virtual machines from vcenter
            deleted_vm_list = list(set(rmcv_vm_moref_list) - set(vCenter_all_vms_moref_id_list))
            LOG.info("Deleted virtual machines moref list is : %s" % deleted_vm_list)
            # finding the virtual machines which are available in vCenter and rmcv DB
            rmcv_active_vm_list = list(set(rmcv_vm_moref_list) - set(deleted_vm_list))
            # updating the rmcv virtual machine table with deleted as true for all the deleted vms in vCenter
            if len(deleted_vm_list) > 0:
                self.update_deleted_rmcv_virtual_machines(context, deleted_vm_list)
            # updating all other information for active virtual machines
            active_vm_morefs = [moid for moid in vCenter_all_vms_moref_list for moref in rmcv_active_vm_list if
                                moref == moid._moId]
            if len(active_vm_morefs) > 0:
                self.update_rmcv_virtual_machines(context, active_vm_morefs)
            if isExplicit_refresh:
                task_desc_string = 'Updating rmv Virtual Machines completed successfully'
                task_percentage = 50
                task_state = 'Running'
                task_status = "Initiated"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
            # get all Datastore morefs from rmcv DB
            rmcv_ds_moref_list = self.db.get_all_datastore_morefs(context)
            # get all datastore moref available in vCenter
            vCenter_all_ds_moref_list = self.vi_helper.get_all_mo_moref_in_vcenter("Datastore")
            vCenter_all_ds_moref_id_list = [moref._moId for moref in vCenter_all_ds_moref_list]
            # find the deleted datastores from vCenter
            deleted_ds_list = list(set(rmcv_ds_moref_list) - set(vCenter_all_ds_moref_id_list))
            LOG.info("Deleted data stores moref list is : %s" % deleted_ds_list)
            # updating the rmcv data stores table with deleted as true for all deleted data stores
            if len(deleted_ds_list) > 0:
                self.update_deleted_rmcv_datastores(context, deleted_ds_list)
            # finding the datastores which are available in both rmv DB and vCenter
            rmcv_active_ds_list = list(set(rmcv_ds_moref_list) - set(deleted_ds_list))
            # updating all other information for active data stores
            active_ds_morefs = [moid for moid in vCenter_all_ds_moref_list for moref in rmcv_active_ds_list if
                                moref == moid._moId]
            if len(active_ds_morefs) > 0:
                self.update_rmcv_data_stores(context, active_ds_morefs)
            if isExplicit_refresh:
                task_desc_string = 'Updating rmv Datastores completed successfully'
                task_percentage = 100
                task_state = 'Completed'
                task_status = "Ok"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)
                vm_task_helper.CustomVMwareTaskEnd("success", task_desc_string)
        except Exception as ex:
            LOG.exception('Exception while refreshing rmv vmware objects ' + str(ex))
            if isExplicit_refresh:
                task_desc_string = 'Exception while refreshing rmv vmware objects'
                task_percentage = 100
                task_state = 'Failed'
                task_status = "Error"
                self._update_task(task_desc_string,
                                  task_percentage,
                                  task_state,
                                  task_id,
                                  rmc_wrapper_service,
                                  vm_task_helper, task_status=task_status)

                # Associating the vCenter Task with User Logged Event.
                vm_task_helper.post_general_user_event(task_desc_string)

                vm_task_helper.CustomVMwareTaskEnd("error", task_desc_string)
        LOG.debug('Refresh RMV vmware objects::Exit')
        return

    def update_deleted_rmcv_virtual_machines(self, context, deleted_vm_moref_list):
        '''
            To update the rmcv virtual machines table for all deleted virtual machines with deleted as True
        :param context:
        :param deleted_vm_moref_list: All deleted vms moref id
        :return:
        '''
        LOG.debug('Update deleted rmcv virtual machines::Enter')
        values = {}
        moref = None

        try:
            for moref_id in deleted_vm_moref_list:
                # Below if condition is to avoid deleting VM table entries during migartion from 5.x to 6.2.
                # Can be removed after 6.2 release
                if moref_id.startswith('migrated-'):
                    continue

                values['status'] = 'deleted'
                moref = moref_id
                self.db.update_rmcv_virtual_machine_by_moref(context, moref_id, values)
        except Exception as e:
            msg = "Unable to update the virtual machine : '%s'" % moref
            LOG.exception(("'%s'. Exception : '%s'") % (msg, str(e)))
            raise e

        LOG.debug('Update deleted rmcv virtual machines::Exit')

    def update_deleted_rmcv_datastores(self, context, deleted_ds_moref_list):
        '''
            To update the rmcv datastore table for all deleted data stores with deleted as True
        :param context:
        :param deleted_ds_moref_list: All deleted datastores moref id
        :return:
        '''
        LOG.debug('Update deleted rmcv Datastores::Enter')
        values = {}
        moref = None

        try:
            for moref_id in deleted_ds_moref_list:
                if moref_id.startswith('dummy_'):
                    continue
                values['status'] = 'deleted'
                moref = moref_id
                self.db.update_rmcv_datastore_by_moref(context, moref_id, values)
        except Exception as e:
            msg = "Unable to update the Datastore : '%s'" % moref
            LOG.exception(("'%s'. Exception : '%s'") % (msg, str(e)))
            raise e

        LOG.debug('Update deleted rmcv Datastores::Exit')

    def update_rmcv_virtual_machines(self, context, vm_moref_list):
        '''
            Updating the rmcv virtual machines table in case any changes found in the vCenter
        :param context:
        :param vm_moref_list: virtual machine moref list
        :return:
        '''
        LOG.debug('Update rmcv virtual machines::Enter')
        host_info = {}
        vm_moref_id = None
        vm_oc_list = None
        try:
            if vm_moref_list:
                prop_list = ["name", "runtime"]
                vm_oc_list = self.vi_helper.get_object_properties(vm_moref_list, prop_list)
            if vm_oc_list:
                for vm_oc in vm_oc_list:
                    values = {}
                    prop_dict = pyvmomi_util.extract_properties(vm_oc)
                    values['name'] = prop_dict.get('name')
                    vm_moref_id = vm_oc.obj._moId
                    host_moref = prop_dict.get('runtime').host if prop_dict.get("runtime") else ""
                    values['host_id'] = host_moref._moId
                    if host_moref in host_info:
                        values['host_name'] = host_info[host_moref]
                    else:
                        host_prop_list = ["name"]
                        host_oc_list = self.vi_helper.get_object_properties(host_moref, host_prop_list)
                        host_name = pyvmomi_util.extract_properties(host_oc_list[0]).get('name')
                        host_info[host_moref] = host_name
                        values['host_name'] = host_info[host_moref]
                    LOG.debug("Updating the Virtual Machine with moref id %s" % vm_moref_id)
                    self.db.update_rmcv_virtual_machine_by_moref(context, vm_moref_id, values)
        except Exception as e:
            msg = "Unable to update the virtual machine : '%s'" % vm_moref_id
            LOG.exception(("'%s'. Exception : '%s'") % (msg, str(e)))
            raise e

        LOG.debug('Update rmcv virtual machines::Exit')

    def update_rmcv_data_stores(self, context, ds_moref_list):
        '''

        :param context:
        :param ds_moref_list: Datastore moref list
        :return:
        '''
        LOG.debug('Update rmcv data stores :: Enter')
        host_info = {}
        ds_moref_id = None
        ds_oc_list = None
        try:
            if ds_moref_list:
                prop_list = ["name", "host"]
                ds_oc_list = self.vi_helper.get_object_properties(ds_moref_list, prop_list)
            if ds_oc_list:
                for ds_oc in ds_oc_list:
                    values = {}
                    prop_dict = pyvmomi_util.extract_properties(ds_oc)
                    values['name'] = prop_dict.get('name')
                    ds_moref_id = ds_oc.obj._moId
                    host_moref = prop_dict.get('host')[0].key if prop_dict.get("host") else ""
                    values['host_id'] = host_moref._moId
                    if host_moref in host_info:
                        values['host_name'] = host_info[host_moref]
                    else:
                        host_prop_list = ["name"]
                        host_oc_list = self.vi_helper.get_object_properties(host_moref, host_prop_list)
                        host_name = pyvmomi_util.extract_properties(host_oc_list[0]).get('name')
                        host_info[host_moref] = host_name
                        values['host_name'] = host_info[host_moref]
                    LOG.debug("Updating the Datastore with moref id %s" % ds_moref_id)
                    self.db.update_rmcv_datastore_by_moref(context, ds_moref_id, values)
        except Exception as e:
            msg = "Unable to update the datastore : '%s'" % ds_moref_id
            LOG.exception(("'%s'. Exception : '%s'") % (msg, str(e)))
            raise e
        LOG.debug('Update rmcv data stores :: Exit')

    def appliance_update(self, context, ip, username, password, is_explicit_update=False):
        """
        This method is the handler for messages sent by RMC for changes in
        RMC IP or Admin user password
        :param context:
        :param ip:
        :param username:
        :param password:
        :return:
        """
        LOG.info("appliance_update::Enter")
        hypervisor_obj = hypervisor_manager()
        response = hypervisor_obj.update_rmc_details_in_extension_client_info(context, ip, username, password)
        LOG.info("appliance_update::Exit")
        if is_explicit_update:
            return response

    def notify_app(self, context, resource_type, resource_info):
        """
        This Method is the Handler for messages sent by RMC for changes in
        resource status
        Currently this Method is implemented for auto deletion
        of expired snapshots and backups.

        Args:
            context:
            resource_type: Type of the resource
            (supported ones-snapshot and backup)
            resource_info: A list of dictionary having id
            and status of resources(Implemented for deleted status)
        Returns: None
       """
        LOG.debug("Received a call back from RMC after deleting expired %s" % resource_type)
        rmcv_copy_name = None

        for item in resource_info:
            if 'status' in item:
                if item['status'] == 'deleted':
                    rmc_copyset_id = item.get('id')
                    try:
                        rmcv_copy = self.db.get_rmcv_copy_by_rmc_copyset_id(context, rmc_copyset_id)
                        rmcv_copy_name = rmcv_copy.name
                        rmcv_copy_id = rmcv_copy.id
                        self.db.delete_rmcv_copy_by_id(context, rmcv_copy_id)
                        LOG.info("Auto deleted %s '%s' after receiving "
                                 "notification from RMC" % (resource_type, rmcv_copy_name))

                    except Exception as ex:
                        msg = "%s" % ex.message if hasattr(ex, 'message') else str(ex)
                        LOG.exception("Auto Deletion of expired %s '%s' "
                                      "record failed with error: %s" %
                                      (resource_type, rmcv_copy_name, msg))
                # if RMC sends any notification other than deleted status we will update RMC-V DB with same
                else:
                    rmc_copyset_id = item.get('id')
                    try:
                        rmcv_copy = self.db.get_rmcv_copy_by_rmc_copyset_id(context, rmc_copyset_id)
                        rmcv_copy_name = rmcv_copy.name
                        rmcv_copy_id = rmcv_copy.id
                        rmcv_copy.status = item['status']
                        self.db.update_rmcv_copy(context, rmcv_copy_id, rmcv_copy)
                        LOG.info("Auto update %s '%s' after receiving "
                                 "notification from RMC" % (resource_type, rmcv_copy_name))

                    except Exception as ex:
                        msg = "%s" % ex.message if hasattr(ex, 'message') else str(ex)
                        LOG.exception("Auto update of %s '%s' "
                                      "record failed with error: %s" %
                                      (resource_type, rmcv_copy_name, msg))

        return

    def update_copy_status(self, context, x_auth_token, copy_id):
        try:
            rmc_copy_set_id = None
            copy_type = ""
            copy_info = self.db.get_rmcv_copy_by_id(context, copy_id)
            if copy_info:
                rmc_copy_set_id = copy_info.rmc_copyset_id
                copy_type = copy_info.type
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            if rmc_copy_set_id:
                if copy_type == rmv_utils.copy_type.SNAPSHOT or copy_type == rmv_utils.copy_type.REMOTE_SNAPSHOT:
                    copy_details = rmc_wrapper_service.get_snapshot(rmc_copy_set_id)
                    copy_set = copy_details.get('snapshotSet', {})
                    if copy_set:
                        copy_info.status = copy_set.get("status", "unknown")
                else:
                    copy_details = rmc_wrapper_service.get_backup_for_backupId(context, rmc_copy_set_id)
                    copy_set = copy_details.get('backupSet')
                    if copy_set:
                        copy_info.status = copy_set.get("status", "unknown")
                self.db.update_rmcv_copy(context, copy_id, copy_info)
        except Exception as e:
            LOG.exception(e)

    def refresh(self, context, x_auth_token, task_id, request_body):
        LOG.debug("refresh : enter")

        refresh_obj = refresh(self.vi_helper)
        refresh_obj.refresh_database(context, x_auth_token, task_id, request_body)

        LOG.debug("refresh : exit")

    def rescan_hosts_and_remove_internal_snaps(self, context, mounted_hosts_list, ds_moref_list, ds_uuid_to_moref_dict,
                                               rmc_wrapper_service, is_restore_success=True):
        LOG.debug("recsan_host:Enter")
        # Some times after HBA re-scan VM connected state will be still not in intact, so retrying one more time
        rescan_success = False
        remove_internal_snap_success = False
        count = 0
        host_moref_list = []
        while count <= 1 and remove_internal_snap_success is False:
            count = count + 1

            for host_mo_ref in mounted_hosts_list:
                try:
                    host_info = self.vi_helper.GetHostSystemCompleteVer2(host_mo_ref)
                    LOG.info("HostSystemMoref: '%s' HostStorageSystemMoref: '%s'",
                             host_info.HostSystemMoref,
                             host_info.HostStorageSystemMoref)
                    self.vi_helper.rescan_all_hbas(host_info.HostStorageSystemMoref)
                    rescan_success = True
                    host_moref_list.append(host_info.HostSystemMoref)
                except Exception as e:
                    LOG.exception("Exception during hba rescan: '%s'", e)
            try:
                if rescan_success and is_restore_success:
                    if len(ds_uuid_to_moref_dict) > 0:
                        ds_moref_list = self.update_ds_moref_rmv_db_and_workflow_post_restore(context, host_moref_list,
                                                                                              ds_uuid_to_moref_dict,
                                                                                              rmc_wrapper_service)
                    LOG.info("Remove all the internal snapshots created on VMs as part of restore")
                    self.remove_internal_snapshot_on_vm_after_restore(ds_moref_list)
                    remove_internal_snap_success = True
            except rmv_exception.VmwareException as e:
                LOG.exception(e)
                if count > 1:
                    raise e
        LOG.debug("recsan_host:Exit")

    def validate_vmware_object(self,
                               context,
                               x_auth_token,
                               query_params):
        LOG.debug("validate_vmware_object : enter")

        validate_class_obj = validate_vmware_obj_class(self, vi_helper=self.vi_helper)
        validated_vmware_object = validate_class_obj.validate_vmware_object(context, x_auth_token, query_params)

        ret = rmv_utils.convert_object_to_dict_recursively(validated_vmware_object)
        LOG.debug("validate_vmware_object : exit")
        return ret

    def get_vcenter_diagnostics_url(self, context, server_uuid):
        """
        This function will generate the vCenter log bundles and return the url to download log file
        :param context:
        :param server_uuid: server uuid to collect logs
        :return: url to download vCenter log_bundle
        """
        LOG.info("get_vcenter_diagnostics_url::Enter")
        response_dict = {}
        try:
            response_dict['hypervisor_uuid'] = server_uuid
            # TODO : Need to get vi_helper object by using server_uuid, if we start multi vCenter support
            self.get_vi_helper()
            vcenter_db_obj = self.db_base.db.vcenter_configuration_get_vcenteruid(context, server_uuid)
            vCenter_host = vcenter_db_obj.host_name

            task_info = self.vi_helper.generate_vcenter_log_bundles()
            if task_info and task_info.state == rmv_utils.OPERATION_STATE_SUCCESS:
                task_result = task_info.result
                if task_result:
                    log_bundle_url = task_result[0].url
                    # url will be in the below format. we have to replace '*' with vcenter host name
                    # https://*:443/diagnostics/vcsupport-5253daa7-1c19-28a3-8f7b-ac2b39ebff25.tgz
                    log_bundle_url = log_bundle_url.replace('*', vCenter_host)
                    response_dict['log_url'] = log_bundle_url
                else:
                    msg = "no results found on generate vCenter log bundle"
                    LOG.error(msg)
                    raise rmv_exception.GeneratevCenterLogBundleException(msg=msg)

            else:
                msg = "Error on generate vcenter log bundle :" + str(task_info.error.localizedMessage)
                LOG.error(msg)
                raise rmv_exception.GeneratevCenterLogBundleException(msg=msg)

        except (rmv_exception.GeneratevCenterLogBundleException, Exception) as e:
            LOG.exception(e)
            if hasattr(e, "msg"):
                msg = e.msg
            elif hasattr(e, "message"):
                msg = e.message
            else:
                msg = "Failed to generate log bundle for vCenter server with id '%s'. Internal error." % server_uuid
            response_dict['error_message'] = msg

        LOG.info("get_vcenter_diagnostics_url::Exit")
        return response_dict

    def get_hypervisor_server_details(self,
                                      context,
                                      x_auth_token,
                                      id=None,
                                      vmbios_uuid=None):
        """
        Method to get registered ESXi/vCenter Server details.

        :param context: context
        :param x_auth_token: auth-token
        :param id: server id
        :param vmbiod_uuid: If virtual machine BIOS UUID is provided, then the Server on which the VM running will be
        returned
        :return: server detail dictionary
        """
        LOG.info("Enter: get_hypervisor_server_details ")
        LOG.debug("operation_input=%s %s", id, vmbios_uuid)
        hypervisors = {}

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            hypervisors_obj = hypervisor_manager()
            hypervisors = hypervisors_obj.get_hypervisor_server_details(context, id, vmbios_uuid)

        except Exception as e:
            LOG.exception("Exception occurred: %s", e)
            raise e
        finally:
            LOG.info("Exit: get_vmware_server_details")
            hypervisors = rmv_utils.convert_object_to_dict_recursively(hypervisors)
            return hypervisors

    def sync_rmv_server_operations(self, context, x_auth_token, request_body, action):

        LOG.info("sync_rmv_server_operations::Enter")
        response_dict = dict()

        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
            hypervisors_obj = hypervisor_manager()
            response_dict = hypervisors_obj.sync_rmv_servers(context, rmc_wrapper_service, request_body, action)
            if response_dict['statusCode'] == "success":
                LOG.info("Creating vCenter session")
                self.validate_vcenter_obj_creation(context, request_body.get('server'))
            else:
                LOG.info(response_dict)

        except Exception as e:
            LOG.exception("Exception occurred: %s", e)

        LOG.info("sync_rmv_server_operations::Exit")

        return response_dict

    def rmv_server_operations(self, context, x_auth_token, task_id, request_body, action):
        """

        :param context:
        :param x_auth_token:
        :param task_id:
        :param request_body:
        :param action:
        :return:
        """
        LOG.debug("rmv_server_operations : enter")
        server = request_body.get('server')
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)

        try:
            # If requested action is register plugin or register server with plugin
            # Need to perform below checks
            # 1. Check RMC-V plugin already registered or not
            # 2. If already registered throw an error, as we are not supporting multi vCenter now
            # 3. If no plugin is registered will validate the vCenter initialization
            # 4. Continue with Plugin operations
            # TODO : need to change the below logic in case of Multi vCenter support
            if action == rmv_utils.ACTION_REGISTER_SERVER_WITH_PLUGIN or \
                    action == rmv_utils.ACTION_REGISTER_RMCV_PLUGIN:

                vcenter_db_object = self.db.vcenter_configuration_get_first(context)
                if vcenter_db_object:
                    for vc_obj in vcenter_db_object:
                        ipHostname = vc_obj.get('host_name', None)
                        msg = 'Only one vCenter can be registered at a time with RMC-V. "\
                                                "vCenter %s is currently registered with this RMC-V.' % ipHostname
                        raise rmv_exception.RmvServerManagerException(msg)
                else:
                    # No RMC-V plugin found in the RMC
                    self.validate_vcenter_obj_creation(context, server)

            hypervisor_obj = hypervisor_manager()
            hypervisor_obj.hypervisor_operations(context, x_auth_token, task_id, request_body, action)

        except (rmv_exception.RmvServerManagerException,
                Exception) as e:

            LOG.exception(e)
            task_desc_str = "Register Server operation failed. "
            task_state = "Failed"
            task_status = "Error"
            msg = ""
            if hasattr(e, "exception_obj"):
                if hasattr(e.exception_obj, "message"):
                    msg = e.exception_obj.message
            elif hasattr(e, "msg"):
                msg = e.msg
            elif hasattr(e, "message"):
                msg = e.message
            elif hasattr(e, "get_description"):
                msg = e.get_description
            else:
                LOG.error(('%s'), e)
                msg = "Unknown error"
            LOG.error(msg)
            task_desc_str = task_desc_str + msg
            self._update_task(task_desc_str, 100, task_state, task_id, rmc_wrapper_service, task_status=task_status)

        LOG.debug("rmv_server_operations : exit")

    def catalogue_migration_callback(self, context, input_kwargs):
        LOG.info("catalogue_migration_callback : enter")

        LOG.info("Received a call back from RMC for migration")

        upgrade_obj = upgrade.Upgrade()
        task_id = upgrade_obj.catalogue_migration_callback(context, input_kwargs)

        LOG.info("catalogue_migration_callback : exit")
        return task_id

    def get_vmx_path_by_mounted_ds(self, context, ds_name, ds_moref, vm_name):
        LOG.debug("get_vmx_path_by_mounted_ds : enter")

        vmx_path = None
        try:
            vmx_path = self.get_recoverable_vm_vmx_file_path(ds_moref, ds_name, vm_name, None)

        except Exception as e:
            LOG.exception("Unable to get the VMX path of a Mounted Datastore. %s " % e)

        LOG.debug("get_vmx_path_by_mounted_ds : exit")
        return vmx_path

    def post_migration_callback(self, context, input_kwargs):
        LOG.info("post_migration_callback : enter")

        LOG.info("Received a call back from RMC for migration")

        upgrade_obj = upgrade.Upgrade()
        task_id = upgrade_obj.post_migration_callback(context, input_kwargs)

        LOG.info("post_migration_callback : exit")
        return task_id

    def get_rmc_version(self):
        LOG.debug("get_rmc_version : enter")

        rmc_version = None
        try:
            rmc_wrapper_service = rmc_wrapper.rmc_wrapper(None)
            response = rmc_wrapper_service.get_rmc_appliance_details(None)
            rmc_app_details = response.get("appliance")
            if rmc_app_details:
                registration_details = rmc_app_details.get("registrationDetails")
                if registration_details:
                    rmc_version = registration_details.get("rmcVersion")
                    rmc_version = rmc_version.split("-")[0]

        except Exception as e:
            LOG.exception("Unable to retrieve RMC version. %s " % e)

        LOG.debug("get_rmc_version : exit")
        return rmc_version

    def upgrade_rmcv_remotecopy(self, context, task_id):
        LOG.info("upgrade_rmcv_remotecopy inside manager layer: Enter")

        upgrade_obj = upgrade.Upgrade()
        upgrade_obj.upgrade_rmcv_remotecopy(context, task_id)

        LOG.info("upgrade_rmcv_remotecopy inside manager layer: Exit")

    def refresh_device_collections(self, context, task_id=None, x_auth_token=None, request_body=None,
                                   is_explicit_refresh=False):

        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        # ToDO :generating dummy client id as the method requires client_id, remove it later on
        client_id = str(uuid.uuid4())
        device_collectons_to_file = dict()
        try:
            rc_groups_obj = remotecopy_groups()
            db_obj = self.db
            rc_groups = dict()
            if is_explicit_refresh:
                task_state = 'Running'
                task_desc_string = "Fetching all device collections"
                task_percentage = 20
                task_status = "Initiated"
                self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                                  task_status=task_status)

            with rmv_locks.update_vcenter_cache:

                rc_groups = rc_groups_obj.get_all_remotecopy_groups(context, client_id, x_auth_token,
                                                                    BackupJobManager.web_client_cache,
                                                                    self.vi_helper.ip, db_obj, self.vi_helper)
                device_collectons_to_file[self.vi_helper.instance_uuid] = rc_groups
                # device_collectons_to_file['refreshType'] = "full"
                if rc_groups:
                    # If fail over is happened on any rc group , then check and update changed moref of datstore belongs to rc group
                    moref_manage_obj = moref_manage(self.vi_helper)
                    moref_manage_obj.check_and_update_mo_ref_if_changed(context, x_auth_token, rc_groups)
                    self.check_and_refresh_protection_groups(context, x_auth_token, rc_groups, rmc_wrapper_service,
                                                             rc_groups_obj)

            rmv_utils.update_to_file(device_collectons_to_file)
            if is_explicit_refresh:
                task_desc_string = 'Fetching all device collections completed'
                task_percentage = 100
                task_state = 'Completed'
                task_status = "Ok"
                self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                                  task_status=task_status)

            # make call back to cache
            rmc_wrapper_service.make_call_to_cache_to_refresh_device_collections(rmv_utils.DEVICE_COLLECTION_FILE_PATH)
        except Exception as e:
            LOG.exception(e)
            msg = 'Failed to fetch device collections'
            if hasattr(e, "msg"):
                msg = e.msg
            task_desc_string = msg
            LOG.error(task_desc_string)
            if is_explicit_refresh:
                task_percentage = 100
                task_state = "Failed"
                task_status = "Error"
                self._update_task(task_desc_string, task_percentage, task_state, task_id, rmc_wrapper_service,
                                  task_status=task_status)

    def check_and_refresh_protection_groups(self, context, x_auth_token, rc_groups, rmc_wrapper_service, rc_groups_obj):
        LOG.debug("check_and_refresh_protection_groups:Enter")

        pg_groups = self.db.get_all_protection_groups(context)
        for pg in pg_groups:
            try:
                resources = pg.resources.get('resources', [])
                capabilities = pg.capabilities
                job_type = pg.job_type
                if rmv_utils.PROTECTION_GROUP_CAPABILITY_REMOTE in capabilities and job_type == rmv_utils.PROTECTION_GROUP_JOB_TYPE_SINGLE:
                    for resource in resources:
                        device_collection_name = resource.get("device_collection_name")
                        device_identifier = resource.get("device_identifier")
                        role_in_db = resource.get("role", "")
                        response_data = rmc_wrapper_service.check_array_registration(device_identifier)
                        device_type = response_data.get("deviceType", "")
                        nimble_group = True if device_type.lower() == rmv_utils.storage_device_types.NIMBLE else False
                        device_collection = rc_groups_obj.get_rc_group_by_name(x_auth_token, device_identifier,
                                                                               device_collection_name,
                                                                               nimble_group=nimble_group)

                        device_groups = device_collection.get("remoteCopyGroups")
                        for rgroup in device_groups:
                            if not nimble_group:
                                local_grp = rgroup.get("local")
                                role_in_array = local_grp.get("role", "")
                                if role_in_db.lower() != role_in_array.lower():
                                    pg_resources_to_db = self.construct_resource_for_pg(role_in_array, resource)
                                    LOG.info("Chaning protection group :%s changed role from:%s to :%s ", pg.name,
                                             role_in_db, role_in_array)
                                    self.db.update_protection_group(context, pg.id, {"resources": pg_resources_to_db})
                            else:
                                replication_type = rgroup.get("replication_type", "")
                                schedule_list = rgroup.get("schedule_list", [])
                                if replication_type != "synchronous":
                                    for schedule in schedule_list:
                                        downstream_partner = schedule.get("downstream_partner")
                                        # if we are having the downstream partner then its a primary role for nimble, for secondary we are not having the downstream
                                        if downstream_partner:
                                            role_in_array = "primary"
                                            # if role_in_db.lower() != role_in_array.lower():
                                            pg_resources_to_db = self.construct_resource_for_pg(role_in_array, resource)
                                            LOG.info("Chaning protection group :%s changed role from:%s to :%s ",
                                                     pg.name, role_in_db, role_in_array)
                                            self.db.update_protection_group(context, pg.id,
                                                                            {"resources": pg_resources_to_db})
                                            target_pg_assoc_list = self.db.get_protection_groups_assoc_by_primary_pg_id(
                                                context, pg.id)
                                            for target_pg_assoc in target_pg_assoc_list:
                                                secondary_pg = self.db.get_protection_group(context,
                                                                                            target_pg_assoc.secondary_pg_id)
                                                secondary_pg_resources = secondary_pg.resources.get('resources', [])
                                                for sec_pg_resource in secondary_pg_resources:
                                                    role_in_array = "secondary"
                                                    pg_resources_to_db = self.construct_resource_for_pg(role_in_array,
                                                                                                        sec_pg_resource)
                                                    self.db.update_protection_group(context, secondary_pg.id,
                                                                                    {"resources": pg_resources_to_db})
                                else:
                                    LOG.info(
                                        "ToDO:we need to write seperate logic for nimble sync replication, to identify primary and secondary collections")

                            break
            except Exception as e:
                LOG.exception(e)

        LOG.debug("check_and_refresh_protection_groups:Exit")

    def construct_resource_for_pg(self, role_in_array, resource):
        LOG.debug("construct_resource_for_pg:Enter")

        pg_resources_to_db = {"resources": []}
        pg_resource = json_helper.protection_group_resource()
        pg_resource.role = role_in_array.lower()
        pg_resource.recovery_set_id = resource.get("recovery_set_id")
        pg_resource.device_identifier = resource.get("device_identifier")
        pg_resource.device_collection_name = resource.get("device_collection_name")
        pg_resource.volumes = resource.get("volumes")
        pg_resource.type = resource.get("type")
        pg_resources_to_db["resources"].append(pg_resource.__dict__)

        LOG.debug("construct_resource_for_pg:Exit")
        return pg_resources_to_db

    def clone_using_new_snapshot(self, context, vmware_db_id, x_auth_token, task_id, copy_id, request_body):
        """
          Create the clone using new snapshot
          :param context: context
          :param vmware_db_id: DB id of vmware obj
          :param x_auth_token: Auth token
          :param task_id: Task Id
          :param copy_id: rmv copy id
          :param request_body: dict containing request body
          :return:
        """

        LOG.debug(_("clone_using_new_snapshot : Enter"))
        rmc_wrapper_service = rmc_wrapper.rmc_wrapper(x_auth_token)
        object = request_body['objectId']
        object_details = object.split(":")
        vmware_object_type = object_details[0]
        vmware_object_moref = object_details[1]
        snapshot_set_id = None
        try:
            self._update_task("Creating Snapshot",
                              10,
                              'Running',
                              task_id,
                              rmc_wrapper_service,
                              task_status="Initiated")

            snapshot_info = self.create_rmv_snapshot(
                context, vmware_db_id, x_auth_token,
                task_id, copy_id, request_body)
            LOG.info('Snapshot creation details: {0}'.format(snapshot_info))

            # check for errors after snapshot creation
            task_details = rmc_wrapper_service.get_task_details(task_id)
            errors_in_snap_creation = rmv_utils.get_error_details(task_details)
            LOG.info('Error during snapshot creation: {0}'.format(errors_in_snap_creation))

            if not errors_in_snap_creation and snapshot_info:
                snapshot_set_id = snapshot_info['snapshotSetId']
                self._update_task("Snapshot Created successfully",
                                  40,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Initiated")

                host_name = request_body['parameters']['esxHostIP']
                vm_list = request_body.get('vm_list', [])
                # Add the db vm id to vm details
                for vm in vm_list:
                    vm_moref = vm['vmmoref']
                    vm_db_obj = self.db_utils.get_virtual_machine_by_moref(context, vm_moref)
                    vm['parent_vm_id'] = vm_db_obj.id
                LOG.debug('vm_list: {0}'.format(vm_list))

                register_folder = request_body.get('register_folder')
                power_on = request_body.get('power_on')

                self._update_task("Creating Clone",
                                  50,
                                  'Running',
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Initiated")

                self.register_vm_snapshot(context, x_auth_token, copy_id, vm_list,
                                          object, task_id, host_name, register_folder,
                                          power_on, vmware_db_id, None)

                # Check for error after clone creation and VM registration
                task_details = rmc_wrapper_service.get_task_details(task_id)
                errors_in_clone_creation = rmv_utils.get_error_details(task_details)
                LOG.info('Error in clone creation: {0}'.format(errors_in_clone_creation))

                if not errors_in_clone_creation:
                    self._update_task("Clone Created successfully",
                                      100,
                                      'Completed',
                                      task_id,
                                      rmc_wrapper_service,
                                      task_status="Ok")
                else:
                    error_msg = errors_in_clone_creation[0].get('errorDetails', "Failed to create Clone")
                    self._update_task("Clone operation failed. cleaning up...",
                                      90,
                                      'Failed',
                                      task_id,
                                      rmc_wrapper_service,
                                      task_status="Error")
                    self.delete_snapshot(
                        context, copy_id, vmware_object_type,
                        vmware_object_moref, x_auth_token, task_id)
                    self._update_task(error_msg,
                                      100,
                                      'Failed',
                                      task_id,
                                      rmc_wrapper_service,
                                      task_status="Error")
            else:
                error_msg = errors_in_snap_creation[0].get('errorDetails', "Failed to create Snapshot")
                self._update_task(error_msg,
                                  100,
                                  'Failed',
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Error")
        except Exception as e:
            LOG.exception("Failed to create clone from snapshot, error: {0}".format(str(e)))
            if snapshot_set_id:
                self._update_task("Clone operation failed. cleaning up...",
                                  90,
                                  'Failed',
                                  task_id,
                                  rmc_wrapper_service,
                                  task_status="Error")
                self.delete_snapshot(
                    context, copy_id, vmware_object_type,
                    vmware_object_moref, x_auth_token, task_id)

            self._update_task(str(e),
                              100,
                              'Failed',
                              task_id,
                              rmc_wrapper_service,
                              task_status="Error")

    def extract_msg_from_exception(self, e):
        if hasattr(e, "msg"):
            LOG.error(('%s'), e.msg)
            msg = e.msg
        elif hasattr(e, "message"):
            LOG.error(('%s'), e.message)
            msg = e.message
        else:
            LOG.error(('%s'), str(e))
            msg = str(e)
        return msg
