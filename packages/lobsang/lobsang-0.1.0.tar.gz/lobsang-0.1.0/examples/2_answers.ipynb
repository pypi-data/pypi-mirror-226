{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe37ead9f09988e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T00:10:08.835737811Z",
     "start_time": "2023-08-24T00:10:07.833848110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lobsang in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: openai in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (0.27.4)\r\n",
      "Requirement already satisfied: python-dotenv in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (0.21.0)\r\n",
      "Requirement already satisfied: jsonschema in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (4.17.3)\r\n",
      "Requirement already satisfied: requests>=2.20 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from openai) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from openai) (4.65.0)\r\n",
      "Requirement already satisfied: aiohttp in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from openai) (3.8.3)\r\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from jsonschema) (22.1.0)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from jsonschema) (0.18.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from aiohttp->openai) (6.0.2)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from aiohttp->openai) (1.8.1)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/simon/miniconda3/envs/lobsang/lib/python3.11/site-packages (from aiohttp->openai) (1.2.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lobsang openai python-dotenv jsonschema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0193a2a5d0737",
   "metadata": {},
   "source": [
    "# Answers\n",
    "\n",
    "Answers are an important concept for Lobsang. They are used to guide the LLM to produce answers in a specific format. For example, you can use an answer to ask the LLM to produce a JSON object. To do so, an answer generally does two things:\n",
    "\n",
    "1. It directs the LLM to produce a specific output format. For example, the `JSONAnswer` directs the LLM to produce a JSON object. It does so by adding a [JSON schema](https://json-schema.org/) as well as an example to the user message.\n",
    "2. It tried to parse the LLM output corresponding to the modified user message from step 1 to the desired format. For example, the `JSONAnswer` tries to parse the LLM output to a JSON object using the provided schema. It will also validate the output against the schema.\n",
    "\n",
    "Let's take a look at the first step. The `JSONAnswer` takes a schema and an example as arguments and embeds them into the user message:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a5f4cea9a570540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T00:10:08.845352626Z",
     "start_time": "2023-08-24T00:10:08.841167529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a marvel hero\n",
      "\n",
      "Create a JSON object with the following schema:\n",
      "```json\n",
      "{'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'The name of the hero'}, 'age': {'type': 'integer', 'minimum': 0, 'description': 'The age of the hero'}, 'powers': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The powers of the hero'}}}\n",
      "```\n",
      "\n",
      "Example:\n",
      "```json\n",
      "{'name': 'Spiderman', 'age': 18, 'powers': ['spider sense', 'web slinging', 'superhuman strength']}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from lobsang.answers import JSONAnswer\n",
    "\n",
    "# For this example, we define a JSON schema for a hero\n",
    "schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\", \"description\": \"The name of the hero\"},\n",
    "        \"age\": {\"type\": \"integer\", \"minimum\": 0, \"description\": \"The age of the hero\"},\n",
    "        \"powers\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\"type\": \"string\"},\n",
    "            \"description\": \"The powers of the hero\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# and an example according to the schema\n",
    "example = {\n",
    "    \"name\": \"Spiderman\",\n",
    "    \"age\": 18,\n",
    "    \"powers\": [\"spider sense\", \"web slinging\", \"superhuman strength\"]\n",
    "}\n",
    "\n",
    "# Create JSON answer\n",
    "hero_answer = JSONAnswer(schema=schema, example=example)\n",
    "\n",
    "# With the answer set up, we can now create the directive (i.e. the modified user message)\n",
    "original = \"Create a marvel hero\"\n",
    "#  ‚òùÔ∏è becomes üëá\n",
    "directive = hero_answer.directive(original)\n",
    "\n",
    "print(directive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4368feea73858355",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50f32ef7d17876b",
   "metadata": {},
   "source": [
    "‚òùÔ∏è As you can see the instructions are added to the user message. Note that this will not update the user message in the chat history. However, it is added as 'directive' to the `info` object of the response.\n",
    "\n",
    "üëá Alright, let's also take a look at how the `JSONAnswer` parses the LLM output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d4e80bd0eeda6fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T00:10:08.846363554Z",
     "start_time": "2023-08-24T00:10:08.844324927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Spiderman', 'age': 18, 'powers': ['spider sense', 'web slinging', 'superhuman strength']}\n"
     ]
    }
   ],
   "source": [
    "# Some response from the LLM\n",
    "response = \"\"\"\n",
    "Sure, i can create a marvel hero for you. Here is an example:\n",
    "```json\n",
    "{\n",
    "    \"name\": \"Spiderman\",\n",
    "    \"age\": 18,\n",
    "    \"powers\": [\"spider sense\", \"web slinging\", \"superhuman strength\"]\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "# Parse response\n",
    "parsed_response = hero_answer.parse(response)\n",
    "\n",
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234b243c756ace68",
   "metadata": {},
   "source": [
    "‚òùÔ∏è As you can see, the `JSONAnswer` parses the LLM output to a dict. It will also validate the output against the schema. If the LLM output is not valid JSON, the answer will raise an error. \n",
    "\n",
    "**Note:** This can be cumbersome if you want to process multiple messages. In [3_subroutines](3_subroutines.ipynb) we will see how to ignore/resolve errors on the fly (e.g. in a message chain).\n",
    "\n",
    "üëá Great! Now let's give it a try! üöÄ Make sure to update the `.env` file with your own OpenAI API key, see [1_basics](1_basics.ipynb) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63bb17548f807a12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T00:10:18.224840593Z",
     "start_time": "2023-08-24T00:10:12.137279869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set! üéâ Let's get started! üöÄ OPENAI_API_KEY={OPENAI_API_KEY[:15]}...\n",
      "USER: Create a marvel hero.\n",
      "ASSISTANT: Here is an example of a Marvel hero JSON object that follows the given schema:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"name\": \"Iron Man\",\n",
      "  \"age\": 40,\n",
      "  \"powers\": [\n",
      "    \"Powered Armor\",\n",
      "    \"Genius-level Intellect\",\n",
      "    \"Flight\",\n",
      "    \"Energy Blasts\",\n",
      "    \"Superhuman Durability\"\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON object represents a hero named \"Iron Man\" who is 40 years old and possesses powers like Powered Armor, Genius-level Intellect, Flight, Energy Blasts, and Superhuman Durability.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from lobsang import Chat, OpenAI, UserMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load OpenAI API key from .env file (please update .env file with your own API key)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY, \"Please set OPENAI_API_KEY in .env file\"\n",
    "\n",
    "print(\"All set! üéâ Let's get started! üöÄ OPENAI_API_KEY={OPENAI_API_KEY[:15]}...\", end=\"\\n\\n\")\n",
    "\n",
    "# Create a chat instance with OpenAI LLM\n",
    "llm = OpenAI(api_key=OPENAI_API_KEY)\n",
    "chat=Chat(llm=llm)\n",
    "\n",
    "# Create a conversation\n",
    "messages = [\n",
    "    UserMessage(\"Create a marvel hero.\"),\n",
    "    hero_answer\n",
    "]\n",
    "\n",
    "# Let's chat! üöÄ\n",
    "chat(messages)\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ae63ed2e0c641f",
   "metadata": {},
   "source": [
    "Ô∏èÔ∏èÔ∏è‚òùÔ∏è Please note that this may throw an error if the LLM's output does not include a JSON block with a valid JSON object. This can happen if the LLM does not produce the desired output. For example, if the LLM does not produce a syntactically valid JSON object.\n",
    "\n",
    "üëá Let's take a closer look at the response from the LLM which we can access via the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "226f8b81e51583e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-24T00:16:23.167377520Z",
     "start_time": "2023-08-24T00:16:23.072605576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data ===\n",
      "{'name': 'Iron Man', 'age': 40, 'powers': ['Powered Armor', 'Genius-level Intellect', 'Flight', 'Energy Blasts', 'Superhuman Durability']}\n",
      "=== Info ===\n",
      "{'directive': \"Create a marvel hero.\\n\\nCreate a JSON object with the following schema:\\n```json\\n{'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'The name of the hero'}, 'age': {'type': 'integer', 'minimum': 0, 'description': 'The age of the hero'}, 'powers': {'type': 'array', 'items': {'type': 'string'}, 'description': 'The powers of the hero'}}}\\n```\\n\\nExample:\\n```json\\n{'name': 'Spiderman', 'age': 18, 'powers': ['spider sense', 'web slinging', 'superhuman strength']}\\n```\"}\n"
     ]
    }
   ],
   "source": [
    "response = chat.history[-1]\n",
    "\n",
    "# print(\"=== Text ===\")\n",
    "# print(response.text)\n",
    "print(\"=== Data ===\")\n",
    "print(response.data)\n",
    "print(\"=== Info ===\")\n",
    "print(response.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951628f63f4f8564",
   "metadata": {},
   "source": [
    "Ô∏èÔ∏èÔ∏è‚òùÔ∏è Here the parsed JSON object is stored in the `data` object. The `info` object contains the modified user message (i.e. the directive) which was used to produce the response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42496dbfb5ec675",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! üéâ You just created your first chat with a `JSONAnswer`! üöÄ \n",
    "\n",
    "In this notebook, we learned how to embed a user message with a `JSONAnswer` and how to parse the LLM's response. We also learned how to create a chat with a `JSONAnswer` and how to access the original message in the chat history. \n",
    "\n",
    "**Note:** In this example we used OpenAI's LLM. However, the `JSONAnswer` can be used with any LLM. You can also adapt the instructions of a directive via the `instructions` argument. Make it sure it contains  `{message}`,  `{example}` and `{schema}` (see DEFAULT_INSTRUCTIONS in [answers/json.py](../lobsang/answers/json.py)).\n",
    "\n",
    "If you have any questions don't hesitate to reach out to us on [Discord](https://discord.gg/wMHVAaqh).\n",
    "If you've found a bug, a spelling mistake or suggestions on what could be improved, please open an issue or a pull request on [GitHub](https://github.com/cereisen/lobsang).\n",
    "\n",
    "See you in the next part! üëã We hope we got you hooked üé£ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
