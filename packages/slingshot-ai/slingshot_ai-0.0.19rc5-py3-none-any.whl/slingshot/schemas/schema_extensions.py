"""
Our autogenerated schemas aren't perfect. This file contains extensions to the autogenerated schemas for things it
doesn't handle well.
"""
from __future__ import annotations

__all__ = [
    "Response",
    "Hyperparameter",
    "RequestedRequirement",
    "RequestedAptPackage",
    "Project",
    "ProjectImpl",
    "HasRunId",
    "HasSourceCodeId",
    "HasBlobArtifactId",
    "HasExecutionEnvironmentId",
    "HasAppSpecId",
    "AppInstanceStatus",
    "JobStatus",
    "AuthTokenUnion",
    "HasExecutionEnvironmentSpecId",
    "Example",
    "Result",
    "Annotation",
    "Prediction",
    "Upsert",
    "ExampleModification",
    "Dataset",
    "LabelStudioInputData",
    "LabelStudioOutputData",
    "LabelStudioText",
    "LabelStudioFileURL",
]

import re
import uuid
from datetime import datetime
from enum import Enum
from typing import Any, Generic, Literal, Optional, Protocol, TypeAlias, TypeVar, Union

from pydantic import BaseModel, ConfigDict, Field, field_validator
from pydantic_core.core_schema import FieldValidationInfo

from .generated import schemas

Hyperparameter = dict[str, Any]

DataT = TypeVar("DataT")


class Response(BaseModel, Generic[DataT]):
    data: Optional[DataT] = None
    error: Optional[schemas.SlingshotLogicalError] = None


class RequirementsParsingError(ValueError):
    pass


class RequestedRequirement(BaseModel):
    library: str
    version: Optional[str] = None
    pin: Optional[Literal["==", "@", ">=", "<=", ">", "<", "~="]] = None

    # Pin must be present iff version is present
    @field_validator("pin")
    def pin_must_be_present_iff_version_is_present(cls, v: str | None, info: FieldValidationInfo) -> object:
        if v is None and info.data.get("version") is not None:
            raise ValueError("pin must be present if version is present")
        if v is not None and info.data.get("version") is None:
            raise ValueError("version must be present if pin is present")
        return v

    @classmethod
    def from_str(cls, line: str) -> RequestedRequirement:
        if not line:
            raise RequirementsParsingError("empty requirement")
        if line.startswith("--"):  # --index-url or --extra-index-url
            raise RequirementsParsingError(f"Unsupported requirement {line}")

        if line.startswith("-"):  # -r or -e or -c
            raise RequirementsParsingError(f"Unsupported requirement {line}")

        match = re.match(r"([^\s>=@<~]+) *(==|@|>=|<=|~=|>|<)? *(\S+)?", line)
        if match is None:
            raise RequirementsParsingError(f"Unsupported requirement {line}")
        library, pin, version = match.groups()
        try:
            return cls(library=library.strip(), version=version and version.strip(), pin=pin and pin.strip())
        except ValueError as e:
            raise RequirementsParsingError(f"Unsupported requirement {line}") from e

    def as_str(self) -> str:
        if self.pin is None or self.version is None:
            return self.library
        return f"{self.library}{self.pin}{self.version}"

    def __str__(self) -> str:
        return self.as_str()


class Project(Protocol):
    project_id: str
    display_name: str


class ProjectImpl(BaseModel):
    project_id: str
    display_name: str


class HasRunId(Protocol):
    run_id: str


class HasExecutionEnvironmentSpecId(Protocol):
    execution_environment_spec_id: str


class HasExecutionEnvironmentId(Protocol):
    execution_environment_id: str


class HasAppSpecId(Protocol):
    app_spec_id: str


class HasSourceCodeId(Protocol):
    source_code_id: str
    source_code_name: str


class HasBlobArtifactId(Protocol):
    blob_artifact_id: str
    blob_artifact_name: str


class RequestedAptPackage(BaseModel):
    name: str

    def __str__(self) -> str:
        return self.name


class AppInstanceStatus(str, Enum):
    STOPPED = "STOPPED"
    STARTING = "STARTING"
    READY = "READY"
    ERROR = "ERROR"


class JobStatus(str, Enum):
    NEW = "NEW"
    ACTIVE = "ACTIVE"
    SUCCESS = "SUCCESS"
    CANCELLING = "CANCELLING"
    CANCELLED = "CANCELLED"
    ERROR = "ERROR"


class AuthTokenUnion(BaseModel):
    token: str
    user_id: Optional[str] = None
    service_account_id: Optional[str] = None

    @classmethod
    def from_auth_token(cls, auth_token: schemas.AuthToken) -> AuthTokenUnion:
        return cls(token=auth_token.token, user_id=auth_token.user_id, service_account_id=None)

    @classmethod
    def from_service_account_token(cls, service_account_token: schemas.ServiceAccountToken) -> AuthTokenUnion:
        return cls(
            token=service_account_token.token, user_id=None, service_account_id=service_account_token.service_account_id
        )

    @property
    def is_service_account(self) -> bool:
        return self.service_account_id is not None

    @property
    def is_user(self) -> bool:
        return self.user_id is not None

    @field_validator("service_account_id")
    def validate_xor(cls, v: str | None, info: FieldValidationInfo) -> str | None:
        if v is None and info.data.get("user_id") is None:
            raise ValueError("Both service_account_id and user_id cannot be None")
        if v is not None and info.data.get("user_id") is not None:
            raise ValueError("Both service_account_id and user_id cannot be set")
        return v


# Note: these are copied from the backend schemas, but should ideally be generated from those.
# TODO: Make these into classes so we can differentiate between them in the type system. This will be used when we
#  handle signed URLs and file uploads
LabelStudioText: TypeAlias = str
LabelStudioFileURL: TypeAlias = str

# TODO: Figure out a way to use these without having to resort to type hacking
LabelStudioInputData = TypeVar("LabelStudioInputData", bound=BaseModel)
LabelStudioOutputData = TypeVar("LabelStudioOutputData", bound=BaseModel)


class Result(BaseModel):
    """
    This is the "Y", i.e. the thing you want to predict.
    """

    result_id: str = Field(
        default_factory=lambda: uuid.uuid4().hex[:8], alias="resultId"
    )  # UUID generated by the end-user
    task: Optional[str] = Field(
        None,
        description="The task, for example 'question answering'. Useful when there are multiple results for a single "
        "annotation, e.g. if a single example has multiple questions.",
    )
    task_type: Union[Literal["classification"], str] = Field(
        ...,
        alias="taskType",
        description="The task type, for example classification. This can be one of the Slingshot-defined types or "
        "something custom",
    )
    value: Any = Field(  # TODO: Temporary until we figure out how to type this while making mypy and pydantic happy
        ...,
        description="The content of the annotation result. For example, for classification, this would be a "
        "dictionary of class names to booleans",
    )

    model_config = ConfigDict(extra='allow', populate_by_name=True)


class Annotation(BaseModel):
    annotation_id: str = Field(
        default_factory=lambda: uuid.uuid4().hex[:8], alias="annotationId"
    )  # UUID generated by the end-user
    result: list[Result] = Field(..., description="The annotation result")
    created_at: Optional[datetime] = Field(
        default_factory=datetime.utcnow, alias="createdAt", description="When the annotation was created"
    )
    updated_at: Optional[datetime] = Field(
        default_factory=datetime.utcnow, alias="updatedAt", description="When the annotation was last updated"
    )
    annotator: Optional[str] = Field(None, alias="annotator", description="The ID or name of the annotator")

    model_config = ConfigDict(populate_by_name=True)


class Prediction(Annotation):
    model: Optional[str] = Field(None, alias="model", description="The ID or name of the model")

    model_config = ConfigDict(populate_by_name=True)


class Example(BaseModel):
    example_id: str = Field(
        default_factory=lambda: uuid.uuid4().hex[:8], alias="exampleId"
    )  # UUID generated by the end-user
    created_at: Optional[datetime] = Field(default_factory=datetime.utcnow, alias="createdAt")
    updated_at: Optional[datetime] = Field(default_factory=datetime.utcnow, alias="updatedAt")
    data: Any  # TODO: Temporary until we figure out how to type this while making mypy and pydantic happy
    annotations: list[Annotation] = Field(default_factory=list)
    predictions: list[Prediction] = Field(default_factory=list)

    model_config = ConfigDict(populate_by_name=True)


class ExampleModification(BaseModel):
    example_id: str = Field(..., alias="exampleId")
    modified_data: Optional[BaseModel] = Field(None, alias="modifiedData")
    new_annotations: list[Annotation] = Field(default_factory=list, alias="newAnnotations")
    new_predictions: list[Prediction] = Field(default_factory=list, alias="newPredictions")

    model_config = ConfigDict(populate_by_name=True)


class Upsert(BaseModel):
    """
    Upserts are used to update the dataset
    """

    upsert_id: Optional[str] = Field(None, alias="upsertId")  # UUID generated by the end-user
    new_examples: list[Example] = Field(default_factory=list, alias="newExamples")
    modified_examples: list[ExampleModification] = Field(default_factory=list, alias="modifiedExamples")
    updated_at: datetime = Field(
        default_factory=datetime.utcnow,
        alias="updatedAt",
        description="The time at which the upsert was created. Defaults to now.",
    )

    model_config = ConfigDict(populate_by_name=True)


class Dataset(BaseModel):
    """
    Dataset is a JSONL of examples
    """

    examples: list[Example]
