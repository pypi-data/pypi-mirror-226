# -*- coding: utf-8 -*-
from setuptools import setup

package_dir = \
{'': 'src'}

packages = \
['sych_llm_playground',
 'sych_llm_playground.providers.aws',
 'sych_llm_playground.providers.aws.utils',
 'sych_llm_playground.utils']

package_data = \
{'': ['*']}

install_requires = \
['boto3>=1.28.29,<2.0.0',
 'click>=8.0.1',
 'inquirer>=3.1.3,<4.0.0',
 'sagemaker==2.177.1']

entry_points = \
{'console_scripts': ['sych-llm-playground = sych_llm_playground.__main__:main']}

setup_kwargs = {
    'name': 'sych-llm-playground',
    'version': '0.3.0',
    'description': 'Sych LLM Playground is a command line tool deploy and interact with language models on the cloud.',
    'long_description': '# Sych LLM Playground\n\n[![PyPI](https://img.shields.io/pypi/v/sych-llm-playground.svg)][pypi_]\n[![Status](https://img.shields.io/pypi/status/sych-llm-playground.svg)][status]\n[![Python Version](https://img.shields.io/pypi/pyversions/sych-llm-playground)][python version]\n[![License](https://img.shields.io/pypi/l/sych-llm-playground)][license]\n\n[![Read the documentation at https://sych-llm-playground.readthedocs.io/](https://img.shields.io/readthedocs/sych-llm-playground/latest.svg?label=Read%20the%20Docs)][read the docs]\n[![Tests](https://github.com/sychhq/sych-llm-playground/workflows/Tests/badge.svg)][tests]\n[![Codecov](https://codecov.io/gh/sychhq/sych-llm-playground/branch/main/graph/badge.svg)][codecov]\n\n[![pre-commit](https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&logoColor=white)][pre-commit]\n[![Black](https://img.shields.io/badge/code%20style-black-000000.svg)][black]\n\n[pypi_]: https://pypi.org/project/sych-llm-playground/\n[status]: https://pypi.org/project/sych-llm-playground/\n[python version]: https://pypi.org/project/sych-llm-playground\n[read the docs]: https://sych-llm-playground.readthedocs.io/\n[tests]: https://github.com/sychhq/sych-llm-playground/actions?workflow=Tests\n[codecov]: https://app.codecov.io/gh/sychhq/sych-llm-playground\n[pre-commit]: https://github.com/pre-commit/pre-commit\n[black]: https://github.com/psf/black\n\n## Requirements\n\n- **Python Version**: 3.10 or higher. Ensure that Python is properly installed on your system.\n\n## Installation\n\nYou can install _Sych LLM Playground_ via [pip] from [PyPI]:\n\n```console\n$ pip install sych-llm-playground\n```\n\n## Usage\n\nPlease see the [Command-line Reference] for details.\n\n## Features\n\n**Sych LLM Playground** offers a streamlined experience for managing and interacting with language models in the cloud. Its capabilities include:\n\n### Configure Cloud Credentials\n\n- A guided setup to input and securely store credentials for your preferred cloud platforms.\n\n```\n> sych-llm-playground configure\n\n                 ******\n            *******  ******\n        *******          *******\n      ****,      *****       *****\n      ***    **************    ***   @@@@@@@@@                    @@@\n      ***    ***       ****    ***   @@@       @@@   @@@  @@@@@@@ @@@@@@@@\n      ***    ***       ****    ***    @@@@@@@@  @@@ @@@  @@@      @@@   @@@\n      **     *****    *****    ***  @&     @@@   @@@@@   @@@      @@@   @@@\n          **************       ***   @@@@@@@      @@@      @@@@@@ @@@   @@@\n      *******              *******               @@@\n          *******      ******\n               **********\n                   **\n\nWelcome to the Sych LLM Playground CLI.\nThis tool is part of our efforts to contribute to the open-source community.\nExplore more at https://sych.io\n\nFor detailed documentation, visit https://sych-llm-playground.readthedocs.io\n\nLet\'s begin with the configuration.\n\n[?] Please choose a provider:: AWS\n > AWS\n\nPlease Provide your AWS Access Key: xxxxxxxx\nPlease provide your AWS Secret Key: xxxxx\nPlease provide your ARN of the IAM role for SageMaker: xxxxxx\nPlease provide the AWS Region you want to deploy in [us-west-2]:\nConfiguration successful!\n\n```\n\n### Deploy Models\n\n- Easily deploy various language models to supported cloud platforms.\n\n```\n> sych-llm-playground deploy\n\n[?] Please choose a provider:: AWS\n > AWS\n\n✓ Cloud Credentials validated.\n\n✓ Cloud Credentials loaded.\n\n[?] Select a model id to deploy:: Llama-2-7b - v2.0.0\n > Llama-2-7b - v2.0.0\n   Llama-2-7b-chat - v1.1.0\n   Llama-2-13b - v2.0.0\n   Llama-2-13b-chat - v1.1.0\n   Llama-2-70b - v1.1.0\n   Llama-2-70b-chat v1.1.0\n\nDeploying... Why not grab a cup of coffee? /|\\\n\n✓ Model and Endpoint Deployed\n\nEndpoint name: sych-llm-pg-meta-textgeneration-llama-2-7b-e-1692399247\n\n✓ Created REST API\n\n✓ Fetched REST API\n\n✓ Created API resources\n\n✓ Created a POST method\n\n✓ Created API Integration with SageMaker endpoint\n\n✓ API Deployed\n\nPublic API HTTP (POST) URL: https://dhdb1mu9w1.execute-api.us-west-2.amazonaws.com/prod/predict\n\nDeployment successful!\n```\n\n### List Resources\n\n- Get an overview of all the deployed resources, including models, endpoints, and API Gateways.\n\n```\n> sych-llm-playground list\n\n[?] Please choose a provider:: AWS\n > AWS\n\n✓ Cloud Credentials validated.\n\n✓ Cloud Credentials loaded.\n\nDeployed Models:\n{\'name\': \'sych-llm-pg-meta-textgeneration-llama-2-7b-f-m-1692586488\'}\n\nDeployed Endpoints:\n{\'name\': \'sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692586488\', \'url\': \'https://runtime.sagemaker.us-west-2.amazonaws.com/endpoints/sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692586488/invocations\'}\n\nDeployed API Gateways:\n{\'name\': \'sych-llm-pg-api-sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692558825\', \'id\': \'dhdb1mu9w1\', \'method\': \'POST\', \'url\': \'https://dhdb1mu9w1.execute-api.us-west-2.amazonaws.com/prod/predict\'}\n\n```\n\n### Interact with Models\n\n- Utilize a simple interface to communicate with deployed models, sending queries and receiving responses including a chat interface with conversation history for chat models:\n\n```\n> sych-llm-playground interact\n\n[?] Please choose a provider:: AWS\n > AWS\n\n✓ Cloud Credentials validated.\n\n✓ Cloud Credentials loaded.\n\n[?] Select an endpoint to interact with:: sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692383398\n > sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692383398\n\nProvide a system instruction to guide the model\'s behavior (optional, e.g., \'Please talk in riddles.\'): Be professional\nYour desired Max new tokens? (default 256): 70\nYour desired top_p? (default 0.9):\nYour desired Temperature? (default 0.6) :\n\nType \'exit\' to end the chat.\n\nYou: Hi my name is Ryan\n\nModel:  Hello Ryan,\n\nIt\'s a pleasure to meet you. How are you today?\n\nYou: What is my name?\n\nModel:  Ryan, it\'s nice to meet you. How are you today?\n\nYou: exit\nExiting chat...\nChat ended.\n\n```\n\n- Interact via Public HTTP API\n\n```\ncurl -X POST \\\n    -H \'Content-Type: application/json\' \\\n    -H \'custom_attributes: accept_eula=true\' \\\n    -d \'{"inputs": [[{"role": "system", "content": "Talk profession"}, {"role": "user", "content": "Hi my name is Ryan"}]], "parameters": {"max_new_tokens": 256, "top_p": 0.9, "temperature": 0.6}}\' \\\n    \'https://valauuhvic.execute-api.us-west-2.amazonaws.com/prod/predict\'\n\n[\n  {\n    "generation":{\n      "role":"assistant",\n      "content":" Hello Ryan, it\'s a pleasure to meet you. How may I assist you today? Is there something specific you need help with or would you like to discuss a particular topic? I\'m here to listen and provide guidance to the best of my abilities. Please feel free to ask me anything."\n    }\n  }\n]%\n\n```\n\n### Cleanup Resources\n\n- Safely remove deployed models, endpoints and API Gateways to manage costs and maintain a clean environment.\n\n```\n> sych-llm-playground cleanup\n\n[?] Please choose a provider:: AWS\n > AWS\n\n✓ Cloud Credentials validated.\n\n✓ Cloud Credentials loaded.\n\n[?] What would you like to cleanup?: Endpoint\n  Model\n> Endpoint\n  API Gateway\n\n[?] Select a endpoint to cleanup:: sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692383398\n > sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692383398\n\nEndpoint sych-llm-pg-meta-textgeneration-llama-2-7b-f-e-1692383398 cleaned up successfully.\n\n```\n\n## Coming Soon\n\n- **Fine-tuning via CLI**: Direct fine-tuning of models using the CLI will be available soon.\n\n- **Interaction via GUI**: Playround will soon support interaction via a graphical user interface.\n\n- **Local Playground** Downloading and interacting selected models will soon be available.\n\n## Supported Models\n\n**Sych LLM Playground** currently supports the following language models, with more to be added soon:\n\n### Llama Models\n\n- **Llama-2-7b**: Version 2.0.0\n- **Llama-2-7b-chat**: Version 1.1.0\n- **Llama-2-13b**: Version 2.0.0\n- **Llama-2-13b-chat**: Version 1.1.0\n- **Llama-2-70b**: Version 1.1.0\n- **Llama-2-70b-chat**: Version 1.1.0\n\nStay tuned for updates as we expand support to include additional language models.\n\n## Supported Cloud Platforms\n\nPlayground currently supports the following platforms:\n\n### [Amazon Web Services (AWS) SageMaker](https://aws.amazon.com)\n\nAmazon SageMaker is a managed service that provides developers and data scientists with the ability to build, train, and deploy machine learning (ML) models quickly and easily. Here are some key concepts to understand:\n\n- **Model**: A trained machine learning model that can be deployed to an endpoint for making predictions.\n- **Endpoint**: A hosted deployment of your model, facilitating real-time predictions.\n- **API Gateway**: A gateway that allows you to call your endpoints. In the context of this tool, it enables interaction with models via a publicly accessible HTTP URL. This tool automatically creates a publicly available POST API endpoint upon successful deployment.\n\nThe naming conventions for Models, Endpoints, and API Gateways deployed by this Playground follow these formats:\n\n- Model: `"sych-llm-pg-{model_id}-m-{timestamp}"`\n- Endpoint: `sych-llm-pg-{model_id}-e-{timestamp}`\n- API Gateway: `"sych-llm-pg-api-{endpoint_name}"`\n\nThe timestamp in the naming convention helps in matching endpoints with their corresponding models, especially when two or more models exist with the same ID.\n\n#### AWS SageMaker Instance Types and Cloud Costs\n\nAWS SageMaker allows running models on specific hardware instance types, such as `ml.g5.2xlarge`. It\'s essential to be aware of the associated costs and quotas:\n\n- It is common to have an applied default quota value of 0 for specific instance types on AWS.\n\n- To enable them, you need to:\n\n  1. Go to your AWS Console > Service Quotas.\n  2. Navigate to AWS Services -> Amazon SageMaker -> Apply Quotas for specific instance types.\n  3. Apply for the required quota. Please note, it can sometimes take over 1 day to get a quota approved.\n\n- [Here\'s a link](https://docs.aws.amazon.com/sagemaker/latest/dg/instance-types-az.html) to search for specific instance types used by a model, which you can apply quotas for. If you can\'t find the instance type for your model, and do not have a quota assigned, the CLI will display an error message with the exact instance type that needs an assigned quota value.\n\n- For more information about the costs associated with SageMaker and the specific instance types, you can refer to the [AWS SageMaker Pricing Page](https://aws.amazon.com/sagemaker/pricing/).\n\n#### Requirements\n\n##### 1. **Register for an AWS Account**\n\nIf you don\'t have one already, you can create an AWS account [here](https://aws.amazon.com).\n\n##### 2. **Create an IAM Role for SageMaker and API Gateway**\n\nFollow these steps to set up the role:\n\na. **Create a New IAM Role**: Navigate to IAM in the AWS Console, and create a new role.\n\nb. **Add Trust Policy**: Use the following custom trust policy to allow SageMaker and API Gateway to assume this role:\n\n```json\n{\n  "Version": "2012-10-17",\n  "Statement": [\n    {\n      "Effect": "Allow",\n      "Principal": {\n        "Service": ["sagemaker.amazonaws.com", "apigateway.amazonaws.com"]\n      },\n      "Action": "sts:AssumeRole"\n    }\n  ]\n}\n```\n\nc. **Attach Permission Policy**: Under the newly created role, attach the `AmazonSageMakerFullAccess` managed policy.\n\n##### 3. **Create an IAM User with Necessary Permissions**\n\nHere\'s how to create the user:\n\na. **Create IAM User**: In the IAM section of the AWS Console, create a new user.\n\nb. **Attach Managed Policies**: Attach the `AmazonSageMakerFullAccess` and `AmazonAPIGatewayAdministrator` managed policies to the user.\n\nc. **Add Custom Inline Policy**: Add the following custom inline policy, replacing `YOUR_IAM_ROLE_ARN` with the ARN of the IAM role you created earlier:\n\n```json\n{\n  "Version": "2012-10-17",\n  "Statement": [\n    {\n      "Effect": "Allow",\n      "Action": "iam:PassRole",\n      "Resource": "YOUR_IAM_ROLE_ARN"\n    }\n  ]\n}\n```\n\nd. **Create an Access Key**: In the user\'s security credentials tab, create a new access key. Be sure to store the generated Access Key ID and Secret Access Key in a safe place.\n\n##### 4. **Configure the CLI**\n\nUse the Access Key ID, Secret Access Key and your IAM role ARN to configure the CLI as shown in the examples above.\n\n### Other Cloud Providers\n\nOther popular cloud platforms are on our roadmap and will be supported soon. Stay tuned for updates, and don\'t hesitate to contribute or request support for your preferred platforms.\n\n## Contributing\n\nContributions are very welcome.\nTo learn more, see the [Contributor Guide].\n\n## License\n\nDistributed under the terms of the [Apache 2.0 license][license],\n_Sych LLM Playground_ is free and open source software.\n\n## Issues\n\nIf you encounter any problems,\nplease [file an issue] along with a detailed description.\n\n[pypi]: https://pypi.org/\n[file an issue]: https://github.com/sychhq/sych-llm-playground/issues\n[pip]: https://pip.pypa.io/\n\n<!-- github-only -->\n\n[license]: https://github.com/sychhq/sych-llm-playground/blob/main/LICENSE\n[contributor guide]: https://github.com/sychhq/sych-llm-playground/blob/main/CONTRIBUTING.md\n[command-line reference]: https://sych-llm-playground.readthedocs.io/en/latest/usage.html\n',
    'author': 'Sych Inc.',
    'author_email': 'dev@sych.io',
    'maintainer': None,
    'maintainer_email': None,
    'url': 'https://github.com/sychhq/sych-llm-playground',
    'package_dir': package_dir,
    'packages': packages,
    'package_data': package_data,
    'install_requires': install_requires,
    'entry_points': entry_points,
    'python_requires': '>=3.10,<4.0',
}


setup(**setup_kwargs)
